{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 02: Data Collection with yfinance\n",
    "\n",
    "**Difficulty**: ‚≠ê (Beginner)\n",
    "\n",
    "**Estimated Time**: 60 minutes\n",
    "\n",
    "**Prerequisites**: \n",
    "- Completed Module 00: Setup and Introduction\n",
    "- Completed Module 01: Bursa Malaysia Fundamentals\n",
    "- Understanding of pandas DataFrames\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Download stock data at different intervals (daily, weekly, monthly, intraday)\n",
    "2. Efficiently download multiple stocks simultaneously\n",
    "3. Handle missing data and data quality issues\n",
    "4. Save and load stock data locally for offline analysis\n",
    "5. Build a watchlist database for your favorite Malaysian stocks\n",
    "6. Retrieve company information and fundamental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Why Data Quality Matters\n",
    "\n",
    "**\"Garbage in, garbage out\"** - This famous programming principle is especially true in stock analysis.\n",
    "\n",
    "### The Foundation of Technical Analysis\n",
    "\n",
    "Every trading decision, indicator calculation, and backtest depends on **quality data**. Poor data leads to:\n",
    "- ‚ùå Incorrect indicator signals\n",
    "- ‚ùå False trading opportunities\n",
    "- ‚ùå Misleading backtest results\n",
    "- ‚ùå Potential losses in real trading\n",
    "\n",
    "### What You'll Master\n",
    "\n",
    "By the end of this module, you'll have a robust data collection system that:\n",
    "- ‚úÖ Downloads clean, validated data\n",
    "- ‚úÖ Handles errors gracefully\n",
    "- ‚úÖ Stores data efficiently for offline use\n",
    "- ‚úÖ Scales to analyze hundreds of stocks\n",
    "\n",
    "Let's build your data infrastructure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")\n",
    "print(f\"Today's date: {datetime.now().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Data Intervals\n",
    "\n",
    "yfinance supports multiple time intervals for different trading strategies:\n",
    "\n",
    "### Available Intervals\n",
    "\n",
    "| Interval | Use Case | Max History | Best For |\n",
    "|----------|----------|-------------|----------|\n",
    "| **1m** | 1 minute | 7 days | Day trading, scalping |\n",
    "| **5m** | 5 minutes | 60 days | Day trading |\n",
    "| **15m** | 15 minutes | 60 days | Intraday swing trading |\n",
    "| **1h** | 1 hour | 730 days | Short-term analysis |\n",
    "| **1d** | 1 day | All history | Swing trading, position trading |\n",
    "| **1wk** | 1 week | All history | Long-term trends |\n",
    "| **1mo** | 1 month | All history | Very long-term analysis |\n",
    "\n",
    "### Choosing the Right Interval\n",
    "\n",
    "- **Beginners**: Start with **daily (1d)** data - easier to analyze, less noise\n",
    "- **Swing Traders**: Daily and weekly data\n",
    "- **Day Traders**: 1m, 5m, or 15m data (requires full-time attention)\n",
    "- **Long-term Investors**: Weekly or monthly data for big picture\n",
    "\n",
    "Let's download data at different intervals!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Maybank data at different intervals\n",
    "ticker = '1155.KL'\n",
    "\n",
    "# Define date ranges\n",
    "end_date = datetime.now()\n",
    "start_date_daily = end_date - timedelta(days=365)  # 1 year for daily\n",
    "start_date_intraday = end_date - timedelta(days=7)  # 7 days for intraday\n",
    "\n",
    "print(f\"Downloading {ticker} (Maybank) at different intervals...\\n\")\n",
    "\n",
    "# Daily data\n",
    "daily_data = yf.download(ticker, start=start_date_daily, end=end_date, \n",
    "                         interval='1d', progress=False)\n",
    "print(f\"‚úÖ Daily data:   {len(daily_data)} rows\")\n",
    "\n",
    "# Weekly data\n",
    "weekly_data = yf.download(ticker, start=start_date_daily, end=end_date, \n",
    "                          interval='1wk', progress=False)\n",
    "print(f\"‚úÖ Weekly data:  {len(weekly_data)} rows\")\n",
    "\n",
    "# Hourly data (last 60 days)\n",
    "start_date_hourly = end_date - timedelta(days=60)\n",
    "hourly_data = yf.download(ticker, start=start_date_hourly, end=end_date, \n",
    "                          interval='1h', progress=False)\n",
    "print(f\"‚úÖ Hourly data:  {len(hourly_data)} rows\")\n",
    "\n",
    "# 5-minute data (last 7 days)\n",
    "minute_5_data = yf.download(ticker, start=start_date_intraday, end=end_date, \n",
    "                            interval='5m', progress=False)\n",
    "print(f\"‚úÖ 5-min data:   {len(minute_5_data)} rows\")\n",
    "\n",
    "print(\"\\nüìä Notice how row count varies by interval!\")\n",
    "print(\"More granular intervals = more data points but shorter history.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the same stock at different intervals\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Maybank (1155.KL) at Different Time Intervals', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# Daily chart\n",
    "axes[0, 0].plot(daily_data.index, daily_data['Adj Close'], linewidth=1.5)\n",
    "axes[0, 0].set_title('Daily Data (1 Year)', fontsize=12)\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Price (RM)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Weekly chart\n",
    "axes[0, 1].plot(weekly_data.index, weekly_data['Adj Close'], \n",
    "                linewidth=2, color='orange')\n",
    "axes[0, 1].set_title('Weekly Data (1 Year)', fontsize=12)\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Price (RM)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Hourly chart\n",
    "if len(hourly_data) > 0:\n",
    "    axes[1, 0].plot(hourly_data.index, hourly_data['Adj Close'], \n",
    "                    linewidth=1, color='green')\n",
    "    axes[1, 0].set_title('Hourly Data (60 Days)', fontsize=12)\n",
    "    axes[1, 0].set_xlabel('Date')\n",
    "    axes[1, 0].set_ylabel('Price (RM)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 5-minute chart\n",
    "if len(minute_5_data) > 0:\n",
    "    axes[1, 1].plot(minute_5_data.index, minute_5_data['Adj Close'], \n",
    "                    linewidth=0.5, color='red', alpha=0.7)\n",
    "    axes[1, 1].set_title('5-Minute Data (7 Days)', fontsize=12)\n",
    "    axes[1, 1].set_xlabel('Date')\n",
    "    axes[1, 1].set_ylabel('Price (RM)')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Observations:\")\n",
    "print(\"‚Ä¢ Daily/weekly = smooth trends, clear patterns\")\n",
    "print(\"‚Ä¢ Hourly/5-min = more noise, harder to analyze\")\n",
    "print(\"‚Ä¢ For learning: START with daily data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Downloading Multiple Stocks Efficiently\n",
    "\n",
    "Analyzing one stock is good, but comparing multiple stocks is better! Let's download several Malaysian blue-chips at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a watchlist of top Malaysian stocks\n",
    "watchlist = {\n",
    "    'Maybank': '1155.KL',\n",
    "    'Public Bank': '1295.KL',\n",
    "    'CIMB': '1023.KL',\n",
    "    'Sime Darby Plantation': '5285.KL',\n",
    "    'Gamuda': '5398.KL',\n",
    "    'Nestle Malaysia': '4707.KL',\n",
    "    'Sunway': '5211.KL',\n",
    "    'Tenaga Nasional': '5347.KL'\n",
    "}\n",
    "\n",
    "print(\"Your Watchlist:\")\n",
    "print(\"=\" * 50)\n",
    "for name, ticker in watchlist.items():\n",
    "    print(f\"{name:25s} : {ticker}\")\n",
    "\n",
    "print(f\"\\nüìä Total stocks: {len(watchlist)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Download all tickers at once (fastest)\n",
    "# yfinance can download multiple tickers in a single call\n",
    "\n",
    "ticker_list = list(watchlist.values())\n",
    "print(f\"Downloading {len(ticker_list)} stocks...\\n\")\n",
    "\n",
    "# Download all at once\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "all_data = yf.download(ticker_list, start=start_date, end=end_date, \n",
    "                       progress=True, group_by='ticker')\n",
    "\n",
    "print(f\"\\n‚úÖ Downloaded {len(all_data)} days of data for {len(ticker_list)} stocks\")\n",
    "print(f\"Data shape: {all_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract closing prices for all stocks\n",
    "# This creates a DataFrame with one column per stock\n",
    "\n",
    "closing_prices = pd.DataFrame()\n",
    "\n",
    "for name, ticker in watchlist.items():\n",
    "    if ticker in all_data:\n",
    "        # Extract Adj Close column for this ticker\n",
    "        closing_prices[name] = all_data[ticker]['Adj Close']\n",
    "\n",
    "# Display first few rows\n",
    "print(\"Closing Prices DataFrame:\")\n",
    "print(closing_prices.head())\n",
    "\n",
    "print(f\"\\nShape: {closing_prices.shape}\")\n",
    "print(f\"Columns: {closing_prices.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all stocks on one chart\n",
    "# Normalize to 100 at start for fair comparison\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Normalize each stock to 100 at start\n",
    "normalized_prices = (closing_prices / closing_prices.iloc[0]) * 100\n",
    "\n",
    "# Plot each stock\n",
    "for column in normalized_prices.columns:\n",
    "    plt.plot(normalized_prices.index, normalized_prices[column], \n",
    "             linewidth=2, label=column, alpha=0.8)\n",
    "\n",
    "plt.axhline(y=100, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.title('Malaysian Blue-Chip Performance Comparison (2023-2024)\\nNormalized to 100', \n",
    "         fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Normalized Price (Start = 100)', fontsize=12)\n",
    "plt.legend(loc='best', fontsize=9, ncol=2)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° This chart shows relative performance - which stocks outperformed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics for all stocks\n",
    "performance_summary = pd.DataFrame()\n",
    "\n",
    "for name in closing_prices.columns:\n",
    "    prices = closing_prices[name].dropna()\n",
    "    \n",
    "    if len(prices) > 0:\n",
    "        start_price = prices.iloc[0]\n",
    "        end_price = prices.iloc[-1]\n",
    "        total_return = ((end_price - start_price) / start_price) * 100\n",
    "        \n",
    "        # Calculate volatility (standard deviation of daily returns)\n",
    "        daily_returns = prices.pct_change().dropna()\n",
    "        volatility = daily_returns.std() * np.sqrt(252) * 100  # Annualized\n",
    "        \n",
    "        performance_summary = pd.concat([performance_summary, pd.DataFrame({\n",
    "            'Stock': [name],\n",
    "            'Start Price': [f\"RM{start_price:.2f}\"],\n",
    "            'End Price': [f\"RM{end_price:.2f}\"],\n",
    "            'Total Return': [f\"{total_return:.2f}%\"],\n",
    "            'Volatility': [f\"{volatility:.2f}%\"]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "# Sort by total return\n",
    "performance_summary = performance_summary.sort_values('Total Return', \n",
    "                                                      ascending=False, \n",
    "                                                      key=lambda x: x.str.rstrip('%').astype(float))\n",
    "\n",
    "print(\"\\nPerformance Summary (2023-2024):\")\n",
    "print(\"=\" * 80)\n",
    "print(performance_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\nüí° Higher return often comes with higher volatility (risk)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handling Missing Data and Data Quality\n",
    "\n",
    "Real-world data is messy. Let's learn to handle common issues:\n",
    "\n",
    "### Common Data Issues\n",
    "\n",
    "1. **Missing dates**: Market holidays, trading halts\n",
    "2. **Zero volume**: Corporate actions, data errors\n",
    "3. **Price gaps**: News events, earnings announcements\n",
    "4. **Outliers**: Fat-finger errors, flash crashes\n",
    "\n",
    "### Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to validate stock data quality\n",
    "\n",
    "def validate_stock_data(data, ticker_name):\n",
    "    \"\"\"\n",
    "    Perform comprehensive data quality checks.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): Stock data from yfinance\n",
    "        ticker_name (str): Name/ticker for reporting\n",
    "    \n",
    "    Returns:\n",
    "        dict: Quality report\n",
    "    \"\"\"\n",
    "    print(f\"\\nData Quality Report: {ticker_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check 1: Missing values\n",
    "    missing_values = data.isnull().sum()\n",
    "    print(f\"\\n1. Missing Values:\")\n",
    "    print(missing_values)\n",
    "    \n",
    "    # Check 2: Zero volume days\n",
    "    zero_volume_days = (data['Volume'] == 0).sum()\n",
    "    print(f\"\\n2. Zero Volume Days: {zero_volume_days}\")\n",
    "    \n",
    "    # Check 3: Price consistency (High >= Low)\n",
    "    price_inconsistencies = (data['High'] < data['Low']).sum()\n",
    "    print(f\"\\n3. Price Inconsistencies (High < Low): {price_inconsistencies}\")\n",
    "    \n",
    "    # Check 4: Extreme price changes (>20% in one day)\n",
    "    daily_returns = data['Adj Close'].pct_change()\n",
    "    extreme_moves = (abs(daily_returns) > 0.20).sum()\n",
    "    print(f\"\\n4. Extreme Price Moves (>20% daily): {extreme_moves}\")\n",
    "    \n",
    "    if extreme_moves > 0:\n",
    "        print(\"   Dates with extreme moves:\")\n",
    "        extreme_dates = data[abs(daily_returns) > 0.20].index\n",
    "        for date in extreme_dates:\n",
    "            ret = daily_returns.loc[date]\n",
    "            print(f\"   - {date.strftime('%Y-%m-%d')}: {ret*100:+.2f}%\")\n",
    "    \n",
    "    # Check 5: Data completeness\n",
    "    total_days = (data.index[-1] - data.index[0]).days\n",
    "    trading_days_expected = total_days / 7 * 5  # Rough estimate\n",
    "    completeness = (len(data) / trading_days_expected) * 100\n",
    "    print(f\"\\n5. Data Completeness: ~{completeness:.1f}%\")\n",
    "    print(f\"   ({len(data)} rows over {total_days} calendar days)\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    issues = missing_values.sum() + zero_volume_days + price_inconsistencies\n",
    "    \n",
    "    if issues == 0 and completeness > 90:\n",
    "        print(\"\\n‚úÖ Overall: Data quality is EXCELLENT\")\n",
    "    elif issues < 10 and completeness > 85:\n",
    "        print(\"\\n‚ö†Ô∏è  Overall: Data quality is GOOD (minor issues)\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Overall: Data quality needs attention\")\n",
    "    \n",
    "    return {\n",
    "        'missing_values': missing_values.sum(),\n",
    "        'zero_volume_days': zero_volume_days,\n",
    "        'price_inconsistencies': price_inconsistencies,\n",
    "        'extreme_moves': extreme_moves,\n",
    "        'completeness': completeness\n",
    "    }\n",
    "\n",
    "# Test with Maybank data\n",
    "quality_report = validate_stock_data(daily_data, 'Maybank (1155.KL)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing data - forward fill method\n",
    "# This is appropriate for stock prices (carry forward last known price)\n",
    "\n",
    "def clean_stock_data(data):\n",
    "    \"\"\"\n",
    "    Clean stock data by handling missing values.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): Raw stock data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Cleaned data\n",
    "    \"\"\"\n",
    "    cleaned = data.copy()\n",
    "    \n",
    "    # Forward fill price data (use last known price)\n",
    "    price_columns = ['Open', 'High', 'Low', 'Close', 'Adj Close']\n",
    "    cleaned[price_columns] = cleaned[price_columns].fillna(method='ffill')\n",
    "    \n",
    "    # Fill volume with 0 (if no trading occurred)\n",
    "    cleaned['Volume'] = cleaned['Volume'].fillna(0)\n",
    "    \n",
    "    # Drop any remaining rows with missing values\n",
    "    cleaned = cleaned.dropna()\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "# Clean the data\n",
    "cleaned_daily_data = clean_stock_data(daily_data)\n",
    "\n",
    "print(f\"Original data: {len(daily_data)} rows\")\n",
    "print(f\"Cleaned data:  {len(cleaned_daily_data)} rows\")\n",
    "print(f\"Rows removed:  {len(daily_data) - len(cleaned_daily_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Saving and Loading Data Locally\n",
    "\n",
    "**Why save data locally?**\n",
    "\n",
    "1. **Faster analysis**: No need to re-download every time\n",
    "2. **Offline work**: Analyze without internet connection\n",
    "3. **Consistent data**: Same data for backtesting\n",
    "4. **API limits**: Avoid hitting rate limits\n",
    "\n",
    "We'll use the `../data/` directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory structure if it doesn't exist\n",
    "data_dir = Path('../data')\n",
    "raw_dir = data_dir / 'raw'\n",
    "processed_dir = data_dir / 'processed'\n",
    "sample_dir = data_dir / 'sample'\n",
    "\n",
    "# Create directories\n",
    "for directory in [raw_dir, processed_dir, sample_dir]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úÖ Directory ready: {directory}\")\n",
    "\n",
    "print(\"\\nüìÅ Data directory structure created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save stock data\n",
    "\n",
    "def save_stock_data(data, ticker, data_type='raw'):\n",
    "    \"\"\"\n",
    "    Save stock data to CSV file.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): Stock data to save\n",
    "        ticker (str): Stock ticker symbol\n",
    "        data_type (str): 'raw', 'processed', or 'sample'\n",
    "    \n",
    "    Returns:\n",
    "        Path: File path where data was saved\n",
    "    \"\"\"\n",
    "    # Determine directory based on data type\n",
    "    if data_type == 'raw':\n",
    "        directory = raw_dir\n",
    "    elif data_type == 'processed':\n",
    "        directory = processed_dir\n",
    "    else:\n",
    "        directory = sample_dir\n",
    "    \n",
    "    # Clean ticker for filename (remove .KL suffix)\n",
    "    clean_ticker = ticker.replace('.KL', '')\n",
    "    \n",
    "    # Create filename with date\n",
    "    date_str = datetime.now().strftime('%Y%m%d')\n",
    "    filename = f\"{clean_ticker}_{data_type}_{date_str}.csv\"\n",
    "    filepath = directory / filename\n",
    "    \n",
    "    # Save to CSV\n",
    "    data.to_csv(filepath)\n",
    "    \n",
    "    print(f\"‚úÖ Saved: {filepath}\")\n",
    "    print(f\"   Size: {filepath.stat().st_size / 1024:.2f} KB\")\n",
    "    print(f\"   Rows: {len(data)}\")\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "# Save Maybank data\n",
    "saved_file = save_stock_data(cleaned_daily_data, '1155.KL', data_type='processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load stock data\n",
    "\n",
    "def load_stock_data(ticker, data_type='processed'):\n",
    "    \"\"\"\n",
    "    Load stock data from CSV file (most recent).\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol\n",
    "        data_type (str): 'raw', 'processed', or 'sample'\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Loaded stock data\n",
    "    \"\"\"\n",
    "    # Determine directory\n",
    "    if data_type == 'raw':\n",
    "        directory = raw_dir\n",
    "    elif data_type == 'processed':\n",
    "        directory = processed_dir\n",
    "    else:\n",
    "        directory = sample_dir\n",
    "    \n",
    "    # Clean ticker\n",
    "    clean_ticker = ticker.replace('.KL', '')\n",
    "    \n",
    "    # Find matching files (use most recent)\n",
    "    pattern = f\"{clean_ticker}_{data_type}_*.csv\"\n",
    "    matching_files = sorted(directory.glob(pattern))\n",
    "    \n",
    "    if not matching_files:\n",
    "        raise FileNotFoundError(f\"No data files found for {ticker} in {directory}\")\n",
    "    \n",
    "    # Load most recent file\n",
    "    latest_file = matching_files[-1]\n",
    "    data = pd.read_csv(latest_file, index_col=0, parse_dates=True)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded: {latest_file.name}\")\n",
    "    print(f\"   Rows: {len(data)}\")\n",
    "    print(f\"   Date range: {data.index[0].strftime('%Y-%m-%d')} to {data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Test loading\n",
    "loaded_data = load_stock_data('1155.KL', data_type='processed')\n",
    "\n",
    "# Verify it matches original\n",
    "print(f\"\\n‚úÖ Data loaded successfully!\")\n",
    "print(f\"First row matches: {loaded_data.iloc[0]['Close'] == cleaned_daily_data.iloc[0]['Close']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retrieving Company Information\n",
    "\n",
    "yfinance provides more than just price data - you can also get company fundamentals!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive company information\n",
    "ticker = yf.Ticker('1155.KL')\n",
    "\n",
    "# Company info (dictionary)\n",
    "info = ticker.info\n",
    "\n",
    "print(\"Maybank Company Information:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display key information\n",
    "key_fields = [\n",
    "    'longName', 'symbol', 'sector', 'industry', 'country',\n",
    "    'marketCap', 'previousClose', 'open', 'volume',\n",
    "    'dividendYield', 'trailingPE', 'forwardPE'\n",
    "]\n",
    "\n",
    "for field in key_fields:\n",
    "    if field in info:\n",
    "        value = info[field]\n",
    "        \n",
    "        # Format based on field type\n",
    "        if field == 'marketCap':\n",
    "            value = f\"RM {value:,.0f}\"\n",
    "        elif field == 'dividendYield' and value:\n",
    "            value = f\"{value*100:.2f}%\"\n",
    "        elif field in ['previousClose', 'open']:\n",
    "            value = f\"RM {value:.2f}\"\n",
    "        elif field == 'volume':\n",
    "            value = f\"{value:,}\"\n",
    "        \n",
    "        print(f\"{field:20s}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get financial statements (if available)\n",
    "# Note: Coverage may be limited for some Malaysian stocks\n",
    "\n",
    "print(\"\\nAttempting to retrieve financial data...\\n\")\n",
    "\n",
    "# Balance Sheet\n",
    "try:\n",
    "    balance_sheet = ticker.balance_sheet\n",
    "    if not balance_sheet.empty:\n",
    "        print(\"‚úÖ Balance Sheet available\")\n",
    "        print(f\"   Columns: {len(balance_sheet.columns)}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Balance Sheet: Limited data\")\n",
    "except:\n",
    "    print(\"‚ùå Balance Sheet: Not available\")\n",
    "\n",
    "# Income Statement\n",
    "try:\n",
    "    income_stmt = ticker.income_stmt\n",
    "    if not income_stmt.empty:\n",
    "        print(\"‚úÖ Income Statement available\")\n",
    "        print(f\"   Columns: {len(income_stmt.columns)}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Income Statement: Limited data\")\n",
    "except:\n",
    "    print(\"‚ùå Income Statement: Not available\")\n",
    "\n",
    "# Cash Flow\n",
    "try:\n",
    "    cash_flow = ticker.cashflow\n",
    "    if not cash_flow.empty:\n",
    "        print(\"‚úÖ Cash Flow available\")\n",
    "        print(f\"   Columns: {len(cash_flow.columns)}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Cash Flow: Limited data\")\n",
    "except:\n",
    "    print(\"‚ùå Cash Flow: Not available\")\n",
    "\n",
    "print(\"\\nüí° Note: Fundamental data coverage varies by stock.\")\n",
    "print(\"   For detailed financials, check Bursa Malaysia announcements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building a Watchlist Database\n",
    "\n",
    "Let's create a system to manage and update a watchlist of stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete watchlist management system\n",
    "\n",
    "class MalaysianStockWatchlist:\n",
    "    \"\"\"\n",
    "    Manage a watchlist of Malaysian stocks with automatic data updates.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name='My Watchlist'):\n",
    "        self.name = name\n",
    "        self.stocks = {}\n",
    "        self.data_cache = {}\n",
    "    \n",
    "    def add_stock(self, name, ticker, sector='Other'):\n",
    "        \"\"\"Add a stock to the watchlist.\"\"\"\n",
    "        self.stocks[ticker] = {\n",
    "            'name': name,\n",
    "            'sector': sector,\n",
    "            'added_date': datetime.now()\n",
    "        }\n",
    "        print(f\"‚úÖ Added: {name} ({ticker}) - {sector}\")\n",
    "    \n",
    "    def remove_stock(self, ticker):\n",
    "        \"\"\"Remove a stock from the watchlist.\"\"\"\n",
    "        if ticker in self.stocks:\n",
    "            name = self.stocks[ticker]['name']\n",
    "            del self.stocks[ticker]\n",
    "            print(f\"‚ùå Removed: {name} ({ticker})\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  {ticker} not in watchlist\")\n",
    "    \n",
    "    def update_all_data(self, days=365):\n",
    "        \"\"\"Download latest data for all stocks in watchlist.\"\"\"\n",
    "        print(f\"\\nUpdating data for {len(self.stocks)} stocks...\\n\")\n",
    "        \n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=days)\n",
    "        \n",
    "        for ticker in self.stocks:\n",
    "            try:\n",
    "                data = yf.download(ticker, start=start_date, end=end_date, \n",
    "                                  progress=False)\n",
    "                self.data_cache[ticker] = data\n",
    "                print(f\"‚úÖ {ticker}: {len(data)} rows\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå {ticker}: Error - {str(e)}\")\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Get summary of all stocks in watchlist.\"\"\"\n",
    "        print(f\"\\n{self.name}\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'Ticker':<12} {'Name':<25} {'Sector':<15} {'Status'}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for ticker, info in self.stocks.items():\n",
    "            status = '‚úÖ Data' if ticker in self.data_cache else '‚ö†Ô∏è  No data'\n",
    "            print(f\"{ticker:<12} {info['name']:<25} {info['sector']:<15} {status}\")\n",
    "        \n",
    "        print(f\"\\nTotal stocks: {len(self.stocks)}\")\n",
    "        print(f\"Data cached: {len(self.data_cache)}\")\n",
    "\n",
    "# Create watchlist\n",
    "my_watchlist = MalaysianStockWatchlist('Malaysian Blue-Chips')\n",
    "\n",
    "# Add stocks\n",
    "my_watchlist.add_stock('Maybank', '1155.KL', 'Banking')\n",
    "my_watchlist.add_stock('Public Bank', '1295.KL', 'Banking')\n",
    "my_watchlist.add_stock('Gamuda', '5398.KL', 'Construction')\n",
    "my_watchlist.add_stock('Nestle Malaysia', '4707.KL', 'Consumer')\n",
    "my_watchlist.add_stock('Sime Darby Plantation', '5285.KL', 'Plantation')\n",
    "\n",
    "# Update data\n",
    "my_watchlist.update_all_data(days=365)\n",
    "\n",
    "# Show summary\n",
    "my_watchlist.get_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Practice Exercises\n",
    "\n",
    "Apply what you've learned!\n",
    "\n",
    "### Exercise 1: Weekly vs Daily Comparison\n",
    "\n",
    "Download **CIMB (1023.KL)** data for 2024 at both daily and weekly intervals. Create a comparison chart and explain which interval would be better for:\n",
    "a) Swing trading (1-3 week holds)\n",
    "b) Long-term investing (6+ months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Build Your REIT Portfolio\n",
    "\n",
    "Create a watchlist of 5 Malaysian REITs. Download their data and calculate:\n",
    "1. Total return for each REIT in 2024\n",
    "2. Average daily volume\n",
    "3. Which REIT would you invest in and why?\n",
    "\n",
    "REITs to consider: 5123.KL (Sentral), 5302.KL (CapitaLand Malaysia), 5184.KL (YTL Hospitality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Data Quality Detective\n",
    "\n",
    "Download data for **Sunway (5211.KL)** for 2024. Run the `validate_stock_data()` function and investigate any data quality issues you find. Are there any extreme price moves? If so, can you find news explaining them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Save Your Portfolio\n",
    "\n",
    "Download data for 3 stocks of your choice. Save each one using the `save_stock_data()` function to the appropriate directory (raw/processed/sample). Then verify you can load them back successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Key Takeaways\n",
    "\n",
    "Congratulations! You now have a solid foundation in data collection.\n",
    "\n",
    "### ‚úÖ Skills Mastered\n",
    "\n",
    "1. **Multiple Intervals**: Download data at daily, weekly, hourly, and minute intervals\n",
    "2. **Batch Downloads**: Efficiently download multiple stocks simultaneously\n",
    "3. **Data Quality**: Validate and clean stock data\n",
    "4. **Persistence**: Save and load data locally for offline analysis\n",
    "5. **Watchlist Management**: Build and maintain a stock watchlist system\n",
    "6. **Company Info**: Retrieve fundamental data beyond just prices\n",
    "\n",
    "### üìä Key Takeaways\n",
    "\n",
    "1. **Start Simple**: Daily data is best for learning (less noise)\n",
    "2. **Quality Matters**: Always validate data before analysis\n",
    "3. **Save Locally**: Faster analysis and consistent results\n",
    "4. **Multiple Stocks**: Compare performance across stocks/sectors\n",
    "5. **Clean Data**: Handle missing values and outliers appropriately\n",
    "\n",
    "### üîß Tools You Built\n",
    "\n",
    "- `calculate_transaction_costs()`: Cost calculator (from Module 01)\n",
    "- `validate_stock_data()`: Data quality checker\n",
    "- `clean_stock_data()`: Data cleaning function\n",
    "- `save_stock_data()` / `load_stock_data()`: Persistence functions\n",
    "- `MalaysianStockWatchlist`: Complete watchlist management class\n",
    "\n",
    "### üéØ What's Next?\n",
    "\n",
    "In **Module 03: Introduction to Technical Indicators**, you'll learn:\n",
    "- Moving Averages (SMA, EMA)\n",
    "- Trend identification\n",
    "- Support and resistance levels\n",
    "- Your first trading signals!\n",
    "\n",
    "### üí° Pro Tips\n",
    "\n",
    "1. **Regular Updates**: Update your watchlist data weekly\n",
    "2. **Version Control**: Include date in filenames for tracking\n",
    "3. **Backup Data**: Keep copies of important datasets\n",
    "4. **Document Issues**: Note any data quality problems you find\n",
    "5. **Cross-Reference**: Verify important data points with official sources\n",
    "\n",
    "### üìö Additional Resources\n",
    "\n",
    "- [yfinance Documentation](https://pypi.org/project/yfinance/)\n",
    "- [Pandas Data Cleaning Guide](https://pandas.pydata.org/docs/user_guide/missing_data.html)\n",
    "- [Bursa Malaysia Announcements](https://www.bursamalaysia.com/market_information/announcements) - Official data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Excellent work completing Module 02!** üéâ\n",
    "\n",
    "You now have a robust data collection and management system. This is the foundation for all future technical analysis.\n",
    "\n",
    "**Next up**: `03_moving_averages_and_trends.ipynb` - Your first technical indicators!\n",
    "\n",
    "---\n",
    "\n",
    "*\"In God we trust. All others must bring data.\" - W. Edwards Deming*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
