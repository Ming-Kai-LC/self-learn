{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Module 07: Scheduled Tasks & Automation\n",
    "\n",
    "**Difficulty**: ⭐⭐⭐ (Advanced)\n",
    "\n",
    "**Estimated Time**: 75 minutes\n",
    "\n",
    "**Prerequisites**: \n",
    "- Completed Modules 00-06\n",
    "- Understanding of subprocess and file operations\n",
    "- Basic knowledge of cron/scheduled tasks\n",
    "- Familiarity with logging concepts\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Create** scheduled tasks using Windows Task Scheduler\n",
    "2. **Implement** Python-based scheduling solutions\n",
    "3. **Build** automated data collection pipelines\n",
    "4. **Configure** email notifications for automation\n",
    "5. **Manage** log files and rotation strategies\n",
    "6. **Handle** errors robustly in unattended scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Introduction: Why Task Scheduling Matters\n",
    "\n",
    "Automated scheduling is essential for data science workflows:\n",
    "\n",
    "### Common Use Cases\n",
    "\n",
    "**1. Data Collection**\n",
    "- Fetch API data daily at 6 AM\n",
    "- Download financial reports weekly\n",
    "- Scrape websites on schedule\n",
    "- Sync cloud datasets hourly\n",
    "\n",
    "**2. Model Training**\n",
    "- Retrain models with fresh data\n",
    "- Run hyperparameter tuning overnight\n",
    "- Generate predictions on schedule\n",
    "- Update feature stores regularly\n",
    "\n",
    "**3. Reporting**\n",
    "- Email daily metrics summaries\n",
    "- Generate weekly performance reports\n",
    "- Monitor data quality alerts\n",
    "- Archive results monthly\n",
    "\n",
    "**4. Maintenance**\n",
    "- Clean up old checkpoint files\n",
    "- Compress log files\n",
    "- Backup important data\n",
    "- Monitor disk space\n",
    "\n",
    "### Scheduling Methods on Windows\n",
    "\n",
    "| Method | Pros | Cons | Best For |\n",
    "|--------|------|------|----------|\n",
    "| **Task Scheduler** | Native, reliable, survives reboots | Complex setup | Production systems |\n",
    "| **schedule library** | Easy Python integration | Requires running process | Development, testing |\n",
    "| **APScheduler** | Powerful, flexible | Heavy dependency | Complex workflows |\n",
    "| **Cron (WSL)** | Familiar to Linux users | Requires WSL | Cross-platform scripts |\n",
    "\n",
    "This module focuses on Task Scheduler and the `schedule` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import required libraries\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Install schedule library if needed\n",
    "try:\n",
    "    import schedule\n",
    "except ImportError:\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'schedule', '-q'])\n",
    "    import schedule\n",
    "\n",
    "print(f\"schedule version: {schedule.__version__}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Windows Task Scheduler Basics\n",
    "\n",
    "Windows Task Scheduler is the native scheduling solution. We can interact with it via Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all scheduled tasks (read-only, safe operation)\n",
    "def list_scheduled_tasks():\n",
    "    \"\"\"\n",
    "    List all Windows scheduled tasks.\n",
    "    \n",
    "    Returns:\n",
    "        list: Task names and states\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use schtasks command to query tasks\n",
    "        result = subprocess.run(\n",
    "            ['schtasks', '/Query', '/FO', 'CSV'],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            # Parse CSV output\n",
    "            lines = result.stdout.strip().split('\\n')\n",
    "            tasks = []\n",
    "            \n",
    "            for line in lines[1:]:  # Skip header\n",
    "                parts = line.split(',')\n",
    "                if len(parts) >= 2:\n",
    "                    task_name = parts[0].strip('\"')\n",
    "                    status = parts[2].strip('\"') if len(parts) > 2 else 'Unknown'\n",
    "                    tasks.append({'name': task_name, 'status': status})\n",
    "            \n",
    "            return tasks\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error listing tasks: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example: List all tasks\n",
    "all_tasks = list_scheduled_tasks()\n",
    "print(f\"Found {len(all_tasks)} scheduled tasks\")\n",
    "\n",
    "# Show first 5 as example\n",
    "print(\"\\nFirst 5 tasks:\")\n",
    "for task in all_tasks[:5]:\n",
    "    print(f\"  {task['name']}: {task['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### 1.1 Creating Scheduled Tasks\n",
    "\n",
    "We can create scheduled tasks programmatically. This is useful for deployment automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scheduled task (demonstration - dry run mode)\n",
    "def create_scheduled_task(task_name, script_path, schedule_time, dry_run=True):\n",
    "    \"\"\"\n",
    "    Create a Windows scheduled task.\n",
    "    \n",
    "    Args:\n",
    "        task_name: Name for the task\n",
    "        script_path: Path to Python script to run\n",
    "        schedule_time: Time in HH:MM format (24-hour)\n",
    "        dry_run: If True, only show command without executing\n",
    "    \n",
    "    Returns:\n",
    "        bool: Success status\n",
    "    \"\"\"\n",
    "    script_path = Path(script_path).resolve()\n",
    "    python_exe = sys.executable\n",
    "    \n",
    "    # Build schtasks command\n",
    "    # /Create: Create new task\n",
    "    # /TN: Task name\n",
    "    # /TR: Task to run\n",
    "    # /SC: Schedule type (DAILY, WEEKLY, MONTHLY, ONCE)\n",
    "    # /ST: Start time\n",
    "    command = [\n",
    "        'schtasks', '/Create',\n",
    "        '/TN', task_name,\n",
    "        '/TR', f'\"{python_exe}\" \"{script_path}\"',\n",
    "        '/SC', 'DAILY',\n",
    "        '/ST', schedule_time,\n",
    "        '/F'  # Force create (overwrite if exists)\n",
    "    ]\n",
    "    \n",
    "    print(f\"{'DRY RUN: Would create' if dry_run else 'Creating'} scheduled task:\")\n",
    "    print(f\"  Task name: {task_name}\")\n",
    "    print(f\"  Script: {script_path}\")\n",
    "    print(f\"  Schedule: Daily at {schedule_time}\")\n",
    "    print(f\"  Command: {' '.join(command)}\")\n",
    "    \n",
    "    if not dry_run:\n",
    "        try:\n",
    "            result = subprocess.run(command, capture_output=True, text=True)\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(\"✓ Task created successfully\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"✗ Failed: {result.stderr}\")\n",
    "                return False\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"\\nSet dry_run=False to actually create task\")\n",
    "        return True\n",
    "\n",
    "# Example: Schedule a data collection script\n",
    "# create_scheduled_task(\n",
    "#     task_name='DataCollection_Daily',\n",
    "#     script_path='scripts/collect_data.py',\n",
    "#     schedule_time='06:00',\n",
    "#     dry_run=True\n",
    "# )\n",
    "\n",
    "print(\"create_scheduled_task() function ready!\")\n",
    "print(\"⚠ Use with caution - always test with dry_run=True first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 2. Python-Based Scheduling with `schedule`\n",
    "\n",
    "The `schedule` library provides a simple Python API for scheduling. Great for development and testing.\n",
    "\n",
    "### When to Use `schedule` vs Task Scheduler\n",
    "\n",
    "**Use `schedule` when:**\n",
    "- Developing and testing automation scripts\n",
    "- Running temporary or short-term schedules\n",
    "- You need fine control within Python\n",
    "- Jobs need to share Python state/memory\n",
    "\n",
    "**Use Task Scheduler when:**\n",
    "- Deploying to production\n",
    "- Need jobs to run even when not logged in\n",
    "- Want tasks to survive system reboots\n",
    "- Need enterprise-level reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic scheduling with schedule library\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "# Job counter for demonstration\n",
    "job_counter = {'count': 0}\n",
    "\n",
    "def sample_job():\n",
    "    \"\"\"Sample job that runs on schedule.\"\"\"\n",
    "    job_counter['count'] += 1\n",
    "    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{now}] Job executed! (Run #{job_counter['count']})\")\n",
    "\n",
    "# Schedule examples\n",
    "print(\"Schedule library examples:\\n\")\n",
    "\n",
    "# Every N minutes\n",
    "schedule.every(10).minutes.do(sample_job)\n",
    "print(\"✓ Scheduled: Every 10 minutes\")\n",
    "\n",
    "# Every hour at specific minute\n",
    "schedule.every().hour.at(\":30\").do(sample_job)\n",
    "print(\"✓ Scheduled: Every hour at :30\")\n",
    "\n",
    "# Daily at specific time\n",
    "schedule.every().day.at(\"09:00\").do(sample_job)\n",
    "print(\"✓ Scheduled: Daily at 09:00\")\n",
    "\n",
    "# Weekday-specific\n",
    "schedule.every().monday.at(\"08:00\").do(sample_job)\n",
    "print(\"✓ Scheduled: Every Monday at 08:00\")\n",
    "\n",
    "# Show all scheduled jobs\n",
    "print(f\"\\nTotal jobs scheduled: {len(schedule.get_jobs())}\")\n",
    "\n",
    "# Clear all jobs (cleanup)\n",
    "schedule.clear()\n",
    "print(\"\\n(All jobs cleared for demonstration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### 2.1 Running the Scheduler\n",
    "\n",
    "The `schedule` library requires a running loop to check and execute jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scheduler runner with graceful shutdown\n",
    "def run_scheduler(max_iterations=None, check_interval=1):\n",
    "    \"\"\"\n",
    "    Run the scheduler loop.\n",
    "    \n",
    "    Args:\n",
    "        max_iterations: Maximum iterations (None = infinite)\n",
    "        check_interval: Seconds between checks\n",
    "    \"\"\"\n",
    "    print(\"Scheduler started. Press Ctrl+C to stop.\")\n",
    "    print(f\"Jobs scheduled: {len(schedule.get_jobs())}\\n\")\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    try:\n",
    "        while max_iterations is None or iteration < max_iterations:\n",
    "            # Run pending jobs\n",
    "            schedule.run_pending()\n",
    "            \n",
    "            # Wait before next check\n",
    "            time.sleep(check_interval)\n",
    "            iteration += 1\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nScheduler stopped by user.\")\n",
    "    \n",
    "    print(f\"Total iterations: {iteration}\")\n",
    "\n",
    "# Example: Run for 10 seconds (demonstration only)\n",
    "# Schedule a job every 2 seconds\n",
    "schedule.every(2).seconds.do(sample_job)\n",
    "\n",
    "print(\"Demo: Running scheduler for 10 seconds...\")\n",
    "run_scheduler(max_iterations=10, check_interval=1)\n",
    "\n",
    "# Cleanup\n",
    "schedule.clear()\n",
    "print(\"\\nDemo complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 3. Automated Data Collection Pipeline\n",
    "\n",
    "Let's build a realistic data collection automation that fetches API data on schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection automation\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "class DataCollector:\n",
    "    \"\"\"\n",
    "    Automated data collection system.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir='data/collected'):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.collection_count = 0\n",
    "    \n",
    "    def collect_data(self, source_name, data_fetcher):\n",
    "        \"\"\"\n",
    "        Collect data from a source.\n",
    "        \n",
    "        Args:\n",
    "            source_name: Name of data source\n",
    "            data_fetcher: Function that returns data\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            # Fetch data\n",
    "            data = data_fetcher()\n",
    "            \n",
    "            # Save with timestamp\n",
    "            filename = f\"{source_name}_{timestamp.strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "            filepath = self.output_dir / filename\n",
    "            \n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump({\n",
    "                    'source': source_name,\n",
    "                    'timestamp': timestamp.isoformat(),\n",
    "                    'data': data\n",
    "                }, f, indent=2)\n",
    "            \n",
    "            self.collection_count += 1\n",
    "            print(f\"✓ [{timestamp.strftime('%H:%M:%S')}] Collected {source_name}\")\n",
    "            print(f\"  Saved to: {filepath.name}\")\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"✗ [{timestamp.strftime('%H:%M:%S')}] Failed to collect {source_name}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get collection statistics.\"\"\"\n",
    "        files = list(self.output_dir.glob('*.json'))\n",
    "        return {\n",
    "            'total_collections': self.collection_count,\n",
    "            'total_files': len(files),\n",
    "            'output_dir': str(self.output_dir)\n",
    "        }\n",
    "\n",
    "# Example data fetcher\n",
    "def fetch_sample_data():\n",
    "    \"\"\"Simulate fetching data from API.\"\"\"\n",
    "    return {\n",
    "        'value': 42,\n",
    "        'status': 'ok',\n",
    "        'items': [1, 2, 3]\n",
    "    }\n",
    "\n",
    "# Test the collector\n",
    "collector = DataCollector(output_dir='data/demo_collected')\n",
    "collector.collect_data('sample_api', fetch_sample_data)\n",
    "\n",
    "print(f\"\\nStats: {collector.get_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### 3.1 Scheduled Data Collection\n",
    "\n",
    "Combine the collector with scheduling for automated data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scheduled data collection example\n",
    "import schedule\n",
    "\n",
    "# Create collector\n",
    "collector = DataCollector(output_dir='data/scheduled_collected')\n",
    "\n",
    "# Define collection job\n",
    "def scheduled_collection_job():\n",
    "    \"\"\"Job that collects data on schedule.\"\"\"\n",
    "    collector.collect_data('scheduled_api', fetch_sample_data)\n",
    "\n",
    "# Schedule collection every 5 seconds (for demo)\n",
    "schedule.every(5).seconds.do(scheduled_collection_job)\n",
    "\n",
    "print(\"Demo: Scheduled data collection\")\n",
    "print(\"Collecting every 5 seconds for 15 seconds...\\n\")\n",
    "\n",
    "# Run for demonstration\n",
    "run_scheduler(max_iterations=15, check_interval=1)\n",
    "\n",
    "# Show results\n",
    "print(f\"\\nFinal stats: {collector.get_stats()}\")\n",
    "\n",
    "# Cleanup\n",
    "schedule.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 4. Email Notifications\n",
    "\n",
    "Send email alerts when automation completes, fails, or detects issues.\n",
    "\n",
    "### Email Configuration\n",
    "\n",
    "For production use, you'll need:\n",
    "- SMTP server credentials (Gmail, Outlook, corporate server)\n",
    "- App-specific password (if using Gmail)\n",
    "- Email addresses for recipients\n",
    "\n",
    "**Security Best Practice**: Store credentials in environment variables or secure configuration files, never in code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email notification system (demonstration)\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "class EmailNotifier:\n",
    "    \"\"\"\n",
    "    Send email notifications for automation events.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, smtp_server, smtp_port, username, password, from_email):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            smtp_server: SMTP server address (e.g., 'smtp.gmail.com')\n",
    "            smtp_port: SMTP port (587 for TLS, 465 for SSL)\n",
    "            username: SMTP username\n",
    "            password: SMTP password (use app-specific password)\n",
    "            from_email: From email address\n",
    "        \"\"\"\n",
    "        self.smtp_server = smtp_server\n",
    "        self.smtp_port = smtp_port\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.from_email = from_email\n",
    "    \n",
    "    def send_notification(self, to_email, subject, body, is_html=False):\n",
    "        \"\"\"\n",
    "        Send email notification.\n",
    "        \n",
    "        Args:\n",
    "            to_email: Recipient email address\n",
    "            subject: Email subject\n",
    "            body: Email body\n",
    "            is_html: If True, body is HTML\n",
    "        \n",
    "        Returns:\n",
    "            bool: Success status\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create message\n",
    "            msg = MIMEMultipart()\n",
    "            msg['From'] = self.from_email\n",
    "            msg['To'] = to_email\n",
    "            msg['Subject'] = subject\n",
    "            \n",
    "            # Attach body\n",
    "            msg.attach(MIMEText(body, 'html' if is_html else 'plain'))\n",
    "            \n",
    "            # Connect and send\n",
    "            with smtplib.SMTP(self.smtp_server, self.smtp_port) as server:\n",
    "                server.starttls()\n",
    "                server.login(self.username, self.password)\n",
    "                server.send_message(msg)\n",
    "            \n",
    "            print(f\"✓ Email sent to {to_email}\")\n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to send email: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def send_success_notification(self, to_email, task_name, stats):\n",
    "        \"\"\"Send success notification with statistics.\"\"\"\n",
    "        subject = f\"✓ {task_name} Completed Successfully\"\n",
    "        \n",
    "        body = f\"\"\"\n",
    "Task: {task_name}\n",
    "Status: Success\n",
    "Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Statistics:\n",
    "{json.dumps(stats, indent=2)}\n",
    "\n",
    "This is an automated message.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.send_notification(to_email, subject, body)\n",
    "    \n",
    "    def send_failure_notification(self, to_email, task_name, error):\n",
    "        \"\"\"Send failure notification with error details.\"\"\"\n",
    "        subject = f\"✗ {task_name} Failed\"\n",
    "        \n",
    "        body = f\"\"\"\n",
    "Task: {task_name}\n",
    "Status: Failed\n",
    "Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Error:\n",
    "{error}\n",
    "\n",
    "Please investigate.\n",
    "\n",
    "This is an automated message.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.send_notification(to_email, subject, body)\n",
    "\n",
    "# Example configuration (DO NOT use real credentials here)\n",
    "print(\"EmailNotifier class ready!\")\n",
    "print(\"\\n⚠ Configuration needed:\")\n",
    "print(\"  1. Set up SMTP server credentials\")\n",
    "print(\"  2. Store in environment variables\")\n",
    "print(\"  3. Use app-specific passwords\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"\"\"\n",
    "# Load from environment\n",
    "import os\n",
    "notifier = EmailNotifier(\n",
    "    smtp_server=os.getenv('SMTP_SERVER'),\n",
    "    smtp_port=int(os.getenv('SMTP_PORT', 587)),\n",
    "    username=os.getenv('SMTP_USERNAME'),\n",
    "    password=os.getenv('SMTP_PASSWORD'),\n",
    "    from_email=os.getenv('FROM_EMAIL')\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 5. Logging and Error Handling\n",
    "\n",
    "Robust logging is critical for unattended automation. You need to diagnose issues without being present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup comprehensive logging\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def setup_automation_logger(log_dir='logs', log_name='automation'):\n",
    "    \"\"\"\n",
    "    Setup logger for automation scripts.\n",
    "    \n",
    "    Args:\n",
    "        log_dir: Directory for log files\n",
    "        log_name: Base name for log files\n",
    "    \n",
    "    Returns:\n",
    "        logging.Logger: Configured logger\n",
    "    \"\"\"\n",
    "    # Create logs directory\n",
    "    log_dir = Path(log_dir)\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create logger\n",
    "    logger = logging.getLogger(log_name)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    \n",
    "    # Clear existing handlers\n",
    "    logger.handlers.clear()\n",
    "    \n",
    "    # File handler - daily log rotation\n",
    "    today = datetime.now().strftime('%Y%m%d')\n",
    "    log_file = log_dir / f\"{log_name}_{today}.log\"\n",
    "    \n",
    "    file_handler = logging.FileHandler(log_file)\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    \n",
    "    # Console handler\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    \n",
    "    # Formatter\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    \n",
    "    file_handler.setFormatter(formatter)\n",
    "    console_handler.setFormatter(formatter)\n",
    "    \n",
    "    # Add handlers\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "    logger.info(f\"Logger initialized. Log file: {log_file}\")\n",
    "    \n",
    "    return logger\n",
    "\n",
    "# Example usage\n",
    "logger = setup_automation_logger(log_dir='logs/demo', log_name='demo_automation')\n",
    "\n",
    "logger.debug(\"Debug message - detailed information\")\n",
    "logger.info(\"Info message - general information\")\n",
    "logger.warning(\"Warning message - something unexpected\")\n",
    "logger.error(\"Error message - something failed\")\n",
    "\n",
    "print(\"\\n✓ Logger configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "### 5.1 Robust Error Handling Pattern\n",
    "\n",
    "Automation scripts must handle errors gracefully and log everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust automation wrapper\n",
    "import traceback\n",
    "\n",
    "def robust_automation_wrapper(task_func, task_name, logger, max_retries=3):\n",
    "    \"\"\"\n",
    "    Wrap automation task with error handling and retries.\n",
    "    \n",
    "    Args:\n",
    "        task_func: Function to execute\n",
    "        task_name: Name of task (for logging)\n",
    "        logger: Logger instance\n",
    "        max_retries: Maximum retry attempts\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (success: bool, result: any, error: str or None)\n",
    "    \"\"\"\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            logger.info(f\"Starting {task_name} (attempt {attempt}/{max_retries})\")\n",
    "            \n",
    "            # Execute task\n",
    "            result = task_func()\n",
    "            \n",
    "            logger.info(f\"✓ {task_name} completed successfully\")\n",
    "            return True, result, None\n",
    "        \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            error_trace = traceback.format_exc()\n",
    "            \n",
    "            logger.error(f\"✗ {task_name} failed (attempt {attempt}/{max_retries})\")\n",
    "            logger.error(f\"Error: {error_msg}\")\n",
    "            logger.debug(f\"Traceback:\\n{error_trace}\")\n",
    "            \n",
    "            # If last attempt, give up\n",
    "            if attempt == max_retries:\n",
    "                logger.error(f\"✗ {task_name} failed after {max_retries} attempts\")\n",
    "                return False, None, error_msg\n",
    "            \n",
    "            # Wait before retry (exponential backoff)\n",
    "            wait_time = 2 ** attempt\n",
    "            logger.info(f\"Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "    \n",
    "    return False, None, \"Max retries exceeded\"\n",
    "\n",
    "# Example task that might fail\n",
    "def unreliable_task():\n",
    "    \"\"\"Simulates a task that sometimes fails.\"\"\"\n",
    "    import random\n",
    "    if random.random() < 0.5:\n",
    "        raise Exception(\"Random failure for demonstration\")\n",
    "    return {\"status\": \"success\", \"data\": [1, 2, 3]}\n",
    "\n",
    "# Test the wrapper\n",
    "logger = setup_automation_logger(log_dir='logs/demo', log_name='robust_demo')\n",
    "success, result, error = robust_automation_wrapper(\n",
    "    unreliable_task,\n",
    "    \"Unreliable Task\",\n",
    "    logger,\n",
    "    max_retries=3\n",
    ")\n",
    "\n",
    "if success:\n",
    "    print(f\"\\n✓ Task succeeded: {result}\")\n",
    "else:\n",
    "    print(f\"\\n✗ Task failed: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### 5.2 Log File Management\n",
    "\n",
    "Logs accumulate over time. Implement rotation and cleanup strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log file management\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def manage_log_files(log_dir, max_age_days=30, compress_age_days=7):\n",
    "    \"\"\"\n",
    "    Manage log files: compress old logs, delete very old logs.\n",
    "    \n",
    "    Args:\n",
    "        log_dir: Directory containing log files\n",
    "        max_age_days: Delete logs older than this\n",
    "        compress_age_days: Compress logs older than this\n",
    "    \n",
    "    Returns:\n",
    "        dict: Statistics of operations\n",
    "    \"\"\"\n",
    "    log_dir = Path(log_dir)\n",
    "    \n",
    "    if not log_dir.exists():\n",
    "        return {'error': 'Log directory does not exist'}\n",
    "    \n",
    "    now = datetime.now()\n",
    "    stats = {\n",
    "        'compressed': 0,\n",
    "        'deleted': 0,\n",
    "        'total_files': 0\n",
    "    }\n",
    "    \n",
    "    # Process all .log files\n",
    "    for log_file in log_dir.glob('*.log'):\n",
    "        stats['total_files'] += 1\n",
    "        \n",
    "        # Get file age\n",
    "        modified_time = datetime.fromtimestamp(log_file.stat().st_mtime)\n",
    "        age_days = (now - modified_time).days\n",
    "        \n",
    "        # Delete if too old\n",
    "        if age_days > max_age_days:\n",
    "            log_file.unlink()\n",
    "            stats['deleted'] += 1\n",
    "            print(f\"Deleted old log: {log_file.name} ({age_days} days old)\")\n",
    "        \n",
    "        # Compress if moderately old\n",
    "        elif age_days > compress_age_days:\n",
    "            # Compress to .gz\n",
    "            gz_file = log_file.with_suffix('.log.gz')\n",
    "            \n",
    "            with open(log_file, 'rb') as f_in:\n",
    "                with gzip.open(gz_file, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "            \n",
    "            # Delete original\n",
    "            log_file.unlink()\n",
    "            stats['compressed'] += 1\n",
    "            print(f\"Compressed log: {log_file.name} → {gz_file.name}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Example usage\n",
    "# stats = manage_log_files('logs/demo', max_age_days=30, compress_age_days=7)\n",
    "# print(f\"\\nLog management stats: {stats}\")\n",
    "\n",
    "print(\"manage_log_files() function ready!\")\n",
    "print(\"Recommended: Run this function weekly as a scheduled task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 6. Practice Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "### Exercise 1: Stock Data Collector\n",
    "\n",
    "Create an automated stock data collection system:\n",
    "1. Fetch stock prices from an API (use sample data)\n",
    "2. Schedule collection every hour\n",
    "3. Save data with timestamps\n",
    "4. Send email if collection fails\n",
    "5. Log all operations\n",
    "\n",
    "**Hint**: Combine DataCollector, schedule, EmailNotifier, and logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your solution here\n",
    "\n",
    "class StockDataCollector:\n",
    "    \"\"\"\n",
    "    Automated stock data collection system.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir, logger, notifier=None):\n",
    "        # TODO: Initialize collector with logging and notifications\n",
    "        pass\n",
    "    \n",
    "    def fetch_stock_data(self, symbol):\n",
    "        # TODO: Fetch stock data (use sample data for now)\n",
    "        pass\n",
    "    \n",
    "    def scheduled_collection(self):\n",
    "        # TODO: Collect data with error handling\n",
    "        pass\n",
    "\n",
    "# Test your collector\n",
    "# collector = StockDataCollector('data/stocks', logger)\n",
    "# collector.scheduled_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "### Exercise 2: Model Training Scheduler\n",
    "\n",
    "Create a scheduled ML model training system:\n",
    "1. Check if new training data is available\n",
    "2. Load data and train model\n",
    "3. Save model with version timestamp\n",
    "4. Generate performance report\n",
    "5. Email report to team\n",
    "6. Clean up old models (keep last 5)\n",
    "\n",
    "**Hint**: Use robust_automation_wrapper for error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your solution here\n",
    "\n",
    "class ModelTrainingScheduler:\n",
    "    \"\"\"\n",
    "    Scheduled ML model training system.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, model_dir, logger):\n",
    "        # TODO: Initialize scheduler\n",
    "        pass\n",
    "    \n",
    "    def check_for_new_data(self):\n",
    "        # TODO: Check if new training data exists\n",
    "        pass\n",
    "    \n",
    "    def train_model(self):\n",
    "        # TODO: Train model with new data\n",
    "        pass\n",
    "    \n",
    "    def cleanup_old_models(self, keep_count=5):\n",
    "        # TODO: Delete old model files\n",
    "        pass\n",
    "\n",
    "# Test your scheduler\n",
    "# scheduler = ModelTrainingScheduler('data/training', 'models', logger)\n",
    "# scheduler.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "### Exercise 3: System Health Monitor\n",
    "\n",
    "Create a system monitoring automation:\n",
    "1. Check disk space every 6 hours\n",
    "2. Check process resource usage\n",
    "3. Alert if disk usage > 90%\n",
    "4. Alert if any process uses > 80% CPU for 5+ minutes\n",
    "5. Generate daily health report\n",
    "6. Archive reports weekly\n",
    "\n",
    "**Hint**: Use psutil for system metrics, schedule for timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your solution here\n",
    "\n",
    "class SystemHealthMonitor:\n",
    "    \"\"\"\n",
    "    Automated system health monitoring.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, logger, notifier=None):\n",
    "        # TODO: Initialize monitor\n",
    "        pass\n",
    "    \n",
    "    def check_disk_space(self):\n",
    "        # TODO: Check disk usage\n",
    "        pass\n",
    "    \n",
    "    def check_processes(self):\n",
    "        # TODO: Check high-resource processes\n",
    "        pass\n",
    "    \n",
    "    def generate_health_report(self):\n",
    "        # TODO: Generate comprehensive report\n",
    "        pass\n",
    "\n",
    "# Test your monitor\n",
    "# monitor = SystemHealthMonitor(logger)\n",
    "# monitor.check_disk_space()\n",
    "# monitor.check_processes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Task Scheduling Methods**\n",
    "   - Windows Task Scheduler: Production-ready, survives reboots\n",
    "   - Python `schedule` library: Development and testing\n",
    "   - Choose based on requirements and environment\n",
    "\n",
    "2. **Automation Patterns**\n",
    "   - Data collection: Fetch, validate, save with timestamps\n",
    "   - Processing: Load, transform, save results\n",
    "   - Maintenance: Cleanup, archival, monitoring\n",
    "\n",
    "3. **Error Handling**\n",
    "   - Always use try-except blocks\n",
    "   - Implement retry logic with exponential backoff\n",
    "   - Log everything (successes and failures)\n",
    "   - Send notifications for critical failures\n",
    "\n",
    "4. **Logging Best Practices**\n",
    "   - Log to both file and console\n",
    "   - Use appropriate log levels (DEBUG, INFO, WARNING, ERROR)\n",
    "   - Include timestamps and context\n",
    "   - Implement log rotation to manage disk space\n",
    "\n",
    "5. **Production Considerations**\n",
    "   - Store credentials securely (environment variables)\n",
    "   - Implement monitoring and alerting\n",
    "   - Test thoroughly before deploying\n",
    "   - Document scheduling and dependencies\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "- **Daily Stock Data Collection**: Fetch market data every morning\n",
    "- **Model Retraining**: Retrain ML models with fresh data weekly\n",
    "- **Report Generation**: Generate and email reports daily\n",
    "- **System Maintenance**: Clean logs, backup data, monitor health\n",
    "- **Data Pipeline**: Orchestrate multi-step ETL processes\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 08: Windows Security & Permissions**, you'll learn:\n",
    "- File permissions and ACLs\n",
    "- User and group management\n",
    "- Running scripts as administrator\n",
    "- Credential management\n",
    "- Security best practices\n",
    "\n",
    "### Self-Assessment\n",
    "\n",
    "Before moving on, make sure you can:\n",
    "- [ ] Create Windows scheduled tasks programmatically\n",
    "- [ ] Use Python `schedule` library for automation\n",
    "- [ ] Implement robust error handling with retries\n",
    "- [ ] Set up comprehensive logging\n",
    "- [ ] Configure email notifications\n",
    "- [ ] Manage log file rotation and cleanup\n",
    "\n",
    "---\n",
    "\n",
    "**Continue to Module 08** when ready!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
