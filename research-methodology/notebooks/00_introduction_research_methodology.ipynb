{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 00: Introduction to Research Methodology\n",
    "\n",
    "**Difficulty**: ‚≠ê (Beginner)\n",
    "\n",
    "**Estimated Time**: 30 minutes\n",
    "\n",
    "**Prerequisites**: None - This is the starting point!\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Explain what research methodology is and why it matters in data science\n",
    "2. Distinguish between methodology, method, and technique\n",
    "3. Describe the scientific method and how it applies to data science\n",
    "4. Identify common research pitfalls and how methodology prevents them\n",
    "5. Recognize the difference between exploratory analysis and rigorous research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import the libraries we'll use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard data science libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration for better visualizations\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Research Methodology?\n",
    "\n",
    "### Understanding the Terminology\n",
    "\n",
    "Before diving in, let's clarify three often-confused terms:\n",
    "\n",
    "**Methodology** = The overall philosophical framework and strategy for conducting research\n",
    "- Example: \"We used an experimental methodology with randomized controlled trials\"\n",
    "- It answers: *What is the overall approach and why?*\n",
    "\n",
    "**Method** = The specific technique or procedure used to collect/analyze data\n",
    "- Example: \"We used surveys and interviews as data collection methods\"\n",
    "- It answers: *What specific tools did you use?*\n",
    "\n",
    "**Technique** = The detailed steps within a method\n",
    "- Example: \"We used stratified random sampling as our sampling technique\"\n",
    "- It answers: *How exactly did you apply the method?*\n",
    "\n",
    "### Why Methodology Matters in Data Science\n",
    "\n",
    "Research methodology is the **systematic framework** that guides how you:\n",
    "1. Formulate research questions\n",
    "2. Design studies and experiments\n",
    "3. Collect and manage data\n",
    "4. Analyze results validly\n",
    "5. Draw sound conclusions\n",
    "6. Ensure reproducibility\n",
    "\n",
    "Without proper methodology, even sophisticated algorithms can produce **misleading or invalid results**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Cost of Poor Methodology: Real Examples\n",
    "\n",
    "Let's look at what happens when methodology is neglected:\n",
    "\n",
    "**Example 1: The Reproducibility Crisis**\n",
    "- A Princeton study found reproducibility failures in 41 papers across 30 fields\n",
    "- These failures affected **648 other papers** that built on the flawed research\n",
    "- Nature's 2016 survey: 70% of researchers couldn't reproduce others' experiments\n",
    "- **50% couldn't even reproduce their own work!**\n",
    "\n",
    "**Example 2: Data Leakage Disasters**\n",
    "- Medical diagnosis model claimed 99% accuracy\n",
    "- Problem: Test data was included in training preprocessing\n",
    "- Real-world accuracy: 65% (dangerous for patient care!)\n",
    "\n",
    "**Example 3: Correlation-Causation Confusion**\n",
    "- Study claimed ice cream sales *cause* drowning deaths (high correlation)\n",
    "- Reality: Both are caused by hot weather (confounding variable)\n",
    "- Proper methodology would identify this through causal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's demonstrate the ice cream-drowning correlation fallacy\n",
    "\n",
    "# Simulate monthly data\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# Temperature (confounding variable)\n",
    "temperature = np.array([5, 6, 10, 15, 20, 25, 30, 29, 23, 17, 10, 6])\n",
    "\n",
    "# Ice cream sales increase with temperature\n",
    "ice_cream_sales = temperature * 100 + np.random.normal(0, 50, 12)\n",
    "\n",
    "# Drowning deaths increase with temperature (more swimming)\n",
    "drowning_deaths = temperature * 2 + np.random.normal(0, 5, 12)\n",
    "\n",
    "# Create DataFrame\n",
    "confounding_data = pd.DataFrame({\n",
    "    'Month': months,\n",
    "    'Temperature_C': temperature,\n",
    "    'Ice_Cream_Sales': ice_cream_sales.astype(int),\n",
    "    'Drowning_Deaths': drowning_deaths.astype(int)\n",
    "})\n",
    "\n",
    "print(\"Monthly Data (Illustrating Confounding Variable):\")\n",
    "print(confounding_data)\n",
    "\n",
    "# Calculate correlations\n",
    "correlation_ice_cream_drowning = confounding_data['Ice_Cream_Sales'].corr(\n",
    "    confounding_data['Drowning_Deaths']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Correlation between ice cream sales and drowning: {correlation_ice_cream_drowning:.3f}\")\n",
    "print(\"\\nWRONG conclusion: 'Ice cream causes drowning!'\")\n",
    "print(\"RIGHT conclusion: 'Temperature affects both (confounding variable)'\")\n",
    "print(\"\\nThis is why proper research methodology is essential!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the confounding relationship\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left plot: Ice cream vs drowning (misleading correlation)\n",
    "axes[0].scatter(confounding_data['Ice_Cream_Sales'], \n",
    "                confounding_data['Drowning_Deaths'],\n",
    "                c=confounding_data['Temperature_C'], \n",
    "                cmap='YlOrRd', s=100, edgecolors='black')\n",
    "axes[0].set_xlabel('Ice Cream Sales', fontsize=12)\n",
    "axes[0].set_ylabel('Drowning Deaths', fontsize=12)\n",
    "axes[0].set_title('Misleading Correlation\\n(Without considering temperature)', \n",
    "                   fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add correlation text\n",
    "axes[0].text(0.05, 0.95, f'r = {correlation_ice_cream_drowning:.3f}',\n",
    "             transform=axes[0].transAxes, fontsize=11,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', \n",
    "             facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# Right plot: Both vs temperature (true relationship)\n",
    "ax2 = axes[1]\n",
    "ax2_twin = ax2.twinx()\n",
    "\n",
    "ax2.plot(confounding_data['Month'], confounding_data['Ice_Cream_Sales'], \n",
    "         'o-', color='blue', linewidth=2, markersize=8, label='Ice Cream Sales')\n",
    "ax2_twin.plot(confounding_data['Month'], confounding_data['Drowning_Deaths'], \n",
    "              's-', color='red', linewidth=2, markersize=8, label='Drowning Deaths')\n",
    "\n",
    "ax2.set_xlabel('Month', fontsize=12)\n",
    "ax2.set_ylabel('Ice Cream Sales', color='blue', fontsize=12)\n",
    "ax2_twin.set_ylabel('Drowning Deaths', color='red', fontsize=12)\n",
    "ax2.set_title('True Relationship\\n(Both driven by temperature)', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add legends\n",
    "ax2.legend(loc='upper left')\n",
    "ax2_twin.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Key Insight: Research methodology helps us identify confounding variables\")\n",
    "print(\"   and distinguish correlation from causation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Identifying Confounding Variables\n",
    "\n",
    "For each scenario below, identify:\n",
    "1. The observed correlation\n",
    "2. The likely confounding variable\n",
    "3. Why this matters for research design\n",
    "\n",
    "**Scenario A**: \"Students who own more books have higher test scores. Therefore, buying more books improves academic performance.\"\n",
    "\n",
    "**Scenario B**: \"Countries with more Nobel laureates consume more chocolate per capita. Therefore, chocolate makes people smarter.\"\n",
    "\n",
    "**Scenario C**: \"Hospitals with more patients have higher death rates. Therefore, hospitals are dangerous.\"\n",
    "\n",
    "*Write your answers in the markdown cell below:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer to Exercise 1:\n",
    "\n",
    "**Scenario A:**\n",
    "- Observed correlation: ___\n",
    "- Confounding variable: ___\n",
    "- Why it matters: ___\n",
    "\n",
    "**Scenario B:**\n",
    "- Observed correlation: ___\n",
    "- Confounding variable: ___\n",
    "- Why it matters: ___\n",
    "\n",
    "**Scenario C:**\n",
    "- Observed correlation: ___\n",
    "- Confounding variable: ___\n",
    "- Why it matters: ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Scientific Method in Data Science\n",
    "\n",
    "The scientific method provides the foundation for rigorous research:\n",
    "\n",
    "```\n",
    "1. OBSERVE ‚Üí Notice patterns or problems\n",
    "      ‚Üì\n",
    "2. QUESTION ‚Üí Formulate specific, answerable questions\n",
    "      ‚Üì\n",
    "3. HYPOTHESIS ‚Üí Propose testable explanations\n",
    "      ‚Üì\n",
    "4. EXPERIMENT ‚Üí Design studies to test hypotheses\n",
    "      ‚Üì\n",
    "5. ANALYZE ‚Üí Examine data systematically\n",
    "      ‚Üì\n",
    "6. CONCLUDE ‚Üí Draw evidence-based conclusions\n",
    "      ‚Üì\n",
    "7. COMMUNICATE ‚Üí Share results for peer review\n",
    "      ‚Üì\n",
    "   (Iterate based on feedback)\n",
    "```\n",
    "\n",
    "### How This Applies to Data Science\n",
    "\n",
    "| Scientific Method Step | Data Science Application | Example |\n",
    "|------------------------|-------------------------|----------|\n",
    "| **Observe** | Exploratory data analysis | \"Customer churn rate increased 15% this quarter\" |\n",
    "| **Question** | Define research question | \"What factors predict customer churn?\" |\n",
    "| **Hypothesis** | Formulate testable claim | \"Customers with low engagement churn more\" |\n",
    "| **Experiment** | Design validation study | Split data, control for confounds, define metrics |\n",
    "| **Analyze** | Build and validate models | Train/test split, cross-validation, significance tests |\n",
    "| **Conclude** | Interpret results | \"Engagement score is significant predictor (p<0.01)\" |\n",
    "| **Communicate** | Report findings | Paper, presentation, or deployed model |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Principle: Falsifiability\n",
    "\n",
    "A cornerstone of scientific methodology is **falsifiability** (Karl Popper):\n",
    "\n",
    "- Good hypothesis: \"Model accuracy will exceed 80% on held-out test data\"\n",
    "  - ‚úì Can be tested and potentially proven false\n",
    "  \n",
    "- Bad hypothesis: \"This model will work well in most cases\"\n",
    "  - ‚úó Too vague to test or falsify\n",
    "\n",
    "**Why this matters**: If a claim can't be proven wrong, it can't be scientifically validated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Evaluating Hypotheses\n",
    "\n",
    "For each hypothesis below, determine if it's testable/falsifiable and explain why:\n",
    "\n",
    "1. \"Adding more features will improve model performance\"\n",
    "2. \"Customer satisfaction score below 7 predicts churn within 3 months\"\n",
    "3. \"Our algorithm is better than competitors\"\n",
    "4. \"Temperature affects ice cream sales with r>0.7 and p<0.05\"\n",
    "\n",
    "*Write your analysis in the code cell below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Create a function to evaluate hypothesis quality\n",
    "\n",
    "def evaluate_hypothesis(hypothesis, measurable, specific, testable):\n",
    "    \"\"\"\n",
    "    Evaluate whether a hypothesis meets scientific standards.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    hypothesis : str\n",
    "        The hypothesis statement to evaluate\n",
    "    measurable : bool\n",
    "        Are the variables quantifiable?\n",
    "    specific : bool\n",
    "        Are the conditions and outcomes clearly defined?\n",
    "    testable : bool\n",
    "        Can this be proven false with data?\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Evaluation results with score and feedback\n",
    "    \"\"\"\n",
    "    score = sum([measurable, specific, testable])\n",
    "    \n",
    "    quality = {\n",
    "        3: \"‚úì Excellent - Scientifically rigorous hypothesis\",\n",
    "        2: \"‚ö† Acceptable - Needs minor clarification\",\n",
    "        1: \"‚úó Poor - Requires major revision\",\n",
    "        0: \"‚úó Invalid - Not scientifically testable\"\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'hypothesis': hypothesis,\n",
    "        'score': score,\n",
    "        'quality': quality[score],\n",
    "        'measurable': '‚úì' if measurable else '‚úó',\n",
    "        'specific': '‚úì' if specific else '‚úó',\n",
    "        'testable': '‚úì' if testable else '‚úó'\n",
    "    }\n",
    "\n",
    "# Example evaluation\n",
    "hypothesis_1 = \"Adding more features will improve model performance\"\n",
    "result_1 = evaluate_hypothesis(\n",
    "    hypothesis_1,\n",
    "    measurable=True,   # Performance can be measured\n",
    "    specific=False,    # \"More features\" is vague\n",
    "    testable=False     # \"Will improve\" is too certain (no falsifiability)\n",
    ")\n",
    "\n",
    "print(\"Hypothesis Evaluation Results:\")\n",
    "print(\"=\"*60)\n",
    "for key, value in result_1.items():\n",
    "    print(f\"{key.capitalize()}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"YOUR TURN: Evaluate the other 3 hypotheses below\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# TODO: Evaluate hypothesis 2\n",
    "# hypothesis_2 = \"Customer satisfaction score below 7 predicts churn within 3 months\"\n",
    "# result_2 = evaluate_hypothesis(...)\n",
    "\n",
    "# TODO: Evaluate hypothesis 3\n",
    "# hypothesis_3 = \"Our algorithm is better than competitors\"\n",
    "# result_3 = evaluate_hypothesis(...)\n",
    "\n",
    "# TODO: Evaluate hypothesis 4\n",
    "# hypothesis_4 = \"Temperature affects ice cream sales with r>0.7 and p<0.05\"\n",
    "# result_4 = evaluate_hypothesis(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Analysis vs. Rigorous Research\n",
    "\n",
    "### The Difference Matters\n",
    "\n",
    "| Aspect | Exploratory Analysis | Rigorous Research |\n",
    "|--------|---------------------|-------------------|\n",
    "| **Purpose** | Generate insights and hypotheses | Test specific hypotheses |\n",
    "| **Data Use** | Explore all available data | Hold-out test set |\n",
    "| **Flexibility** | Try many approaches | Pre-specified methods |\n",
    "| **Standards** | Informal, iterative | Formal validation |\n",
    "| **Reproducibility** | Optional | Required |\n",
    "| **Documentation** | Minimal notes | Complete audit trail |\n",
    "| **Outcome** | Questions to investigate | Publishable findings |\n",
    "\n",
    "### Both Are Valuable!\n",
    "\n",
    "**Exploratory analysis** is essential for:\n",
    "- Understanding data structure\n",
    "- Identifying patterns\n",
    "- Generating hypotheses\n",
    "- Prototyping models\n",
    "\n",
    "**Rigorous research** is required for:\n",
    "- Making causal claims\n",
    "- Publishing findings\n",
    "- Deploying to production\n",
    "- Regulatory compliance\n",
    "\n",
    "### The Critical Mistake: P-Hacking\n",
    "\n",
    "**P-hacking** = Running many tests until finding significant results, then reporting only those.\n",
    "\n",
    "Example:\n",
    "1. Try 20 different predictors\n",
    "2. Find 1 with p < 0.05\n",
    "3. Report only that one as \"significant\"\n",
    "4. Problem: Expected false positive rate is 1 in 20 at p=0.05!\n",
    "\n",
    "**Solution**: Proper methodology requires:\n",
    "- Pre-registration of hypotheses\n",
    "- Multiple comparison corrections (Bonferroni, FDR)\n",
    "- Replication on independent data\n",
    "- Transparent reporting of all tests performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration: The Danger of P-Hacking\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Simulate an experiment with NO real effect\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create random data for \"control\" and \"treatment\" groups\n",
    "# Both are drawn from the same distribution - NO TRUE DIFFERENCE\n",
    "control_group = np.random.normal(100, 15, 50)\n",
    "treatment_group = np.random.normal(100, 15, 50)  # Same parameters!\n",
    "\n",
    "# Run a t-test\n",
    "t_stat, p_value = stats.ttest_ind(control_group, treatment_group)\n",
    "\n",
    "print(\"Single Honest Test:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Control mean: {control_group.mean():.2f}\")\n",
    "print(f\"Treatment mean: {treatment_group.mean():.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Significant at Œ±=0.05? {p_value < 0.05}\")\n",
    "print(\"\\n‚úì This is proper methodology - one pre-specified test\\n\")\n",
    "\n",
    "# Now demonstrate p-hacking: try many different \"analyses\"\n",
    "print(\"\\nP-Hacking Demonstration:\")\n",
    "print(\"=\"*50)\n",
    "print(\"Trying 20 different 'analyses' on the same data...\\n\")\n",
    "\n",
    "significant_results = []\n",
    "\n",
    "for i in range(20):\n",
    "    # Each \"analysis\" uses different random subsets or transformations\n",
    "    # This simulates trying different predictors, subgroups, or transformations\n",
    "    \n",
    "    subset_size = np.random.randint(30, 50)\n",
    "    control_subset = np.random.choice(control_group, subset_size)\n",
    "    treatment_subset = np.random.choice(treatment_group, subset_size)\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(control_subset, treatment_subset)\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        significant_results.append((i+1, p_value))\n",
    "        print(f\"   Analysis {i+1}: p = {p_value:.4f} ‚ö†Ô∏è SIGNIFICANT!\")\n",
    "\n",
    "print(f\"\\n‚ùå Found {len(significant_results)} 'significant' results out of 20 tests\")\n",
    "print(f\"   Expected false positives at Œ±=0.05: ~{20*0.05:.0f}\")\n",
    "print(f\"\\n   This demonstrates why p-hacking is dangerous:\")\n",
    "print(f\"   We found 'significant' results even though there's NO real effect!\")\n",
    "print(f\"\\n   Proper correction (Bonferroni): Œ± = 0.05/20 = 0.0025\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Planning Your Research Approach\n",
    "\n",
    "You're tasked with analyzing customer churn for a subscription service. Decide whether each activity belongs in:\n",
    "- **Phase 1**: Exploratory Analysis\n",
    "- **Phase 2**: Rigorous Research\n",
    "- **Both**: Needed in both phases\n",
    "\n",
    "Activities:\n",
    "1. Creating visualizations of churn rates by customer segment\n",
    "2. Testing the hypothesis \"low engagement predicts churn\"\n",
    "3. Trying multiple machine learning algorithms\n",
    "4. Evaluating model performance on held-out test set\n",
    "5. Documenting data preprocessing steps\n",
    "6. Investigating outliers and anomalies\n",
    "7. Reporting confidence intervals for predictions\n",
    "8. Setting random seeds for reproducibility\n",
    "\n",
    "*Categorize each activity below:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Categorize research activities\n",
    "\n",
    "activities = {\n",
    "    1: \"Creating visualizations of churn rates by customer segment\",\n",
    "    2: \"Testing the hypothesis 'low engagement predicts churn'\",\n",
    "    3: \"Trying multiple machine learning algorithms\",\n",
    "    4: \"Evaluating model performance on held-out test set\",\n",
    "    5: \"Documenting data preprocessing steps\",\n",
    "    6: \"Investigating outliers and anomalies\",\n",
    "    7: \"Reporting confidence intervals for predictions\",\n",
    "    8: \"Setting random seeds for reproducibility\"\n",
    "}\n",
    "\n",
    "# TODO: Assign each activity to the appropriate phase\n",
    "# Use: 'Exploratory', 'Rigorous', or 'Both'\n",
    "\n",
    "your_categorization = {\n",
    "    1: \"???\",  # Replace ??? with your answer\n",
    "    2: \"???\",\n",
    "    3: \"???\",\n",
    "    4: \"???\",\n",
    "    5: \"???\",\n",
    "    6: \"???\",\n",
    "    7: \"???\",\n",
    "    8: \"???\"\n",
    "}\n",
    "\n",
    "# Print your categorization\n",
    "print(\"Your Research Activity Categorization:\")\n",
    "print(\"=\"*60)\n",
    "for num, activity in activities.items():\n",
    "    phase = your_categorization[num]\n",
    "    print(f\"{num}. {activity}\")\n",
    "    print(f\"   ‚Üí Phase: {phase}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Common Research Pitfalls\n",
    "\n",
    "Good methodology helps you avoid these systematic errors:\n",
    "\n",
    "### Top 5 Pitfalls in Data Science Research\n",
    "\n",
    "1. **Solving the Wrong Problem**\n",
    "   - Building technically correct solutions to misunderstood questions\n",
    "   - Prevention: Deep stakeholder engagement, clear problem formulation\n",
    "\n",
    "2. **Data Leakage**\n",
    "   - Using information from test data during training\n",
    "   - Prevention: Split data FIRST, fit preprocessing only on training data\n",
    "\n",
    "3. **Confusing Correlation and Causation**\n",
    "   - Claiming X causes Y based only on correlation\n",
    "   - Prevention: Causal diagrams, randomized experiments, domain expertise\n",
    "\n",
    "4. **Overfitting**\n",
    "   - Model performs well on training data but fails on new data\n",
    "   - Prevention: Cross-validation, regularization, simpler models\n",
    "\n",
    "5. **P-Hacking / Multiple Comparisons**\n",
    "   - Testing many hypotheses and reporting only significant ones\n",
    "   - Prevention: Pre-registration, multiple comparison corrections\n",
    "\n",
    "### How Methodology Helps\n",
    "\n",
    "Each pitfall has methodological solutions:\n",
    "\n",
    "| Pitfall | Methodological Solution |\n",
    "|---------|-------------------------|\n",
    "| Wrong problem | Systematic requirements gathering, stakeholder interviews |\n",
    "| Data leakage | Proper train/validation/test split protocols |\n",
    "| Correlation‚â†causation | Experimental design, causal inference frameworks |\n",
    "| Overfitting | Cross-validation, regularization, validation sets |\n",
    "| P-hacking | Pre-registration, Bonferroni correction, replication |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "‚úÖ **Research methodology** is the systematic framework guiding rigorous data science research\n",
    "\n",
    "‚úÖ **Methodology ‚â† Method ‚â† Technique** - these are different levels of abstraction\n",
    "\n",
    "‚úÖ **The scientific method** provides a time-tested framework: observe, question, hypothesize, experiment, analyze, conclude, communicate\n",
    "\n",
    "‚úÖ **Falsifiability** is essential - good hypotheses must be testable and potentially disprovable\n",
    "\n",
    "‚úÖ **Exploratory analysis** generates hypotheses; **rigorous research** tests them\n",
    "\n",
    "‚úÖ **Common pitfalls** (data leakage, p-hacking, correlation‚â†causation) have methodological solutions\n",
    "\n",
    "‚úÖ **Reproducibility requires** proper methodology from the start, not as an afterthought\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 01: Research Foundations and Paradigms**, you'll learn:\n",
    "- Positivist vs interpretivist vs pragmatic approaches\n",
    "- When to use quantitative, qualitative, or mixed methods\n",
    "- How philosophical frameworks shape research design\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- **Book**: \"The Book of Why\" by Judea Pearl (causal inference)\n",
    "- **Paper**: \"Leakage in Data Mining: Formulation, Detection, and Avoidance\" (Kaufman et al.)\n",
    "- **Guide**: NeurIPS Reproducibility Checklist\n",
    "- **Course**: \"Experimental Design and Analysis\" (MIT OpenCourseWare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Assessment\n",
    "\n",
    "Before moving to Module 01, ensure you can:\n",
    "\n",
    "- [ ] Define research methodology and distinguish it from methods and techniques\n",
    "- [ ] Explain why the reproducibility crisis matters\n",
    "- [ ] Identify confounding variables in correlation claims\n",
    "- [ ] Evaluate whether a hypothesis is testable/falsifiable\n",
    "- [ ] Distinguish exploratory analysis from rigorous research\n",
    "- [ ] Recognize common pitfalls (data leakage, p-hacking)\n",
    "- [ ] Describe the scientific method's application to data science\n",
    "\n",
    "If you can confidently check all boxes, you're ready for Module 01! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
