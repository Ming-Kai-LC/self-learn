{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 06: Reproducibility Crisis and Documentation Standards\n",
    "\n",
    "**Difficulty**: \u2b50\u2b50 (Intermediate)\n",
    "\n",
    "**Estimated Time**: 75 minutes\n",
    "\n",
    "**Prerequisites**: Module 05: Statistical Validation and Hypothesis Testing\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand the reproducibility crisis in ML-based science\n",
    "2. Apply the NeurIPS reproducibility checklist\n",
    "3. Implement comprehensive documentation standards\n",
    "4. Use version control effectively for research\n",
    "5. Create reproducible computational environments\n",
    "6. Design data preprocessing pipelines that prevent data leakage\n",
    "7. Document data lineage and transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print('\u2713 Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Reproducibility Crisis in ML-Based Science\n",
    "\n",
    "### Understanding the Scale\n",
    "\n",
    "The reproducibility crisis is a systemic problem in modern science.\n",
    "\n",
    "**Key Statistics:**\n",
    "\n",
    "- **Princeton Study**: 41 papers from 30 fields had reproducibility failures\n",
    "- **Cascading Impact**: These 41 papers affected 648 subsequent papers\n",
    "- **Nature 2016 Survey**: 70% of researchers couldn't reproduce others' work\n",
    "- **Self-Reproducibility**: Over 50% couldn't reproduce their own work\n",
    "- **Root Cause**: Data leakage is the most pervasive cause\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "Irreproducible research has serious consequences:\n",
    "1. Wasted resources building on flawed findings\n",
    "2. Scientific community moves in wrong directions\n",
    "3. The scientific method breaks down\n",
    "4. Loss of public trust in science\n",
    "5. Real-world harm in applied domains (medicine, autonomous systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "categories = ['Flawed Papers', 'Papers Affected']\n",
    "values = [41, 648]\n",
    "colors = ['#e74c3c', '#c0392b']\n",
    "\n",
    "axes[0, 0].bar(categories, values, color=colors, edgecolor='black', linewidth=2)\n",
    "axes[0, 0].set_ylabel('Number of Papers', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_title('Princeton Study: Cascading Effects', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylim(0, 700)\n",
    "\n",
    "for i, val in enumerate(values):\n",
    "    axes[0, 0].text(i, val + 20, str(val), ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "axes[0, 1].bar([1, 2], [30, 50], color=['#e74c3c', '#e74c3c'], edgecolor='black', linewidth=2)\n",
    "axes[0, 1].set_xticks([1, 2])\n",
    "axes[0, 1].set_xticklabels(['Reproduce Others', 'Reproduce Own'])\n",
    "axes[0, 1].set_ylabel('Success Rate (%)', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_title('Nature 2016: Success Rates', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylim(0, 100)\n",
    "\n",
    "causes = ['Data Leakage', 'Poor Docs', 'Missing Params', 'No Seed', 'Env Variation']\n",
    "freqs = [45, 28, 18, 12, 10]\n",
    "\n",
    "axes[1, 0].barh(causes, freqs, color=['#e74c3c', '#e67e22', '#f39c12', '#f1c40f', '#2ecc71'], edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Frequency (%)', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_title('Common Causes of Irreproducibility', fontsize=12, fontweight='bold')\n",
    "\n",
    "years = [2019, 2020, 2021, 2022, 2023, 2024]\n",
    "adoption = [15, 32, 48, 65, 78, 88]\n",
    "\n",
    "axes[1, 1].plot(years, adoption, marker='o', linewidth=3, markersize=10, color='#3498db')\n",
    "axes[1, 1].set_xlabel('Year', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Papers with Checklist (%)', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_title('NeurIPS Checklist Adoption', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylim(0, 100)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Reproducibility crisis declining with better standards!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The NeurIPS Reproducibility Checklist\n",
    "\n",
    "### The Seven Core Requirements\n",
    "\n",
    "**1. Claims Accuracy** - All claims must match actual findings\n",
    "\n",
    "**2. Limitations Documentation** - Clearly acknowledge assumptions and limitations\n",
    "\n",
    "**3. Experimental Reproducibility** - Sufficient detail for others to replicate\n",
    "\n",
    "**4. Open Access** - Make data and code publicly available\n",
    "\n",
    "**5. Experimental Settings** - Report all hyperparameters and hardware specs\n",
    "\n",
    "**6. Statistical Significance** - Results with confidence intervals and error bars\n",
    "\n",
    "**7. Compute Resources** - Report training time, memory, GPU hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Research Documentation Standards\n",
    "\n",
    "### The Core Principle\n",
    "\n",
    "**'If methods cannot be reproduced from documentation alone, the documentation is insufficient.'**\n",
    "\n",
    "### What to Document\n",
    "\n",
    "**Electronic Lab Notebooks:**\n",
    "- Date and time of work\n",
    "- Detailed methods for colleague replication\n",
    "- Equipment settings and procedures\n",
    "- Deviations from protocol\n",
    "- Negative results\n",
    "- Links to raw data with versions\n",
    "\n",
    "**Data Dictionary:**\n",
    "- Short and long variable names\n",
    "- Format and units\n",
    "- Allowable values\n",
    "- Complete definitions\n",
    "\n",
    "**Data Lineage:**\n",
    "- Source of origin\n",
    "- All transformations in order\n",
    "- Processing pipeline steps\n",
    "- Version information\n",
    "- Software dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pd.DataFrame({\n",
    "    'Short Name': ['cust_id', 'age', 'tenure', 'churn', 'charges'],\n",
    "    'Long Name': ['Customer ID', 'Age', 'Months with Company', 'Churn Status', 'Monthly Charges'],\n",
    "    'Format': ['Integer 6 digits', 'Integer 18-80', 'Integer 0-72', 'Binary 0/1', 'Decimal 2 places'],\n",
    "    'Units': ['ID', 'Years', 'Months', 'Binary', 'USD/month'],\n",
    "    'Definition': ['Unique customer ID', 'Age at extraction', 'Months with account', 'Stopped service (1=yes)', 'Monthly charges billed']\n",
    "})\n",
    "\n",
    "print('DATA DICTIONARY EXAMPLE')\n",
    "print('='*100)\n",
    "print(data_dict.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Code Reproducibility and Environment Management\n",
    "\n",
    "### The Cardinal Rule\n",
    "\n",
    "**'Fit preprocessing transformations ONLY on training data. Never use test set statistics.'**\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "Using test set information in preprocessing is DATA LEAKAGE\u2014one of the top causes of irreproducibility.\n",
    "\n",
    "### Common Data Leakage Sources\n",
    "\n",
    "1. Preprocessing before train-test split\n",
    "2. Using future information (time series)\n",
    "3. Including proxy variables\n",
    "4. Improper group handling\n",
    "5. Feature selection on full dataset\n",
    "\n",
    "### The Seven-Step Data Preprocessing Workflow\n",
    "\n",
    "1. Data Acquisition\n",
    "2. Library Import\n",
    "3. Data Loading & Inspection\n",
    "4. Missing Value Handling (fit training only)\n",
    "5. Categorical Encoding (fit training only)\n",
    "6. Feature Scaling (fit training only)\n",
    "7. Data Splitting (do this FIRST!)\n",
    "\n",
    "**Critical Order**: Split data FIRST (step 7), then apply steps 4-6 ONLY to training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "X_raw = np.random.randn(100, 3) * 10 + np.array([100, 50, 20])\n",
    "\n",
    "print('INCORRECT APPROACH (DATA LEAKAGE):')\n",
    "print('='*60)\n",
    "scaler_wrong = StandardScaler()\n",
    "X_scaled = scaler_wrong.fit_transform(X_raw)\n",
    "X_train, X_test = train_test_split(X_scaled, test_size=0.2, random_state=42)\n",
    "print('Problem: Scaler fit on ALL data (includes test set)')\n",
    "print('Result: Test statistics influenced the scaler!\\n')\n",
    "\n",
    "print('CORRECT APPROACH (NO LEAKAGE):')\n",
    "print('='*60)\n",
    "X_train, X_test = train_test_split(X_raw, test_size=0.2, random_state=42)\n",
    "scaler_correct = StandardScaler()\n",
    "X_train_scaled = scaler_correct.fit_transform(X_train)\n",
    "X_test_scaled = scaler_correct.transform(X_test)\n",
    "print('Solution: Scaler fit ONLY on training data')\n",
    "print('Result: Test data never influences the scaler!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Version Control for Reproducible Research\n",
    "\n",
    "### Why Git Matters\n",
    "\n",
    "- Creates audit trails of changes\n",
    "- Enables rollback to working versions\n",
    "- Documents decisions through commit messages\n",
    "- Facilitates collaboration\n",
    "- Enables reproducibility at specific commits\n",
    "\n",
    "### Repository Best Practices\n",
    "\n",
    "**Track (\u2713):**\n",
    "- Notebooks without outputs\n",
    "- Scripts and source code\n",
    "- Sample data <10MB\n",
    "- README and documentation\n",
    "- Requirements.txt and environment.yml\n",
    "\n",
    "**Ignore (\u274c):**\n",
    "- Notebook outputs\n",
    "- Large datasets >10MB\n",
    "- Virtual environments\n",
    "- Cache files\n",
    "- Credentials and secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exercise 1: Create a Reproducibility Checklist\n",
    "\n",
    "You're submitting a paper 'Deep Learning for Time Series' to NeurIPS.\n",
    "\n",
    "**Current Status:**\n",
    "- \u2713 Code on GitHub\n",
    "- \u2713 Random seeds set\n",
    "- \u2717 No confidence intervals (only mean: 94.3%)\n",
    "- \u2717 Training time not documented (48 hours)\n",
    "- \u2713 Limitations described\n",
    "- \u2717 No setup instructions on GitHub\n",
    "\n",
    "**Task**: Analyze which reproducibility items are complete and what needs fixing before publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EXERCISE 1: REPRODUCIBILITY CHECKLIST')\n",
    "print('='*70)\n",
    "print('\\nReview the paper status above.')\n",
    "print('\\nQuestions to answer:')\n",
    "print('1. Which items are clearly complete?')\n",
    "print('2. What is preventing publication readiness?')\n",
    "print('3. What priority order for fixes?')\n",
    "print('4. Which checklist items need most work?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exercise 2: Write a Data Dictionary\n",
    "\n",
    "Create a data dictionary for house price prediction with variables:\n",
    "- sqft: Square footage\n",
    "- beds: Number of bedrooms\n",
    "- price: Sale price\n",
    "- zip: Postal code\n",
    "- year: Year built\n",
    "- cond: Condition rating\n",
    "\n",
    "Include short names, long names, format, units, and definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EXERCISE 2: DATA DICTIONARY')\n",
    "print('='*70)\n",
    "print('\\nCreate a DataFrame with columns:')\n",
    "print('- Short Name, Long Name, Format, Units, Definition')\n",
    "print('\\nFor variables: sqft, beds, price, zip, year, cond')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exercise 3: Identify Data Leakage\n",
    "\n",
    "Analyze three scenarios:\n",
    "\n",
    "**Scenario A**: Impute missing values on full dataset, then split\n",
    "\n",
    "**Scenario B**: Split first, then select features using training only\n",
    "\n",
    "**Scenario C**: Use information from AFTER the prediction time\n",
    "\n",
    "For each: (1) Has leakage? (2) Why? (3) How to fix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EXERCISE 3: DATA LEAKAGE ANALYSIS')\n",
    "print('='*70)\n",
    "print('\\nAnalyze each scenario for data leakage:')\n",
    "print('\\nScenario A: Preprocess all, then split')\n",
    "print('  - Has leakage? YES/NO')\n",
    "print('  - Why?')\n",
    "print('  - Fix?')\n",
    "print('\\nScenario B: Split, then feature select on training')\n",
    "print('  - Has leakage? YES/NO')\n",
    "print('  - Why?')\n",
    "print('  - Fix?')\n",
    "print('\\nScenario C: Use future information')\n",
    "print('  - Has leakage? YES/NO')\n",
    "print('  - Why?')\n",
    "print('  - Fix?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "\u2705 **Reproducibility Crisis**: 70% of researchers can't reproduce others' work; data leakage is primary cause\n",
    "\n",
    "\u2705 **NeurIPS Checklist**: Seven requirements (claims, limitations, experimental details, open access, settings, statistics, compute)\n",
    "\n",
    "\u2705 **Documentation**: Electronic lab notebooks, data dictionaries, READMEs, data lineage\n",
    "\n",
    "\u2705 **Environment**: Specify Python/library versions, set random seeds, document dependencies\n",
    "\n",
    "\u2705 **Data Leakage Prevention**: Cardinal rule\u2014fit preprocessing ONLY on training data\n",
    "\n",
    "\u2705 **Version Control**: Use Git for audit trails, track code/data/docs, ignore outputs/secrets\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Module 07: Literature Review Methodologies** covers:\n",
    "- Systematic reviews (PRISMA 2020)\n",
    "- Scoping reviews (JBI methodology)\n",
    "- Meta-analysis techniques\n",
    "- Risk of bias assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Assessment\n",
    "\n",
    "Before Module 07, ensure you can:\n",
    "\n",
    "- [ ] Explain the reproducibility crisis and causes\n",
    "- [ ] Apply the NeurIPS seven-item checklist\n",
    "- [ ] Create comprehensive data dictionaries\n",
    "- [ ] Document data lineage and transformations\n",
    "- [ ] Set up reproducible environments\n",
    "- [ ] Prevent data leakage in preprocessing\n",
    "- [ ] Use version control for research\n",
    "- [ ] Write clear README files\n",
    "- [ ] Report results with uncertainty measures\n",
    "\n",
    "If all boxes checked, you're ready for Module 07! \ud83c\udf89"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}