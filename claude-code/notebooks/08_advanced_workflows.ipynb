{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## 12. Additional Resources\n\n### Official Documentation\n\n**Claude Code Documentation**:\n- [Skills Guide](https://docs.anthropic.com/claude-code/skills) - Creating and using skills\n- [Commands Reference](https://docs.anthropic.com/claude-code/commands) - Slash command documentation\n- [Hooks Documentation](https://docs.anthropic.com/claude-code/hooks) - Hook system and examples\n- [MCP Servers](https://docs.anthropic.com/claude-code/mcp) - Model Context Protocol integrations\n- [Subagents Guide](https://docs.anthropic.com/claude-code/subagents) - Multi-agent orchestration\n\n---\n\n### Python Libraries for Workflows\n\n**Concurrency and Parallelism**:\n- [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) - Thread/process pools\n- [asyncio](https://docs.python.org/3/library/asyncio.html) - Async programming\n- [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) - Process-based parallelism\n\n**Error Handling and Resilience**:\n- [tenacity](https://github.com/jd/tenacity) - Retry library\n- [pybreaker](https://github.com/danielfm/pybreaker) - Circuit breaker implementation\n- [retrying](https://github.com/rholder/retrying) - Retry decorator\n\n**Workflow Orchestration**:\n- [Prefect](https://www.prefect.io/) - Modern workflow orchestration\n- [Apache Airflow](https://airflow.apache.org/) - Workflow management platform\n- [Luigi](https://github.com/spotify/luigi) - Python workflow engine\n- [Celery](https://docs.celeryproject.org/) - Distributed task queue\n\n**Caching**:\n- [functools.lru_cache](https://docs.python.org/3/library/functools.html#functools.lru_cache) - Built-in memoization\n- [cachetools](https://github.com/tkem/cachetools) - Extensible caching\n- [diskcache](https://github.com/grantjenks/python-diskcache) - Disk-based cache\n- [Redis](https://redis.io/) - In-memory data store\n\n---\n\n### Books and Articles\n\n**Books**:\n- \"Release It!\" by Michael Nygard - Resilience patterns\n- \"Site Reliability Engineering\" by Google - SRE practices\n- \"Designing Data-Intensive Applications\" by Martin Kleppmann - System design\n- \"The DevOps Handbook\" by Gene Kim - DevOps practices\n\n**Articles**:\n- [Martin Fowler: Circuit Breaker](https://martinfowler.com/bliki/CircuitBreaker.html)\n- [AWS: Retry Strategies](https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/)\n- [Google: Graceful Degradation](https://landing.google.com/sre/sre-book/chapters/addressing-cascading-failures/)\n- [Netflix: Chaos Engineering](https://netflixtechblog.com/chaos-engineering-upgraded-878d341f15fa)\n\n---\n\n### Open Source Examples\n\n**Study real-world workflows**:\n\n1. **GitHub Actions Workflows**:\n   - Search for `.github/workflows/` in popular repos\n   - See CI/CD patterns in action\n   - Learn from mature workflows\n\n2. **GitLab CI Examples**:\n   - [GitLab CI/CD Examples](https://docs.gitlab.com/ee/ci/examples/)\n   - Multi-stage pipelines\n   - Environment-specific deployments\n\n3. **Jenkins Pipelines**:\n   - [Jenkins Pipeline Examples](https://www.jenkins.io/doc/pipeline/examples/)\n   - Declarative and scripted pipelines\n   - Integration patterns\n\n---\n\n### Community Resources\n\n**Forums and Communities**:\n- [Claude Code Community](https://community.anthropic.com/) - Official community\n- [r/devops](https://www.reddit.com/r/devops/) - DevOps discussions\n- [DevOps Stack Exchange](https://devops.stackexchange.com/) - Q&A\n- [SRE Weekly Newsletter](https://sreweekly.com/) - Weekly SRE content\n\n**Discord/Slack Communities**:\n- Claude Code Discord - Get help from other users\n- DevOps Chat - Community discussions\n- Platform Engineering - Emerging practices\n\n---\n\n### Tools and Platforms\n\n**CI/CD Platforms**:\n- GitHub Actions - Integrated with GitHub\n- GitLab CI/CD - Full DevOps platform\n- Jenkins - Open source automation server\n- CircleCI - Cloud-based CI/CD\n- Travis CI - GitHub integration\n\n**Monitoring and Observability**:\n- Prometheus - Metrics collection\n- Grafana - Visualization\n- Datadog - Full-stack monitoring\n- New Relic - APM platform\n- Sentry - Error tracking\n\n**Infrastructure as Code**:\n- Terraform - Multi-cloud IaC\n- Pulumi - Modern IaC\n- Ansible - Configuration management\n- CloudFormation - AWS native\n\n---\n\n### Practice Resources\n\n**Hands-on Labs**:\n- [Katacoda](https://www.katacoda.com/) - Interactive learning scenarios\n- [GitHub Learning Lab](https://lab.github.com/) - Hands-on tutorials\n- [AWS Workshops](https://workshops.aws/) - Cloud automation\n- [Google Cloud Skills Boost](https://www.cloudskillsboost.google/) - GCP training\n\n**Coding Practice**:\n- Automate your daily tasks\n- Contribute to open source CI/CD\n- Build a personal automation library\n- Share workflows on GitHub\n\n---\n\n### Related Modules in This Course\n\n**Prerequisites** (review if needed):\n- [Module 03: Skills](03_working_with_skills.ipynb) - Skill system basics\n- [Module 04: Commands](04_custom_slash_commands.ipynb) - Creating commands\n- [Module 05: Hooks](05_hooks_automation.ipynb) - Automation hooks\n- [Module 06: MCP](06_mcp_servers_integrations.ipynb) - External integrations\n- [Module 07: Subagents](07_subagents_orchestration.ipynb) - Multi-agent patterns\n\n**Next Steps**:\n- Module 09: Production Best Practices (Coming soon)\n- Module 10: Advanced MCP Integrations (Coming soon)\n\n---\n\n### Getting Help\n\n**When you're stuck**:\n\n1. **Check the documentation** - Most answers are there\n2. **Search the community** - Others likely had the same issue\n3. **Create minimal examples** - Simplify to isolate the problem\n4. **Ask for help** - Community is friendly and helpful\n5. **Share your solution** - Help others learn\n\n---\n\n**You've completed Module 08!** üéâ\n\nYou now have the knowledge to build production-grade workflows combining skills, commands, hooks, subagents, and MCP integrations. Practice with the exercises, build real projects, and share your learnings with the community.\n\n**Happy automating!** üöÄ\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 11. What's Next?\n\n### Module 09: Production Best Practices (Coming Soon)\n\nIn the next module, you'll learn how to take your workflows to production:\n\n**Topics covered**:\n- **Observability**: Logging, metrics, tracing\n- **Testing**: Unit tests for workflows\n- **Configuration Management**: Environment-specific settings\n- **Secret Management**: Secure credential handling\n- **Monitoring**: Health checks, alerting\n- **Documentation**: Workflow documentation standards\n- **Team Collaboration**: Sharing workflows across teams\n\n---\n\n### Recommended Learning Path\n\n**If you want to go deeper on specific topics**:\n\n1. **More on Error Handling** ‚Üí Study resilience patterns:\n   - Bulkhead pattern\n   - Timeout strategies\n   - Fallback mechanisms\n   - Chaos engineering\n\n2. **More on Performance** ‚Üí Advanced optimization:\n   - Process pools vs thread pools\n   - Async/await patterns\n   - Memory profiling\n   - Bottleneck analysis\n\n3. **More on Integration** ‚Üí External systems:\n   - REST API integration\n   - Message queues (RabbitMQ, Kafka)\n   - Webhook handling\n   - Event-driven architectures\n\n4. **More on Testing** ‚Üí Workflow testing:\n   - Integration testing\n   - End-to-end testing\n   - Performance testing\n   - Chaos testing\n\n---\n\n### Practice Projects\n\n**Build these to reinforce your learning**:\n\n1. **Personal DevOps Dashboard**\n   - Aggregate data from GitHub, CI/CD, monitoring\n   - Visualize team metrics\n   - Alert on anomalies\n\n2. **Automated Content Pipeline**\n   - Process images/videos\n   - Generate thumbnails\n   - Optimize for web\n   - Deploy to CDN\n\n3. **Multi-Cloud Backup System**\n   - Backup to multiple providers\n   - Verify backup integrity\n   - Automate retention policies\n   - Test restore procedures\n\n4. **Code Quality Dashboard**\n   - Track metrics over time\n   - Identify trends\n   - Suggest improvements\n   - Celebrate wins\n\n---\n\n### Next Steps\n\n**Immediate actions**:\n\n1. **Review your current workflows**\n   - Which could benefit from automation?\n   - Where are manual bottlenecks?\n   - What fails frequently?\n\n2. **Start small**\n   - Pick one repetitive task\n   - Automate just that\n   - Iterate and improve\n\n3. **Share with your team**\n   - Document your workflows\n   - Teach others\n   - Get feedback\n   - Collaborate on improvements\n\n4. **Keep learning**\n   - Study production workflows in open source\n   - Read case studies\n   - Experiment with new patterns\n   - Share your learnings\n\n---\n\n**Remember**: The best workflow is one that's actually used. Start simple, prove value, then expand.\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Summary\n\n### Key Takeaways\n\n**1. Workflow Integration Patterns**\n\nYou learned how to combine Claude Code components:\n- **Skills**: Provide domain expertise\n- **Commands**: Trigger workflows\n- **Hooks**: Enforce standards\n- **Subagents**: Parallel execution\n- **MCP**: External integrations\n\n**Integration creates powerful automation** that's greater than the sum of its parts.\n\n---\n\n**2. Error Handling Strategies**\n\nFour essential patterns:\n- **Fail Fast**: Validate early, save time\n- **Retry with Backoff**: Handle transient failures\n- **Circuit Breaker**: Prevent cascading failures\n- **Transactional Rollback**: Undo on error\n\n**Good error messages** include what failed, why, and how to fix it.\n\n---\n\n**3. Performance Optimization**\n\nFive key techniques:\n- **Parallel Execution**: Run independent tasks simultaneously (4x speedup)\n- **Sequential Execution**: Maintain order for dependencies\n- **Caching**: Avoid repeating expensive operations (10-100x speedup)\n- **Resource Management**: Prevent system overload\n- **Thread Safety**: Protect shared state\n\n**Choose the right strategy** based on task dependencies and resources.\n\n---\n\n**4. Real-World Applications**\n\nFour complete workflow examples:\n1. **PR Review**: Automated code review with parallel checks\n2. **CI/CD Pipeline**: Build, test, and deploy with validation\n3. **Documentation**: Generate and maintain project docs\n4. **Database Migration**: Safe schema changes with rollback\n\n**Production workflows** combine multiple patterns with robust error handling.\n\n---\n\n### Integration Patterns Summary\n\n| Pattern | Components | Use Case | Complexity |\n|---------|-----------|----------|------------|\n| **Skill + Command** | Expertise + Trigger | Code generation, analysis | ‚≠ê |\n| **Command + Hook** | Trigger + Validation | Quality gates, compliance | ‚≠ê‚≠ê |\n| **Skill + Command + Hook** | Full stack | Release automation | ‚≠ê‚≠ê‚≠ê |\n| **Multi-Agent + MCP** | Parallel + External | PR review, CI/CD | ‚≠ê‚≠ê‚≠ê |\n| **Full Workflow** | All components | Production deployment | ‚≠ê‚≠ê‚≠ê |\n\n---\n\n### Performance Comparison\n\n| Strategy | Speed | Complexity | Best For |\n|----------|-------|------------|----------|\n| **Sequential** | 1x | Low | Dependent tasks |\n| **Parallel (4 cores)** | ~4x | Medium | Independent tasks |\n| **Cached** | 10-100x | Medium | Repeated operations |\n| **Mixed** | Varies | High | Complex workflows |\n\n---\n\n### What You Can Build Now\n\nWith the skills from this module, you can create:\n\n‚úÖ **Automated Development Workflows**\n- Code review automation\n- Quality gate enforcement\n- Release preparation\n- Documentation generation\n\n‚úÖ **CI/CD Pipelines**\n- Multi-stage testing\n- Parallel builds\n- Environment-specific deployments\n- Automatic rollbacks\n\n‚úÖ **Monitoring and Maintenance**\n- Health check systems\n- Performance monitoring\n- Security audits\n- Backup automation\n\n‚úÖ **Custom Workflows**\n- Any multi-step automation\n- Integration with external systems\n- Error handling and recovery\n- Performance-optimized execution\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 9. Practice Exercises\n\nTest your understanding with these challenging workflow exercises. Each combines multiple concepts from this module.\n\n---\n\n### Exercise 9.1: Multi-Service Health Check Workflow ‚≠ê‚≠ê\n\n**Goal**: Build a workflow that monitors multiple services and alerts on failures.\n\n**Requirements**:\n- Check 5+ services in parallel (API, database, cache, queue, storage)\n- Retry failed checks with exponential backoff\n- Use circuit breaker for repeatedly failing services\n- Generate health report with status dashboard\n- Send notifications for critical failures\n\n**Skills practiced**:\n- Parallel execution\n- Error handling\n- Circuit breaker pattern\n- Logging and notification\n\n---\n\n### Exercise 9.2: Automated Code Refactoring Pipeline ‚≠ê‚≠ê‚≠ê\n\n**Goal**: Create a workflow that automatically refactors code across a codebase.\n\n**Requirements**:\n- Scan codebase for refactoring opportunities\n- Apply refactorings in parallel (rename, extract function, etc.)\n- Run tests after each refactoring\n- Rollback if tests fail\n- Generate refactoring report\n- Create git commit with changes\n\n**Skills practiced**:\n- Workflow orchestration\n- Transaction management\n- Testing integration\n- Git automation\n\n---\n\n### Exercise 9.3: Dynamic Resource Scaling Workflow ‚≠ê‚≠ê‚≠ê\n\n**Goal**: Build a workflow that scales resources based on load.\n\n**Requirements**:\n- Monitor system metrics (CPU, memory, requests/sec)\n- Decide when to scale up/down\n- Apply scaling changes with zero downtime\n- Validate new instances are healthy\n- Update load balancer configuration\n- Log all scaling events\n\n**Skills practiced**:\n- Performance optimization\n- Resource management\n- Validation and health checks\n- Logging\n\n---\n\n### Exercise 9.4: Comprehensive Security Audit Workflow ‚≠ê‚≠ê‚≠ê\n\n**Goal**: Create a complete security audit workflow.\n\n**Requirements**:\n- Scan for multiple vulnerability types in parallel:\n  - Dependency vulnerabilities (npm audit, pip-audit)\n  - Code security issues (Bandit, semgrep)\n  - Secret detection (gitleaks)\n  - Container vulnerabilities (if using Docker)\n- Categorize issues by severity\n- Block deployment if critical issues found\n- Generate detailed security report\n- Track issue resolution over time\n\n**Skills practiced**:\n- Parallel execution\n- Error handling\n- Integration with external tools\n- Reporting\n\n---\n\n### Exercise 9.5: Multi-Environment Deployment Workflow ‚≠ê‚≠ê‚≠ê\n\n**Goal**: Build a production-grade deployment workflow with multiple environments.\n\n**Requirements**:\n- Deploy to: dev ‚Üí staging ‚Üí canary ‚Üí production\n- Run environment-specific tests at each stage\n- Require manual approval before production\n- Support rollback at any stage\n- Monitor metrics after deployment\n- Automatically rollback if error rate increases\n- Send deployment notifications\n\n**Skills practiced**:\n- Sequential workflow with validation\n- Error handling and rollback\n- Monitoring integration\n- Notification system\n\n---\n\n### Challenge Exercise 9.6: Build Your Own Workflow ‚≠ê‚≠ê‚≠ê\n\n**Goal**: Design and implement a workflow for your own use case.\n\n**Suggestions**:\n- Blog post publishing pipeline (write ‚Üí review ‚Üí optimize images ‚Üí deploy)\n- Data pipeline (extract ‚Üí transform ‚Üí load ‚Üí validate)\n- Backup automation (backup ‚Üí verify ‚Üí upload ‚Üí cleanup old backups)\n- Content moderation (scan ‚Üí classify ‚Üí review ‚Üí publish/reject)\n- Report generation (gather data ‚Üí analyze ‚Üí generate charts ‚Üí email)\n\n**Requirements**:\n- Use at least 4 different patterns from this module\n- Include error handling and rollback\n- Add performance optimization (parallel or caching)\n- Generate comprehensive status reports\n- Document your workflow design\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Example 4: Database Migration (Complete Implementation)\n\nclass DatabaseMigrationWorkflow:\n    \"\"\"Safe database migration with automatic rollback.\"\"\"\n    \n    def __init__(self):\n        self.transaction = WorkflowTransaction()\n        self.backups = []\n    \n    def create_backup(self, environment):\n        \"\"\"Create database backup.\"\"\"\n        print(f\"  üíæ Creating backup for {environment}...\")\n        time.sleep(0.5)\n        \n        backup_file = f\"backup_{environment}_{int(time.time())}.sql\"\n        self.backups.append(backup_file)\n        \n        self.transaction.record_change('create_backup', {\n            'environment': environment,\n            'backup_file': backup_file\n        })\n        \n        print(f\"     Backup saved: {backup_file}\")\n        return backup_file\n    \n    def test_migration_syntax(self, migration_file):\n        \"\"\"Validate migration SQL syntax.\"\"\"\n        print(f\"  üîç Testing migration syntax...\")\n        time.sleep(0.3)\n        \n        # Simulate syntax check\n        return {'valid': True, 'errors': []}\n    \n    def apply_migration(self, environment, migration_file):\n        \"\"\"Apply migration to database.\"\"\"\n        print(f\"  üîÑ Applying migration to {environment}...\")\n        time.sleep(0.8)\n        \n        # Simulate migration steps\n        steps = [\n            \"Creating new table: user_sessions\",\n            \"Adding column: users.last_login\",\n            \"Creating index: idx_users_email\",\n            \"Migrating existing data\"\n        ]\n        \n        for step in steps:\n            print(f\"     {step}\")\n            time.sleep(0.2)\n        \n        self.transaction.record_change('apply_migration', {\n            'environment': environment,\n            'migration': migration_file\n        })\n        \n        return {'success': True, 'rows_affected': 15000}\n    \n    def validate_data_integrity(self, environment):\n        \"\"\"Validate data after migration.\"\"\"\n        print(f\"  ‚úÖ Validating data integrity...\")\n        time.sleep(0.5)\n        \n        # Simulate integrity checks\n        checks = [\n            {'check': 'Foreign key constraints', 'passed': True},\n            {'check': 'Null value constraints', 'passed': True},\n            {'check': 'Data type consistency', 'passed': True},\n            {'check': 'Row count validation', 'passed': True}\n        ]\n        \n        all_passed = all(c['passed'] for c in checks)\n        \n        for check in checks:\n            status = \"‚úì\" if check['passed'] else \"‚úó\"\n            print(f\"     {status} {check['check']}\")\n        \n        return {\n            'valid': all_passed,\n            'checks': checks\n        }\n    \n    def run_smoke_tests_db(self, environment):\n        \"\"\"Run application smoke tests against migrated DB.\"\"\"\n        print(f\"  üí® Running smoke tests...\")\n        time.sleep(0.4)\n        \n        tests = ['User login', 'Data retrieval', 'Write operations']\n        \n        for test in tests:\n            print(f\"     ‚úì {test}\")\n        \n        return {'passed': 3, 'failed': 0}\n    \n    def rollback_migration(self, environment, backup_file):\n        \"\"\"Rollback to backup if migration fails.\"\"\"\n        print(f\"\\n  ‚è™ Rolling back {environment} to backup...\")\n        time.sleep(0.6)\n        \n        print(f\"     Restoring from: {backup_file}\")\n        print(f\"     Database restored to pre-migration state\")\n        \n        return {'success': True}\n    \n    def run_migration(self, migration_file, test_on_staging=True):\n        \"\"\"Execute complete migration workflow.\"\"\"\n        print(f\"\\nüóÑÔ∏è  Starting Database Migration Workflow\\n\")\n        print(f\"Migration: {migration_file}\")\n        print(\"=\" * 60)\n        \n        try:\n            # Step 1: Validate syntax\n            print(\"\\nStep 1: Syntax Validation\")\n            print(\"-\" * 60)\n            syntax = self.test_migration_syntax(migration_file)\n            if not syntax['valid']:\n                raise Exception(f\"Invalid SQL: {syntax['errors']}\")\n            print(\"‚úÖ Migration syntax valid\\n\")\n            \n            # Step 2: Staging migration (optional but recommended)\n            if test_on_staging:\n                print(\"Step 2: Staging Environment\")\n                print(\"-\" * 60)\n                \n                staging_backup = self.create_backup('staging')\n                \n                result = self.apply_migration('staging', migration_file)\n                print(f\"‚úÖ Migration applied ({result['rows_affected']} rows affected)\")\n                \n                validation = self.validate_data_integrity('staging')\n                if not validation['valid']:\n                    raise Exception(\"Data integrity check failed on staging\")\n                print(\"‚úÖ Data integrity validated\")\n                \n                smoke = self.run_smoke_tests_db('staging')\n                if smoke['failed'] > 0:\n                    raise Exception(f\"{smoke['failed']} smoke tests failed\")\n                print(f\"‚úÖ Smoke tests passed ({smoke['passed']}/{smoke['passed']})\\n\")\n            \n            # Step 3: Production migration\n            print(\"Step 3: Production Environment\")\n            print(\"-\" * 60)\n            \n            # Create backup BEFORE migration\n            prod_backup = self.create_backup('production')\n            \n            # Apply migration\n            result = self.apply_migration('production', migration_file)\n            print(f\"‚úÖ Migration applied ({result['rows_affected']} rows affected)\")\n            \n            # Validate\n            validation = self.validate_data_integrity('production')\n            if not validation['valid']:\n                print(\"‚ùå Data integrity check failed!\")\n                print(\"   Initiating rollback...\")\n                self.rollback_migration('production', prod_backup)\n                raise Exception(\"Migration rolled back due to validation failure\")\n            \n            print(\"‚úÖ Data integrity validated\")\n            \n            # Final smoke tests\n            smoke = self.run_smoke_tests_db('production')\n            if smoke['failed'] > 0:\n                print(f\"‚ùå {smoke['failed']} smoke tests failed!\")\n                print(\"   Initiating rollback...\")\n                self.rollback_migration('production', prod_backup)\n                raise Exception(\"Migration rolled back due to test failures\")\n            \n            print(f\"‚úÖ Smoke tests passed ({smoke['passed']}/{smoke['passed']})\")\n            \n            # Commit transaction\n            self.transaction.commit()\n            \n            # Success summary\n            print(\"\\n\" + \"=\" * 60)\n            print(\"Migration Summary:\")\n            print(\"=\" * 60)\n            print(f\"‚úÖ Status: SUCCESS\")\n            print(f\"üìä Rows affected: {result['rows_affected']:,}\")\n            print(f\"üíæ Backups created: {len(self.backups)}\")\n            print(f\"‚úÖ All integrity checks passed\")\n            print(f\"‚úÖ All smoke tests passed\")\n            \n            if test_on_staging:\n                print(f\"\\nüß™ Tested on staging first: Yes\")\n            \n            print(f\"\\nüí° Tip: Keep backups for 7 days before cleanup\")\n            \n            return {\n                'status': 'success',\n                'rows_affected': result['rows_affected'],\n                'backups': self.backups\n            }\n            \n        except Exception as e:\n            print(f\"\\n‚ùå Migration failed: {e}\")\n            print(\"\\nüîÑ Transaction rolled back\")\n            self.transaction.rollback()\n            \n            print(f\"\\nüíæ Backups available for manual recovery:\")\n            for backup in self.backups:\n                print(f\"   - {backup}\")\n            \n            raise\n\n# Test database migration workflow\nmigration = DatabaseMigrationWorkflow()\n\ntry:\n    result = migration.run_migration(\n        \"migrations/001_add_user_sessions.sql\",\n        test_on_staging=True\n    )\nexcept Exception as e:\n    print(f\"\\nWorkflow stopped due to error: {e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Example 4: Database Migration Workflow\n\n**Goal**: Safely migrate database schema with zero downtime.\n\n**Components**:\n- Transaction: Rollback on failure\n- Error handling: Backup before migration\n- Validation: Test migration on staging first\n\n**Workflow steps**:\n1. Backup database\n2. Test migration on staging\n3. Apply migration to production\n4. Validate data integrity\n5. Rollback if validation fails\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Example 3: Documentation Generation (Complete Implementation)\n\nclass DocumentationWorkflow:\n    \"\"\"Automated documentation generation and updates.\"\"\"\n    \n    def analyze_codebase(self, source_dir=\".\"):\n        \"\"\"Analyze codebase structure.\"\"\"\n        print(\"  üìÇ Analyzing codebase structure...\")\n        time.sleep(0.3)\n        \n        # Simulate code analysis\n        return {\n            'modules': ['auth', 'api', 'models', 'utils'],\n            'classes': 12,\n            'functions': 45,\n            'total_lines': 3250\n        }\n    \n    def extract_docstrings(self, module):\n        \"\"\"Extract docstrings from module.\"\"\"\n        print(f\"  üìù Extracting docstrings from {module}...\")\n        time.sleep(0.2)\n        \n        # Simulate extraction\n        return {\n            'module': module,\n            'functions': [\n                {\n                    'name': 'authenticate',\n                    'docstring': 'Authenticate user with credentials.',\n                    'params': ['username', 'password'],\n                    'returns': 'User object'\n                },\n                {\n                    'name': 'authorize',\n                    'docstring': 'Check user permissions.',\n                    'params': ['user', 'resource'],\n                    'returns': 'bool'\n                }\n            ]\n        }\n    \n    def generate_api_docs(self, modules):\n        \"\"\"Generate API documentation.\"\"\"\n        print(\"  üîß Generating API documentation...\")\n        time.sleep(0.4)\n        \n        docs = []\n        for module in modules:\n            docstrings = self.extract_docstrings(module)\n            \n            # Format as markdown\n            module_doc = f\"# {module.title()} Module\\n\\n\"\n            \n            for func in docstrings['functions']:\n                module_doc += f\"## `{func['name']}()\\n\\n\"\n                module_doc += f\"{func['docstring']}\\n\\n\"\n                module_doc += f\"**Parameters:**\\n\"\n                for param in func['params']:\n                    module_doc += f\"- `{param}`\\n\"\n                module_doc += f\"\\n**Returns:** {func['returns']}\\n\\n\"\n            \n            docs.append({\n                'module': module,\n                'content': module_doc\n            })\n        \n        return docs\n    \n    def generate_examples(self, module):\n        \"\"\"Generate usage examples.\"\"\"\n        print(f\"  üí° Generating examples for {module}...\")\n        time.sleep(0.2)\n        \n        if module == 'auth':\n            return \"\"\"\n## Usage Examples\n\n```python\nfrom myproject import auth\n\n# Authenticate a user\nuser = auth.authenticate('john', 'password123')\n\n# Check permissions\ncan_access = auth.authorize(user, 'admin_panel')\n```\n\"\"\"\n        return \"\"\n    \n    def update_readme(self, structure):\n        \"\"\"Update README with project structure.\"\"\"\n        print(\"  üìÑ Updating README...\")\n        time.sleep(0.3)\n        \n        readme = f\"\"\"# Project Documentation\n\n## Project Structure\n\n- **Modules:** {len(structure['modules'])}\n- **Classes:** {structure['classes']}\n- **Functions:** {structure['functions']}\n- **Lines of Code:** {structure['total_lines']:,}\n\n## Modules\n\n\"\"\"\n        \n        for module in structure['modules']:\n            readme += f\"- [{module}](docs/{module}.md)\\n\"\n        \n        readme += \"\\n## Installation\\n\\n\"\n        readme += \"```bash\\npip install -r requirements.txt\\n```\\n\"\n        \n        return readme\n    \n    def validate_documentation(self, docs):\n        \"\"\"Validate generated documentation.\"\"\"\n        print(\"  ‚úÖ Validating documentation...\")\n        time.sleep(0.2)\n        \n        issues = []\n        \n        # Check for empty sections\n        for doc in docs:\n            if len(doc['content']) < 100:\n                issues.append(f\"Short documentation in {doc['module']}\")\n        \n        # Check for broken links (simulated)\n        # In real implementation: check all markdown links\n        \n        return {\n            'valid': len(issues) == 0,\n            'issues': issues,\n            'doc_count': len(docs)\n        }\n    \n    def generate_documentation(self, source_dir=\".\"):\n        \"\"\"Complete documentation generation workflow.\"\"\"\n        print(\"\\nüìö Starting Documentation Generation Workflow\\n\")\n        \n        # Step 1: Analyze codebase\n        structure = self.analyze_codebase(source_dir)\n        print(f\"‚úÖ Found {len(structure['modules'])} modules\\n\")\n        \n        # Step 2: Generate API docs (parallel)\n        print(\"Generating API Documentation:\")\n        print(\"=\" * 50)\n        api_docs = self.generate_api_docs(structure['modules'])\n        print(f\"‚úÖ Generated {len(api_docs)} module docs\\n\")\n        \n        # Step 3: Generate examples\n        print(\"Generating Examples:\")\n        print(\"=\" * 50)\n        for module in structure['modules'][:2]:  # Just first 2 for demo\n            example = self.generate_examples(module)\n            if example:\n                print(f\"‚úÖ Created examples for {module}\")\n        print()\n        \n        # Step 4: Update README\n        print(\"Updating README:\")\n        print(\"=\" * 50)\n        readme = self.update_readme(structure)\n        print(\"‚úÖ README updated\\n\")\n        \n        # Step 5: Validate\n        print(\"Validating Documentation:\")\n        print(\"=\" * 50)\n        validation = self.validate_documentation(api_docs)\n        \n        if validation['valid']:\n            print(\"‚úÖ All documentation valid\")\n        else:\n            print(f\"‚ö†Ô∏è  Found {len(validation['issues'])} issues:\")\n            for issue in validation['issues']:\n                print(f\"   - {issue}\")\n        \n        # Generate summary\n        print(\"\\n\" + \"=\" * 50)\n        print(\"Documentation Summary:\")\n        print(\"=\" * 50)\n        print(f\"üìÑ Modules documented: {len(api_docs)}\")\n        print(f\"üìù README updated: Yes\")\n        print(f\"‚úÖ Validation status: {'Passed' if validation['valid'] else 'Issues found'}\")\n        print(\"\\nGenerated files:\")\n        for doc in api_docs:\n            print(f\"  - docs/{doc['module']}.md\")\n        print(f\"  - README.md\")\n        \n        return {\n            'structure': structure,\n            'api_docs': api_docs,\n            'readme': readme,\n            'validation': validation\n        }\n\n# Test documentation workflow\ndoc_gen = DocumentationWorkflow()\nresult = doc_gen.generate_documentation(\".\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Example 3: Documentation Generation Workflow\n\n**Goal**: Automatically generate and update project documentation.\n\n**Components**:\n- Skill: Documentation best practices\n- Agents: Analyze code structure\n- Caching: Avoid regenerating unchanged docs\n\n**Workflow steps**:\n1. Analyze codebase structure\n2. Extract docstrings and comments\n3. Generate API documentation\n4. Create code examples\n5. Update README\n6. Validate links and formatting\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Example 2: CI/CD Pipeline (Complete Implementation)\n\nclass CICDPipeline:\n    \"\"\"Automated CI/CD pipeline with testing, building, and deployment.\"\"\"\n    \n    def __init__(self):\n        self.cache = WorkflowCache(\".cicd_cache\")\n        self.state = WorkflowState()\n        self.transaction = WorkflowTransaction()\n    \n    def run_unit_tests(self):\n        \"\"\"Run unit tests.\"\"\"\n        print(\"  üß™ Running unit tests...\")\n        time.sleep(0.5)\n        \n        # Simulate test execution\n        return {\n            'name': 'unit_tests',\n            'passed': 145,\n            'failed': 0,\n            'duration': 15.3,\n            'status': 'pass'\n        }\n    \n    def run_integration_tests(self):\n        \"\"\"Run integration tests.\"\"\"\n        print(\"  üîó Running integration tests...\")\n        time.sleep(0.5)\n        \n        return {\n            'name': 'integration_tests',\n            'passed': 23,\n            'failed': 0,\n            'duration': 8.7,\n            'status': 'pass'\n        }\n    \n    def run_linting(self):\n        \"\"\"Run code linting.\"\"\"\n        print(\"  üìã Running linter...\")\n        time.sleep(0.3)\n        \n        return {\n            'name': 'linting',\n            'issues': 2,\n            'warnings': 5,\n            'duration': 3.2,\n            'status': 'warning'\n        }\n    \n    def build_artifacts(self, commit_hash):\n        \"\"\"Build application artifacts with caching.\"\"\"\n        print(\"  üî® Building artifacts...\")\n        \n        # Check cache\n        cache_key = {'commit': commit_hash}\n        cached = self.cache.get('build', cache_key)\n        \n        if cached:\n            print(\"     Using cached build\")\n            return cached\n        \n        # Build (simulated)\n        time.sleep(1.0)\n        \n        result = {\n            'name': 'build',\n            'artifacts': ['app.js', 'app.css', 'index.html'],\n            'size_mb': 2.4,\n            'duration': 25.1,\n            'status': 'pass'\n        }\n        \n        # Cache the result\n        self.cache.set('build', cache_key, result)\n        \n        return result\n    \n    def deploy_to_staging(self):\n        \"\"\"Deploy to staging environment.\"\"\"\n        print(\"  üöÄ Deploying to staging...\")\n        time.sleep(0.8)\n        \n        self.transaction.record_change('deploy_staging', {\n            'environment': 'staging',\n            'url': 'https://staging.example.com'\n        })\n        \n        return {\n            'name': 'staging_deploy',\n            'url': 'https://staging.example.com',\n            'status': 'deployed'\n        }\n    \n    def run_smoke_tests(self, url):\n        \"\"\"Run smoke tests on deployed environment.\"\"\"\n        print(f\"  üí® Running smoke tests on {url}...\")\n        time.sleep(0.4)\n        \n        return {\n            'name': 'smoke_tests',\n            'tests_passed': 10,\n            'status': 'pass'\n        }\n    \n    def run_pipeline(self, commit_hash, auto_deploy=False):\n        \"\"\"Execute complete CI/CD pipeline.\"\"\"\n        print(f\"\\nüöÄ Starting CI/CD Pipeline for commit: {commit_hash[:8]}\\n\")\n        \n        try:\n            # Phase 1: Testing (Parallel)\n            print(\"Phase 1: Testing\")\n            print(\"=\" * 50)\n            \n            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n                test_futures = [\n                    executor.submit(self.run_unit_tests),\n                    executor.submit(self.run_integration_tests),\n                    executor.submit(self.run_linting)\n                ]\n                \n                test_results = [f.result() for f in test_futures]\n            \n            # Check if tests passed\n            failed_tests = [r for r in test_results if r['status'] == 'fail']\n            if failed_tests:\n                raise Exception(f\"Tests failed: {failed_tests}\")\n            \n            print(\"‚úÖ All tests passed\\n\")\n            \n            # Phase 2: Build\n            print(\"Phase 2: Build\")\n            print(\"=\" * 50)\n            build_result = self.build_artifacts(commit_hash)\n            print(f\"‚úÖ Build complete: {build_result['size_mb']}MB\\n\")\n            \n            # Phase 3: Deploy to Staging\n            print(\"Phase 3: Staging Deployment\")\n            print(\"=\" * 50)\n            staging_result = self.deploy_to_staging()\n            print(f\"‚úÖ Deployed to: {staging_result['url']}\\n\")\n            \n            # Phase 4: Smoke Tests\n            print(\"Phase 4: Smoke Tests\")\n            print(\"=\" * 50)\n            smoke_result = self.run_smoke_tests(staging_result['url'])\n            print(f\"‚úÖ Smoke tests passed: {smoke_result['tests_passed']}/10\\n\")\n            \n            # Commit transaction\n            self.transaction.commit()\n            \n            # Phase 5: Production (optional)\n            if auto_deploy:\n                print(\"Phase 5: Production Deployment\")\n                print(\"=\" * 50)\n                print(\"üöÄ Auto-deploying to production...\")\n                time.sleep(0.5)\n                print(\"‚úÖ Deployed to: https://example.com\\n\")\n            else:\n                print(\"‚è∏Ô∏è  Production deployment requires manual approval\")\n                print(\"   Run: /deploy-production\\n\")\n            \n            # Generate report\n            print(\"=\" * 50)\n            print(\"Pipeline Summary:\")\n            print(\"=\" * 50)\n            total_time = sum(r.get('duration', 0) for r in test_results)\n            total_time += build_result['duration']\n            \n            print(f\"‚úÖ Status: SUCCESS\")\n            print(f\"‚è±Ô∏è  Total time: {total_time:.1f}s\")\n            print(f\"üß™ Tests: {sum(r.get('passed', 0) for r in test_results)} passed\")\n            print(f\"üì¶ Build: {build_result['size_mb']}MB\")\n            print(f\"üåç Staging: {staging_result['url']}\")\n            \n            return {\n                'status': 'success',\n                'commit': commit_hash,\n                'test_results': test_results,\n                'build': build_result,\n                'staging': staging_result\n            }\n            \n        except Exception as e:\n            print(f\"\\n‚ùå Pipeline failed: {e}\")\n            print(\"üîÑ Rolling back changes...\\n\")\n            self.transaction.rollback()\n            \n            raise\n\n# Test the CI/CD pipeline\npipeline = CICDPipeline()\n\n# Simulate pipeline run\ncommit = \"abc123def456\"\nresult = pipeline.run_pipeline(commit, auto_deploy=False)\n\n# Clean up cache\nif Path(\".cicd_cache\").exists():\n    import shutil\n    shutil.rmtree(\".cicd_cache\")\n    print(\"\\n‚úÖ Cleaned up CI/CD cache\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Example 2: CI/CD Pipeline Workflow\n\n**Goal**: Automated continuous integration and deployment pipeline.\n\n**Components**:\n- Hook: Trigger on git push\n- Agents: Parallel test/build\n- Error handling: Rollback on failure\n- Caching: Speed up builds\n\n**Workflow steps**:\n1. Detect code push (Hook)\n2. Run tests in parallel (Agents)\n3. Build artifacts (with caching)\n4. Deploy to staging\n5. Run smoke tests\n6. Deploy to production (manual approval)\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Example 1: PR Review Automation (Complete Implementation)\n\nclass PRReviewWorkflow:\n    \"\"\"Automated pull request review workflow.\"\"\"\n    \n    def __init__(self):\n        self.review_results = {}\n    \n    def fetch_pr_data(self, pr_number):\n        \"\"\"Simulate fetching PR from GitHub API.\"\"\"\n        print(f\"üì• Fetching PR #{pr_number} from GitHub...\")\n        \n        # In real implementation: use MCP GitHub integration\n        # pr_data = mcp.github.get_pr(pr_number)\n        \n        return {\n            'number': pr_number,\n            'title': 'Add user authentication',\n            'files_changed': ['auth.py', 'tests/test_auth.py', 'README.md'],\n            'additions': 150,\n            'deletions': 20\n        }\n    \n    def review_code_quality(self, files):\n        \"\"\"Analyze code quality.\"\"\"\n        print(\"  üîç Reviewing code quality...\")\n        time.sleep(0.5)  # Simulate analysis\n        \n        issues = []\n        for file in files:\n            if file.endswith('.py'):\n                # Simulate finding issues\n                if 'auth' in file:\n                    issues.append({\n                        'file': file,\n                        'line': 45,\n                        'severity': 'medium',\n                        'message': 'Consider adding input validation'\n                    })\n        \n        return {\n            'aspect': 'code_quality',\n            'status': 'warning' if issues else 'pass',\n            'issues': issues\n        }\n    \n    def review_security(self, files):\n        \"\"\"Run security analysis.\"\"\"\n        print(\"  üîí Running security scan...\")\n        time.sleep(0.5)\n        \n        issues = []\n        for file in files:\n            # Simulate security check\n            if 'auth' in file:\n                issues.append({\n                    'file': file,\n                    'line': 23,\n                    'severity': 'high',\n                    'message': 'Potential SQL injection vulnerability'\n                })\n        \n        return {\n            'aspect': 'security',\n            'status': 'fail' if issues else 'pass',\n            'issues': issues\n        }\n    \n    def review_test_coverage(self, files):\n        \"\"\"Check test coverage.\"\"\"\n        print(\"  üìä Checking test coverage...\")\n        time.sleep(0.5)\n        \n        test_files = [f for f in files if 'test_' in f]\n        coverage = len(test_files) / len(files) * 100\n        \n        return {\n            'aspect': 'test_coverage',\n            'status': 'pass' if coverage >= 50 else 'warning',\n            'coverage': coverage,\n            'issues': [] if coverage >= 50 else [{\n                'message': f'Low test coverage: {coverage:.0f}%'\n            }]\n        }\n    \n    def review_documentation(self, files):\n        \"\"\"Review documentation.\"\"\"\n        print(\"  üìù Reviewing documentation...\")\n        time.sleep(0.5)\n        \n        has_readme_update = any('README' in f for f in files)\n        \n        return {\n            'aspect': 'documentation',\n            'status': 'pass' if has_readme_update else 'warning',\n            'issues': [] if has_readme_update else [{\n                'message': 'Consider updating README.md'\n            }]\n        }\n    \n    def run_parallel_reviews(self, files):\n        \"\"\"Run all review aspects in parallel.\"\"\"\n        print(\"\\nüîÑ Running parallel reviews...\")\n        \n        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n            futures = {\n                executor.submit(self.review_code_quality, files): 'quality',\n                executor.submit(self.review_security, files): 'security',\n                executor.submit(self.review_test_coverage, files): 'coverage',\n                executor.submit(self.review_documentation, files): 'docs'\n            }\n            \n            results = {}\n            for future in concurrent.futures.as_completed(futures):\n                result = future.result()\n                results[result['aspect']] = result\n        \n        print(\"‚úÖ All reviews complete\\n\")\n        return results\n    \n    def generate_review_comment(self, results):\n        \"\"\"Generate review comment from results.\"\"\"\n        comment_lines = [\"# Automated PR Review\\n\"]\n        \n        # Overall status\n        critical_issues = sum(\n            1 for r in results.values() \n            if r['status'] == 'fail'\n        )\n        \n        if critical_issues > 0:\n            comment_lines.append(\"‚ùå **Changes requested** - Critical issues found\\n\")\n        else:\n            comment_lines.append(\"‚úÖ **Approved** - All checks passed\\n\")\n        \n        # Details for each aspect\n        for aspect, result in results.items():\n            icon = {'pass': '‚úÖ', 'warning': '‚ö†Ô∏è', 'fail': '‚ùå'}[result['status']]\n            comment_lines.append(f\"\\n## {icon} {aspect.replace('_', ' ').title()}\")\n            \n            if result['issues']:\n                comment_lines.append(\"\\n**Issues found:**\")\n                for issue in result['issues']:\n                    if 'file' in issue:\n                        comment_lines.append(\n                            f\"- `{issue['file']}:{issue.get('line', '?')}` - {issue['message']}\"\n                        )\n                    else:\n                        comment_lines.append(f\"- {issue['message']}\")\n        \n        return '\\n'.join(comment_lines)\n    \n    def post_review(self, pr_number, comment, approve):\n        \"\"\"Post review to GitHub.\"\"\"\n        action = \"APPROVE\" if approve else \"REQUEST_CHANGES\"\n        print(f\"üì§ Posting review to PR #{pr_number}: {action}\\n\")\n        \n        # In real implementation: use MCP GitHub integration\n        # mcp.github.post_review(pr_number, comment, action)\n        \n        print(\"Review Comment:\")\n        print(\"=\" * 60)\n        print(comment)\n        print(\"=\" * 60)\n    \n    def review_pr(self, pr_number):\n        \"\"\"Complete PR review workflow.\"\"\"\n        print(f\"\\nüöÄ Starting PR Review Workflow for PR #{pr_number}\\n\")\n        \n        # Step 1: Fetch PR\n        pr_data = self.fetch_pr_data(pr_number)\n        print(f\"‚úÖ Fetched: {pr_data['title']}\")\n        print(f\"   Files: {len(pr_data['files_changed'])}, \"\n              f\"+{pr_data['additions']}/-{pr_data['deletions']}\\n\")\n        \n        # Step 2: Run parallel reviews\n        results = self.run_parallel_reviews(pr_data['files_changed'])\n        \n        # Step 3: Generate comment\n        comment = self.generate_review_comment(results)\n        \n        # Step 4: Determine approval\n        has_critical = any(r['status'] == 'fail' for r in results.values())\n        approve = not has_critical\n        \n        # Step 5: Post review\n        self.post_review(pr_number, comment, approve)\n        \n        return {\n            'pr_number': pr_number,\n            'approved': approve,\n            'results': results\n        }\n\n# Test the PR review workflow\nreviewer = PRReviewWorkflow()\nresult = reviewer.review_pr(123)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 8. Real-World Workflow Examples\n\nLet's build complete, production-ready workflows that combine all the concepts we've learned.\n\n### Example 1: Automated PR Review Workflow\n\n**Goal**: Automatically review pull requests with comprehensive quality checks.\n\n**Components**:\n- Skill: Code review expertise\n- MCP: GitHub API integration\n- Agents: Parallel review aspects\n- Hook: Block merge if critical issues found\n\n**Workflow steps**:\n1. Fetch PR from GitHub (MCP)\n2. Parallel review (Agents):\n   - Code quality analysis\n   - Security scan\n   - Test coverage check\n   - Documentation review\n3. Generate review comments\n4. Post to GitHub (MCP)\n5. Set PR status (approve/request changes)\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Hands-On: Performance Optimization Exercises ‚≠ê‚≠ê‚≠ê\n\n**Exercise 7.1**: Optimize a file processing workflow that currently processes files sequentially. Make it parallel while respecting memory limits.\n\n**Exercise 7.2**: Add intelligent caching to a workflow that fetches API data. Cache should expire after 5 minutes.\n\n**Exercise 7.3**: Build a rate-limited API client that processes requests in batches without exceeding API limits (e.g., 100 requests/minute).\n\nTry these exercises to apply performance optimization patterns!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from threading import Semaphore, Lock\nimport concurrent.futures\n\n# Pattern 3a: Semaphore for Resource Limiting\nclass ResourceLimitedWorkflow:\n    \"\"\"Limit concurrent resource usage with semaphores.\"\"\"\n    \n    def __init__(self, max_concurrent=2):\n        self.semaphore = Semaphore(max_concurrent)\n        self.max_concurrent = max_concurrent\n    \n    def resource_intensive_task(self, task_id):\n        \"\"\"Task that uses limited resource (e.g., memory, API connections).\"\"\"\n        with self.semaphore:\n            print(f\"  Task {task_id}: Acquired resource\")\n            time.sleep(1)  # Simulate work\n            print(f\"  Task {task_id}: Released resource\")\n            return f\"Task {task_id} complete\"\n    \n    def run_tasks(self, num_tasks):\n        \"\"\"Run multiple tasks with resource limiting.\"\"\"\n        print(f\"üîí Running {num_tasks} tasks with max {self.max_concurrent} concurrent\\n\")\n        \n        with concurrent.futures.ThreadPoolExecutor(max_workers=num_tasks) as executor:\n            futures = [executor.submit(self.resource_intensive_task, i+1) \n                      for i in range(num_tasks)]\n            \n            results = [f.result() for f in concurrent.futures.as_completed(futures)]\n        \n        print(f\"\\n‚úÖ All tasks complete\")\n        return results\n\n# Test resource limiting\nworkflow = ResourceLimitedWorkflow(max_concurrent=2)\nworkflow.run_tasks(6)\n\nprint(\"\\nNotice: Only 2 tasks run at a time, others wait for resource\\n\")\n\n# Pattern 3b: Thread-Safe State Management\nclass WorkflowState:\n    \"\"\"Thread-safe workflow state tracking.\"\"\"\n    \n    def __init__(self):\n        self.lock = Lock()\n        self.completed_tasks = []\n        self.failed_tasks = []\n        self.metrics = {\n            'total_time': 0,\n            'tasks_completed': 0\n        }\n    \n    def record_success(self, task_name, duration):\n        \"\"\"Record successful task completion.\"\"\"\n        with self.lock:\n            self.completed_tasks.append(task_name)\n            self.metrics['tasks_completed'] += 1\n            self.metrics['total_time'] += duration\n    \n    def record_failure(self, task_name, error):\n        \"\"\"Record task failure.\"\"\"\n        with self.lock:\n            self.failed_tasks.append((task_name, str(error)))\n    \n    def get_status(self):\n        \"\"\"Get current status (thread-safe).\"\"\"\n        with self.lock:\n            return {\n                'completed': len(self.completed_tasks),\n                'failed': len(self.failed_tasks),\n                'avg_time': (self.metrics['total_time'] / self.metrics['tasks_completed'] \n                           if self.metrics['tasks_completed'] > 0 else 0)\n            }\n\n# Test thread-safe state\nstate = WorkflowState()\n\ndef worker_task(task_id, state):\n    \"\"\"Simulated worker that updates shared state.\"\"\"\n    start = time.time()\n    \n    try:\n        time.sleep(0.1)  # Simulate work\n        duration = time.time() - start\n        state.record_success(f\"task_{task_id}\", duration)\n        return \"success\"\n    except Exception as e:\n        state.record_failure(f\"task_{task_id}\", e)\n        return \"failure\"\n\n# Run multiple tasks in parallel\nprint(\"üîê Thread-safe state management:\")\nwith concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n    futures = [executor.submit(worker_task, i, state) for i in range(20)]\n    results = [f.result() for f in futures]\n\nstatus = state.get_status()\nprint(f\"\\n‚úÖ Final Status:\")\nprint(f\"   Completed: {status['completed']}\")\nprint(f\"   Failed: {status['failed']}\")\nprint(f\"   Avg Time: {status['avg_time']:.3f}s\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Pattern 3: Resource Management\n\nControl concurrent resource usage to prevent system overload:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from functools import lru_cache\nimport hashlib\nimport json\n\n# Pattern 2a: Function Memoization with @lru_cache\n@lru_cache(maxsize=128)\ndef expensive_computation(n):\n    \"\"\"Expensive recursive computation (Fibonacci).\"\"\"\n    print(f\"  Computing fib({n})...\")\n    if n <= 1:\n        return n\n    return expensive_computation(n - 1) + expensive_computation(n - 2)\n\nprint(\"Without cache, computing fib(10) multiple times:\")\nfor _ in range(3):\n    start = time.time()\n    result = expensive_computation(10)\n    print(f\"Result: {result}, Time: {time.time() - start:.4f}s\\n\")\n\nprint(\"Notice: First call is slow, subsequent calls are instant (cached)!\\n\")\n\n# Clear cache for next example\nexpensive_computation.cache_clear()\n\n# Pattern 2b: Workflow Result Caching\nclass WorkflowCache:\n    \"\"\"Cache workflow results based on inputs.\"\"\"\n    \n    def __init__(self, cache_dir=\".workflow_cache\"):\n        self.cache_dir = Path(cache_dir)\n        self.cache_dir.mkdir(exist_ok=True)\n    \n    def _get_cache_key(self, workflow_name, inputs):\n        \"\"\"Generate cache key from workflow name and inputs.\"\"\"\n        # Hash the inputs for a stable key\n        input_str = json.dumps(inputs, sort_keys=True)\n        input_hash = hashlib.md5(input_str.encode()).hexdigest()\n        return f\"{workflow_name}_{input_hash}.json\"\n    \n    def get(self, workflow_name, inputs):\n        \"\"\"Get cached result if available.\"\"\"\n        cache_file = self.cache_dir / self._get_cache_key(workflow_name, inputs)\n        \n        if cache_file.exists():\n            print(f\"üíæ Cache HIT for {workflow_name}\")\n            return json.loads(cache_file.read_text())\n        \n        print(f\"‚ùå Cache MISS for {workflow_name}\")\n        return None\n    \n    def set(self, workflow_name, inputs, result):\n        \"\"\"Cache workflow result.\"\"\"\n        cache_file = self.cache_dir / self._get_cache_key(workflow_name, inputs)\n        cache_file.write_text(json.dumps(result))\n        print(f\"üíæ Cached result for {workflow_name}\")\n    \n    def clear(self):\n        \"\"\"Clear all cached results.\"\"\"\n        for cache_file in self.cache_dir.glob(\"*.json\"):\n            cache_file.unlink()\n        print(\"üóëÔ∏è  Cache cleared\")\n\n# Example: Cache expensive workflow results\ncache = WorkflowCache()\n\ndef run_expensive_workflow(config):\n    \"\"\"Simulate expensive workflow (e.g., running full test suite).\"\"\"\n    print(\"üîÑ Running expensive workflow...\")\n    time.sleep(2)  # Simulate work\n    return {\n        'status': 'success',\n        'tests_passed': 150,\n        'coverage': 85.5,\n        'duration': 2.0\n    }\n\ndef cached_workflow(config):\n    \"\"\"Run workflow with caching.\"\"\"\n    # Try to get from cache\n    result = cache.get(\"test_suite\", config)\n    \n    if result:\n        return result\n    \n    # Not cached, run workflow\n    result = run_expensive_workflow(config)\n    \n    # Save to cache\n    cache.set(\"test_suite\", config, result)\n    \n    return result\n\n# Test caching\nconfig = {'python_version': '3.9', 'test_files': ['test_*.py']}\n\nprint(\"First run (not cached):\")\nstart = time.time()\nresult1 = cached_workflow(config)\nprint(f\"Result: {result1}\")\nprint(f\"Time: {time.time() - start:.2f}s\\n\")\n\nprint(\"Second run (cached):\")\nstart = time.time()\nresult2 = cached_workflow(config)\nprint(f\"Result: {result2}\")\nprint(f\"Time: {time.time() - start:.2f}s\")\n\n# Clean up\ncache.clear()\nif Path(\".workflow_cache\").exists():\n    import shutil\n    shutil.rmtree(\".workflow_cache\")\n    print(\"‚úÖ Cleaned up cache directory\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Pattern 2: Caching and Memoization\n\nCache expensive operations to avoid recomputing:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import concurrent.futures\nimport time\n\n# Simulate expensive tasks (e.g., running tests, linting files)\ndef expensive_task(task_id, duration=1):\n    \"\"\"Simulate a task that takes time to complete.\"\"\"\n    time.sleep(duration)\n    return f\"Task {task_id} completed in {duration}s\"\n\n# Sequential execution\ndef run_sequential(tasks):\n    \"\"\"Run tasks one after another.\"\"\"\n    start = time.time()\n    results = []\n    \n    print(\"üîÑ Sequential Execution:\")\n    for i, task in enumerate(tasks, 1):\n        print(f\"  Running task {i}/{len(tasks)}...\")\n        result = expensive_task(i, task)\n        results.append(result)\n    \n    elapsed = time.time() - start\n    print(f\"‚úÖ Completed in {elapsed:.2f}s\\n\")\n    return results, elapsed\n\n# Parallel execution\ndef run_parallel(tasks, max_workers=4):\n    \"\"\"Run tasks in parallel using thread pool.\"\"\"\n    start = time.time()\n    results = []\n    \n    print(f\"‚ö° Parallel Execution ({max_workers} workers):\")\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        # Submit all tasks\n        futures = [executor.submit(expensive_task, i+1, task) \n                   for i, task in enumerate(tasks)]\n        \n        # Collect results as they complete\n        for future in concurrent.futures.as_completed(futures):\n            result = future.result()\n            results.append(result)\n            print(f\"  ‚úì {result}\")\n    \n    elapsed = time.time() - start\n    print(f\"‚úÖ Completed in {elapsed:.2f}s\\n\")\n    return results, elapsed\n\n# Test with 8 tasks, each taking 1 second\ntasks = [1] * 8  # 8 tasks, 1 second each\n\n# Sequential: 8 seconds total\nseq_results, seq_time = run_sequential(tasks)\n\n# Parallel: ~2 seconds with 4 workers\npar_results, par_time = run_parallel(tasks, max_workers=4)\n\n# Calculate speedup\nspeedup = seq_time / par_time\nprint(f\"üìä Performance Comparison:\")\nprint(f\"  Sequential: {seq_time:.2f}s\")\nprint(f\"  Parallel:   {par_time:.2f}s\")\nprint(f\"  Speedup:    {speedup:.2f}x faster\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Pattern 1: Parallel vs Sequential Execution\n\nLet's compare performance of different execution strategies:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 7. Performance Optimization\n\n### Why Performance Matters\n\n**Slow workflow**:\n- Users wait and get frustrated\n- CI/CD pipelines take hours\n- Developers context-switch while waiting\n\n**Fast workflow**:\n- Immediate feedback\n- Higher productivity\n- Better developer experience\n\n**Performance goals**:\n- **Interactive**: < 2 seconds for user commands\n- **Batch**: < 5 minutes for full workflow\n- **Scalable**: Linear time with input size\n\n### Performance Optimization Strategies\n\n**1. Parallel Execution**\n- Run independent tasks simultaneously\n- Use all CPU cores\n- 4x speedup on 4-core machine\n\n**2. Sequential Execution**\n- Tasks with dependencies run in order\n- Clear failure points\n- Easier debugging\n\n**3. Caching**\n- Store expensive computation results\n- Reuse across workflow runs\n- 10-100x speedup for repeated operations\n\n**4. Lazy Evaluation**\n- Compute only when needed\n- Skip unnecessary work\n- Especially useful for optional steps\n\n**5. Resource Management**\n- Limit concurrent operations\n- Prevent memory exhaustion\n- Queue tasks if needed\n\n### Parallel vs Sequential Decision Tree\n\n```\nCan tasks run independently?\n‚îú‚îÄ YES: Use parallel execution\n‚îÇ  ‚îú‚îÄ Do they share resources? \n‚îÇ  ‚îÇ  ‚îú‚îÄ YES: Use locks or semaphores\n‚îÇ  ‚îÇ  ‚îî‚îÄ NO: Full parallelism\n‚îÇ\n‚îî‚îÄ NO: Use sequential execution\n   ‚îî‚îÄ Optimize individual steps\n```\n\n### When to Use What\n\n| Scenario | Strategy | Reason |\n|----------|----------|--------|\n| Independent tests | Parallel | No dependencies |\n| Linting multiple files | Parallel | No shared state |\n| Git operations | Sequential | Maintain consistency |\n| Database migrations | Sequential | Order matters |\n| API calls with rate limits | Sequential + delay | Respect limits |\n| File downloads | Parallel (limited) | Network I/O bound |\n| Data transformations | Parallel | CPU bound |\n| Build pipeline | Mixed | Some steps parallel, some sequential |\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Exercise 6.3 Solution: Error Logger with Severity\nfrom enum import Enum\nfrom datetime import datetime\n\nclass Severity(Enum):\n    DEBUG = 1\n    INFO = 2\n    WARNING = 3\n    ERROR = 4\n    CRITICAL = 5\n\nclass ErrorLogger:\n    \"\"\"Log errors by severity with notification support.\"\"\"\n    \n    def __init__(self, log_file=\"workflow_errors.log\"):\n        self.log_file = Path(log_file)\n        self.errors_by_severity = {s: [] for s in Severity}\n    \n    def log(self, severity: Severity, message: str, exception: Exception = None):\n        \"\"\"Log an error with severity level.\"\"\"\n        \n        timestamp = datetime.now().isoformat()\n        \n        # Format log entry\n        log_entry = {\n            'timestamp': timestamp,\n            'severity': severity.name,\n            'message': message,\n            'exception': str(exception) if exception else None\n        }\n        \n        # Store in memory\n        self.errors_by_severity[severity].append(log_entry)\n        \n        # Write to file\n        log_line = f\"[{timestamp}] {severity.name}: {message}\"\n        if exception:\n            log_line += f\"\\n  Exception: {exception}\"\n        \n        with open(self.log_file, 'a') as f:\n            f.write(log_line + '\\n')\n        \n        # Print with color-coding\n        icons = {\n            Severity.DEBUG: 'üîç',\n            Severity.INFO: '‚ÑπÔ∏è',\n            Severity.WARNING: '‚ö†Ô∏è',\n            Severity.ERROR: '‚ùå',\n            Severity.CRITICAL: 'üö®'\n        }\n        print(f\"{icons[severity]} {log_line}\")\n        \n        # Send notification for critical errors\n        if severity == Severity.CRITICAL:\n            self._send_notification(log_entry)\n    \n    def _send_notification(self, log_entry):\n        \"\"\"Send notification for critical errors.\"\"\"\n        print(f\"\\nüìß NOTIFICATION SENT:\")\n        print(f\"   To: dev-team@company.com\")\n        print(f\"   Subject: CRITICAL ERROR in workflow\")\n        print(f\"   Message: {log_entry['message']}\\n\")\n    \n    def get_summary(self):\n        \"\"\"Get summary of all logged errors.\"\"\"\n        print(\"\\nüìä Error Summary:\")\n        print(\"=\" * 50)\n        \n        for severity in Severity:\n            count = len(self.errors_by_severity[severity])\n            if count > 0:\n                print(f\"  {severity.name}: {count} errors\")\n        \n        # Show critical errors in detail\n        critical = self.errors_by_severity[Severity.CRITICAL]\n        if critical:\n            print(f\"\\nüö® Critical Errors ({len(critical)}):\")\n            for err in critical:\n                print(f\"  - {err['timestamp']}: {err['message']}\")\n\n# Test the error logger\nlogger = ErrorLogger(\"test_errors.log\")\n\n# Simulate various errors during a workflow\nlogger.log(Severity.INFO, \"Starting release workflow\")\nlogger.log(Severity.DEBUG, \"Validating version number\")\nlogger.log(Severity.WARNING, \"Found 3 TODOs in code\", \n           Exception(\"Non-blocking warning\"))\nlogger.log(Severity.ERROR, \"Test suite failed\", \n           Exception(\"2 tests failed\"))\nlogger.log(Severity.CRITICAL, \"Database migration failed - data corruption risk!\",\n           Exception(\"Migration rollback failed\"))\n\n# Get summary\nlogger.get_summary()\n\n# Clean up test file\nif Path(\"test_errors.log\").exists():\n    Path(\"test_errors.log\").unlink()\n    print(\"\\n‚úÖ Cleaned up test log file\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Exercise 6.2 Solution: Circuit Breaker Pattern\nclass CircuitBreaker:\n    \"\"\"\n    Stops calling a failing service after threshold is reached.\n    \n    States:\n    - CLOSED: Normal operation, calls go through\n    - OPEN: Too many failures, block all calls\n    - HALF_OPEN: Testing if service recovered\n    \"\"\"\n    \n    def __init__(self, failure_threshold=5, timeout=60):\n        self.failure_threshold = failure_threshold\n        self.timeout = timeout\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = \"CLOSED\"\n    \n    def call(self, func, *args, **kwargs):\n        \"\"\"Execute function through circuit breaker.\"\"\"\n        \n        # Check if we should attempt to recover\n        if self.state == \"OPEN\":\n            if time.time() - self.last_failure_time >= self.timeout:\n                print(\"üîÑ Circuit breaker entering HALF_OPEN state (testing recovery)\")\n                self.state = \"HALF_OPEN\"\n            else:\n                remaining = self.timeout - (time.time() - self.last_failure_time)\n                raise Exception(\n                    f\"üö´ Circuit breaker is OPEN\\n\"\n                    f\"   Service is unavailable\\n\"\n                    f\"   Will retry in {remaining:.0f}s\\n\"\n                    f\"   Failures: {self.failure_count}/{self.failure_threshold}\"\n                )\n        \n        try:\n            result = func(*args, **kwargs)\n            \n            # Success! Reset if we were testing recovery\n            if self.state == \"HALF_OPEN\":\n                print(\"‚úÖ Circuit breaker CLOSED (service recovered)\")\n                self.state = \"CLOSED\"\n                self.failure_count = 0\n            \n            return result\n        \n        except Exception as e:\n            self.failure_count += 1\n            self.last_failure_time = time.time()\n            \n            print(f\"‚ö†Ô∏è  Failure {self.failure_count}/{self.failure_threshold}: {e}\")\n            \n            if self.failure_count >= self.failure_threshold:\n                self.state = \"OPEN\"\n                print(f\"üö´ Circuit breaker OPEN (too many failures)\")\n            \n            raise\n\n# Test circuit breaker\nbreaker = CircuitBreaker(failure_threshold=3, timeout=5)\n\ndef unreliable_service():\n    \"\"\"Service that always fails.\"\"\"\n    raise ConnectionError(\"Service unavailable\")\n\n# Make multiple calls to trigger circuit breaker\nfor i in range(5):\n    try:\n        breaker.call(unreliable_service)\n    except Exception as e:\n        print(f\"Call {i+1}: {type(e).__name__}\\n\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Exercise 6.1 Solution: File Operation Error Handler\ndef safe_file_operation(operation, filepath, *args, **kwargs):\n    \"\"\"\n    Execute file operation with helpful error messages.\n    \n    Args:\n        operation: File operation function (e.g., Path.read_text, Path.write_text)\n        filepath: Path to file\n        *args, **kwargs: Arguments for the operation\n    \"\"\"\n    file_path = Path(filepath)\n    \n    try:\n        return operation(file_path, *args, **kwargs)\n    \n    except FileNotFoundError:\n        # Suggest creating the file or checking the path\n        suggestions = [\n            f\"File not found: {file_path}\",\n            \"\",\n            \"Possible solutions:\",\n            f\"1. Check if path is correct: {file_path.absolute()}\",\n            f\"2. Create parent directories: {file_path.parent}\",\n            f\"3. Verify file name spelling\",\n        ]\n        \n        # Check if parent directory exists\n        if not file_path.parent.exists():\n            suggestions.append(f\"\\n‚ö†Ô∏è  Parent directory doesn't exist: {file_path.parent}\")\n            suggestions.append(f\"   Create it: mkdir -p {file_path.parent}\")\n        \n        raise FileNotFoundError('\\n'.join(suggestions))\n    \n    except PermissionError:\n        raise PermissionError(\n            f\"Permission denied: {file_path}\\n\"\n            f\"\\n\"\n            f\"Possible solutions:\\n\"\n            f\"1. Check file permissions: ls -l {file_path}\\n\"\n            f\"2. Run with sudo (if appropriate)\\n\"\n            f\"3. Change ownership: chown $USER {file_path}\"\n        )\n    \n    except IsADirectoryError:\n        raise IsADirectoryError(\n            f\"Expected file but found directory: {file_path}\\n\"\n            f\"\\n\"\n            f\"Did you mean:\\n\"\n            f\"- {file_path}/README.md\\n\"\n            f\"- {file_path}/config.json\"\n        )\n\n# Test with various error scenarios\nprint(\"Test 1: Missing file\")\ntry:\n    safe_file_operation(Path.read_text, \"nonexistent.txt\")\nexcept FileNotFoundError as e:\n    print(f\"‚úÖ Caught error with helpful message:\\n{e}\\n\")\n\nprint(\"Test 2: Directory instead of file\")\ntry:\n    safe_file_operation(Path.read_text, \".claude\")\nexcept IsADirectoryError as e:\n    print(f\"‚úÖ Caught error with helpful message:\\n{e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Hands-On: Error Handling Exercises ‚≠ê‚≠ê‚≠ê\n\n**Exercise 6.1**: Create an error handler for file operations that provides helpful recovery suggestions.\n\n**Exercise 6.2**: Implement a circuit breaker pattern that stops retrying after repeated failures.\n\n**Exercise 6.3**: Build an error logger that categorizes errors by severity and sends notifications for critical issues.\n\nTry implementing these patterns on your own before looking at the solutions below.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Pattern 3: Transactional Rollback\nclass WorkflowTransaction:\n    \"\"\"Track changes and rollback on failure.\"\"\"\n    \n    def __init__(self):\n        self.changes = []\n        self.completed = False\n    \n    def record_change(self, action: str, data: Any):\n        \"\"\"Record a change that can be rolled back.\"\"\"\n        self.changes.append({\n            'action': action,\n            'data': data,\n            'timestamp': time.time()\n        })\n    \n    def commit(self):\n        \"\"\"Mark transaction as successful.\"\"\"\n        self.completed = True\n        print(f\"‚úÖ Transaction committed ({len(self.changes)} changes)\")\n    \n    def rollback(self):\n        \"\"\"Undo all changes.\"\"\"\n        if self.completed:\n            print(\"‚ö†Ô∏è  Transaction already committed, cannot rollback\")\n            return\n        \n        print(f\"üîÑ Rolling back {len(self.changes)} changes...\")\n        \n        # Undo in reverse order\n        for change in reversed(self.changes):\n            print(f\"   ‚Ü©Ô∏è  Undoing: {change['action']}\")\n            # In real implementation, execute actual undo operations\n        \n        self.changes.clear()\n        print(\"‚úÖ Rollback complete\")\n\n# Example usage in a workflow\ndef risky_workflow():\n    \"\"\"Workflow that might fail mid-execution.\"\"\"\n    transaction = WorkflowTransaction()\n    \n    try:\n        # Step 1: Update version file\n        print(\"Step 1: Updating version...\")\n        transaction.record_change(\"update_version\", \"1.2.0\")\n        \n        # Step 2: Update changelog\n        print(\"Step 2: Updating changelog...\")\n        transaction.record_change(\"update_changelog\", \"Added new features\")\n        \n        # Step 3: Build artifacts (this fails)\n        print(\"Step 3: Building artifacts...\")\n        raise RuntimeError(\"Build failed: Missing dependency\")\n        \n        # Step 4: Would never reach here\n        transaction.record_change(\"create_tag\", \"v1.2.0\")\n        \n        transaction.commit()\n        \n    except Exception as e:\n        print(f\"\\n‚ùå Workflow failed: {e}\")\n        print(\"   Rolling back all changes...\\n\")\n        transaction.rollback()\n        raise\n\n# Test the rollback mechanism\ntry:\n    risky_workflow()\nexcept RuntimeError:\n    print(\"\\nüí° Changes were rolled back safely!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Pattern 2: Retry with Exponential Backoff\ndef retry_with_backoff(func, max_retries=3, base_delay=1):\n    \"\"\"Retry a function with exponential backoff.\"\"\"\n    \n    for attempt in range(max_retries):\n        try:\n            result = func()\n            print(f\"‚úÖ Success on attempt {attempt + 1}\")\n            return result\n        except Exception as e:\n            if attempt == max_retries - 1:\n                print(f\"‚ùå Failed after {max_retries} attempts\")\n                raise\n            \n            delay = base_delay * (2 ** attempt)\n            print(f\"‚ö†Ô∏è  Attempt {attempt + 1} failed: {e}\")\n            print(f\"   Retrying in {delay}s...\")\n            time.sleep(delay)\n\n# Simulate an unreliable API call\ncall_count = 0\n\ndef unreliable_api_call():\n    \"\"\"Simulates API that fails first 2 times.\"\"\"\n    global call_count\n    call_count += 1\n    \n    if call_count < 3:\n        raise ConnectionError(f\"Network timeout (attempt {call_count})\")\n    \n    return {\"status\": \"success\", \"data\": \"API response\"}\n\n# Test retry mechanism\ncall_count = 0  # Reset\ntry:\n    result = retry_with_backoff(unreliable_api_call)\n    print(f\"Final result: {result}\")\nexcept Exception as e:\n    print(f\"Final failure: {e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import time\nfrom pathlib import Path\nfrom typing import Optional, Dict, Any\n\n# Pattern 1: Fail Fast Validation\ndef validate_inputs_early(version: str, project_dir: Path) -> None:\n    \"\"\"Validate all inputs before starting workflow.\"\"\"\n    \n    # Check version format\n    parts = version.split('.')\n    if len(parts) != 3 or not all(p.isdigit() for p in parts):\n        raise ValueError(\n            f\"Invalid version format: {version}\\n\"\n            f\"Expected: X.Y.Z (e.g., 1.2.0)\"\n        )\n    \n    # Check project directory exists\n    if not project_dir.exists():\n        raise FileNotFoundError(\n            f\"Project directory not found: {project_dir}\\n\"\n            f\"Please verify the path is correct\"\n        )\n    \n    # Check for required files\n    required_files = ['setup.py', 'README.md', 'requirements.txt']\n    missing = [f for f in required_files if not (project_dir / f).exists()]\n    \n    if missing:\n        raise FileNotFoundError(\n            f\"Missing required files: {', '.join(missing)}\\n\"\n            f\"Please create these files before releasing\"\n        )\n    \n    print(\"‚úÖ Input validation passed\")\n\n# Test it\ntry:\n    validate_inputs_early(\"1.2.0\", Path(\".\"))\n    print(\"   Version format: Valid\")\n    print(\"   Project directory: Found\")\nexcept (ValueError, FileNotFoundError) as e:\n    print(f\"‚ùå Validation failed:\\n{e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Error Handling Code Patterns\n\nLet's implement robust error handling patterns in Python:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 08: Advanced Workflows\n",
    "\n",
    "**Difficulty**: ‚≠ê‚≠ê‚≠ê Advanced  \n",
    "**Estimated Time**: 180 minutes  \n",
    "**Prerequisites**: [Module 03 - Skills](03_working_with_skills.ipynb), [Module 04 - Commands](04_custom_slash_commands.ipynb), [Module 05 - Hooks](05_hooks_automation.ipynb), [Module 06 - MCP](06_mcp_servers_integrations.ipynb), [Module 07 - Subagents](07_subagents_orchestration.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "1. Combine skills, commands, hooks, and subagents into unified workflows\n",
    "2. Design and implement multi-step automation patterns\n",
    "3. Implement robust error handling and recovery strategies\n",
    "4. Optimize workflow performance for speed and efficiency\n",
    "5. Build production-ready automation pipelines\n",
    "6. Monitor and improve workflow effectiveness\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Advanced Workflows\n",
    "\n",
    "### What are Advanced Workflows?\n",
    "\n",
    "**Advanced workflows** combine multiple Claude Code components into cohesive automation systems that solve real-world problems.\n",
    "\n",
    "**Simple task**: \"Review this file\"\n",
    "- Uses: 1 agent, 1 tool\n",
    "- Time: 30 seconds\n",
    "\n",
    "**Advanced workflow**: \"Prepare codebase for production release\"\n",
    "- Uses: Skills + Commands + Hooks + Agents + MCP\n",
    "- Steps: 15+ automated tasks\n",
    "- Time: 5 minutes (vs 2 hours manually)\n",
    "\n",
    "### Components Integration\n",
    "\n",
    "**The 6 building blocks**:\n",
    "\n",
    "| Component | Role | Example |\n",
    "|-----------|------|----------|\n",
    "| **Tools** | Built-in operations | Read, Write, Bash, Grep |\n",
    "| **Skills** | Domain expertise | Testing patterns, code review |\n",
    "| **Commands** | User triggers | `/release`, `/review-pr` |\n",
    "| **Hooks** | Auto-validation | Pre-commit checks |\n",
    "| **Subagents** | Specialized workers | Test generator, security scanner |\n",
    "| **MCP** | External services | GitHub API, databases |\n",
    "\n",
    "### Workflow Architecture\n",
    "\n",
    "**A complete workflow**:\n",
    "\n",
    "```\n",
    "User: /prepare-release\n",
    "  ‚Üì\n",
    "[Slash Command] Triggers workflow\n",
    "  ‚Üì\n",
    "[Skill] Provides release best practices\n",
    "  ‚Üì\n",
    "[Subagents] Parallel execution:\n",
    "  ‚îú‚îÄ Run tests\n",
    "  ‚îú‚îÄ Check security\n",
    "  ‚îú‚îÄ Update docs\n",
    "  ‚îî‚îÄ Build artifacts\n",
    "  ‚Üì\n",
    "[Hook] Validates release criteria\n",
    "  ‚Üì\n",
    "[MCP] Creates GitHub release\n",
    "  ‚Üì\n",
    "‚úÖ Release ready!\n",
    "```\n",
    "\n",
    "### Real-World Workflow Examples\n",
    "\n",
    "**1. Pull Request Review Pipeline**\n",
    "```\n",
    "Command: /review-pr 123\n",
    "‚îú‚îÄ MCP: Fetch PR from GitHub\n",
    "‚îú‚îÄ Skill: PR review patterns\n",
    "‚îú‚îÄ Agents (parallel):\n",
    "‚îÇ  ‚îú‚îÄ Code quality review\n",
    "‚îÇ  ‚îú‚îÄ Security scan\n",
    "‚îÇ  ‚îî‚îÄ Test coverage check\n",
    "‚îú‚îÄ Hook: Validate review completeness\n",
    "‚îî‚îÄ MCP: Post review comments\n",
    "```\n",
    "\n",
    "**2. Automated Documentation Pipeline**\n",
    "```\n",
    "Command: /update-docs\n",
    "‚îú‚îÄ Agents (sequential):\n",
    "‚îÇ  ‚îú‚îÄ Analyze codebase structure\n",
    "‚îÇ  ‚îú‚îÄ Generate API docs\n",
    "‚îÇ  ‚îú‚îÄ Create examples\n",
    "‚îÇ  ‚îî‚îÄ Update README\n",
    "‚îú‚îÄ Hook: Validate markdown quality\n",
    "‚îî‚îÄ Bash: Commit and push\n",
    "```\n",
    "\n",
    "**3. CI/CD Workflow**\n",
    "```\n",
    "Hook: On git push\n",
    "‚îú‚îÄ Agents (parallel):\n",
    "‚îÇ  ‚îú‚îÄ Run test suite\n",
    "‚îÇ  ‚îú‚îÄ Lint codebase\n",
    "‚îÇ  ‚îî‚îÄ Build artifacts\n",
    "‚îú‚îÄ Error handling: Rollback on failure\n",
    "‚îî‚îÄ MCP: Deploy to staging\n",
    "```\n",
    "\n",
    "### Benefits of Advanced Workflows\n",
    "\n",
    "**Consistency**:\n",
    "- Same process every time\n",
    "- No steps forgotten\n",
    "- Follows best practices\n",
    "\n",
    "**Speed**:\n",
    "- Parallel execution\n",
    "- Automated repetitive tasks\n",
    "- 10-20x faster than manual\n",
    "\n",
    "**Quality**:\n",
    "- Automated validation\n",
    "- Comprehensive checks\n",
    "- Catches issues early\n",
    "\n",
    "**Scalability**:\n",
    "- Works for 1 or 1000 files\n",
    "- Reusable across projects\n",
    "- Team-wide standards\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Combining Skills, Commands, and Hooks\n",
    "\n",
    "### The Three-Layer Architecture\n",
    "\n",
    "**Layer 1: Skills** (Knowledge)\n",
    "- Provide domain expertise\n",
    "- Activate automatically on keywords\n",
    "- Guide Claude's approach\n",
    "\n",
    "**Layer 2: Commands** (Triggers)\n",
    "- User-initiated workflows\n",
    "- Reusable task sequences\n",
    "- Accept arguments for flexibility\n",
    "\n",
    "**Layer 3: Hooks** (Guardrails)\n",
    "- Automatic validation\n",
    "- Quality enforcement\n",
    "- Block dangerous operations\n",
    "\n",
    "### Integration Pattern 1: Skill + Command\n",
    "\n",
    "**Skill provides expertise, command triggers workflow**:\n",
    "\n",
    "**Skill**: `.claude/skills/testing-expert/SKILL.md`\n",
    "```markdown\n",
    "# Testing Expert\n",
    "\n",
    "Expertise in test-driven development, test coverage, and testing best practices.\n",
    "\n",
    "## When Activated\n",
    "- User mentions: test, testing, TDD, coverage\n",
    "- Commands: /add-tests, /test-coverage\n",
    "\n",
    "## Guidelines\n",
    "- Follow AAA pattern (Arrange-Act-Assert)\n",
    "- Each test tests one thing\n",
    "- Use descriptive test names\n",
    "- Mock external dependencies\n",
    "```\n",
    "\n",
    "**Command**: `.claude/commands/add-tests.md`\n",
    "```markdown\n",
    "# Add Tests Command\n",
    "\n",
    "Generate comprehensive tests for the specified file.\n",
    "\n",
    "## Usage\n",
    "/add-tests <filepath>\n",
    "\n",
    "## Task\n",
    "1. Read the source file: $ARGUMENTS\n",
    "2. Analyze all functions and classes\n",
    "3. Generate unit tests covering:\n",
    "   - Happy path cases\n",
    "   - Edge cases (empty, None, extremes)\n",
    "   - Error cases (exceptions)\n",
    "4. Create test file following testing-expert skill guidelines\n",
    "5. Run tests to verify they work\n",
    "```\n",
    "\n",
    "**Workflow**:\n",
    "```\n",
    "User: /add-tests src/auth.py\n",
    "  ‚Üì\n",
    "[Command] Loads add-tests prompt\n",
    "  ‚Üì\n",
    "[Skill] Testing-expert activates (keyword: \"tests\")\n",
    "  ‚Üì\n",
    "Claude: Uses testing expertise to generate high-quality tests\n",
    "```\n",
    "\n",
    "### Integration Pattern 2: Command + Hook\n",
    "\n",
    "**Command executes workflow, hook validates**:\n",
    "\n",
    "**Command**: `.claude/commands/commit.md`\n",
    "```markdown\n",
    "# Smart Commit\n",
    "\n",
    "Commit changes with automatic quality checks.\n",
    "\n",
    "## Task\n",
    "1. Review changes: git status, git diff\n",
    "2. Generate descriptive commit message\n",
    "3. Add changed files: git add\n",
    "4. Commit with message\n",
    "5. Show commit details: git log -1\n",
    "```\n",
    "\n",
    "**Hook**: `.claude/hooks/pre-commit.sh`\n",
    "```bash\n",
    "#!/bin/bash\n",
    "# Runs before git commit\n",
    "\n",
    "if [[ \"$TOOL_ARGS\" =~ \"git commit\" ]]; then\n",
    "    # Run linter\n",
    "    flake8 . || exit 1\n",
    "    \n",
    "    # Run tests\n",
    "    pytest || exit 1\n",
    "    \n",
    "    echo \"‚úÖ Pre-commit checks passed\"\n",
    "fi\n",
    "\n",
    "exit 0\n",
    "```\n",
    "\n",
    "**Workflow**:\n",
    "```\n",
    "User: /commit\n",
    "  ‚Üì\n",
    "[Command] Initiates commit workflow\n",
    "  ‚Üì\n",
    "Claude: git add, git commit\n",
    "  ‚Üì\n",
    "[Hook] Pre-commit validation triggers\n",
    "  ‚îú‚îÄ Run linter ‚úì\n",
    "  ‚îú‚îÄ Run tests ‚úì\n",
    "  ‚îî‚îÄ All passed ‚Üí Allow commit\n",
    "```\n",
    "\n",
    "### Integration Pattern 3: Skill + Command + Hook\n",
    "\n",
    "**Complete workflow with all three layers**:\n",
    "\n",
    "**Use case**: Security-conscious code review\n",
    "\n",
    "**Skill**: Security expertise\n",
    "- Knows common vulnerabilities (SQL injection, XSS, etc.)\n",
    "- Understands secure coding patterns\n",
    "\n",
    "**Command**: `/security-review <file>`\n",
    "- Triggers comprehensive security analysis\n",
    "- Uses security skill for guidance\n",
    "\n",
    "**Hook**: Block commits with security issues\n",
    "- Scans for hardcoded secrets\n",
    "- Checks for known vulnerabilities\n",
    "- Blocks commit if issues found\n",
    "\n",
    "**Workflow**:\n",
    "```\n",
    "User: /security-review auth.py\n",
    "  ‚Üì\n",
    "[Skill] Security-expert activates\n",
    "  ‚Üì\n",
    "[Command] Runs security review steps:\n",
    "  ‚îú‚îÄ Scan for SQL injection\n",
    "  ‚îú‚îÄ Check authentication logic\n",
    "  ‚îú‚îÄ Verify input validation\n",
    "  ‚îî‚îÄ Generate security report\n",
    "  ‚Üì\n",
    "User: /commit\n",
    "  ‚Üì\n",
    "[Hook] Security scan before commit:\n",
    "  ‚îú‚îÄ Check for hardcoded credentials ‚úó FOUND\n",
    "  ‚îî‚îÄ Block commit with error\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hands-On Section 1: Build a Code Quality Workflow ‚≠ê‚≠ê\n",
    "\n",
    "Let's build a complete code quality workflow combining skills, commands, and hooks.\n",
    "\n",
    "### Exercise 1: Create Code Quality Skill\n",
    "\n",
    "**Goal**: Skill that provides code quality expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create skills directory\n",
    "skills_dir = Path('.claude/skills/code-quality')\n",
    "skills_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create skill definition\n",
    "skill_content = '''# Code Quality Expert\n",
    "\n",
    "Expert in code quality, maintainability, and best practices across multiple languages.\n",
    "\n",
    "## Description\n",
    "\n",
    "This skill provides expertise in:\n",
    "- Code readability and clarity\n",
    "- Design patterns and anti-patterns\n",
    "- Performance optimization\n",
    "- Testing best practices\n",
    "- Documentation standards\n",
    "\n",
    "## Activation Keywords\n",
    "\n",
    "- quality, code quality, refactor, refactoring\n",
    "- clean code, maintainability\n",
    "- best practices, code review\n",
    "- optimize, optimization\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "### Code Quality Principles\n",
    "\n",
    "1. **Readability First**\n",
    "   - Clear variable and function names\n",
    "   - Consistent formatting\n",
    "   - Comments explain WHY, not WHAT\n",
    "\n",
    "2. **SOLID Principles**\n",
    "   - Single Responsibility: One class, one purpose\n",
    "   - Open/Closed: Open for extension, closed for modification\n",
    "   - Liskov Substitution: Subtypes must be substitutable\n",
    "   - Interface Segregation: Many specific interfaces\n",
    "   - Dependency Inversion: Depend on abstractions\n",
    "\n",
    "3. **DRY (Don't Repeat Yourself)**\n",
    "   - Extract common logic into functions\n",
    "   - Use inheritance/composition wisely\n",
    "   - Avoid code duplication\n",
    "\n",
    "4. **KISS (Keep It Simple, Stupid)**\n",
    "   - Simplest solution that works\n",
    "   - Avoid over-engineering\n",
    "   - Clear > Clever\n",
    "\n",
    "### Code Review Checklist\n",
    "\n",
    "- [ ] Functions < 50 lines\n",
    "- [ ] Descriptive naming (no x, temp, data)\n",
    "- [ ] No magic numbers (use constants)\n",
    "- [ ] Proper error handling\n",
    "- [ ] Unit tests for new code\n",
    "- [ ] No code duplication\n",
    "- [ ] Comments for complex logic\n",
    "- [ ] Consistent style\n",
    "\n",
    "### Language-Specific Guidelines\n",
    "\n",
    "**Python**:\n",
    "- Follow PEP 8\n",
    "- Use type hints (Python 3.5+)\n",
    "- List comprehensions for simple transformations\n",
    "- Context managers for resources\n",
    "\n",
    "**JavaScript**:\n",
    "- Use const/let, avoid var\n",
    "- Arrow functions for callbacks\n",
    "- Async/await over callbacks\n",
    "- Destructuring for cleaner code\n",
    "\n",
    "## Output Format\n",
    "\n",
    "When reviewing code, provide:\n",
    "\n",
    "1. **Overall Assessment**: Brief summary\n",
    "2. **Strengths**: What's done well\n",
    "3. **Issues by Priority**:\n",
    "   - Critical: Bugs, security issues\n",
    "   - High: Maintainability concerns\n",
    "   - Medium: Style inconsistencies\n",
    "   - Low: Minor improvements\n",
    "4. **Specific Recommendations**: With line numbers and examples\n",
    "'''\n",
    "\n",
    "skill_file = skills_dir / 'SKILL.md'\n",
    "skill_file.write_text(skill_content)\n",
    "\n",
    "print(f\"‚úÖ Created code quality skill: {skill_file}\")\n",
    "print(\"\\nüìö Skill provides expertise in:\")\n",
    "print(\"   - SOLID principles\")\n",
    "print(\"   - DRY and KISS\")\n",
    "print(\"   - Code review checklists\")\n",
    "print(\"   - Language-specific best practices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Create Quality Check Command\n",
    "\n",
    "**Goal**: Slash command that triggers comprehensive quality check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create commands directory\n",
    "commands_dir = Path('.claude/commands')\n",
    "commands_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create quality check command\n",
    "command_content = '''# Quality Check\n",
    "\n",
    "Comprehensive code quality analysis using code-quality skill.\n",
    "\n",
    "## Description\n",
    "\n",
    "Performs thorough code quality review including:\n",
    "- Code structure and organization\n",
    "- Naming conventions\n",
    "- Design patterns\n",
    "- Testing coverage\n",
    "- Documentation quality\n",
    "\n",
    "## Usage\n",
    "\n",
    "/quality-check <filepath or directory>\n",
    "\n",
    "## Examples\n",
    "\n",
    "/quality-check src/auth.py\n",
    "/quality-check src/\n",
    "/quality-check .\n",
    "\n",
    "## Task\n",
    "\n",
    "You are a code quality expert. Perform a comprehensive quality review:\n",
    "\n",
    "1. **Read the target**: $ARGUMENTS\n",
    "   - If file: analyze that file\n",
    "   - If directory: find all code files\n",
    "\n",
    "2. **Analyze Structure**:\n",
    "   - File organization\n",
    "   - Function/class sizes\n",
    "   - Dependency management\n",
    "   - Module cohesion\n",
    "\n",
    "3. **Check Code Quality**:\n",
    "   - Naming: Are names descriptive?\n",
    "   - Complexity: Any functions too complex?\n",
    "   - Duplication: Is code DRY?\n",
    "   - Comments: Helpful and up-to-date?\n",
    "\n",
    "4. **Review Design**:\n",
    "   - SOLID principles followed?\n",
    "   - Appropriate design patterns?\n",
    "   - Separation of concerns?\n",
    "   - Error handling strategy?\n",
    "\n",
    "5. **Test Coverage**:\n",
    "   - Do test files exist?\n",
    "   - Are critical paths tested?\n",
    "   - Test quality and clarity?\n",
    "\n",
    "6. **Generate Report**:\n",
    "\n",
    "```markdown\n",
    "# Code Quality Report\n",
    "\n",
    "## Summary\n",
    "Overall Score: X/10\n",
    "[2-3 sentence summary]\n",
    "\n",
    "## Strengths\n",
    "- [What's done well]\n",
    "- [Good practices observed]\n",
    "\n",
    "## Issues\n",
    "\n",
    "### Critical (Fix Immediately)\n",
    "1. **File:Line** - [Issue and impact]\n",
    "   Solution: [How to fix]\n",
    "\n",
    "### High Priority\n",
    "1. **File:Line** - [Issue]\n",
    "\n",
    "### Medium Priority\n",
    "1. **File:Line** - [Issue]\n",
    "\n",
    "## Recommendations\n",
    "1. [Top priority improvement]\n",
    "2. [Second priority]\n",
    "3. [Third priority]\n",
    "\n",
    "## Next Steps\n",
    "- [ ] [Concrete action item]\n",
    "- [ ] [Concrete action item]\n",
    "```\n",
    "\n",
    "Use the code-quality skill for expert guidance.\n",
    "'''\n",
    "\n",
    "command_file = commands_dir / 'quality-check.md'\n",
    "command_file.write_text(command_content)\n",
    "\n",
    "print(f\"‚úÖ Created quality-check command: {command_file}\")\n",
    "print(\"\\nüéØ Usage: /quality-check <file or directory>\")\n",
    "print(\"\\nüìã This command will:\")\n",
    "print(\"   - Analyze code structure\")\n",
    "print(\"   - Check quality metrics\")\n",
    "print(\"   - Review design patterns\")\n",
    "print(\"   - Assess test coverage\")\n",
    "print(\"   - Generate comprehensive report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Create Quality Gate Hook\n",
    "\n",
    "**Goal**: Hook that enforces quality standards before commits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hooks directory\n",
    "hooks_dir = Path('.claude/hooks')\n",
    "hooks_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create quality gate hook\n",
    "hook_content = '''#!/bin/bash\n",
    "\n",
    "# Quality Gate Hook\n",
    "# Enforces code quality standards before commits\n",
    "\n",
    "# Only run on git commit commands\n",
    "if [[ \"$TOOL_NAME\" = \"Bash\" && \"$TOOL_ARGS\" =~ \"git commit\" ]]; then\n",
    "    \n",
    "    echo \"üîç Quality Gate: Running checks...\"\n",
    "    echo \"\"\n",
    "    \n",
    "    # Track failures\n",
    "    FAILED=0\n",
    "    \n",
    "    # Get staged files\n",
    "    STAGED_FILES=$(git diff --cached --name-only --diff-filter=ACM)\n",
    "    \n",
    "    if [ -z \"$STAGED_FILES\" ]; then\n",
    "        echo \"‚ö†Ô∏è  No staged files found\"\n",
    "        exit 0\n",
    "    fi\n",
    "    \n",
    "    # Check 1: Code Formatting\n",
    "    echo \"  ‚Üí Checking code formatting...\"\n",
    "    \n",
    "    # Python files\n",
    "    PY_FILES=$(echo \"$STAGED_FILES\" | grep \"\\.py$\" || true)\n",
    "    if [ -n \"$PY_FILES\" ]; then\n",
    "        if command -v black &>/dev/null; then\n",
    "            if ! black --check $PY_FILES 2>/dev/null; then\n",
    "                echo \"    ‚ùå Python formatting failed\"\n",
    "                echo \"       Run: black <filename>\"\n",
    "                FAILED=1\n",
    "            else\n",
    "                echo \"    ‚úÖ Python formatting passed\"\n",
    "            fi\n",
    "        fi\n",
    "    fi\n",
    "    \n",
    "    # Check 2: Linting\n",
    "    echo \"  ‚Üí Running linter...\"\n",
    "    \n",
    "    if [ -n \"$PY_FILES\" ]; then\n",
    "        if command -v flake8 &>/dev/null; then\n",
    "            if ! flake8 $PY_FILES --max-line-length=100 --extend-ignore=E203 2>/dev/null; then\n",
    "                echo \"    ‚ùå Linting failed\"\n",
    "                FAILED=1\n",
    "            else\n",
    "                echo \"    ‚úÖ Linting passed\"\n",
    "            fi\n",
    "        fi\n",
    "    fi\n",
    "    \n",
    "    # Check 3: Function Length\n",
    "    echo \"  ‚Üí Checking function length...\"\n",
    "    \n",
    "    for file in $PY_FILES; do\n",
    "        # Find functions longer than 50 lines\n",
    "        LONG_FUNCS=$(awk '/^def / {start=NR; name=$2} /^def / || /^class / {if (start && NR-start>50) print FILENAME\":\"start\": \"name} END {if (start && NR-start>50) print FILENAME\":\"start\": \"name}' \"$file\" 2>/dev/null || true)\n",
    "        \n",
    "        if [ -n \"$LONG_FUNCS\" ]; then\n",
    "            echo \"    ‚ö†Ô∏è  Long functions found in $file\"\n",
    "            echo \"       Consider breaking into smaller functions\"\n",
    "        fi\n",
    "    done\n",
    "    \n",
    "    echo \"    ‚úÖ Function length checked\"\n",
    "    \n",
    "    # Check 4: TODOs/FIXMEs\n",
    "    echo \"  ‚Üí Checking for TODOs/FIXMEs...\"\n",
    "    \n",
    "    TODO_COUNT=0\n",
    "    for file in $STAGED_FILES; do\n",
    "        TODOS=$(grep -i \"TODO\\|FIXME\" \"$file\" 2>/dev/null || true)\n",
    "        if [ -n \"$TODOS\" ]; then\n",
    "            ((TODO_COUNT++))\n",
    "        fi\n",
    "    done\n",
    "    \n",
    "    if [ $TODO_COUNT -gt 0 ]; then\n",
    "        echo \"    ‚ö†Ô∏è  Found $TODO_COUNT file(s) with TODO/FIXME\"\n",
    "        echo \"       Consider resolving before commit\"\n",
    "    else\n",
    "        echo \"    ‚úÖ No TODOs/FIXMEs\"\n",
    "    fi\n",
    "    \n",
    "    echo \"\"\n",
    "    \n",
    "    # Final decision\n",
    "    if [ $FAILED -eq 1 ]; then\n",
    "        echo \"‚ùå Quality Gate FAILED\"\n",
    "        echo \"\"\n",
    "        echo \"Fix the issues above before committing.\"\n",
    "        echo \"Or run: /quality-check <file> for detailed analysis\"\n",
    "        exit 1\n",
    "    else\n",
    "        echo \"‚úÖ Quality Gate PASSED\"\n",
    "        echo \"   All checks completed successfully\"\n",
    "    fi\n",
    "fi\n",
    "\n",
    "exit 0\n",
    "'''\n",
    "\n",
    "hook_file = hooks_dir / 'quality-gate.sh'\n",
    "hook_file.write_text(hook_content)\n",
    "hook_file.chmod(0o755)\n",
    "\n",
    "print(f\"‚úÖ Created quality gate hook: {hook_file}\")\n",
    "print(\"‚úÖ Made executable (chmod 755)\")\n",
    "print(\"\\nüîí This hook will:\")\n",
    "print(\"   - Check code formatting (black)\")\n",
    "print(\"   - Run linter (flake8)\")\n",
    "print(\"   - Validate function length (<50 lines)\")\n",
    "print(\"   - Detect TODOs/FIXMEs\")\n",
    "print(\"   - Block commit if checks fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Configure and Test the Workflow\n",
    "\n",
    "**Goal**: Enable the hook and test the complete workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Update settings.json to enable the hook\n",
    "settings_file = Path('.claude/settings.json')\n",
    "\n",
    "if settings_file.exists():\n",
    "    settings = json.loads(settings_file.read_text())\n",
    "else:\n",
    "    settings = {}\n",
    "\n",
    "# Add quality gate hook\n",
    "if 'hooks' not in settings:\n",
    "    settings['hooks'] = {}\n",
    "\n",
    "settings['hooks']['tool_call'] = {\n",
    "    'command': '.claude/hooks/quality-gate.sh'\n",
    "}\n",
    "\n",
    "settings_file.write_text(json.dumps(settings, indent=2))\n",
    "\n",
    "print(\"‚úÖ Updated .claude/settings.json\")\n",
    "print(\"\\nüìã Quality Gate Workflow is now active!\")\n",
    "print(\"\\nüéØ Try this workflow:\")\n",
    "print(\"   1. Run: /quality-check <your-file>\")\n",
    "print(\"      ‚Üí Uses skill + command for detailed review\")\n",
    "print(\"\")\n",
    "print(\"   2. Make improvements based on report\")\n",
    "print(\"\")\n",
    "print(\"   3. Try to commit: git commit -m 'message'\")\n",
    "print(\"      ‚Üí Hook validates quality automatically\")\n",
    "print(\"\")\n",
    "print(\"   4. If quality checks pass ‚Üí Commit succeeds\")\n",
    "print(\"      If checks fail ‚Üí Commit blocked with clear errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Workflow Diagram\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ          Code Quality Workflow                  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "Phase 1: Manual Review\n",
    "  User: /quality-check src/auth.py\n",
    "    ‚Üì\n",
    "  [Command] quality-check.md loads\n",
    "    ‚Üì\n",
    "  [Skill] code-quality activates (keyword: \"quality\")\n",
    "    ‚Üì\n",
    "  Claude: Comprehensive analysis using skill guidelines\n",
    "    ‚îú‚îÄ Structure check\n",
    "    ‚îú‚îÄ Naming review\n",
    "    ‚îú‚îÄ Design patterns\n",
    "    ‚îî‚îÄ Test coverage\n",
    "    ‚Üì\n",
    "  Output: Detailed quality report\n",
    "\n",
    "Phase 2: Make Improvements\n",
    "  Developer fixes issues from report\n",
    "\n",
    "Phase 3: Automatic Validation\n",
    "  User: git commit -m \"Improve auth module\"\n",
    "    ‚Üì\n",
    "  [Hook] quality-gate.sh triggers\n",
    "    ‚îú‚îÄ ‚úÖ Format check (black)\n",
    "    ‚îú‚îÄ ‚úÖ Linter (flake8)\n",
    "    ‚îú‚îÄ ‚úÖ Function length\n",
    "    ‚îî‚îÄ ‚úÖ No TODOs\n",
    "    ‚Üì\n",
    "  All passed ‚Üí ‚úÖ Commit allowed\n",
    "  \n",
    "  OR\n",
    "  \n",
    "  Any failed ‚Üí ‚ùå Commit blocked\n",
    "    ‚Üì\n",
    "  Clear error messages guide fixes\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Error Recovery Workflows\n\n**When to use**: Handle failures gracefully.\n\n**Pattern**:\n```\nTry:\n  Execute task\nCatch error:\n  Log error\n  Attempt recovery\n  If recovery fails:\n    Rollback changes\n    Notify user\n```\n\n**Example: Deployment with Rollback**\n```\n1. Backup current state\n2. Try deployment:\n   a. Run tests\n   b. Build artifacts\n   c. Deploy to staging\n   d. Smoke tests\n3. If any step fails:\n   a. Log detailed error\n   b. Restore from backup\n   c. Notify team\n   d. Create rollback report\n```\n\n---"
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Hands-On Section 2: Build a Release Preparation Workflow ‚≠ê‚≠ê‚≠ê\n\nLet's build a production-ready release preparation workflow that combines multiple components.\n\n### Exercise 5: Create Release Workflow Command\n\n**Goal**: Automate the entire release preparation process.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 6. Error Handling and Recovery\n\n### Why Error Handling Matters in Workflows\n\n**Workflows without error handling**:\n```\nStep 1 ‚Üí Step 2 ‚Üí ERROR ‚Üí ‚ùå Workflow crashes\n                          ‚ùå Partial state\n                          ‚ùå No recovery\n```\n\n**Workflows with error handling**:\n```\nStep 1 ‚Üí Step 2 ‚Üí ERROR ‚Üí Log error\n                       ‚Üì\n                    Attempt recovery\n                       ‚Üì\n                    Rollback if needed\n                       ‚Üì\n                    Clear error message\n```\n\n### Error Handling Strategies\n\n**1. Fail Fast**\n- Validate inputs before starting\n- Check prerequisites upfront\n- Don't waste time on doomed operations\n\n**2. Graceful Degradation**\n- Continue with reduced functionality\n- Skip optional steps\n- Complete what's possible\n\n**3. Transactional Rollback**\n- Track all changes\n- Restore previous state on failure\n- Leave no partial modifications\n\n**4. Retry with Backoff**\n- Temporary failures (network, API limits)\n- Exponential backoff: 1s, 2s, 4s, 8s\n- Max retry limit\n\n### Error Types and Responses\n\n| Error Type | Strategy | Example |\n|------------|----------|---------|\n| **User Input** | Validate early, clear message | Invalid version number |\n| **External Service** | Retry with backoff | API rate limit |\n| **File System** | Check existence first | Missing file |\n| **Network** | Timeout + retry | Connection failed |\n| **Logic Error** | Fail fast, log details | Assertion failed |\n| **Resource** | Cleanup, release locks | Out of memory |\n\n### Error Reporting Best Practices\n\n**Bad error message**:\n```\n‚ùå Error occurred\n```\n\n**Good error message**:\n```\n‚úÖ Build failed in Phase 2: Test Suite\n   \n   Error: pytest exited with code 1\n   \n   Failed tests:\n   - test_auth.py::test_login_invalid\n   - test_api.py::test_rate_limiting\n   \n   Next steps:\n   1. Review test output above\n   2. Fix failing tests\n   3. Run: pytest -v for details\n   4. Re-run: /prepare-release 1.2.0\n```\n\n**Elements of good error messages**:\n- **What failed**: Specific step/phase\n- **Why it failed**: Root cause\n- **Impact**: What can't be completed\n- **Next steps**: Concrete actions to fix\n\n---",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}