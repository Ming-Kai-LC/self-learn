# Data Science Development Prompts

**Purpose**: Use these prompts to parallelize development across multiple Claude Code sessions.

**Instructions**:
1. Copy the relevant prompt below
2. Start a new Claude Code session
3. Paste the prompt to begin development
4. Each session will work independently on different folders

---

## üî• HIGHEST PRIORITY - Machine Learning

### Prompt 1: ML Fundamentals (Part 1 - Regression & Classification)

```
I need you to develop Machine Learning fundamentals notebooks for the data-science project.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards and guidelines
- Location: /home/user/self-learn/data-science/05_machine_learning/

**Your Task**:
Create notebooks for ML Fundamentals covering:

1. **Linear Regression** (3 notebooks):
   - Module 00: Introduction to ML and Linear Regression (‚≠ê)
   - Module 01: Multiple Linear Regression (‚≠ê‚≠ê)
   - Module 02: Polynomial Regression and Regularization (‚≠ê‚≠ê)

2. **Logistic Regression** (3 notebooks):
   - Module 03: Binary Classification with Logistic Regression (‚≠ê)
   - Module 04: Multiclass Classification (‚≠ê‚≠ê)
   - Module 05: Advanced Logistic Regression (‚≠ê‚≠ê‚≠ê)

**Requirements**:
- Follow notebook quality standards (‚â•30% markdown, ‚â•3 exercises per concept)
- Use sample datasets (add to data/sample/ if needed, <10MB)
- Include visualizations for all concepts
- Progressive difficulty (‚≠ê to ‚≠ê‚≠ê‚≠ê)
- Test all notebooks ("Restart and Run All")
- Create README.md for the ml-fundamentals subfolder

**Deliverables**:
- 6 complete, tested notebooks
- README.md with learning path
- requirements.txt with dependencies
- Sample data files (if needed)

**Commit Message Format**: [Data-Science-ML] Add: Linear and Logistic Regression modules

Work on branch: claude/ml-fundamentals-regression-[SESSION_ID]
When done, commit and push your changes.
```

---

### Prompt 2: ML Fundamentals (Part 2 - Tree-Based Models)

```
I need you to develop Machine Learning tree-based model notebooks for the data-science project.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards
- Location: /home/user/self-learn/data-science/05_machine_learning/

**Your Task**:
Create notebooks for tree-based ML algorithms:

1. **Decision Trees** (3 notebooks):
   - Module 06: Introduction to Decision Trees (‚≠ê)
   - Module 07: Tree Pruning and Hyperparameters (‚≠ê‚≠ê)
   - Module 08: Regression Trees (‚≠ê‚≠ê)

2. **Random Forests** (3 notebooks):
   - Module 09: Introduction to Random Forests (‚≠ê)
   - Module 10: Feature Importance and Selection (‚≠ê‚≠ê)
   - Module 11: Advanced Random Forest Techniques (‚≠ê‚≠ê‚≠ê)

**Requirements**:
- Follow notebook quality standards (‚â•30% markdown, ‚â•3 exercises)
- Include decision tree visualizations
- Feature importance plots
- Comparison with linear models
- Real-world datasets (classification and regression)
- Test all notebooks

**Deliverables**:
- 6 complete notebooks
- Sample datasets with tree visualization examples
- README section for tree-based methods

**Commit Message Format**: [Data-Science-ML] Add: Decision Trees and Random Forests modules

Work on branch: claude/ml-fundamentals-trees-[SESSION_ID]
```

---

### Prompt 3: ML Fundamentals (Part 3 - Other Algorithms)

```
I need you to develop notebooks for SVM, KNN, and Naive Bayes algorithms.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards
- Location: /home/user/self-learn/data-science/05_machine_learning/

**Your Task**:
Create notebooks covering:

1. **Support Vector Machines** (3 notebooks):
   - Module 12: Introduction to SVM (‚≠ê)
   - Module 13: Kernel Tricks and Non-linear SVM (‚≠ê‚≠ê)
   - Module 14: SVM for Multi-class Classification (‚≠ê‚≠ê‚≠ê)

2. **K-Nearest Neighbors** (2 notebooks):
   - Module 15: KNN for Classification and Regression (‚≠ê)
   - Module 16: Distance Metrics and Optimization (‚≠ê‚≠ê)

3. **Naive Bayes** (2 notebooks):
   - Module 17: Probability Theory and Naive Bayes (‚≠ê)
   - Module 18: Text Classification with Naive Bayes (‚≠ê‚≠ê)

**Requirements**:
- Visual explanations of decision boundaries
- Comparison of different algorithms
- When to use each algorithm (decision guide)
- Real-world applications
- Test all notebooks

**Deliverables**:
- 7 complete notebooks
- Algorithm comparison guide
- Sample datasets for each algorithm type

**Commit Message Format**: [Data-Science-ML] Add: SVM, KNN, and Naive Bayes modules

Work on branch: claude/ml-fundamentals-algorithms-[SESSION_ID]
```

---

### Prompt 4: ML Model Evaluation & Validation

```
I need you to develop notebooks covering model evaluation, validation, and hyperparameter tuning.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards
- Location: /home/user/self-learn/data-science/05_machine_learning/

**Your Task**:
Create comprehensive evaluation and validation notebooks:

1. **Model Evaluation** (3 notebooks):
   - Module 19: Classification Metrics (Accuracy, Precision, Recall, F1) (‚≠ê)
   - Module 20: Regression Metrics (MSE, RMSE, R¬≤, MAE) (‚≠ê)
   - Module 21: ROC Curves and AUC (‚≠ê‚≠ê)

2. **Cross-Validation** (3 notebooks):
   - Module 22: Train-Test Split and Validation Sets (‚≠ê)
   - Module 23: K-Fold Cross-Validation (‚≠ê‚≠ê)
   - Module 24: Stratified and Time-Series CV (‚≠ê‚≠ê‚≠ê)

3. **Hyperparameter Tuning** (3 notebooks):
   - Module 25: Grid Search (‚≠ê‚≠ê)
   - Module 26: Random Search and Bayesian Optimization (‚≠ê‚≠ê‚≠ê)
   - Module 27: Best Practices and Avoiding Overfitting (‚≠ê‚≠ê‚≠ê)

**Requirements**:
- Visual confusion matrices
- Learning curves
- Validation curves
- Practical examples with multiple algorithms
- Common pitfalls and solutions

**Deliverables**:
- 9 complete notebooks
- Evaluation metrics cheat sheet
- Complete ML fundamentals README

**Commit Message Format**: [Data-Science-ML] Add: Model evaluation and validation modules

Work on branch: claude/ml-evaluation-validation-[SESSION_ID]
```

---

### Prompt 5: ML Ensemble Methods

```
I need you to develop notebooks for ensemble learning methods.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards
- Location: /home/user/self-learn/data-science/05_machine_learning/ensemble-methods/

**Your Task**:
Create ensemble methods notebooks:

1. **Bagging and Boosting Fundamentals** (3 notebooks):
   - Module 00: Introduction to Ensemble Learning (‚≠ê)
   - Module 01: Bagging and Bootstrap Aggregating (‚≠ê‚≠ê)
   - Module 02: AdaBoost (‚≠ê‚≠ê)

2. **Gradient Boosting** (4 notebooks):
   - Module 03: Gradient Boosting Fundamentals (‚≠ê‚≠ê)
   - Module 04: XGBoost (‚≠ê‚≠ê‚≠ê)
   - Module 05: LightGBM (‚≠ê‚≠ê‚≠ê)
   - Module 06: CatBoost (‚≠ê‚≠ê‚≠ê)

3. **Stacking and Blending** (3 notebooks):
   - Module 07: Model Stacking (‚≠ê‚≠ê‚≠ê)
   - Module 08: Blending Techniques (‚≠ê‚≠ê‚≠ê)
   - Module 09: Ensemble Best Practices (‚≠ê‚≠ê‚≠ê)

**Requirements**:
- Compare ensemble vs single models
- Hyperparameter tuning for each method
- Feature importance analysis
- Kaggle competition examples
- Performance benchmarks

**Deliverables**:
- 10 complete notebooks
- Ensemble methods comparison guide
- README for ensemble-methods subfolder

**Commit Message Format**: [Data-Science-ML] Add: Ensemble methods (Bagging, Boosting, Stacking)

Work on branch: claude/ml-ensemble-methods-[SESSION_ID]
```

---

### Prompt 6: ML Feature Engineering

```
I need you to develop notebooks for feature engineering techniques.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards
- Location: /home/user/self-learn/data-science/05_machine_learning/feature-engineering/

**Your Task**:
Create feature engineering notebooks:

1. **Feature Selection** (4 notebooks):
   - Module 00: Introduction to Feature Engineering (‚≠ê)
   - Module 01: Filter Methods (Correlation, Chi-Square) (‚≠ê)
   - Module 02: Wrapper Methods (RFE, Forward/Backward Selection) (‚≠ê‚≠ê)
   - Module 03: Embedded Methods (Lasso, Tree-based) (‚≠ê‚≠ê)

2. **Feature Extraction** (4 notebooks):
   - Module 04: Principal Component Analysis (PCA) (‚≠ê‚≠ê)
   - Module 05: Linear Discriminant Analysis (LDA) (‚≠ê‚≠ê)
   - Module 06: t-SNE and UMAP (‚≠ê‚≠ê‚≠ê)
   - Module 07: Autoencoders for Feature Learning (‚≠ê‚≠ê‚≠ê)

3. **Encoding and Transformation** (4 notebooks):
   - Module 08: Categorical Encoding (One-Hot, Label, Target) (‚≠ê)
   - Module 09: Numerical Transformations (Scaling, Normalization) (‚≠ê)
   - Module 10: Feature Crosses and Interactions (‚≠ê‚≠ê)
   - Module 11: Advanced Feature Engineering Pipeline (‚≠ê‚≠ê‚≠ê)

**Requirements**:
- Before/after comparisons
- Impact on model performance
- Visualization of dimensionality reduction
- Practical pipeline examples
- Common pitfalls and solutions

**Deliverables**:
- 12 complete notebooks
- Feature engineering workflow guide
- README for feature-engineering subfolder

**Commit Message Format**: [Data-Science-ML] Add: Feature engineering techniques

Work on branch: claude/ml-feature-engineering-[SESSION_ID]
```

---

## üî• HIGH PRIORITY - Deep Learning Gaps

### Prompt 7: Deep Learning Fundamentals

```
I need you to fill critical gaps in deep learning by creating fundamentals notebooks.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards
- Location: /home/user/self-learn/data-science/06_deep_learning/
- Note: CNN module already exists, focus on fundamentals

**Your Task**:
Create deep learning fundamentals notebooks:

1. **Neural Network Basics** (4 notebooks):
   - Module 00: Introduction to Neural Networks (‚≠ê)
   - Module 01: Perceptrons and Activation Functions (‚≠ê)
   - Module 02: Forward Propagation (‚≠ê‚≠ê)
   - Module 03: Backpropagation and Gradient Descent (‚≠ê‚≠ê)

2. **Training Neural Networks** (4 notebooks):
   - Module 04: Loss Functions and Optimizers (‚≠ê‚≠ê)
   - Module 05: Regularization (Dropout, L1/L2) (‚≠ê‚≠ê)
   - Module 06: Batch Normalization and Layer Normalization (‚≠ê‚≠ê‚≠ê)
   - Module 07: Learning Rate Schedules and Advanced Optimizers (‚≠ê‚≠ê‚≠ê)

3. **Deep Learning Architectures** (3 notebooks):
   - Module 08: Fully Connected Networks (‚≠ê)
   - Module 09: Model Design Patterns (‚≠ê‚≠ê)
   - Module 10: Transfer Learning Fundamentals (‚≠ê‚≠ê)

**Requirements**:
- Visual explanations of concepts (network diagrams, gradient flow)
- Code from scratch (understand internals)
- PyTorch and/or TensorFlow implementations
- Training visualizations (loss curves, accuracy)
- Practical examples with real datasets

**Deliverables**:
- 11 complete notebooks
- Deep learning fundamentals README
- Model training best practices guide

**Commit Message Format**: [Data-Science-DL] Add: Deep learning fundamentals modules

Work on branch: claude/dl-fundamentals-[SESSION_ID]
```

---

### Prompt 8: NLP and Transformers

```
I need you to develop NLP and transformer notebooks for deep learning.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards
- Location: /home/user/self-learn/data-science/06_deep_learning/
- CNN already exists, add NLP alongside it

**Your Task**:
Create NLP and transformer notebooks:

1. **RNN and LSTM** (4 notebooks):
   - Module 11: Introduction to RNN (‚≠ê)
   - Module 12: LSTM and GRU (‚≠ê‚≠ê)
   - Module 13: Bidirectional RNN (‚≠ê‚≠ê)
   - Module 14: Sequence-to-Sequence Models (‚≠ê‚≠ê‚≠ê)

2. **Attention Mechanisms** (3 notebooks):
   - Module 15: Attention Mechanism Fundamentals (‚≠ê‚≠ê)
   - Module 16: Self-Attention (‚≠ê‚≠ê)
   - Module 17: Multi-Head Attention (‚≠ê‚≠ê‚≠ê)

3. **Transformers** (5 notebooks):
   - Module 18: Transformer Architecture (‚≠ê‚≠ê)
   - Module 19: BERT for Text Classification (‚≠ê‚≠ê‚≠ê)
   - Module 20: GPT and Text Generation (‚≠ê‚≠ê‚≠ê)
   - Module 21: Fine-tuning Pre-trained Models (‚≠ê‚≠ê‚≠ê)
   - Module 22: Hugging Face Transformers Library (‚≠ê‚≠ê)

**Requirements**:
- Attention visualization
- Text preprocessing pipelines
- Pre-trained model usage
- Fine-tuning examples
- NLP tasks: classification, generation, QA
- Use small datasets for quick training

**Deliverables**:
- 12 complete notebooks
- NLP/Transformers README section
- Pre-trained model usage guide

**Commit Message Format**: [Data-Science-DL] Add: NLP, RNN, LSTM, and Transformers modules

Work on branch: claude/dl-nlp-transformers-[SESSION_ID]
```

---

## üî• HIGH PRIORITY - MLOps and Deployment

### Prompt 9: MLOps - Docker and Containerization

```
I need you to develop MLOps notebooks focusing on Docker and containerization.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards
- Location: /home/user/self-learn/data-science/09_mlops_deployment/

**Your Task**:
Create Docker and containerization notebooks:

1. **Docker Fundamentals** (4 notebooks):
   - Module 00: Introduction to Docker and Containers (‚≠ê)
   - Module 01: Dockerfile and Building Images (‚≠ê)
   - Module 02: Docker Compose for Multi-Container Apps (‚≠ê‚≠ê)
   - Module 03: Docker Best Practices for ML (‚≠ê‚≠ê)

2. **Containerizing ML Models** (4 notebooks):
   - Module 04: Packaging ML Models with Docker (‚≠ê‚≠ê)
   - Module 05: Creating ML APIs with FastAPI (‚≠ê‚≠ê)
   - Module 06: Flask for Model Deployment (‚≠ê‚≠ê)
   - Module 07: Optimizing Container Size and Performance (‚≠ê‚≠ê‚≠ê)

**Requirements**:
- Working Dockerfiles for ML projects
- API endpoints for model inference
- Example requests and responses
- Testing containerized applications
- Security best practices

**Deliverables**:
- 8 complete notebooks
- Sample Dockerfiles and docker-compose.yml
- API deployment examples
- README for containerization section

**Commit Message Format**: [Data-Science-MLOps] Add: Docker and containerization modules

Work on branch: claude/mlops-docker-[SESSION_ID]
```

---

### Prompt 10: MLOps - Experiment Tracking and Model Registry

```
I need you to develop MLOps notebooks for experiment tracking and model management.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards
- Location: /home/user/self-learn/data-science/09_mlops_deployment/

**Your Task**:
Create experiment tracking and model registry notebooks:

1. **MLflow** (5 notebooks):
   - Module 08: Introduction to MLflow (‚≠ê)
   - Module 09: MLflow Tracking (Logging Metrics, Parameters) (‚≠ê‚≠ê)
   - Module 10: MLflow Projects (‚≠ê‚≠ê)
   - Module 11: MLflow Models and Registry (‚≠ê‚≠ê‚≠ê)
   - Module 12: MLflow Deployment (‚≠ê‚≠ê‚≠ê)

2. **Weights & Biases** (3 notebooks):
   - Module 13: W&B for Experiment Tracking (‚≠ê‚≠ê)
   - Module 14: Hyperparameter Sweeps with W&B (‚≠ê‚≠ê‚≠ê)
   - Module 15: Model Registry and Versioning (‚≠ê‚≠ê)

3. **DVC (Data Version Control)** (2 notebooks):
   - Module 16: Version Control for Data and Models (‚≠ê‚≠ê)
   - Module 17: DVC Pipelines (‚≠ê‚≠ê‚≠ê)

**Requirements**:
- Compare different tracking tools
- Real experiment tracking examples
- Model versioning workflows
- Reproducibility best practices

**Deliverables**:
- 10 complete notebooks
- MLflow setup guide
- Experiment tracking best practices

**Commit Message Format**: [Data-Science-MLOps] Add: MLflow, W&B, and DVC modules

Work on branch: claude/mlops-tracking-[SESSION_ID]
```

---

### Prompt 11: MLOps - CI/CD and Production Deployment

```
I need you to develop MLOps notebooks for CI/CD and production deployment.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards
- Location: /home/user/self-learn/data-science/09_mlops_deployment/

**Your Task**:
Create CI/CD and deployment notebooks:

1. **CI/CD for ML** (4 notebooks):
   - Module 18: Introduction to CI/CD for ML (‚≠ê)
   - Module 19: GitHub Actions for ML Workflows (‚≠ê‚≠ê)
   - Module 20: Automated Testing for ML Models (‚≠ê‚≠ê)
   - Module 21: Continuous Training Pipelines (‚≠ê‚≠ê‚≠ê)

2. **Kubernetes for ML** (4 notebooks):
   - Module 22: Kubernetes Fundamentals (‚≠ê‚≠ê)
   - Module 23: Deploying ML Models to Kubernetes (‚≠ê‚≠ê‚≠ê)
   - Module 24: KServe/Seldon for Model Serving (‚≠ê‚≠ê‚≠ê)
   - Module 25: Scaling and Load Balancing (‚≠ê‚≠ê‚≠ê)

3. **Monitoring and Observability** (3 notebooks):
   - Module 26: Model Monitoring and Drift Detection (‚≠ê‚≠ê)
   - Module 27: Logging and Alerting (‚≠ê‚≠ê)
   - Module 28: A/B Testing and Canary Deployments (‚≠ê‚≠ê‚≠ê)

**Requirements**:
- Working CI/CD pipelines
- Kubernetes deployment manifests
- Monitoring dashboards
- Production best practices
- Cost optimization strategies

**Deliverables**:
- 11 complete notebooks
- CI/CD pipeline templates
- Kubernetes deployment examples
- Complete MLOps README

**Commit Message Format**: [Data-Science-MLOps] Add: CI/CD, Kubernetes, and monitoring modules

Work on branch: claude/mlops-cicd-deployment-[SESSION_ID]
```

---

## üî• HIGH PRIORITY - Portfolio Projects

### Prompt 12: Portfolio Projects - Beginner Level (‚≠ê)

```
I need you to create beginner-level portfolio projects showcasing fundamental ML skills.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards
- Location: /home/user/self-learn/data-science/11_portfolio_projects/

**Your Task**:
Create 3-4 beginner portfolio projects (‚≠ê difficulty):

1. **Project 01: Iris Classification** (‚≠ê)
   - Multi-class classification
   - EDA, visualization, basic ML models
   - Model comparison and evaluation

2. **Project 02: House Price Prediction** (‚≠ê)
   - Regression problem
   - Feature engineering basics
   - Linear regression and tree-based models

3. **Project 03: Customer Segmentation** (‚≠ê)
   - Clustering with K-Means
   - Visualization of segments
   - Business insights

4. **Project 04: Sentiment Analysis** (‚≠ê)
   - Text classification
   - Basic NLP preprocessing
   - Logistic regression or Naive Bayes

**Requirements**:
- End-to-end ML pipeline (data ‚Üí model ‚Üí evaluation)
- Clear business problem statement
- Visualizations and insights
- Model deployment code (simple API)
- Complete documentation
- Professional presentation

**Deliverables**:
- 3-4 complete project notebooks
- README for each project
- Sample datasets
- Deployment examples

**Commit Message Format**: [Data-Science-Portfolio] Add: Beginner-level projects (‚≠ê)

Work on branch: claude/portfolio-beginner-[SESSION_ID]
```

---

### Prompt 13: Portfolio Projects - Intermediate Level (‚≠ê‚≠ê)

```
I need you to create intermediate-level portfolio projects showcasing advanced ML techniques.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards
- Location: /home/user/self-learn/data-science/11_portfolio_projects/

**Your Task**:
Create 3-4 intermediate portfolio projects (‚≠ê‚≠ê difficulty):

1. **Project 05: Credit Card Fraud Detection** (‚≠ê‚≠ê)
   - Imbalanced classification
   - Anomaly detection techniques
   - Ensemble methods (XGBoost, Random Forest)
   - Performance on imbalanced data

2. **Project 06: Movie Recommendation System** (‚≠ê‚≠ê)
   - Collaborative filtering
   - Content-based filtering
   - Hybrid approaches
   - Evaluation metrics for recommenders

3. **Project 07: Time Series Forecasting** (‚≠ê‚≠ê)
   - Stock price or sales forecasting
   - ARIMA, SARIMA, Prophet
   - Feature engineering for time series
   - Walk-forward validation

4. **Project 08: Image Classification with CNN** (‚≠ê‚≠ê)
   - CNN architecture design
   - Transfer learning (ResNet, VGG)
   - Data augmentation
   - Model interpretation (Grad-CAM)

**Requirements**:
- Complex data preprocessing
- Advanced feature engineering
- Multiple modeling approaches
- Hyperparameter tuning
- Model interpretation
- Deployment-ready code

**Deliverables**:
- 3-4 complete project notebooks
- Detailed README for each
- Model comparison analysis
- Deployment examples with API

**Commit Message Format**: [Data-Science-Portfolio] Add: Intermediate-level projects (‚≠ê‚≠ê)

Work on branch: claude/portfolio-intermediate-[SESSION_ID]
```

---

### Prompt 14: Portfolio Projects - Advanced Level (‚≠ê‚≠ê‚≠ê)

```
I need you to create advanced-level portfolio projects showcasing expert ML/DL skills.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Read /home/user/self-learn/.claude/CLAUDE.md for quality standards
- Location: /home/user/self-learn/data-science/11_portfolio_projects/

**Your Task**:
Create 3-4 advanced portfolio projects (‚≠ê‚≠ê‚≠ê difficulty):

1. **Project 09: NLP Question Answering System** (‚≠ê‚≠ê‚≠ê)
   - Fine-tuned BERT/RoBERTa
   - Custom dataset creation
   - Attention visualization
   - Production-ready API with caching

2. **Project 10: Object Detection and Segmentation** (‚≠ê‚≠ê‚≠ê)
   - YOLO or Faster R-CNN
   - Instance segmentation (Mask R-CNN)
   - Real-time inference optimization
   - Deployment to edge devices

3. **Project 11: Kaggle Competition Solution** (‚≠ê‚≠ê‚≠ê)
   - Full competition pipeline
   - Advanced ensemble techniques
   - Feature engineering creativity
   - Model stacking and blending
   - Detailed solution writeup

4. **Project 12: End-to-End MLOps Pipeline** (‚≠ê‚≠ê‚≠ê)
   - CI/CD with GitHub Actions
   - MLflow experiment tracking
   - Docker containerization
   - Kubernetes deployment
   - Monitoring and alerting
   - A/B testing framework

**Requirements**:
- Production-quality code
- Comprehensive documentation
- Reproducible results
- Performance benchmarks
- Scalability considerations
- Security best practices

**Deliverables**:
- 3-4 complete advanced projects
- Detailed architecture documentation
- Deployment guides
- Performance reports
- Complete portfolio README

**Commit Message Format**: [Data-Science-Portfolio] Add: Advanced-level projects (‚≠ê‚≠ê‚≠ê)

Work on branch: claude/portfolio-advanced-[SESSION_ID]
```

---

## MEDIUM PRIORITY - Expansion Projects

### Prompt 15: Mathematics - Advanced Topics

```
I need you to expand the mathematics folder with advanced topics.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Current: 8 notebooks covering basics
- Location: /home/user/self-learn/data-science/01_mathematics/

**Your Task**:
Add advanced mathematics notebooks:

1. **Advanced Probability** (3 notebooks):
   - Module 09: Probability Distributions (‚≠ê‚≠ê)
   - Module 10: Bayesian Statistics (‚≠ê‚≠ê‚≠ê)
   - Module 11: Markov Chains and Monte Carlo (‚≠ê‚≠ê‚≠ê)

2. **Advanced Linear Algebra** (3 notebooks):
   - Module 12: Matrix Decompositions (SVD, QR) (‚≠ê‚≠ê)
   - Module 13: Eigenvalues and Eigenvectors (‚≠ê‚≠ê)
   - Module 14: Linear Algebra for ML (‚≠ê‚≠ê‚≠ê)

3. **Optimization** (3 notebooks):
   - Module 15: Convex Optimization (‚≠ê‚≠ê)
   - Module 16: Gradient-Based Optimization (‚≠ê‚≠ê)
   - Module 17: Constrained Optimization (‚≠ê‚≠ê‚≠ê)

**Deliverables**:
- 9 additional notebooks
- Updated mathematics README
- Visualization-heavy explanations

**Commit Message Format**: [Data-Science-Math] Add: Advanced probability, linear algebra, and optimization

Work on branch: claude/math-advanced-[SESSION_ID]
```

---

### Prompt 16: Visualization - Advanced Techniques

```
I need you to expand visualization folder with advanced techniques.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Current: 8 notebooks covering basics
- Location: /home/user/self-learn/data-science/03_visualization/

**Your Task**:
Add advanced visualization notebooks:

1. **Advanced Plotly** (4 notebooks):
   - Module 09: 3D Visualizations (‚≠ê‚≠ê)
   - Module 10: Animated Visualizations (‚≠ê‚≠ê)
   - Module 11: Interactive Dashboards with Dash (‚≠ê‚≠ê‚≠ê)
   - Module 12: Custom Plotly Components (‚≠ê‚≠ê‚≠ê)

2. **Geographic Visualizations** (3 notebooks):
   - Module 13: Maps with Folium (‚≠ê‚≠ê)
   - Module 14: Choropleth Maps (‚≠ê‚≠ê)
   - Module 15: Geospatial Data with GeoPandas (‚≠ê‚≠ê‚≠ê)

3. **Advanced Techniques** (3 notebooks):
   - Module 16: Custom Styling and Themes (‚≠ê‚≠ê)
   - Module 17: Network Visualizations (‚≠ê‚≠ê)
   - Module 18: Real-time Data Visualization (‚≠ê‚≠ê‚≠ê)

**Deliverables**:
- 10 additional notebooks
- Interactive examples
- Updated visualization README

**Commit Message Format**: [Data-Science-Viz] Add: Advanced Plotly, maps, and custom visualizations

Work on branch: claude/viz-advanced-[SESSION_ID]
```

---

### Prompt 17: Computer Vision - Advanced Techniques

```
I need you to expand computer vision folder with advanced CV and deep learning.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Current: 10 notebooks with OpenCV basics
- Location: /home/user/self-learn/data-science/07_computer_vision/

**Your Task**:
Add advanced computer vision notebooks:

1. **Object Detection** (4 notebooks):
   - Module 11: Introduction to Object Detection (‚≠ê‚≠ê)
   - Module 12: YOLO Implementation (‚≠ê‚≠ê‚≠ê)
   - Module 13: Faster R-CNN (‚≠ê‚≠ê‚≠ê)
   - Module 14: Real-time Object Detection (‚≠ê‚≠ê‚≠ê)

2. **Segmentation** (3 notebooks):
   - Module 15: Semantic Segmentation (U-Net) (‚≠ê‚≠ê‚≠ê)
   - Module 16: Instance Segmentation (Mask R-CNN) (‚≠ê‚≠ê‚≠ê)
   - Module 17: Panoptic Segmentation (‚≠ê‚≠ê‚≠ê)

3. **Advanced Applications** (3 notebooks):
   - Module 18: Face Recognition Systems (‚≠ê‚≠ê)
   - Module 19: Video Processing and Tracking (‚≠ê‚≠ê‚≠ê)
   - Module 20: Generative Models (GANs for Images) (‚≠ê‚≠ê‚≠ê)

**Deliverables**:
- 10 additional notebooks
- Pre-trained model examples
- Real-time demo applications
- Updated CV README

**Commit Message Format**: [Data-Science-CV] Add: Object detection, segmentation, and advanced CV

Work on branch: claude/cv-advanced-[SESSION_ID]
```

---

### Prompt 18: Big Data - PySpark Development

```
I need you to develop the complete big data folder focusing on PySpark.

**Context**:
- Read /home/user/self-learn/data-science/COMPLETION_STATUS.md for project status
- Currently empty (0 notebooks)
- Location: /home/user/self-learn/data-science/08_big_data/

**Your Task**:
Create comprehensive PySpark notebooks:

1. **PySpark Fundamentals** (5 notebooks):
   - Module 00: Introduction to Big Data and Spark (‚≠ê)
   - Module 01: PySpark Setup and RDDs (‚≠ê)
   - Module 02: DataFrames and Datasets (‚≠ê‚≠ê)
   - Module 03: Spark SQL (‚≠ê‚≠ê)
   - Module 04: Data Transformations and Actions (‚≠ê‚≠ê)

2. **PySpark ML** (5 notebooks):
   - Module 05: MLlib Introduction (‚≠ê‚≠ê)
   - Module 06: Classification with PySpark (‚≠ê‚≠ê)
   - Module 07: Regression with PySpark (‚≠ê‚≠ê)
   - Module 08: Clustering with PySpark (‚≠ê‚≠ê‚≠ê)
   - Module 09: Pipeline and Model Persistence (‚≠ê‚≠ê‚≠ê)

3. **Advanced Spark** (5 notebooks):
   - Module 10: Spark Streaming (‚≠ê‚≠ê‚≠ê)
   - Module 11: Performance Tuning (‚≠ê‚≠ê‚≠ê)
   - Module 12: GraphX for Graph Processing (‚≠ê‚≠ê‚≠ê)
   - Module 13: Delta Lake (‚≠ê‚≠ê‚≠ê)
   - Module 14: Spark on Cloud (AWS/GCP/Azure) (‚≠ê‚≠ê‚≠ê)

**Requirements**:
- Use sample datasets appropriate for big data scenarios
- Performance comparisons with pandas
- Best practices for distributed computing
- Real-world use cases

**Deliverables**:
- 15 complete notebooks
- Big data README
- Setup guides for local and cloud Spark
- Sample datasets

**Commit Message Format**: [Data-Science-BigData] Add: Complete PySpark fundamentals and advanced topics

Work on branch: claude/bigdata-pyspark-[SESSION_ID]
```

---

## Usage Instructions

### For Single Session Development:
1. Choose one prompt from above
2. Copy the entire prompt block
3. Start new Claude Code session
4. Paste and start working

### For Parallel Development:
1. Start multiple Claude Code sessions
2. Assign different prompts to each session
3. Each session works independently
4. Merge results when all complete

### Branch Naming:
- Replace `[SESSION_ID]` with your Claude Code session ID
- Example: `claude/ml-fundamentals-regression-01ABC123def`

### After Completion:
1. Each session should commit and push to its branch
2. Review all branches
3. Merge to main branch when satisfied
4. Update COMPLETION_STATUS.md

---

## Priority Order for Development

**If doing sequentially, follow this order**:

1. ‚ö° **Prompts 1-4**: ML Fundamentals (foundation for everything)
2. ‚ö° **Prompt 5**: ML Ensemble Methods (essential ML skill)
3. ‚ö° **Prompt 6**: Feature Engineering (practical ML skill)
4. ‚ö° **Prompt 7**: Deep Learning Fundamentals (DL foundation)
5. ‚ö° **Prompt 8**: NLP and Transformers (modern DL)
6. ‚ö° **Prompts 9-11**: MLOps (production skills)
7. ‚ö° **Prompts 12-14**: Portfolio Projects (showcase skills)
8. üìä **Prompts 15-18**: Expansion topics (as needed)

**If doing in parallel, group by**:
- **ML Track**: Prompts 1-6
- **DL Track**: Prompts 7-8
- **MLOps Track**: Prompts 9-11
- **Portfolio Track**: Prompts 12-14
- **Expansion Track**: Prompts 15-18

---

**Total Prompts**: 18 specialized development prompts
**Estimated Total Time**: 400-500 hours of development
**Target Output**: ~200-250 additional notebooks

Good luck with the development! üöÄ
