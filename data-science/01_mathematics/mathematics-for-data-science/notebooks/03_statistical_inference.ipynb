{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 03: Statistical Inference\n",
    "\n",
    "**Difficulty**: ⭐⭐ Intermediate\n",
    "\n",
    "**Estimated Time**: 90 minutes\n",
    "\n",
    "**Prerequisites**: \n",
    "- Module 01: Descriptive Statistics\n",
    "- Module 02: Probability Fundamentals\n",
    "- Understanding of mean, standard deviation, and normal distribution\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand sampling distributions and their relationship to population parameters\n",
    "2. Apply the Central Limit Theorem to make inferences about populations\n",
    "3. Calculate and interpret confidence intervals\n",
    "4. Conduct hypothesis tests using p-values\n",
    "5. Understand Type I and Type II errors\n",
    "6. Apply statistical inference to A/B testing scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Configure visualization\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display options\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Population vs Sample\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "**Population**: The entire group we want to study\n",
    "- Population mean: $\\mu$\n",
    "- Population standard deviation: $\\sigma$\n",
    "- Usually impossible or impractical to measure\n",
    "\n",
    "**Sample**: A subset of the population\n",
    "- Sample mean: $\\bar{x}$\n",
    "- Sample standard deviation: $s$\n",
    "- Used to estimate population parameters\n",
    "\n",
    "**Statistical Inference**: Using sample data to make conclusions about the population\n",
    "\n",
    "**Why sampling?**\n",
    "- Cost-effective\n",
    "- Time-efficient  \n",
    "- Sometimes destructive testing (you can't test all lightbulbs!)\n",
    "- Population may be infinite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Population vs Sample\n",
    "# Imagine the TRUE population of heights (which we normally don't know)\n",
    "\n",
    "# Create a population of 10,000 people\n",
    "population_mean = 170  # cm\n",
    "population_std = 10  # cm\n",
    "population_size = 10000\n",
    "\n",
    "population = np.random.normal(population_mean, population_std, population_size)\n",
    "\n",
    "# Take a sample of 100 people\n",
    "sample_size = 100\n",
    "sample = np.random.choice(population, size=sample_size, replace=False)\n",
    "\n",
    "print(\"=== Population Parameters (TRUE values) ===\")\n",
    "print(f\"Population mean (μ): {population_mean} cm\")\n",
    "print(f\"Population std (σ): {population_std} cm\")\n",
    "print(f\"Actual population mean: {np.mean(population):.2f} cm\")\n",
    "print(f\"Actual population std: {np.std(population):.2f} cm\")\n",
    "\n",
    "print(f\"\\n=== Sample Statistics (estimates) ===\")\n",
    "print(f\"Sample size (n): {sample_size}\")\n",
    "print(f\"Sample mean (x̄): {np.mean(sample):.2f} cm\")\n",
    "print(f\"Sample std (s): {np.std(sample, ddof=1):.2f} cm\")  # ddof=1 for sample std\n",
    "\n",
    "print(f\"\\nDifference between sample mean and true mean: {abs(np.mean(sample) - population_mean):.2f} cm\")\n",
    "print(\"\\nThe sample mean is our ESTIMATE of the population mean.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize population vs sample\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Population\n",
    "axes[0].hist(population, bins=50, edgecolor='black', alpha=0.7, color='lightblue')\n",
    "axes[0].axvline(np.mean(population), color='red', linestyle='--', linewidth=2.5,\n",
    "               label=f'Population μ = {np.mean(population):.2f}')\n",
    "axes[0].set_title(f'Population (N = {population_size:,})', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Height (cm)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].legend(fontsize=11)\n",
    "\n",
    "# Sample\n",
    "axes[1].hist(sample, bins=20, edgecolor='black', alpha=0.7, color='lightgreen')\n",
    "axes[1].axvline(np.mean(sample), color='blue', linestyle='--', linewidth=2.5,\n",
    "               label=f'Sample x̄ = {np.mean(sample):.2f}')\n",
    "axes[1].axvline(np.mean(population), color='red', linestyle='--', linewidth=2.5,\n",
    "               label=f'True μ = {np.mean(population):.2f}', alpha=0.7)\n",
    "axes[1].set_title(f'Sample (n = {sample_size})', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Height (cm)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].legend(fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sampling Distribution and the Central Limit Theorem\n",
    "\n",
    "### Sampling Distribution\n",
    "The distribution of a statistic (like the mean) if we repeated our sampling many times.\n",
    "\n",
    "### Central Limit Theorem (CLT)\n",
    "**One of the most important theorems in statistics!**\n",
    "\n",
    "For a population with mean $\\mu$ and standard deviation $\\sigma$, the sampling distribution of the sample mean $\\bar{x}$ approaches a normal distribution as sample size $n$ increases:\n",
    "\n",
    "$$\\bar{x} \\sim N\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)$$\n",
    "\n",
    "**Key insights**:\n",
    "1. The mean of the sampling distribution equals the population mean: $E[\\bar{x}] = \\mu$\n",
    "2. The standard deviation of the sampling distribution (standard error): $SE = \\frac{\\sigma}{\\sqrt{n}}$\n",
    "3. Works even if the population isn't normally distributed!\n",
    "4. Larger samples give more precise estimates (smaller SE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the Central Limit Theorem\n",
    "# Take many samples and look at the distribution of their means\n",
    "\n",
    "num_samples = 10000  # Number of samples to take\n",
    "sample_size = 30  # Size of each sample\n",
    "\n",
    "sample_means = []\n",
    "\n",
    "# Take many samples and calculate their means\n",
    "for i in range(num_samples):\n",
    "    sample = np.random.choice(population, size=sample_size, replace=False)\n",
    "    sample_means.append(np.mean(sample))\n",
    "\n",
    "sample_means = np.array(sample_means)\n",
    "\n",
    "# Theoretical values from CLT\n",
    "theoretical_mean = population_mean\n",
    "theoretical_se = population_std / np.sqrt(sample_size)\n",
    "\n",
    "print(\"=== Central Limit Theorem Demonstration ===\")\n",
    "print(f\"Number of samples: {num_samples:,}\")\n",
    "print(f\"Sample size: {sample_size}\")\n",
    "print(f\"\\nTheoretical (from CLT):\")\n",
    "print(f\"  Mean of sampling distribution: {theoretical_mean:.2f}\")\n",
    "print(f\"  Standard error (SE): {theoretical_se:.2f}\")\n",
    "print(f\"\\nActual (from simulation):\")\n",
    "print(f\"  Mean of sample means: {np.mean(sample_means):.2f}\")\n",
    "print(f\"  Standard deviation of sample means: {np.std(sample_means):.2f}\")\n",
    "print(f\"\\nThe simulation confirms the CLT predictions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sampling distribution\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(sample_means, bins=50, density=True, edgecolor='black', \n",
    "         alpha=0.7, label='Sampling distribution (simulated)')\n",
    "\n",
    "# Overlay the theoretical normal distribution\n",
    "x = np.linspace(sample_means.min(), sample_means.max(), 100)\n",
    "theoretical_dist = stats.norm.pdf(x, theoretical_mean, theoretical_se)\n",
    "plt.plot(x, theoretical_dist, 'r-', linewidth=3, \n",
    "         label=f'Theoretical Normal(μ={theoretical_mean}, SE={theoretical_se:.2f})')\n",
    "\n",
    "plt.axvline(theoretical_mean, color='green', linestyle='--', linewidth=2,\n",
    "           label=f'Population mean = {theoretical_mean}')\n",
    "plt.xlabel('Sample Mean', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.title(f'Sampling Distribution of Sample Mean (n={sample_size})', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The histogram matches the theoretical normal curve - this is the CLT in action!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of sample size on standard error\n",
    "\n",
    "sample_sizes = [5, 10, 30, 50, 100, 200]\n",
    "standard_errors = []\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, n in enumerate(sample_sizes):\n",
    "    # Take many samples of size n\n",
    "    means = []\n",
    "    for _ in range(1000):\n",
    "        sample = np.random.choice(population, size=n, replace=False)\n",
    "        means.append(np.mean(sample))\n",
    "    \n",
    "    means = np.array(means)\n",
    "    se = np.std(means)\n",
    "    standard_errors.append(se)\n",
    "    \n",
    "    # Plot\n",
    "    axes[idx].hist(means, bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].axvline(population_mean, color='red', linestyle='--', linewidth=2)\n",
    "    axes[idx].set_title(f'n={n}, SE={se:.2f}', fontweight='bold')\n",
    "    axes[idx].set_xlabel('Sample Mean')\n",
    "    axes[idx].set_xlim(150, 190)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== Sample Size Effect ===\")\n",
    "for n, se in zip(sample_sizes, standard_errors):\n",
    "    print(f\"n={n:3d}: SE={se:.2f}\")\n",
    "print(\"\\nAs sample size increases, the standard error DECREASES!\")\n",
    "print(\"Larger samples give more precise estimates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Confidence Intervals\n",
    "\n",
    "A **confidence interval** gives a range of plausible values for a population parameter.\n",
    "\n",
    "### For a population mean (when σ is known):\n",
    "\n",
    "$$CI = \\bar{x} \\pm z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "\n",
    "### For a population mean (when σ is unknown - use t-distribution):\n",
    "\n",
    "$$CI = \\bar{x} \\pm t_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}}$$\n",
    "\n",
    "**Interpretation**: We are X% confident that the true population mean lies within this interval.\n",
    "\n",
    "**Common confidence levels**:\n",
    "- 90% CI: $z = 1.645$\n",
    "- 95% CI: $z = 1.96$ (most common)\n",
    "- 99% CI: $z = 2.576$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a 95% confidence interval\n",
    "\n",
    "# Take a sample\n",
    "sample_size = 50\n",
    "sample_data = np.random.choice(population, size=sample_size, replace=False)\n",
    "\n",
    "# Sample statistics\n",
    "sample_mean = np.mean(sample_data)\n",
    "sample_std = np.std(sample_data, ddof=1)\n",
    "sample_se = sample_std / np.sqrt(sample_size)\n",
    "\n",
    "# 95% confidence interval using t-distribution\n",
    "confidence_level = 0.95\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = stats.t.ppf(1 - alpha/2, df=sample_size - 1)\n",
    "\n",
    "margin_of_error = t_critical * sample_se\n",
    "ci_lower = sample_mean - margin_of_error\n",
    "ci_upper = sample_mean + margin_of_error\n",
    "\n",
    "print(\"=== 95% Confidence Interval ===\")\n",
    "print(f\"Sample size: {sample_size}\")\n",
    "print(f\"Sample mean: {sample_mean:.2f} cm\")\n",
    "print(f\"Sample std: {sample_std:.2f} cm\")\n",
    "print(f\"Standard error: {sample_se:.2f} cm\")\n",
    "print(f\"\\nt-critical value (df={sample_size-1}): {t_critical:.3f}\")\n",
    "print(f\"Margin of error: {margin_of_error:.2f} cm\")\n",
    "print(f\"\\n95% Confidence Interval: [{ci_lower:.2f}, {ci_upper:.2f}] cm\")\n",
    "print(f\"\\nInterpretation: We are 95% confident that the true population mean\")\n",
    "print(f\"is between {ci_lower:.2f} cm and {ci_upper:.2f} cm.\")\n",
    "\n",
    "# Check if the true mean is in the interval\n",
    "contains_true_mean = ci_lower <= population_mean <= ci_upper\n",
    "print(f\"\\nTrue population mean: {population_mean} cm\")\n",
    "print(f\"Does the CI contain the true mean? {contains_true_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize what \"95% confident\" means\n",
    "# If we repeated the sampling 100 times, about 95 CIs would contain the true mean\n",
    "\n",
    "num_trials = 100\n",
    "sample_size = 30\n",
    "confidence_level = 0.95\n",
    "\n",
    "ci_contains_mean = []\n",
    "ci_lowers = []\n",
    "ci_uppers = []\n",
    "sample_means_list = []\n",
    "\n",
    "for i in range(num_trials):\n",
    "    # Take a sample\n",
    "    sample = np.random.choice(population, size=sample_size, replace=False)\n",
    "    s_mean = np.mean(sample)\n",
    "    s_std = np.std(sample, ddof=1)\n",
    "    s_se = s_std / np.sqrt(sample_size)\n",
    "    \n",
    "    # Calculate CI\n",
    "    t_crit = stats.t.ppf(1 - (1-confidence_level)/2, df=sample_size - 1)\n",
    "    moe = t_crit * s_se\n",
    "    ci_low = s_mean - moe\n",
    "    ci_high = s_mean + moe\n",
    "    \n",
    "    ci_lowers.append(ci_low)\n",
    "    ci_uppers.append(ci_high)\n",
    "    sample_means_list.append(s_mean)\n",
    "    \n",
    "    # Check if CI contains true mean\n",
    "    ci_contains_mean.append(ci_low <= population_mean <= ci_high)\n",
    "\n",
    "# Count how many CIs contain the true mean\n",
    "num_containing = sum(ci_contains_mean)\n",
    "percentage = (num_containing / num_trials) * 100\n",
    "\n",
    "print(f\"=== Confidence Interval Simulation ===\")\n",
    "print(f\"Number of samples: {num_trials}\")\n",
    "print(f\"Confidence level: {confidence_level*100:.0f}%\")\n",
    "print(f\"\\nCIs containing true mean: {num_containing}/{num_trials} ({percentage:.1f}%)\")\n",
    "print(f\"Expected: ~{confidence_level*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the confidence intervals\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot only first 50 CIs for clarity\n",
    "for i in range(min(50, num_trials)):\n",
    "    color = 'green' if ci_contains_mean[i] else 'red'\n",
    "    alpha = 0.7 if ci_contains_mean[i] else 1.0\n",
    "    plt.plot([ci_lowers[i], ci_uppers[i]], [i, i], color=color, alpha=alpha, linewidth=1.5)\n",
    "    plt.scatter(sample_means_list[i], i, color=color, s=20, zorder=3)\n",
    "\n",
    "plt.axvline(population_mean, color='blue', linestyle='--', linewidth=2.5, \n",
    "           label=f'True population mean = {population_mean}')\n",
    "plt.xlabel('Height (cm)', fontsize=12)\n",
    "plt.ylabel('Sample Number', fontsize=12)\n",
    "plt.title(f'95% Confidence Intervals from {min(50, num_trials)} Samples\\nGreen = Contains true mean, Red = Misses', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAbout {confidence_level*100:.0f}% of the intervals (green) contain the true mean.\")\n",
    "print(f\"About {(1-confidence_level)*100:.0f}% miss the true mean (red).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hypothesis Testing\n",
    "\n",
    "**Hypothesis testing** is a formal process for making decisions based on data.\n",
    "\n",
    "### The Process:\n",
    "\n",
    "1. **State hypotheses**:\n",
    "   - Null hypothesis ($H_0$): The status quo, no effect\n",
    "   - Alternative hypothesis ($H_a$ or $H_1$): What we're testing for\n",
    "\n",
    "2. **Choose significance level** ($\\alpha$): Usually 0.05 (5%)\n",
    "\n",
    "3. **Calculate test statistic**:\n",
    "   $$t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}$$\n",
    "\n",
    "4. **Find p-value**: Probability of observing data this extreme if $H_0$ is true\n",
    "\n",
    "5. **Make decision**:\n",
    "   - If p-value < $\\alpha$: Reject $H_0$ (result is statistically significant)\n",
    "   - If p-value ≥ $\\alpha$: Fail to reject $H_0$ (insufficient evidence)\n",
    "\n",
    "### Types of Tests:\n",
    "- **Two-tailed**: $H_a: \\mu \\neq \\mu_0$\n",
    "- **Right-tailed**: $H_a: \\mu > \\mu_0$\n",
    "- **Left-tailed**: $H_a: \\mu < \\mu_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Testing if a new diet increases average weight loss\n",
    "# H0: μ = 0 kg (no weight loss)\n",
    "# Ha: μ > 0 kg (positive weight loss)\n",
    "\n",
    "# Sample of 30 people on the diet\n",
    "weight_loss = np.array([2.1, 3.5, 1.8, 4.2, 2.9, 3.1, 1.5, 2.8, 3.9, 2.4,\n",
    "                       3.3, 2.7, 1.9, 3.6, 2.2, 3.8, 2.5, 3.4, 1.7, 2.9,\n",
    "                       3.2, 2.6, 3.7, 2.3, 3.5, 2.8, 3.1, 2.4, 3.3, 2.7])\n",
    "\n",
    "n = len(weight_loss)\n",
    "sample_mean = np.mean(weight_loss)\n",
    "sample_std = np.std(weight_loss, ddof=1)\n",
    "hypothesized_mean = 0  # H0: no weight loss\n",
    "\n",
    "# Calculate t-statistic\n",
    "t_statistic = (sample_mean - hypothesized_mean) / (sample_std / np.sqrt(n))\n",
    "\n",
    "# Calculate p-value (one-tailed test)\n",
    "p_value = 1 - stats.t.cdf(t_statistic, df=n-1)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"=== Hypothesis Test: Weight Loss Diet ===\")\n",
    "print(f\"H0: μ = {hypothesized_mean} kg (no effect)\")\n",
    "print(f\"Ha: μ > {hypothesized_mean} kg (diet works)\")\n",
    "print(f\"\\nSample size: {n}\")\n",
    "print(f\"Sample mean: {sample_mean:.2f} kg\")\n",
    "print(f\"Sample std: {sample_std:.2f} kg\")\n",
    "print(f\"\\nt-statistic: {t_statistic:.4f}\")\n",
    "print(f\"p-value: {p_value:.6f}\")\n",
    "print(f\"Significance level (α): {alpha}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "if p_value < alpha:\n",
    "    print(f\"CONCLUSION: Reject H0 (p < {alpha})\")\n",
    "    print(f\"The diet DOES lead to significant weight loss!\")\n",
    "else:\n",
    "    print(f\"CONCLUSION: Fail to reject H0 (p ≥ {alpha})\")\n",
    "    print(f\"Insufficient evidence that the diet works.\")\n",
    "\n",
    "print(f\"\\nInterpretation: There's only a {p_value*100:.4f}% chance of seeing\")\n",
    "print(f\"this much weight loss (or more) if the diet has no effect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the hypothesis test\n",
    "\n",
    "# Create t-distribution\n",
    "x = np.linspace(-4, 6, 1000)\n",
    "y = stats.t.pdf(x, df=n-1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, y, linewidth=2.5, label=f't-distribution (df={n-1})')\n",
    "\n",
    "# Shade rejection region (right tail)\n",
    "t_critical = stats.t.ppf(1 - alpha, df=n-1)\n",
    "x_reject = x[x >= t_critical]\n",
    "y_reject = stats.t.pdf(x_reject, df=n-1)\n",
    "plt.fill_between(x_reject, y_reject, alpha=0.3, color='red', \n",
    "                label=f'Rejection region (α={alpha})')\n",
    "\n",
    "# Shade p-value region\n",
    "x_pvalue = x[x >= t_statistic]\n",
    "y_pvalue = stats.t.pdf(x_pvalue, df=n-1)\n",
    "plt.fill_between(x_pvalue, y_pvalue, alpha=0.5, color='orange',\n",
    "                label=f'p-value = {p_value:.4f}')\n",
    "\n",
    "# Mark critical value and test statistic\n",
    "plt.axvline(t_critical, color='red', linestyle='--', linewidth=2,\n",
    "           label=f't-critical = {t_critical:.3f}')\n",
    "plt.axvline(t_statistic, color='blue', linestyle='--', linewidth=2.5,\n",
    "           label=f't-statistic = {t_statistic:.3f}')\n",
    "\n",
    "plt.xlabel('t-value', fontsize=12)\n",
    "plt.ylabel('Probability Density', fontsize=12)\n",
    "plt.title('One-Tailed Hypothesis Test Visualization', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Since t-statistic ({t_statistic:.3f}) > t-critical ({t_critical:.3f}),\")\n",
    "print(f\"we reject H0 at the {alpha} significance level.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Type I and Type II Errors\n",
    "\n",
    "### Error Types:\n",
    "\n",
    "|  | $H_0$ is True | $H_0$ is False |\n",
    "|---|---|---|\n",
    "| **Reject $H_0$** | Type I Error (α) | Correct! (Power = 1-β) |\n",
    "| **Fail to Reject $H_0$** | Correct! | Type II Error (β) |\n",
    "\n",
    "**Type I Error (False Positive)**:\n",
    "- Rejecting $H_0$ when it's actually true\n",
    "- Probability = $\\alpha$ (significance level)\n",
    "- Example: Concluding a drug works when it doesn't\n",
    "\n",
    "**Type II Error (False Negative)**:\n",
    "- Failing to reject $H_0$ when it's actually false\n",
    "- Probability = $\\beta$\n",
    "- Example: Missing a real effect\n",
    "\n",
    "**Statistical Power**:\n",
    "- Probability of correctly rejecting a false $H_0$\n",
    "- Power = $1 - \\beta$\n",
    "- Higher power = better ability to detect real effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Type I and Type II errors\n",
    "\n",
    "# Scenario: Testing if a coin is biased\n",
    "# H0: p = 0.5 (fair coin)\n",
    "# Ha: p ≠ 0.5 (biased coin)\n",
    "\n",
    "num_simulations = 10000\n",
    "n_flips = 100\n",
    "alpha = 0.05\n",
    "\n",
    "# Type I Error: H0 is TRUE (coin is fair, p=0.5)\n",
    "type_i_errors = 0\n",
    "for _ in range(num_simulations):\n",
    "    # Flip a FAIR coin\n",
    "    flips = np.random.binomial(n_flips, 0.5)\n",
    "    p_hat = flips / n_flips\n",
    "    \n",
    "    # Two-tailed test\n",
    "    se = np.sqrt(0.5 * 0.5 / n_flips)\n",
    "    z = (p_hat - 0.5) / se\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "    \n",
    "    # If we reject H0 (but it's true!), that's a Type I error\n",
    "    if p_value < alpha:\n",
    "        type_i_errors += 1\n",
    "\n",
    "type_i_rate = type_i_errors / num_simulations\n",
    "\n",
    "print(\"=== Type I Error Simulation ===\")\n",
    "print(f\"Scenario: Coin IS fair (p = 0.5)\")\n",
    "print(f\"Number of tests: {num_simulations:,}\")\n",
    "print(f\"Significance level (α): {alpha}\")\n",
    "print(f\"\\nType I errors: {type_i_errors:,}\")\n",
    "print(f\"Type I error rate: {type_i_rate:.4f}\")\n",
    "print(f\"Expected rate: {alpha}\")\n",
    "print(f\"\\nInterpretation: About {type_i_rate*100:.1f}% of the time, we incorrectly\")\n",
    "print(f\"concluded the fair coin was biased!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type II Error: H0 is FALSE (coin is biased, p=0.6)\n",
    "true_p = 0.6  # Coin is actually biased\n",
    "type_ii_errors = 0\n",
    "\n",
    "for _ in range(num_simulations):\n",
    "    # Flip a BIASED coin (p=0.6)\n",
    "    flips = np.random.binomial(n_flips, true_p)\n",
    "    p_hat = flips / n_flips\n",
    "    \n",
    "    # Two-tailed test (using null hypothesis p=0.5)\n",
    "    se = np.sqrt(0.5 * 0.5 / n_flips)\n",
    "    z = (p_hat - 0.5) / se\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "    \n",
    "    # If we fail to reject H0 (but it's false!), that's a Type II error\n",
    "    if p_value >= alpha:\n",
    "        type_ii_errors += 1\n",
    "\n",
    "type_ii_rate = type_ii_errors / num_simulations\n",
    "power = 1 - type_ii_rate\n",
    "\n",
    "print(\"=== Type II Error Simulation ===\")\n",
    "print(f\"Scenario: Coin IS biased (p = {true_p})\")\n",
    "print(f\"Number of tests: {num_simulations:,}\")\n",
    "print(f\"\\nType II errors (β): {type_ii_errors:,}\")\n",
    "print(f\"Type II error rate: {type_ii_rate:.4f}\")\n",
    "print(f\"Statistical Power (1-β): {power:.4f}\")\n",
    "print(f\"\\nInterpretation: {type_ii_rate*100:.1f}% of the time, we failed to detect\")\n",
    "print(f\"that the coin was biased. Our test has {power*100:.1f}% power.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. A/B Testing\n",
    "\n",
    "**A/B testing** compares two groups to determine if there's a significant difference.\n",
    "\n",
    "**Common applications**:\n",
    "- Website design changes\n",
    "- Marketing campaigns\n",
    "- Product features\n",
    "- Medical treatments\n",
    "\n",
    "### Two-Sample t-test:\n",
    "\n",
    "$$t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}$$\n",
    "\n",
    "$H_0$: The two groups have the same mean ($\\mu_1 = \\mu_2$)\n",
    "\n",
    "$H_a$: The two groups have different means ($\\mu_1 \\neq \\mu_2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A/B Testing Example: Website redesign\n",
    "# Does the new design increase time spent on site?\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Control group (old design) - average 5 minutes\n",
    "control_group = np.random.normal(loc=5.0, scale=1.5, size=200)\n",
    "\n",
    "# Treatment group (new design) - average 5.5 minutes\n",
    "treatment_group = np.random.normal(loc=5.5, scale=1.5, size=200)\n",
    "\n",
    "# Calculate statistics\n",
    "control_mean = np.mean(control_group)\n",
    "control_std = np.std(control_group, ddof=1)\n",
    "treatment_mean = np.mean(treatment_group)\n",
    "treatment_std = np.std(treatment_group, ddof=1)\n",
    "\n",
    "print(\"=== A/B Test: Website Redesign ===\")\n",
    "print(f\"\\nControl Group (Old Design):\")\n",
    "print(f\"  n = {len(control_group)}\")\n",
    "print(f\"  Mean = {control_mean:.2f} minutes\")\n",
    "print(f\"  Std = {control_std:.2f} minutes\")\n",
    "\n",
    "print(f\"\\nTreatment Group (New Design):\")\n",
    "print(f\"  n = {len(treatment_group)}\")\n",
    "print(f\"  Mean = {treatment_mean:.2f} minutes\")\n",
    "print(f\"  Std = {treatment_std:.2f} minutes\")\n",
    "\n",
    "print(f\"\\nDifference in means: {treatment_mean - control_mean:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform two-sample t-test\n",
    "\n",
    "# Using scipy's ttest_ind\n",
    "t_stat, p_value = stats.ttest_ind(treatment_group, control_group)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"=== Two-Sample t-Test Results ===\")\n",
    "print(f\"H0: μ_treatment = μ_control (no difference)\")\n",
    "print(f\"Ha: μ_treatment ≠ μ_control (there is a difference)\")\n",
    "print(f\"\\nt-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.6f}\")\n",
    "print(f\"Significance level: {alpha}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "if p_value < alpha:\n",
    "    print(f\"CONCLUSION: Reject H0 (p < {alpha})\")\n",
    "    print(f\"The new design SIGNIFICANTLY increases time on site!\")\n",
    "    print(f\"Average increase: {treatment_mean - control_mean:.2f} minutes\")\n",
    "else:\n",
    "    print(f\"CONCLUSION: Fail to reject H0 (p ≥ {alpha})\")\n",
    "    print(f\"No significant difference between designs.\")\n",
    "\n",
    "# Calculate effect size (Cohen's d)\n",
    "pooled_std = np.sqrt((control_std**2 + treatment_std**2) / 2)\n",
    "cohens_d = (treatment_mean - control_mean) / pooled_std\n",
    "\n",
    "print(f\"\\nEffect Size (Cohen's d): {cohens_d:.3f}\")\n",
    "if abs(cohens_d) < 0.2:\n",
    "    print(\"Effect size: Small\")\n",
    "elif abs(cohens_d) < 0.5:\n",
    "    print(\"Effect size: Medium\")\n",
    "else:\n",
    "    print(\"Effect size: Large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the A/B test results\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histograms\n",
    "axes[0].hist(control_group, bins=30, alpha=0.6, label='Control (Old)', \n",
    "            edgecolor='black', color='blue')\n",
    "axes[0].hist(treatment_group, bins=30, alpha=0.6, label='Treatment (New)', \n",
    "            edgecolor='black', color='red')\n",
    "axes[0].axvline(control_mean, color='blue', linestyle='--', linewidth=2.5,\n",
    "               label=f'Control mean = {control_mean:.2f}')\n",
    "axes[0].axvline(treatment_mean, color='red', linestyle='--', linewidth=2.5,\n",
    "               label=f'Treatment mean = {treatment_mean:.2f}')\n",
    "axes[0].set_xlabel('Time on Site (minutes)', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution Comparison', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "\n",
    "# Box plots\n",
    "data_for_box = [control_group, treatment_group]\n",
    "bp = axes[1].boxplot(data_for_box, labels=['Control', 'Treatment'],\n",
    "                     patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor('lightblue')\n",
    "bp['boxes'][1].set_facecolor('lightcoral')\n",
    "axes[1].set_ylabel('Time on Site (minutes)', fontsize=12)\n",
    "axes[1].set_title('Box Plot Comparison', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"The treatment group clearly shows higher time on site.\")\n",
    "print(f\"This visual difference is confirmed by the statistical test (p = {p_value:.6f}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Practice Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Confidence Interval Calculation\n",
    "\n",
    "A sample of 40 customers spent an average of $\\$85$ with a standard deviation of $\\$12$ at a store.\n",
    "\n",
    "Tasks:\n",
    "1. Calculate a 90% confidence interval for the population mean\n",
    "2. Calculate a 99% confidence interval for the population mean\n",
    "3. Explain why the 99% CI is wider than the 90% CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "n = 40\n",
    "sample_mean = 85\n",
    "sample_std = 12\n",
    "se = sample_std / np.sqrt(n)\n",
    "\n",
    "print(\"=== Exercise 1 Solution ===\")\n",
    "print(f\"Sample size: {n}\")\n",
    "print(f\"Sample mean: ${sample_mean}\")\n",
    "print(f\"Sample std: ${sample_std}\")\n",
    "print(f\"Standard error: ${se:.2f}\")\n",
    "\n",
    "# 1. 90% CI\n",
    "conf_90 = 0.90\n",
    "alpha_90 = 1 - conf_90\n",
    "t_crit_90 = stats.t.ppf(1 - alpha_90/2, df=n-1)\n",
    "moe_90 = t_crit_90 * se\n",
    "ci_90_lower = sample_mean - moe_90\n",
    "ci_90_upper = sample_mean + moe_90\n",
    "\n",
    "print(f\"\\n1. 90% Confidence Interval:\")\n",
    "print(f\"   t-critical (df={n-1}): {t_crit_90:.3f}\")\n",
    "print(f\"   Margin of error: ${moe_90:.2f}\")\n",
    "print(f\"   CI: [${ci_90_lower:.2f}, ${ci_90_upper:.2f}]\")\n",
    "\n",
    "# 2. 99% CI\n",
    "conf_99 = 0.99\n",
    "alpha_99 = 1 - conf_99\n",
    "t_crit_99 = stats.t.ppf(1 - alpha_99/2, df=n-1)\n",
    "moe_99 = t_crit_99 * se\n",
    "ci_99_lower = sample_mean - moe_99\n",
    "ci_99_upper = sample_mean + moe_99\n",
    "\n",
    "print(f\"\\n2. 99% Confidence Interval:\")\n",
    "print(f\"   t-critical (df={n-1}): {t_crit_99:.3f}\")\n",
    "print(f\"   Margin of error: ${moe_99:.2f}\")\n",
    "print(f\"   CI: [${ci_99_lower:.2f}, ${ci_99_upper:.2f}]\")\n",
    "\n",
    "print(f\"\\n3. Why is the 99% CI wider?\")\n",
    "print(f\"   90% CI width: ${ci_90_upper - ci_90_lower:.2f}\")\n",
    "print(f\"   99% CI width: ${ci_99_upper - ci_99_lower:.2f}\")\n",
    "print(f\"\\n   Explanation: To be MORE confident (99% vs 90%) that we've\")\n",
    "print(f\"   captured the true population mean, we need a WIDER interval.\")\n",
    "print(f\"   Higher confidence requires more uncertainty (wider range).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Hypothesis Test\n",
    "\n",
    "A coffee shop claims their average wait time is 5 minutes. You suspect it's actually longer.\n",
    "You measure wait times for 25 customers and get: mean = 5.8 minutes, std = 1.2 minutes.\n",
    "\n",
    "Tasks:\n",
    "1. Set up the null and alternative hypotheses\n",
    "2. Calculate the t-statistic and p-value\n",
    "3. Make a decision at α = 0.05\n",
    "4. Visualize the hypothesis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "n = 25\n",
    "sample_mean = 5.8\n",
    "sample_std = 1.2\n",
    "claimed_mean = 5.0\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"=== Exercise 2 Solution ===\")\n",
    "\n",
    "# 1. Hypotheses\n",
    "print(\"1. Hypotheses:\")\n",
    "print(f\"   H0: μ = {claimed_mean} minutes (wait time is as claimed)\")\n",
    "print(f\"   Ha: μ > {claimed_mean} minutes (wait time is longer)\")\n",
    "print(f\"   This is a ONE-TAILED (right-tailed) test.\")\n",
    "\n",
    "# 2. Calculate t-statistic and p-value\n",
    "se = sample_std / np.sqrt(n)\n",
    "t_stat = (sample_mean - claimed_mean) / se\n",
    "p_value = 1 - stats.t.cdf(t_stat, df=n-1)\n",
    "\n",
    "print(f\"\\n2. Test Statistics:\")\n",
    "print(f\"   Sample mean: {sample_mean} minutes\")\n",
    "print(f\"   Standard error: {se:.4f}\")\n",
    "print(f\"   t-statistic: {t_stat:.4f}\")\n",
    "print(f\"   p-value: {p_value:.6f}\")\n",
    "\n",
    "# 3. Decision\n",
    "print(f\"\\n3. Decision at α = {alpha}:\")\n",
    "if p_value < alpha:\n",
    "    print(f\"   p-value ({p_value:.6f}) < α ({alpha})\")\n",
    "    print(f\"   REJECT H0\")\n",
    "    print(f\"   Conclusion: The wait time IS significantly longer than claimed.\")\n",
    "else:\n",
    "    print(f\"   p-value ({p_value:.6f}) ≥ α ({alpha})\")\n",
    "    print(f\"   FAIL TO REJECT H0\")\n",
    "    print(f\"   Conclusion: Insufficient evidence that wait time is longer.\")\n",
    "\n",
    "# 4. Visualization\n",
    "x = np.linspace(-4, 6, 1000)\n",
    "y = stats.t.pdf(x, df=n-1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, y, linewidth=2.5, label=f't-distribution (df={n-1})')\n",
    "\n",
    "# Critical value\n",
    "t_crit = stats.t.ppf(1 - alpha, df=n-1)\n",
    "x_reject = x[x >= t_crit]\n",
    "y_reject = stats.t.pdf(x_reject, df=n-1)\n",
    "plt.fill_between(x_reject, y_reject, alpha=0.3, color='red',\n",
    "                label=f'Rejection region (α={alpha})')\n",
    "\n",
    "# p-value region\n",
    "x_pvalue = x[x >= t_stat]\n",
    "y_pvalue = stats.t.pdf(x_pvalue, df=n-1)\n",
    "plt.fill_between(x_pvalue, y_pvalue, alpha=0.5, color='orange',\n",
    "                label=f'p-value = {p_value:.4f}')\n",
    "\n",
    "plt.axvline(t_crit, color='red', linestyle='--', linewidth=2,\n",
    "           label=f't-critical = {t_crit:.3f}')\n",
    "plt.axvline(t_stat, color='blue', linestyle='--', linewidth=2.5,\n",
    "           label=f't-statistic = {t_stat:.3f}')\n",
    "\n",
    "plt.xlabel('t-value', fontsize=12)\n",
    "plt.ylabel('Probability Density', fontsize=12)\n",
    "plt.title('One-Tailed Hypothesis Test: Coffee Shop Wait Times', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: A/B Test\n",
    "\n",
    "An e-commerce site tests two checkout button colors:\n",
    "- Red button: 180 users, 54 conversions (30%)\n",
    "- Blue button: 200 users, 70 conversions (35%)\n",
    "\n",
    "Tasks:\n",
    "1. State the hypotheses\n",
    "2. Perform a two-proportion z-test\n",
    "3. Calculate the p-value\n",
    "4. Make a conclusion at α = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "n_red = 180\n",
    "conversions_red = 54\n",
    "n_blue = 200\n",
    "conversions_blue = 70\n",
    "\n",
    "p_red = conversions_red / n_red\n",
    "p_blue = conversions_blue / n_blue\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"=== Exercise 3 Solution: A/B Test ===\")\n",
    "\n",
    "# 1. Hypotheses\n",
    "print(\"1. Hypotheses:\")\n",
    "print(\"   H0: p_red = p_blue (no difference in conversion rates)\")\n",
    "print(\"   Ha: p_red ≠ p_blue (conversion rates are different)\")\n",
    "\n",
    "print(f\"\\nData:\")\n",
    "print(f\"   Red button: {conversions_red}/{n_red} = {p_red:.4f} ({p_red*100:.2f}%)\")\n",
    "print(f\"   Blue button: {conversions_blue}/{n_blue} = {p_blue:.4f} ({p_blue*100:.2f}%)\")\n",
    "print(f\"   Difference: {(p_blue - p_red)*100:.2f} percentage points\")\n",
    "\n",
    "# 2. Two-proportion z-test\n",
    "# Pooled proportion\n",
    "p_pool = (conversions_red + conversions_blue) / (n_red + n_blue)\n",
    "\n",
    "# Standard error\n",
    "se = np.sqrt(p_pool * (1 - p_pool) * (1/n_red + 1/n_blue))\n",
    "\n",
    "# Z-statistic\n",
    "z_stat = (p_blue - p_red) / se\n",
    "\n",
    "# P-value (two-tailed)\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "\n",
    "print(f\"\\n2. Test Statistics:\")\n",
    "print(f\"   Pooled proportion: {p_pool:.4f}\")\n",
    "print(f\"   Standard error: {se:.4f}\")\n",
    "print(f\"   z-statistic: {z_stat:.4f}\")\n",
    "\n",
    "print(f\"\\n3. P-value: {p_value:.6f}\")\n",
    "\n",
    "# 4. Conclusion\n",
    "print(f\"\\n4. Decision at α = {alpha}:\")\n",
    "if p_value < alpha:\n",
    "    print(f\"   p-value ({p_value:.6f}) < α ({alpha})\")\n",
    "    print(f\"   REJECT H0\")\n",
    "    print(f\"   Conclusion: Blue button has SIGNIFICANTLY higher conversion rate!\")\n",
    "    print(f\"   Recommendation: Use the BLUE button.\")\n",
    "else:\n",
    "    print(f\"   p-value ({p_value:.6f}) ≥ α ({alpha})\")\n",
    "    print(f\"   FAIL TO REJECT H0\")\n",
    "    print(f\"   Conclusion: No significant difference in conversion rates.\")\n",
    "    print(f\"   Recommendation: Either button is fine, or collect more data.\")\n",
    "\n",
    "# Visualization\n",
    "categories = ['Red Button', 'Blue Button']\n",
    "conversion_rates = [p_red * 100, p_blue * 100]\n",
    "sample_sizes = [n_red, n_blue]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Conversion rates\n",
    "bars = axes[0].bar(categories, conversion_rates, color=['red', 'blue'], \n",
    "                   alpha=0.7, edgecolor='black')\n",
    "axes[0].set_ylabel('Conversion Rate (%)', fontsize=12)\n",
    "axes[0].set_title('Conversion Rate Comparison', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, rate in zip(bars, conversion_rates):\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{rate:.1f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Stacked bar for conversions\n",
    "converted = [conversions_red, conversions_blue]\n",
    "not_converted = [n_red - conversions_red, n_blue - conversions_blue]\n",
    "\n",
    "axes[1].bar(categories, converted, label='Converted', color='green', alpha=0.7, edgecolor='black')\n",
    "axes[1].bar(categories, not_converted, bottom=converted, label='Not Converted', \n",
    "           color='gray', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_ylabel('Number of Users', fontsize=12)\n",
    "axes[1].set_title('Conversion Counts', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Key Takeaways\n",
    "\n",
    "In this module, you learned:\n",
    "\n",
    "✅ **Population vs Sample**\n",
    "- Populations are complete groups; samples are subsets\n",
    "- Sample statistics estimate population parameters\n",
    "- $\\bar{x}$ estimates $\\mu$, $s$ estimates $\\sigma$\n",
    "\n",
    "✅ **Central Limit Theorem**\n",
    "- Sample means follow normal distribution for large n\n",
    "- Standard error: $SE = \\sigma / \\sqrt{n}$\n",
    "- Larger samples → smaller standard error → more precise estimates\n",
    "\n",
    "✅ **Confidence Intervals**\n",
    "- Range of plausible values for population parameter\n",
    "- Higher confidence → wider interval\n",
    "- 95% CI: About 95% of such intervals contain true parameter\n",
    "\n",
    "✅ **Hypothesis Testing**\n",
    "- Formal framework for making decisions from data\n",
    "- p-value: Probability of data if H₀ is true\n",
    "- If p < α: Reject H₀ (statistically significant)\n",
    "- Type I error (α): False positive\n",
    "- Type II error (β): False negative\n",
    "\n",
    "✅ **A/B Testing**\n",
    "- Compare two groups to find significant differences\n",
    "- Two-sample t-test for means\n",
    "- Two-proportion z-test for proportions\n",
    "- Critical for data-driven decision making\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 04: Linear Algebra Foundations**, you'll learn:\n",
    "- Vectors and vector operations\n",
    "- Matrices and matrix operations\n",
    "- Systems of linear equations\n",
    "- Applications to data science and machine learning\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Khan Academy - Inference](https://www.khanacademy.org/math/statistics-probability/significance-tests-one-sample)\n",
    "- [StatQuest - Hypothesis Testing](https://www.youtube.com/watch?v=0oc49DyA3hU)\n",
    "- [Evan Miller - A/B Testing](https://www.evanmiller.org/ab-testing/)\n",
    "- [3Blue1Brown - Central Limit Theorem](https://www.youtube.com/watch?v=zeJD6dqJ5lo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Fantastic progress!** You now understand how to make statistical inferences from sample data - a critical skill for data science.\n",
    "\n",
    "**Next**: Proceed to `04_linear_algebra_foundations.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
