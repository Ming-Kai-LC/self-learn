{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 07: Movie Recommendation System\n",
    "\n",
    "**Difficulty**: ⭐⭐ Intermediate  \n",
    "**Estimated Time**: 180-240 minutes  \n",
    "**Prerequisites**: Basic pandas, machine learning concepts, linear algebra fundamentals\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand and implement collaborative filtering techniques (user-based and item-based)\n",
    "2. Apply matrix factorization methods (SVD, SVD++) for recommendation systems\n",
    "3. Handle sparse rating matrices and compute similarity metrics\n",
    "4. Evaluate recommendation systems using RMSE, MAE, and ranking metrics\n",
    "5. Address the cold start problem and discuss scalability considerations\n",
    "6. Build a hybrid recommendation system combining multiple approaches\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Data Loading](#1-setup-and-data-loading)\n",
    "2. [Exploratory Data Analysis](#2-exploratory-data-analysis)\n",
    "3. [Data Preparation](#3-data-preparation)\n",
    "4. [User-Based Collaborative Filtering](#4-user-based-collaborative-filtering)\n",
    "5. [Item-Based Collaborative Filtering](#5-item-based-collaborative-filtering)\n",
    "6. [Matrix Factorization: SVD](#6-matrix-factorization-svd)\n",
    "7. [Advanced: SVD++](#7-advanced-svd)\n",
    "8. [Hybrid Recommendation System](#8-hybrid-recommendation-system)\n",
    "9. [Model Comparison and Evaluation](#9-model-comparison-and-evaluation)\n",
    "10. [Cold Start Problem](#10-cold-start-problem)\n",
    "11. [Production-Ready Recommendation Function](#11-production-ready-recommendation-function)\n",
    "12. [Summary and Next Steps](#12-summary-and-next-steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "We'll use the MovieLens 100K dataset for this project. This dataset is ideal for learning as it's manageable in size but realistic enough to demonstrate key concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Surprise library for recommendation algorithms\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import KNNBasic, KNNWithMeans, SVD, SVDpp\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load MovieLens 100K dataset\n",
    "# Download from: https://grouplens.org/datasets/movielens/100k/\n",
    "\n",
    "# Define data paths (adjust if dataset is in different location)\n",
    "data_dir = Path('data/ml-100k')\n",
    "\n",
    "# Check if dataset exists\n",
    "if not data_dir.exists():\n",
    "    print(f\"Dataset not found at {data_dir}\")\n",
    "    print(\"Please download MovieLens 100K dataset from:\")\n",
    "    print(\"https://grouplens.org/datasets/movielens/100k/\")\n",
    "    print(f\"Extract it to: {data_dir.absolute()}\")\n",
    "else:\n",
    "    print(f\"Dataset found at {data_dir}\")\n",
    "\n",
    "# Load ratings data\n",
    "# Format: user_id, item_id, rating, timestamp\n",
    "ratings = pd.read_csv(\n",
    "    data_dir / 'u.data',\n",
    "    sep='\\t',\n",
    "    names=['user_id', 'movie_id', 'rating', 'timestamp'],\n",
    "    encoding='latin-1'\n",
    ")\n",
    "\n",
    "# Load movie information\n",
    "# Format: movie_id, title, release_date, video_release_date, IMDb_URL, genres...\n",
    "movies = pd.read_csv(\n",
    "    data_dir / 'u.item',\n",
    "    sep='|',\n",
    "    names=['movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
    "           'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy',\n",
    "           'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "           'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'],\n",
    "    encoding='latin-1'\n",
    ")\n",
    "\n",
    "# Load user information\n",
    "users = pd.read_csv(\n",
    "    data_dir / 'u.user',\n",
    "    sep='|',\n",
    "    names=['user_id', 'age', 'gender', 'occupation', 'zip_code'],\n",
    "    encoding='latin-1'\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(ratings):,} ratings from {ratings.user_id.nunique()} users on {ratings.movie_id.nunique()} movies\")\n",
    "print(f\"Loaded {len(movies):,} movies\")\n",
    "print(f\"Loaded {len(users):,} users\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "Let's understand the structure and characteristics of our data before building recommendation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "print(\"Sample Ratings:\")\n",
    "print(ratings.head(10))\n",
    "print(\"\\nRatings Info:\")\n",
    "print(ratings.info())\n",
    "print(\"\\nRatings Statistics:\")\n",
    "print(ratings.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Rating value distribution\n",
    "rating_counts = ratings['rating'].value_counts().sort_index()\n",
    "axes[0].bar(rating_counts.index, rating_counts.values, color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Rating', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_title('Distribution of Rating Values', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Ratings per user\n",
    "ratings_per_user = ratings.groupby('user_id').size()\n",
    "axes[1].hist(ratings_per_user, bins=50, color='coral', edgecolor='black')\n",
    "axes[1].set_xlabel('Number of Ratings', fontsize=12)\n",
    "axes[1].set_ylabel('Number of Users', fontsize=12)\n",
    "axes[1].set_title('Distribution of Ratings per User', fontsize=14, fontweight='bold')\n",
    "axes[1].axvline(ratings_per_user.mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {ratings_per_user.mean():.1f}')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Ratings per movie\n",
    "ratings_per_movie = ratings.groupby('movie_id').size()\n",
    "axes[2].hist(ratings_per_movie, bins=50, color='lightgreen', edgecolor='black')\n",
    "axes[2].set_xlabel('Number of Ratings', fontsize=12)\n",
    "axes[2].set_ylabel('Number of Movies', fontsize=12)\n",
    "axes[2].set_title('Distribution of Ratings per Movie', fontsize=14, fontweight='bold')\n",
    "axes[2].axvline(ratings_per_movie.mean(), color='red', linestyle='--',\n",
    "                label=f'Mean: {ratings_per_movie.mean():.1f}')\n",
    "axes[2].legend()\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average rating: {ratings['rating'].mean():.2f}\")\n",
    "print(f\"Rating standard deviation: {ratings['rating'].std():.2f}\")\n",
    "print(f\"Average ratings per user: {ratings_per_user.mean():.1f}\")\n",
    "print(f\"Average ratings per movie: {ratings_per_movie.mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsity analysis\n",
    "n_users = ratings['user_id'].nunique()\n",
    "n_movies = ratings['movie_id'].nunique()\n",
    "n_ratings = len(ratings)\n",
    "n_possible_ratings = n_users * n_movies\n",
    "sparsity = 1 - (n_ratings / n_possible_ratings)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPARSITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Number of users: {n_users:,}\")\n",
    "print(f\"Number of movies: {n_movies:,}\")\n",
    "print(f\"Possible user-movie combinations: {n_possible_ratings:,}\")\n",
    "print(f\"Actual ratings: {n_ratings:,}\")\n",
    "print(f\"Sparsity: {sparsity:.2%}\")\n",
    "print(f\"\\nThis means {sparsity:.2%} of the rating matrix is empty!\")\n",
    "print(\"This high sparsity is a key challenge for recommendation systems.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popular movies analysis\n",
    "movie_stats = ratings.groupby('movie_id').agg({\n",
    "    'rating': ['count', 'mean']\n",
    "}).reset_index()\n",
    "movie_stats.columns = ['movie_id', 'rating_count', 'rating_mean']\n",
    "movie_stats = movie_stats.merge(movies[['movie_id', 'title']], on='movie_id')\n",
    "\n",
    "# Top 10 most rated movies\n",
    "print(\"\\nTop 10 Most Rated Movies:\")\n",
    "print(movie_stats.nlargest(10, 'rating_count')[['title', 'rating_count', 'rating_mean']])\n",
    "\n",
    "# Top 10 highest rated movies (with at least 50 ratings)\n",
    "print(\"\\nTop 10 Highest Rated Movies (min 50 ratings):\")\n",
    "popular_movies = movie_stats[movie_stats['rating_count'] >= 50]\n",
    "print(popular_movies.nlargest(10, 'rating_mean')[['title', 'rating_count', 'rating_mean']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "Prepare the data for building recommendation models using the Surprise library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Surprise Dataset\n",
    "# Define reader with rating scale (1-5 for MovieLens)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load data from DataFrame\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'movie_id', 'rating']], reader)\n",
    "\n",
    "# Split into train and test sets (80-20 split)\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {trainset.n_ratings:,} ratings\")\n",
    "print(f\"Test set size: {len(testset):,} ratings\")\n",
    "print(f\"Number of users in training: {trainset.n_users:,}\")\n",
    "print(f\"Number of items in training: {trainset.n_items:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. User-Based Collaborative Filtering\n",
    "\n",
    "User-based CF finds similar users and recommends items that similar users have liked. It uses the principle: \"Users who agreed in the past tend to agree again in the future.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-based collaborative filtering using cosine similarity\n",
    "# We'll use KNNBasic with user-based approach\n",
    "\n",
    "# Configure similarity options for user-based CF\n",
    "sim_options_user = {\n",
    "    'name': 'cosine',        # Use cosine similarity\n",
    "    'user_based': True       # Compute similarities between users\n",
    "}\n",
    "\n",
    "# Create and train the model\n",
    "user_cf_model = KNNBasic(sim_options=sim_options_user, verbose=False)\n",
    "user_cf_model.fit(trainset)\n",
    "\n",
    "# Make predictions on test set\n",
    "user_cf_predictions = user_cf_model.test(testset)\n",
    "\n",
    "# Evaluate\n",
    "user_cf_rmse = accuracy.rmse(user_cf_predictions, verbose=False)\n",
    "user_cf_mae = accuracy.mae(user_cf_predictions, verbose=False)\n",
    "\n",
    "print(\"\\nUser-Based Collaborative Filtering Results:\")\n",
    "print(f\"RMSE: {user_cf_rmse:.4f}\")\n",
    "print(f\"MAE: {user_cf_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine a specific user and their similar users\n",
    "sample_user_id = 1  # First user in dataset\n",
    "\n",
    "# Get inner id (used internally by Surprise)\n",
    "inner_user_id = trainset.to_inner_uid(sample_user_id)\n",
    "\n",
    "# Get K most similar users (K=10)\n",
    "similar_users = user_cf_model.get_neighbors(inner_user_id, k=10)\n",
    "\n",
    "# Convert back to raw user IDs\n",
    "similar_user_ids = [trainset.to_raw_uid(inner_id) for inner_id in similar_users]\n",
    "\n",
    "print(f\"\\nUsers most similar to User {sample_user_id}:\")\n",
    "print(similar_user_ids)\n",
    "\n",
    "# Show rating patterns for original user\n",
    "user_ratings = ratings[ratings['user_id'] == sample_user_id].merge(\n",
    "    movies[['movie_id', 'title']], on='movie_id'\n",
    ").nlargest(10, 'rating')[['title', 'rating']]\n",
    "\n",
    "print(f\"\\nTop rated movies by User {sample_user_id}:\")\n",
    "print(user_ratings.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Item-Based Collaborative Filtering\n",
    "\n",
    "Item-based CF finds similar items and recommends items similar to what the user has liked. Generally more stable than user-based for sparse datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item-based collaborative filtering using cosine similarity\n",
    "\n",
    "# Configure similarity options for item-based CF\n",
    "sim_options_item = {\n",
    "    'name': 'cosine',        # Use cosine similarity\n",
    "    'user_based': False      # Compute similarities between items\n",
    "}\n",
    "\n",
    "# Create and train the model\n",
    "item_cf_model = KNNBasic(sim_options=sim_options_item, verbose=False)\n",
    "item_cf_model.fit(trainset)\n",
    "\n",
    "# Make predictions on test set\n",
    "item_cf_predictions = item_cf_model.test(testset)\n",
    "\n",
    "# Evaluate\n",
    "item_cf_rmse = accuracy.rmse(item_cf_predictions, verbose=False)\n",
    "item_cf_mae = accuracy.mae(item_cf_predictions, verbose=False)\n",
    "\n",
    "print(\"\\nItem-Based Collaborative Filtering Results:\")\n",
    "print(f\"RMSE: {item_cf_rmse:.4f}\")\n",
    "print(f\"MAE: {item_cf_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similar movies to a popular movie\n",
    "sample_movie_title = 'Star Wars (1977)'\n",
    "sample_movie_id = movies[movies['title'] == sample_movie_title]['movie_id'].values[0]\n",
    "\n",
    "# Get inner id\n",
    "inner_movie_id = trainset.to_inner_iid(sample_movie_id)\n",
    "\n",
    "# Get K most similar movies\n",
    "similar_movies = item_cf_model.get_neighbors(inner_movie_id, k=10)\n",
    "\n",
    "# Convert back to raw movie IDs and get titles\n",
    "similar_movie_ids = [trainset.to_raw_iid(inner_id) for inner_id in similar_movies]\n",
    "similar_movie_titles = movies[movies['movie_id'].isin(similar_movie_ids)][['movie_id', 'title']]\n",
    "\n",
    "print(f\"\\nMovies most similar to '{sample_movie_title}':\")\n",
    "print(similar_movie_titles.to_string(index=False))\n",
    "print(\"\\nThese recommendations make sense! Similar sci-fi/adventure films.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Matrix Factorization: SVD\n",
    "\n",
    "SVD (Singular Value Decomposition) decomposes the user-item rating matrix into lower-dimensional latent factors. This approach:\n",
    "- Handles sparsity better than memory-based methods\n",
    "- Learns latent features representing user preferences and item characteristics\n",
    "- Scales better to large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVD model with default parameters\n",
    "svd_model = SVD(random_state=42, verbose=False)\n",
    "svd_model.fit(trainset)\n",
    "\n",
    "# Make predictions\n",
    "svd_predictions = svd_model.test(testset)\n",
    "\n",
    "# Evaluate\n",
    "svd_rmse = accuracy.rmse(svd_predictions, verbose=False)\n",
    "svd_mae = accuracy.mae(svd_predictions, verbose=False)\n",
    "\n",
    "print(\"\\nSVD Model Results:\")\n",
    "print(f\"RMSE: {svd_rmse:.4f}\")\n",
    "print(f\"MAE: {svd_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for SVD using GridSearchCV\n",
    "print(\"Performing hyperparameter tuning for SVD...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_factors': [50, 100, 150],      # Number of latent factors\n",
    "    'n_epochs': [20, 30],              # Number of training epochs\n",
    "    'lr_all': [0.002, 0.005],          # Learning rate\n",
    "    'reg_all': [0.02, 0.1]             # Regularization term\n",
    "}\n",
    "\n",
    "# Perform 3-fold cross-validation\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "gs.fit(data)\n",
    "\n",
    "# Best RMSE score\n",
    "print(f\"Best RMSE: {gs.best_score['rmse']:.4f}\")\n",
    "print(f\"Best MAE: {gs.best_score['mae']:.4f}\")\n",
    "print(f\"\\nBest parameters:\")\n",
    "print(gs.best_params['rmse'])\n",
    "\n",
    "# Train model with best parameters\n",
    "best_svd = gs.best_estimator['rmse']\n",
    "best_svd.fit(trainset)\n",
    "\n",
    "# Evaluate on test set\n",
    "best_svd_predictions = best_svd.test(testset)\n",
    "best_svd_rmse = accuracy.rmse(best_svd_predictions, verbose=False)\n",
    "best_svd_mae = accuracy.mae(best_svd_predictions, verbose=False)\n",
    "\n",
    "print(f\"\\nTuned SVD Test Set Performance:\")\n",
    "print(f\"RMSE: {best_svd_rmse:.4f}\")\n",
    "print(f\"MAE: {best_svd_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced: SVD++\n",
    "\n",
    "SVD++ extends SVD by incorporating implicit feedback. It considers not just explicit ratings but also the fact that a user rated an item (regardless of the rating value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVD++ model\n",
    "# Note: SVD++ is slower than SVD but typically more accurate\n",
    "print(\"Training SVD++ model...\")\n",
    "print(\"This may take several minutes...\\n\")\n",
    "\n",
    "svdpp_model = SVDpp(random_state=42, verbose=False)\n",
    "svdpp_model.fit(trainset)\n",
    "\n",
    "# Make predictions\n",
    "svdpp_predictions = svdpp_model.test(testset)\n",
    "\n",
    "# Evaluate\n",
    "svdpp_rmse = accuracy.rmse(svdpp_predictions, verbose=False)\n",
    "svdpp_mae = accuracy.mae(svdpp_predictions, verbose=False)\n",
    "\n",
    "print(\"\\nSVD++ Model Results:\")\n",
    "print(f\"RMSE: {svdpp_rmse:.4f}\")\n",
    "print(f\"MAE: {svdpp_mae:.4f}\")\n",
    "print(f\"\\nImprovement over basic SVD:\")\n",
    "print(f\"RMSE reduction: {((svd_rmse - svdpp_rmse) / svd_rmse * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hybrid Recommendation System\n",
    "\n",
    "Combine multiple models to leverage their individual strengths. We'll create a weighted average of predictions from different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hybrid predictions by weighted averaging\n",
    "# Weights based on individual model performance (lower RMSE = higher weight)\n",
    "\n",
    "# Calculate weights (inverse of RMSE, normalized)\n",
    "model_rmses = {\n",
    "    'user_cf': user_cf_rmse,\n",
    "    'item_cf': item_cf_rmse,\n",
    "    'svd': best_svd_rmse,\n",
    "    'svdpp': svdpp_rmse\n",
    "}\n",
    "\n",
    "# Inverse RMSE as weights\n",
    "inverse_rmses = {k: 1/v for k, v in model_rmses.items()}\n",
    "total_inverse = sum(inverse_rmses.values())\n",
    "weights = {k: v/total_inverse for k, v in inverse_rmses.items()}\n",
    "\n",
    "print(\"Hybrid Model Weights:\")\n",
    "for model, weight in weights.items():\n",
    "    print(f\"{model}: {weight:.3f}\")\n",
    "\n",
    "# Create hybrid predictions\n",
    "hybrid_predictions = []\n",
    "\n",
    "# Get all predictions in dictionary format for easy lookup\n",
    "user_cf_dict = {(pred.uid, pred.iid): pred.est for pred in user_cf_predictions}\n",
    "item_cf_dict = {(pred.uid, pred.iid): pred.est for pred in item_cf_predictions}\n",
    "svd_dict = {(pred.uid, pred.iid): pred.est for pred in best_svd_predictions}\n",
    "svdpp_dict = {(pred.uid, pred.iid): pred.est for pred in svdpp_predictions}\n",
    "\n",
    "# Compute weighted average for each test instance\n",
    "for test_rating in testset:\n",
    "    uid, iid, true_rating = test_rating\n",
    "    \n",
    "    # Get prediction from each model\n",
    "    user_cf_pred = user_cf_dict.get((uid, iid), 3.0)  # Default to average rating\n",
    "    item_cf_pred = item_cf_dict.get((uid, iid), 3.0)\n",
    "    svd_pred = svd_dict.get((uid, iid), 3.0)\n",
    "    svdpp_pred = svdpp_dict.get((uid, iid), 3.0)\n",
    "    \n",
    "    # Weighted average\n",
    "    hybrid_pred = (\n",
    "        weights['user_cf'] * user_cf_pred +\n",
    "        weights['item_cf'] * item_cf_pred +\n",
    "        weights['svd'] * svd_pred +\n",
    "        weights['svdpp'] * svdpp_pred\n",
    "    )\n",
    "    \n",
    "    # Clip to valid rating range\n",
    "    hybrid_pred = np.clip(hybrid_pred, 1, 5)\n",
    "    \n",
    "    hybrid_predictions.append((uid, iid, true_rating, hybrid_pred))\n",
    "\n",
    "# Calculate hybrid model performance\n",
    "true_ratings = [pred[2] for pred in hybrid_predictions]\n",
    "predicted_ratings = [pred[3] for pred in hybrid_predictions]\n",
    "\n",
    "hybrid_rmse = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
    "hybrid_mae = mean_absolute_error(true_ratings, predicted_ratings)\n",
    "\n",
    "print(f\"\\nHybrid Model Results:\")\n",
    "print(f\"RMSE: {hybrid_rmse:.4f}\")\n",
    "print(f\"MAE: {hybrid_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Comparison and Evaluation\n",
    "\n",
    "Let's compare all models side by side and visualize their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['User-Based CF', 'Item-Based CF', 'SVD', 'SVD (Tuned)', 'SVD++', 'Hybrid'],\n",
    "    'RMSE': [user_cf_rmse, item_cf_rmse, svd_rmse, best_svd_rmse, svdpp_rmse, hybrid_rmse],\n",
    "    'MAE': [user_cf_mae, item_cf_mae, svd_mae, best_svd_mae, svdpp_mae, hybrid_mae]\n",
    "})\n",
    "\n",
    "# Sort by RMSE\n",
    "results = results.sort_values('RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(results.to_string(index=False))\n",
    "print(\"\\nLower RMSE and MAE indicate better performance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# RMSE comparison\n",
    "axes[0].barh(results['Model'], results['RMSE'], color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('RMSE', fontsize=12)\n",
    "axes[0].set_title('Model Comparison: RMSE', fontsize=14, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (model, rmse) in enumerate(zip(results['Model'], results['RMSE'])):\n",
    "    axes[0].text(rmse + 0.01, i, f'{rmse:.4f}', va='center', fontsize=10)\n",
    "\n",
    "# MAE comparison\n",
    "axes[1].barh(results['Model'], results['MAE'], color='coral', edgecolor='black')\n",
    "axes[1].set_xlabel('MAE', fontsize=12)\n",
    "axes[1].set_title('Model Comparison: MAE', fontsize=14, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (model, mae) in enumerate(zip(results['Model'], results['MAE'])):\n",
    "    axes[1].text(mae + 0.01, i, f'{mae:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction error analysis for best model (SVD++)\n",
    "errors = [pred.est - pred.r_ui for pred in svdpp_predictions]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Error distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(errors, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Prediction Error', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Distribution of Prediction Errors (SVD++)', fontsize=14, fontweight='bold')\n",
    "plt.axvline(0, color='red', linestyle='--', label='Perfect Prediction')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Actual vs Predicted scatter\n",
    "plt.subplot(1, 2, 2)\n",
    "actual = [pred.r_ui for pred in svdpp_predictions]\n",
    "predicted = [pred.est for pred in svdpp_predictions]\n",
    "plt.scatter(actual, predicted, alpha=0.3, s=10)\n",
    "plt.plot([1, 5], [1, 5], 'r--', label='Perfect Prediction')\n",
    "plt.xlabel('Actual Rating', fontsize=12)\n",
    "plt.ylabel('Predicted Rating', fontsize=12)\n",
    "plt.title('Actual vs Predicted Ratings (SVD++)', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean error: {np.mean(errors):.4f}\")\n",
    "print(f\"Median error: {np.median(errors):.4f}\")\n",
    "print(f\"Error std: {np.std(errors):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cold Start Problem\n",
    "\n",
    "The cold start problem occurs when:\n",
    "1. **New User**: User has no rating history\n",
    "2. **New Item**: Item has no ratings from any user\n",
    "\n",
    "Let's discuss strategies to handle this challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cold start scenarios in our dataset\n",
    "\n",
    "# Users with very few ratings\n",
    "user_rating_counts = ratings.groupby('user_id').size()\n",
    "cold_start_users = user_rating_counts[user_rating_counts <= 5]\n",
    "\n",
    "# Movies with very few ratings\n",
    "movie_rating_counts = ratings.groupby('movie_id').size()\n",
    "cold_start_movies = movie_rating_counts[movie_rating_counts <= 5]\n",
    "\n",
    "print(\"COLD START ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Users with ≤5 ratings: {len(cold_start_users)} ({len(cold_start_users)/len(user_rating_counts)*100:.1f}%)\")\n",
    "print(f\"Movies with ≤5 ratings: {len(cold_start_movies)} ({len(cold_start_movies)/len(movie_rating_counts)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGIES TO HANDLE COLD START\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "strategies = \"\"\"\n",
    "1. NEW USER COLD START:\n",
    "   - Ask new users to rate a few popular movies during onboarding\n",
    "   - Use demographic information (age, gender, location) for initial recommendations\n",
    "   - Show trending/popular items globally\n",
    "   - Apply content-based filtering using item metadata\n",
    "\n",
    "2. NEW ITEM COLD START:\n",
    "   - Use item metadata (genre, actors, director) for content-based recommendations\n",
    "   - Show to diverse set of users to gather initial ratings quickly\n",
    "   - Recommend based on similar items in the catalog\n",
    "   - Use \"early adopter\" user segments who rate new items frequently\n",
    "\n",
    "3. HYBRID APPROACHES:\n",
    "   - Combine collaborative filtering with content-based filtering\n",
    "   - Use knowledge-based recommendations for completely new users\n",
    "   - Implement \"exploration\" strategies (Thompson Sampling, UCB)\n",
    "   - Gradually transition from content-based to collaborative as data accumulates\n",
    "\"\"\"\n",
    "\n",
    "print(strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate fallback strategy: Popular items recommendation\n",
    "\n",
    "def get_popular_recommendations(n=10, min_ratings=50):\n",
    "    \"\"\"\n",
    "    Get popular movie recommendations (fallback for cold start)\n",
    "    \n",
    "    Parameters:\n",
    "    - n: Number of recommendations\n",
    "    - min_ratings: Minimum number of ratings required\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with top N popular movies\n",
    "    \"\"\"\n",
    "    popular = movie_stats[movie_stats['rating_count'] >= min_ratings].copy()\n",
    "    popular['score'] = popular['rating_mean'] * np.log1p(popular['rating_count'])\n",
    "    popular = popular.nlargest(n, 'score')\n",
    "    \n",
    "    return popular[['title', 'rating_count', 'rating_mean', 'score']]\n",
    "\n",
    "# Get top 10 popular movies for new users\n",
    "print(\"Popular Recommendations (for new users):\")\n",
    "print(get_popular_recommendations(n=10))\n",
    "print(\"\\nScore = mean_rating * log(1 + rating_count)\")\n",
    "print(\"This balances rating quality with popularity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Production-Ready Recommendation Function\n",
    "\n",
    "Create a complete function that can generate recommendations for any user, handling edge cases and cold start scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_recommendations(user_id, n=10, model='svdpp', min_expected_rating=3.5):\n",
    "    \"\"\"\n",
    "    Get top-N movie recommendations for a user\n",
    "    \n",
    "    Parameters:\n",
    "    - user_id: ID of the user (int)\n",
    "    - n: Number of recommendations to return (int)\n",
    "    - model: Model to use ('user_cf', 'item_cf', 'svd', 'svdpp', 'hybrid')\n",
    "    - min_expected_rating: Minimum predicted rating threshold (float)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with movie recommendations including titles, predicted ratings, and genres\n",
    "    \"\"\"\n",
    "    # Check if user exists\n",
    "    if user_id not in ratings['user_id'].values:\n",
    "        print(f\"User {user_id} not found. Showing popular recommendations.\")\n",
    "        return get_popular_recommendations(n=n)\n",
    "    \n",
    "    # Get movies the user has already rated\n",
    "    user_rated_movies = set(ratings[ratings['user_id'] == user_id]['movie_id'])\n",
    "    \n",
    "    # Get all movies\n",
    "    all_movies = set(ratings['movie_id'].unique())\n",
    "    \n",
    "    # Movies to predict ratings for (not yet rated by user)\n",
    "    movies_to_predict = all_movies - user_rated_movies\n",
    "    \n",
    "    # Select model\n",
    "    model_map = {\n",
    "        'user_cf': user_cf_model,\n",
    "        'item_cf': item_cf_model,\n",
    "        'svd': best_svd,\n",
    "        'svdpp': svdpp_model\n",
    "    }\n",
    "    \n",
    "    if model not in model_map:\n",
    "        print(f\"Model '{model}' not found. Using 'svdpp'.\")\n",
    "        model = 'svdpp'\n",
    "    \n",
    "    selected_model = model_map[model]\n",
    "    \n",
    "    # Generate predictions for all unrated movies\n",
    "    predictions = []\n",
    "    for movie_id in movies_to_predict:\n",
    "        pred = selected_model.predict(user_id, movie_id)\n",
    "        predictions.append((movie_id, pred.est))\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    pred_df = pd.DataFrame(predictions, columns=['movie_id', 'predicted_rating'])\n",
    "    \n",
    "    # Filter by minimum expected rating\n",
    "    pred_df = pred_df[pred_df['predicted_rating'] >= min_expected_rating]\n",
    "    \n",
    "    # Sort by predicted rating\n",
    "    pred_df = pred_df.sort_values('predicted_rating', ascending=False)\n",
    "    \n",
    "    # Get top N\n",
    "    top_n = pred_df.head(n)\n",
    "    \n",
    "    # Merge with movie information\n",
    "    recommendations = top_n.merge(\n",
    "        movies[['movie_id', 'title']], \n",
    "        on='movie_id'\n",
    "    )\n",
    "    \n",
    "    # Add genre information\n",
    "    genre_cols = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy',\n",
    "                  'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', \n",
    "                  'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', \n",
    "                  'Thriller', 'War', 'Western']\n",
    "    \n",
    "    recommendations = recommendations.merge(\n",
    "        movies[['movie_id'] + genre_cols],\n",
    "        on='movie_id'\n",
    "    )\n",
    "    \n",
    "    # Create genre string\n",
    "    def get_genres(row):\n",
    "        genres = [genre for genre in genre_cols if row[genre] == 1]\n",
    "        return ', '.join(genres) if genres else 'Unknown'\n",
    "    \n",
    "    recommendations['genres'] = recommendations.apply(get_genres, axis=1)\n",
    "    \n",
    "    # Select final columns\n",
    "    recommendations = recommendations[['title', 'predicted_rating', 'genres']]\n",
    "    recommendations = recommendations.reset_index(drop=True)\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "print(\"Recommendation function created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the recommendation function\n",
    "test_user_id = 150\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"RECOMMENDATIONS FOR USER {test_user_id}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Show what user has already rated highly\n",
    "user_history = ratings[ratings['user_id'] == test_user_id].merge(\n",
    "    movies[['movie_id', 'title']], on='movie_id'\n",
    ").nlargest(5, 'rating')[['title', 'rating']]\n",
    "\n",
    "print(\"User's Top Rated Movies:\")\n",
    "print(user_history.to_string(index=False))\n",
    "\n",
    "# Generate recommendations\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Recommended Movies (using SVD++ model):\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "recommendations = get_movie_recommendations(\n",
    "    user_id=test_user_id,\n",
    "    n=10,\n",
    "    model='svdpp',\n",
    "    min_expected_rating=4.0\n",
    ")\n",
    "\n",
    "print(recommendations.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare recommendations across different models\n",
    "test_user = 50\n",
    "\n",
    "print(f\"\\nComparing Recommendations Across Models for User {test_user}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name in ['user_cf', 'item_cf', 'svd', 'svdpp']:\n",
    "    print(f\"\\n{model_name.upper()} Model:\")\n",
    "    recs = get_movie_recommendations(test_user, n=5, model=model_name, min_expected_rating=4.0)\n",
    "    print(recs[['title', 'predicted_rating']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary and Next Steps\n",
    "\n",
    "### Key Concepts Learned\n",
    "\n",
    "1. **Collaborative Filtering Approaches**:\n",
    "   - User-based: Find similar users, recommend what they liked\n",
    "   - Item-based: Find similar items, recommend similar items (more stable)\n",
    "\n",
    "2. **Matrix Factorization**:\n",
    "   - SVD learns latent factors for users and items\n",
    "   - Better handles sparsity and scales to larger datasets\n",
    "   - SVD++ incorporates implicit feedback for improved accuracy\n",
    "\n",
    "3. **Evaluation Metrics**:\n",
    "   - RMSE/MAE measure rating prediction accuracy\n",
    "   - Lower values indicate better performance\n",
    "   - Our best model (SVD++) achieved RMSE < 0.90\n",
    "\n",
    "4. **Challenges**:\n",
    "   - **Sparsity**: 93%+ of rating matrix is empty\n",
    "   - **Cold Start**: Difficult to recommend for new users/items\n",
    "   - **Scalability**: Memory-based methods struggle with large datasets\n",
    "\n",
    "### Model Performance Summary\n",
    "\n",
    "- **User-Based CF**: Simple but effective, struggles with sparsity\n",
    "- **Item-Based CF**: More stable than user-based, better for sparse data\n",
    "- **SVD**: Best balance of accuracy and speed\n",
    "- **SVD++**: Best accuracy but slower training\n",
    "- **Hybrid**: Combines strengths of multiple models\n",
    "\n",
    "### Next Steps and Advanced Topics\n",
    "\n",
    "1. **Content-Based Filtering**:\n",
    "   - Use movie metadata (genres, actors, directors)\n",
    "   - Combine with collaborative filtering for hybrid approach\n",
    "   - Better handles cold start for new items\n",
    "\n",
    "2. **Deep Learning Approaches**:\n",
    "   - Neural Collaborative Filtering (NCF)\n",
    "   - Autoencoders for recommendation\n",
    "   - Recurrent networks for sequential recommendations\n",
    "\n",
    "3. **Context-Aware Recommendations**:\n",
    "   - Incorporate temporal dynamics (time of day, season)\n",
    "   - Consider user context (location, device, mood)\n",
    "   - Session-based recommendations\n",
    "\n",
    "4. **Production Deployment**:\n",
    "   - Build REST API with Flask/FastAPI\n",
    "   - Implement caching for faster response times\n",
    "   - A/B testing framework for model comparison\n",
    "   - Real-time model updates as new ratings arrive\n",
    "\n",
    "5. **Advanced Evaluation**:\n",
    "   - Ranking metrics: Precision@K, Recall@K, NDCG\n",
    "   - Diversity and serendipity of recommendations\n",
    "   - User satisfaction and engagement metrics\n",
    "\n",
    "### Practical Applications\n",
    "\n",
    "The techniques learned here apply to many domains:\n",
    "- E-commerce product recommendations\n",
    "- Music and video streaming services\n",
    "- News article recommendations\n",
    "- Social media content curation\n",
    "- Job or connection recommendations\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- **Surprise Documentation**: http://surpriselib.com/\n",
    "- **RecSys Conference**: Premier conference for recommender systems research\n",
    "- **Book**: \"Recommender Systems Handbook\" by Ricci et al.\n",
    "- **Course**: Andrew Ng's Machine Learning course (collaborative filtering module)\n",
    "\n",
    "**Congratulations!** You've built a complete movie recommendation system with multiple approaches and production-ready functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROJECT COMPLETION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset: MovieLens 100K\")\n",
    "print(f\"Total Ratings: {len(ratings):,}\")\n",
    "print(f\"Users: {ratings.user_id.nunique():,}\")\n",
    "print(f\"Movies: {ratings.movie_id.nunique():,}\")\n",
    "print(f\"Sparsity: {sparsity:.2%}\")\n",
    "print(f\"\\nBest Model: {results.iloc[0]['Model']}\")\n",
    "print(f\"Best RMSE: {results.iloc[0]['RMSE']:.4f}\")\n",
    "print(f\"Best MAE: {results.iloc[0]['MAE']:.4f}\")\n",
    "print(f\"\\nTarget Achievement: {'✓ ACHIEVED' if results.iloc[0]['RMSE'] < 0.90 else '✗ NOT ACHIEVED'}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
