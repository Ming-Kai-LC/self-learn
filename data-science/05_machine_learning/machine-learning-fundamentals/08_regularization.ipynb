{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 08: Regularization (L1, L2, Elastic Net)\n",
    "\n",
    "**Difficulty**: ⭐⭐ Intermediate  \n",
    "**Estimated Time**: 75 minutes  \n",
    "**Prerequisites**: \n",
    "- [Module 03: Linear Regression](03_linear_regression.ipynb)\n",
    "- [Module 07: Cross-Validation and Hyperparameter Tuning](07_cross_validation_hyperparameter_tuning.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand overfitting vs underfitting and the bias-variance tradeoff\n",
    "2. Apply Ridge regression (L2 regularization) to prevent overfitting\n",
    "3. Use Lasso regression (L1 regularization) for feature selection\n",
    "4. Implement Elastic Net (combination of L1 and L2)\n",
    "5. Choose appropriate regularization strength (alpha parameter)\n",
    "6. Visualize how regularization affects model coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Overfitting Problem\n",
    "\n",
    "### What is Overfitting?\n",
    "\n",
    "**Overfitting**: Model learns training data *too well*, including noise!\n",
    "\n",
    "**Symptoms**:\n",
    "- Perfect (or very high) training accuracy\n",
    "- Poor test accuracy\n",
    "- Model memorizes data instead of learning patterns\n",
    "\n",
    "### Underfitting vs Overfitting vs Just Right\n",
    "\n",
    "```\n",
    "UNDERFITTING          JUST RIGHT           OVERFITTING\n",
    "Too Simple            Balanced             Too Complex\n",
    "    |                    |                      |\n",
    "  High Bias         Low Bias             High Variance\n",
    "  Low Variance      Low Variance         Low Bias\n",
    "    |\n",
    "  Poor on both      Good on both         Great on train\n",
    "  train and test    train and test       Poor on test\n",
    "```\n",
    "\n",
    "### Real-World Analogy\n",
    "\n",
    "**Studying for exam**:\n",
    "- **Underfitting**: Only study one chapter (miss key concepts)\n",
    "- **Just Right**: Understand principles (can handle variations)\n",
    "- **Overfitting**: Memorize all practice problems word-for-word (can't handle new questions)\n",
    "\n",
    "### The Solution: Regularization\n",
    "\n",
    "**Regularization**: Add penalty for model complexity!\n",
    "\n",
    "**Benefits**:\n",
    "- Prevents overfitting\n",
    "- Improves generalization\n",
    "- Can perform automatic feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Visualization settings\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate overfitting with polynomial features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Generate synthetic data with noise\n",
    "np.random.seed(42)\n",
    "X_simple = np.linspace(0, 10, 50).reshape(-1, 1)\n",
    "y_simple = 2 * X_simple.ravel() + 5 + np.random.normal(0, 2, 50)\n",
    "\n",
    "# Split data\n",
    "X_train_simple, X_test_simple, y_train_simple, y_test_simple = train_test_split(\n",
    "    X_simple, y_simple, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Test different polynomial degrees\n",
    "degrees = [1, 3, 15]\n",
    "results = []\n",
    "\n",
    "for degree in degrees:\n",
    "    # Transform features\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly.fit_transform(X_train_simple)\n",
    "    X_test_poly = poly.transform(X_test_simple)\n",
    "    \n",
    "    # Train model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train_simple)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_score = model.score(X_train_poly, y_train_simple)\n",
    "    test_score = model.score(X_test_poly, y_test_simple)\n",
    "    \n",
    "    results.append({\n",
    "        'Degree': degree,\n",
    "        'Train R²': train_score,\n",
    "        'Test R²': test_score,\n",
    "        'Gap': train_score - test_score\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Impact of Model Complexity:\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- Degree 1: Slight underfitting (both scores decent)\")\n",
    "print(\"- Degree 3: Good balance\")\n",
    "print(\"- Degree 15: Severe overfitting (perfect train, poor test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize underfitting vs overfitting\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "for idx, degree in enumerate(degrees):\n",
    "    # Transform and fit\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly.fit_transform(X_train_simple)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train_simple)\n",
    "    \n",
    "    # Generate smooth curve for visualization\n",
    "    X_plot = np.linspace(0, 10, 200).reshape(-1, 1)\n",
    "    X_plot_poly = poly.transform(X_plot)\n",
    "    y_plot = model.predict(X_plot_poly)\n",
    "    \n",
    "    # Plot\n",
    "    axes[idx].scatter(X_train_simple, y_train_simple, alpha=0.6, label='Training data')\n",
    "    axes[idx].scatter(X_test_simple, y_test_simple, alpha=0.6, label='Test data')\n",
    "    axes[idx].plot(X_plot, y_plot, 'r-', linewidth=2, label='Model fit')\n",
    "    \n",
    "    title = f\"Degree {degree}\\n\"\n",
    "    if degree == 1:\n",
    "        title += \"UNDERFITTING\"\n",
    "    elif degree == 3:\n",
    "        title += \"JUST RIGHT\"\n",
    "    else:\n",
    "        title += \"OVERFITTING\"\n",
    "    \n",
    "    axes[idx].set_title(title, fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('X', fontsize=11)\n",
    "    axes[idx].set_ylabel('y', fontsize=11)\n",
    "    axes[idx].legend(fontsize=9)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how degree 15 model passes through almost every training point\")\n",
    "print(\"but makes wild predictions between points!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ridge Regression (L2 Regularization)\n",
    "\n",
    "### How It Works\n",
    "\n",
    "**Standard Linear Regression**:\n",
    "- Minimize: Sum of Squared Errors\n",
    "- Problem: Can have very large coefficients\n",
    "\n",
    "**Ridge Regression**:\n",
    "- Minimize: Sum of Squared Errors + α × (Sum of Squared Coefficients)\n",
    "- Penalty term: L2 norm = sum of squared coefficients\n",
    "\n",
    "### Mathematical Formula\n",
    "\n",
    "```\n",
    "Loss = MSE + α × Σ(coefficient²)\n",
    "         ↑             ↑\n",
    "    Fit data    Regularization penalty\n",
    "```\n",
    "\n",
    "### Effect of Alpha (α)\n",
    "\n",
    "- **α = 0**: No regularization (standard linear regression)\n",
    "- **α → small**: Slight regularization\n",
    "- **α → large**: Strong regularization (coefficients shrink toward 0)\n",
    "- **α → ∞**: All coefficients → 0 (underfitting)\n",
    "\n",
    "### Key Properties\n",
    "\n",
    "✓ Shrinks coefficients but doesn't make them exactly 0  \n",
    "✓ Works well when all features are relevant  \n",
    "✓ Stable with correlated features  \n",
    "✓ Must scale features first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load California housing dataset\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing_df = pd.read_csv('data/sample/california_housing.csv')\n",
    "\n",
    "X_housing = housing_df.drop('median_house_value', axis=1)\n",
    "y_housing = housing_df['median_house_value']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_housing, y_housing, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features (IMPORTANT for regularization!)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Dataset shape: {X_housing.shape}\")\n",
    "print(f\"Features: {list(X_housing.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Linear Regression vs Ridge\n",
    "# Standard Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_train_score = lr_model.score(X_train_scaled, y_train)\n",
    "lr_test_score = lr_model.score(X_test_scaled, y_test)\n",
    "\n",
    "# Ridge Regression (α=10)\n",
    "ridge_model = Ridge(alpha=10)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "ridge_train_score = ridge_model.score(X_train_scaled, y_train)\n",
    "ridge_test_score = ridge_model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Linear Regression (No Regularization):\")\n",
    "print(f\"  Train R²: {lr_train_score:.3f}\")\n",
    "print(f\"  Test R²:  {lr_test_score:.3f}\")\n",
    "print(f\"  Gap:      {lr_train_score - lr_test_score:.3f}\\n\")\n",
    "\n",
    "print(\"Ridge Regression (α=10):\")\n",
    "print(f\"  Train R²: {ridge_train_score:.3f}\")\n",
    "print(f\"  Test R²:  {ridge_test_score:.3f}\")\n",
    "print(f\"  Gap:      {ridge_train_score - ridge_test_score:.3f}\")\n",
    "\n",
    "print(\"\\nRidge slightly sacrifices training performance for better generalization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different alpha values\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    train_scores.append(model.score(X_train_scaled, y_train))\n",
    "    test_scores.append(model.score(X_test_scaled, y_test))\n",
    "\n",
    "# Find best alpha\n",
    "best_idx = np.argmax(test_scores)\n",
    "best_alpha = alphas[best_idx]\n",
    "\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Best test R²: {test_scores[best_idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize alpha tuning\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(alphas, train_scores, 'o-', linewidth=2, markersize=8, label='Train R²')\n",
    "plt.semilogx(alphas, test_scores, 's-', linewidth=2, markersize=8, label='Test R²')\n",
    "plt.scatter([best_alpha], [test_scores[best_idx]], s=300, c='green', \n",
    "           marker='*', label=f'Best α={best_alpha}', zorder=5)\n",
    "plt.xlabel('Alpha (Regularization Strength)', fontsize=12)\n",
    "plt.ylabel('R² Score', fontsize=12)\n",
    "plt.title('Ridge Regression: Impact of Alpha\\n(Low α = weak regularization, High α = strong regularization)', \n",
    "         fontsize=13, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(\"- α too small: Approaches standard linear regression\")\n",
    "print(\"- α too large: Underfitting (all coefficients shrink to ~0)\")\n",
    "print(f\"- α = {best_alpha}: Best balance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare coefficients: Linear vs Ridge\n",
    "coef_comparison = pd.DataFrame({\n",
    "    'Feature': X_housing.columns,\n",
    "    'Linear Regression': lr_model.coef_,\n",
    "    'Ridge (α=10)': ridge_model.coef_\n",
    "})\n",
    "\n",
    "print(\"Coefficient Comparison:\\n\")\n",
    "print(coef_comparison.to_string(index=False))\n",
    "print(\"\\nNotice: Ridge coefficients are smaller (shrunk toward 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coefficient shrinkage\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x_pos = np.arange(len(X_housing.columns))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x_pos - width/2, lr_model.coef_, width, label='Linear Regression', alpha=0.7)\n",
    "ax.bar(x_pos + width/2, ridge_model.coef_, width, label='Ridge (α=10)', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Feature', fontsize=12)\n",
    "ax.set_ylabel('Coefficient Value', fontsize=12)\n",
    "ax.set_title('Coefficient Shrinkage with Ridge Regularization', fontsize=13, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(X_housing.columns, rotation=45, ha='right')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.axhline(y=0, color='black', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lasso Regression (L1 Regularization)\n",
    "\n",
    "### How It Works\n",
    "\n",
    "**Lasso Regression**:\n",
    "- Minimize: Sum of Squared Errors + α × (Sum of Absolute Coefficients)\n",
    "- Penalty term: L1 norm = sum of absolute values\n",
    "\n",
    "### Mathematical Formula\n",
    "\n",
    "```\n",
    "Loss = MSE + α × Σ|coefficient|\n",
    "         ↑             ↑\n",
    "    Fit data    Regularization penalty\n",
    "```\n",
    "\n",
    "### Ridge vs Lasso\n",
    "\n",
    "**Ridge (L2)**:\n",
    "- Penalty: coefficient²\n",
    "- Effect: Shrinks coefficients smoothly\n",
    "- Result: All coefficients remain non-zero (just smaller)\n",
    "\n",
    "**Lasso (L1)**:\n",
    "- Penalty: |coefficient|\n",
    "- Effect: Can set coefficients to exactly 0\n",
    "- Result: Automatic feature selection!\n",
    "\n",
    "### When to Use Lasso\n",
    "\n",
    "✓ When you suspect many features are irrelevant  \n",
    "✓ Want automatic feature selection  \n",
    "✓ Need interpretable model (fewer features)  \n",
    "✓ Want sparse models (many zero coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load synthetic regression data (many features)\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "synthetic_df = pd.read_csv('data/sample/synthetic_regression.csv')\n",
    "\n",
    "X_synthetic = synthetic_df.drop('target', axis=1)\n",
    "y_synthetic = synthetic_df['target']\n",
    "\n",
    "print(f\"Dataset shape: {X_synthetic.shape}\")\n",
    "print(f\"Number of features: {X_synthetic.shape[1]}\")\n",
    "print(\"\\nMany features - some may be irrelevant!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and scale\n",
    "X_train_syn, X_test_syn, y_train_syn, y_test_syn = train_test_split(\n",
    "    X_synthetic, y_synthetic, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "scaler_syn = StandardScaler()\n",
    "X_train_syn_scaled = scaler_syn.fit_transform(X_train_syn)\n",
    "X_test_syn_scaled = scaler_syn.transform(X_test_syn)\n",
    "\n",
    "# Train three models\n",
    "lr_syn = LinearRegression()\n",
    "ridge_syn = Ridge(alpha=1)\n",
    "lasso_syn = Lasso(alpha=1)\n",
    "\n",
    "lr_syn.fit(X_train_syn_scaled, y_train_syn)\n",
    "ridge_syn.fit(X_train_syn_scaled, y_train_syn)\n",
    "lasso_syn.fit(X_train_syn_scaled, y_train_syn)\n",
    "\n",
    "# Count non-zero coefficients\n",
    "lr_nonzero = np.sum(np.abs(lr_syn.coef_) > 0.001)\n",
    "ridge_nonzero = np.sum(np.abs(ridge_syn.coef_) > 0.001)\n",
    "lasso_nonzero = np.sum(np.abs(lasso_syn.coef_) > 0.001)\n",
    "\n",
    "print(\"Comparison of Three Models:\\n\")\n",
    "print(f\"Linear Regression:\")\n",
    "print(f\"  Test R²: {lr_syn.score(X_test_syn_scaled, y_test_syn):.3f}\")\n",
    "print(f\"  Non-zero coefficients: {lr_nonzero}/{len(lr_syn.coef_)}\\n\")\n",
    "\n",
    "print(f\"Ridge (L2):\")\n",
    "print(f\"  Test R²: {ridge_syn.score(X_test_syn_scaled, y_test_syn):.3f}\")\n",
    "print(f\"  Non-zero coefficients: {ridge_nonzero}/{len(ridge_syn.coef_)}\\n\")\n",
    "\n",
    "print(f\"Lasso (L1):\")\n",
    "print(f\"  Test R²: {lasso_syn.score(X_test_syn_scaled, y_test_syn):.3f}\")\n",
    "print(f\"  Non-zero coefficients: {lasso_nonzero}/{len(lasso_syn.coef_)}\")\n",
    "\n",
    "print(f\"\\nLasso selected only {lasso_nonzero} features (automatic feature selection)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coefficient values\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "models = [lr_syn, ridge_syn, lasso_syn]\n",
    "titles = ['Linear Regression', 'Ridge (L2)', 'Lasso (L1)']\n",
    "\n",
    "for idx, (model, title) in enumerate(zip(models, titles)):\n",
    "    coef_vals = model.coef_\n",
    "    axes[idx].bar(range(len(coef_vals)), coef_vals, alpha=0.7)\n",
    "    axes[idx].set_xlabel('Feature Index', fontsize=11)\n",
    "    axes[idx].set_ylabel('Coefficient Value', fontsize=11)\n",
    "    axes[idx].set_title(title, fontsize=12, fontweight='bold')\n",
    "    axes[idx].axhline(y=0, color='black', linewidth=0.8)\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice: Lasso sets many coefficients to exactly 0 (feature selection)!\")\n",
    "print(\"Ridge shrinks coefficients but keeps them all non-zero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Lasso feature selection\n",
    "# Train Lasso with different alphas\n",
    "alphas_lasso = [0.01, 0.1, 1, 10, 100]\n",
    "n_features_selected = []\n",
    "\n",
    "for alpha in alphas_lasso:\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "    lasso.fit(X_train_syn_scaled, y_train_syn)\n",
    "    n_selected = np.sum(np.abs(lasso.coef_) > 0.001)\n",
    "    n_features_selected.append(n_selected)\n",
    "    \n",
    "print(\"Lasso Feature Selection at Different Alpha Values:\\n\")\n",
    "for alpha, n_features in zip(alphas_lasso, n_features_selected):\n",
    "    print(f\"α = {alpha:6.2f}: {n_features:3d} features selected (out of {X_synthetic.shape[1]})\")\n",
    "\n",
    "print(\"\\nPattern: Higher α → More aggressive selection → Fewer features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature selection path\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(alphas_lasso, n_features_selected, 'o-', linewidth=2, markersize=10)\n",
    "plt.xlabel('Alpha (Regularization Strength)', fontsize=12)\n",
    "plt.ylabel('Number of Selected Features', fontsize=12)\n",
    "plt.title('Lasso Feature Selection\\n(Higher α = Fewer features)', \n",
    "         fontsize=13, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Elastic Net (Combination of L1 and L2)\n",
    "\n",
    "### Best of Both Worlds\n",
    "\n",
    "**Elastic Net** = Ridge + Lasso\n",
    "\n",
    "### Mathematical Formula\n",
    "\n",
    "```\n",
    "Loss = MSE + α × (λ × Σ|coef| + (1-λ) × Σ(coef²))\n",
    "         ↑        ↑               ↑\n",
    "    Fit data   L1 (Lasso)    L2 (Ridge)\n",
    "```\n",
    "\n",
    "**Two hyperparameters**:\n",
    "- **α**: Overall regularization strength\n",
    "- **l1_ratio** (λ): Balance between L1 and L2\n",
    "  - λ = 0: Pure Ridge\n",
    "  - λ = 1: Pure Lasso\n",
    "  - λ = 0.5: Equal mix\n",
    "\n",
    "### When to Use Elastic Net\n",
    "\n",
    "✓ When features are correlated (Lasso might arbitrarily pick one)  \n",
    "✓ Want feature selection but more stable than Lasso  \n",
    "✓ Not sure whether to use Ridge or Lasso  \n",
    "✓ Default safe choice for regularization\n",
    "\n",
    "### Advantages\n",
    "\n",
    "1. More stable than Lasso with correlated features\n",
    "2. Can select groups of correlated features\n",
    "3. Better than Ridge for feature selection\n",
    "4. Flexible - can tune to behave like Ridge or Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net example\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Test different l1_ratio values\n",
    "l1_ratios = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "alpha_en = 1.0\n",
    "\n",
    "results_elastic = []\n",
    "\n",
    "for l1_ratio in l1_ratios:\n",
    "    model = ElasticNet(alpha=alpha_en, l1_ratio=l1_ratio, max_iter=10000)\n",
    "    model.fit(X_train_syn_scaled, y_train_syn)\n",
    "    \n",
    "    test_score = model.score(X_test_syn_scaled, y_test_syn)\n",
    "    n_selected = np.sum(np.abs(model.coef_) > 0.001)\n",
    "    \n",
    "    results_elastic.append({\n",
    "        'l1_ratio': l1_ratio,\n",
    "        'Type': 'Pure Ridge' if l1_ratio == 0 else \n",
    "                'Pure Lasso' if l1_ratio == 1 else \n",
    "                f'Mix ({int(l1_ratio*100)}% L1)',\n",
    "        'Test R²': test_score,\n",
    "        'Features Selected': n_selected\n",
    "    })\n",
    "\n",
    "results_elastic_df = pd.DataFrame(results_elastic)\n",
    "print(f\"Elastic Net Results (α={alpha_en}):\\n\")\n",
    "print(results_elastic_df.to_string(index=False))\n",
    "print(\"\\nNotice the transition from Ridge (no feature selection) to Lasso (aggressive selection)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Elastic Net behavior\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Test R² vs l1_ratio\n",
    "axes[0].plot(results_elastic_df['l1_ratio'], results_elastic_df['Test R²'], \n",
    "            'o-', linewidth=2, markersize=10)\n",
    "axes[0].set_xlabel('l1_ratio (0=Ridge, 1=Lasso)', fontsize=12)\n",
    "axes[0].set_ylabel('Test R²', fontsize=12)\n",
    "axes[0].set_title('Elastic Net Performance', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Features selected vs l1_ratio\n",
    "axes[1].plot(results_elastic_df['l1_ratio'], results_elastic_df['Features Selected'], \n",
    "            's-', linewidth=2, markersize=10, color='orange')\n",
    "axes[1].set_xlabel('l1_ratio (0=Ridge, 1=Lasso)', fontsize=12)\n",
    "axes[1].set_ylabel('Number of Features Selected', fontsize=12)\n",
    "axes[1].set_title('Feature Selection Behavior', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Elastic Net gives you control over the tradeoff!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bias-Variance Tradeoff\n",
    "\n",
    "### The Fundamental Tradeoff\n",
    "\n",
    "**Total Error** = Bias² + Variance + Irreducible Error\n",
    "\n",
    "### Definitions\n",
    "\n",
    "**Bias**: \n",
    "- Error from overly simplistic assumptions\n",
    "- High bias → Underfitting\n",
    "- Model consistently wrong in same direction\n",
    "\n",
    "**Variance**:\n",
    "- Error from sensitivity to training data fluctuations\n",
    "- High variance → Overfitting\n",
    "- Predictions vary wildly with different training sets\n",
    "\n",
    "**Irreducible Error**:\n",
    "- Noise in data (can't be reduced)\n",
    "\n",
    "### The Tradeoff\n",
    "\n",
    "```\n",
    "Simple Model          →          Complex Model\n",
    "High Bias                         High Variance\n",
    "Low Variance                      Low Bias\n",
    "Underfitting                      Overfitting\n",
    "       ↓                                ↓\n",
    "    Add complexity              Add regularization\n",
    "```\n",
    "\n",
    "### Regularization's Role\n",
    "\n",
    "**Regularization increases bias slightly but decreases variance significantly**\n",
    "\n",
    "- Small α: Low bias, high variance (may overfit)\n",
    "- Large α: High bias, low variance (may underfit)\n",
    "- Optimal α: Minimizes total error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate bias-variance tradeoff\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Test range of alpha values\n",
    "alphas_bv = np.logspace(-3, 3, 20)\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for alpha in alphas_bv:\n",
    "    model = Ridge(alpha=alpha)\n",
    "    \n",
    "    # Training error\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    train_pred = model.predict(X_train_scaled)\n",
    "    train_errors.append(mean_squared_error(y_train, train_pred))\n",
    "    \n",
    "    # Test error (approximates generalization error)\n",
    "    test_pred = model.predict(X_test_scaled)\n",
    "    test_errors.append(mean_squared_error(y_test, test_pred))\n",
    "\n",
    "# Find optimal alpha\n",
    "optimal_idx = np.argmin(test_errors)\n",
    "optimal_alpha = alphas_bv[optimal_idx]\n",
    "\n",
    "print(f\"Optimal alpha: {optimal_alpha:.3f}\")\n",
    "print(f\"Minimum test error: {test_errors[optimal_idx]:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bias-variance tradeoff\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(alphas_bv, train_errors, 'b-', linewidth=2, label='Training Error (Bias)')\n",
    "plt.semilogx(alphas_bv, test_errors, 'r-', linewidth=2, label='Test Error (Bias + Variance)')\n",
    "plt.scatter([optimal_alpha], [test_errors[optimal_idx]], s=300, c='green', \n",
    "           marker='*', label=f'Optimal α={optimal_alpha:.3f}', zorder=5)\n",
    "\n",
    "# Annotate regions\n",
    "plt.text(0.001, max(test_errors)*0.95, 'High Variance\\n(Overfitting)', \n",
    "        fontsize=10, ha='left', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n",
    "plt.text(100, max(test_errors)*0.95, 'High Bias\\n(Underfitting)', \n",
    "        fontsize=10, ha='right', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "plt.xlabel('Alpha (Regularization Strength)', fontsize=12)\n",
    "plt.ylabel('Mean Squared Error', fontsize=12)\n",
    "plt.title('Bias-Variance Tradeoff in Ridge Regression', fontsize=13, fontweight='bold')\n",
    "plt.legend(fontsize=11, loc='upper center')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- Left (low α): Small gap between train/test (high variance)\")\n",
    "print(\"- Right (high α): Large gap (high bias, both errors increase)\")\n",
    "print(f\"- Optimal α={optimal_alpha:.3f}: Best balance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Ridge Regularization Path\n",
    "\n",
    "Visualize how Ridge coefficients change with alpha:\n",
    "1. Use California housing data\n",
    "2. Train Ridge models with alphas from 0.001 to 1000 (log scale, 50 points)\n",
    "3. For each alpha, store all coefficients\n",
    "4. Create a plot showing coefficient values vs alpha\n",
    "5. Each feature should be a separate line\n",
    "6. Which features shrink fastest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Lasso Feature Selection\n",
    "\n",
    "Use Lasso for feature selection on synthetic data:\n",
    "1. Train Lasso with alpha=1.0\n",
    "2. Identify which features have non-zero coefficients\n",
    "3. Retrain a simple LinearRegression using ONLY selected features\n",
    "4. Compare performance:\n",
    "   - Full model (all features)\n",
    "   - Lasso (all features with regularization)\n",
    "   - Selected model (only selected features)\n",
    "5. Which approach works best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Elastic Net Grid Search\n",
    "\n",
    "Find optimal hyperparameters for Elastic Net:\n",
    "1. Use GridSearchCV or RandomizedSearchCV\n",
    "2. Search over:\n",
    "   - alpha: [0.01, 0.1, 1, 10, 100]\n",
    "   - l1_ratio: [0, 0.25, 0.5, 0.75, 1.0]\n",
    "3. Use 5-fold cross-validation\n",
    "4. Print best parameters and score\n",
    "5. Create heatmap of alpha vs l1_ratio showing CV scores\n",
    "\n",
    "Use California housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Regularization Comparison\n",
    "\n",
    "Comprehensive comparison of all regularization methods:\n",
    "1. Load synthetic_regression dataset\n",
    "2. Split into train/test (70/30)\n",
    "3. Scale features\n",
    "4. Train and evaluate:\n",
    "   - Linear Regression (no regularization)\n",
    "   - Ridge (tune alpha with cross-validation)\n",
    "   - Lasso (tune alpha with cross-validation)\n",
    "   - Elastic Net (tune both alpha and l1_ratio)\n",
    "5. Create comparison table with:\n",
    "   - Train R², Test R²\n",
    "   - Number of features selected\n",
    "   - Training time\n",
    "6. Which model would you choose and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Overfitting vs Underfitting**:\n",
    "   - **Overfitting**: Model too complex, learns noise, poor generalization\n",
    "   - **Underfitting**: Model too simple, misses patterns\n",
    "   - **Just Right**: Captures true patterns, generalizes well\n",
    "\n",
    "2. **Ridge Regression (L2)**:\n",
    "   - Penalty: Sum of squared coefficients\n",
    "   - Effect: Shrinks coefficients toward 0 (but not to exactly 0)\n",
    "   - Use when: All features potentially relevant\n",
    "   - Hyperparameter: alpha (higher = stronger regularization)\n",
    "\n",
    "3. **Lasso Regression (L1)**:\n",
    "   - Penalty: Sum of absolute coefficients\n",
    "   - Effect: Can set coefficients to exactly 0\n",
    "   - Use when: Want automatic feature selection\n",
    "   - Result: Sparse models (many zero coefficients)\n",
    "\n",
    "4. **Elastic Net**:\n",
    "   - Combination of L1 and L2 penalties\n",
    "   - Two hyperparameters: alpha and l1_ratio\n",
    "   - More stable than Lasso with correlated features\n",
    "   - Default safe choice for regularization\n",
    "\n",
    "5. **Bias-Variance Tradeoff**:\n",
    "   - Total Error = Bias² + Variance + Noise\n",
    "   - Simple models: High bias, low variance\n",
    "   - Complex models: Low bias, high variance\n",
    "   - Regularization: Trades slight bias increase for large variance decrease\n",
    "\n",
    "6. **Best Practices**:\n",
    "   - **Always scale features** before regularization\n",
    "   - Use cross-validation to tune alpha\n",
    "   - Try multiple regularization methods\n",
    "   - Start with Elastic Net (flexible)\n",
    "   - Monitor train/test gap to detect overfitting\n",
    "\n",
    "### Choosing Regularization Method\n",
    "\n",
    "| Scenario | Recommended Method |\n",
    "|----------|-------------------|\n",
    "| All features relevant | Ridge (L2) |\n",
    "| Many irrelevant features | Lasso (L1) |\n",
    "| Correlated features | Ridge or Elastic Net |\n",
    "| Want feature selection | Lasso or Elastic Net |\n",
    "| Not sure | Elastic Net (safe default) |\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 09: Support Vector Machines**, you'll learn:\n",
    "- Maximum margin classification\n",
    "- Linear and non-linear SVM\n",
    "- The kernel trick (RBF, polynomial)\n",
    "- Hyperparameters: C and gamma\n",
    "- SVC vs SVR (classification vs regression)\n",
    "- Decision boundary visualization\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Ridge and Lasso - StatQuest](https://www.youtube.com/watch?v=Q81RR3yKn30)\n",
    "- [Regularization Explained - Andrew Ng](https://www.coursera.org/lecture/machine-learning/regularization-and-bias-variance-4VDlf)\n",
    "- [scikit-learn Regularization Guide](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification)\n",
    "- [Bias-Variance Tradeoff](https://www.youtube.com/watch?v=EuBBz3bI-aA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
