{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 00: Introduction to Machine Learning\n",
    "\n",
    "**Difficulty**: ⭐ Beginner  \n",
    "**Estimated Time**: 60 minutes  \n",
    "**Prerequisites**: \n",
    "- Basic Python programming\n",
    "- NumPy and Pandas fundamentals\n",
    "- Basic statistics knowledge\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Define machine learning and explain its core concepts\n",
    "2. Distinguish between supervised, unsupervised, and reinforcement learning\n",
    "3. Understand the typical ML workflow and pipeline\n",
    "4. Set up and use scikit-learn for basic ML tasks\n",
    "5. Build your first ML model using scikit-learn\n",
    "6. Recognize common ML terminology and concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, let's import all the libraries we'll need for this introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn basics\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display versions\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is Machine Learning?\n",
    "\n",
    "### Definition\n",
    "\n",
    "**Machine Learning (ML)** is a subset of artificial intelligence that enables computers to learn from data without being explicitly programmed. Instead of writing specific rules, we provide examples and let the algorithm discover patterns.\n",
    "\n",
    "### Traditional Programming vs Machine Learning\n",
    "\n",
    "**Traditional Programming:**\n",
    "- Input: Data + Rules → Output: Answers\n",
    "- Example: Calculate total price = quantity × unit_price\n",
    "\n",
    "**Machine Learning:**\n",
    "- Input: Data + Answers → Output: Rules (Model)\n",
    "- Example: Given images and labels, learn to recognize cats vs dogs\n",
    "\n",
    "### When to Use Machine Learning?\n",
    "\n",
    "ML is useful when:\n",
    "1. **Problems are too complex** for traditional programming (speech recognition, image classification)\n",
    "2. **Rules keep changing** (fraud detection, stock market prediction)\n",
    "3. **Patterns exist in data** but are hard to describe explicitly\n",
    "4. **You have sufficient data** to train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Types of Machine Learning\n",
    "\n",
    "Machine learning algorithms can be categorized into three main types:\n",
    "\n",
    "### 3.1 Supervised Learning\n",
    "\n",
    "**Definition**: Learning from labeled data (input-output pairs)\n",
    "\n",
    "**Two main types:**\n",
    "- **Classification**: Predict discrete categories (spam vs not spam, cat vs dog)\n",
    "- **Regression**: Predict continuous values (house prices, temperature)\n",
    "\n",
    "**Common algorithms:**\n",
    "- Linear Regression, Logistic Regression\n",
    "- Decision Trees, Random Forests\n",
    "- Support Vector Machines (SVM)\n",
    "- Neural Networks\n",
    "\n",
    "### 3.2 Unsupervised Learning\n",
    "\n",
    "**Definition**: Learning from unlabeled data (finding hidden patterns)\n",
    "\n",
    "**Common tasks:**\n",
    "- **Clustering**: Group similar items together (customer segmentation)\n",
    "- **Dimensionality Reduction**: Reduce number of features while preserving information (PCA)\n",
    "- **Anomaly Detection**: Find unusual patterns (fraud detection)\n",
    "\n",
    "**Common algorithms:**\n",
    "- K-Means, DBSCAN (clustering)\n",
    "- PCA, t-SNE (dimensionality reduction)\n",
    "\n",
    "### 3.3 Reinforcement Learning\n",
    "\n",
    "**Definition**: Learning through interaction with an environment (trial and error)\n",
    "\n",
    "**Key concepts:**\n",
    "- Agent takes actions in an environment\n",
    "- Receives rewards or penalties\n",
    "- Learns optimal behavior to maximize cumulative reward\n",
    "\n",
    "**Applications:**\n",
    "- Game playing (AlphaGo, chess)\n",
    "- Robotics\n",
    "- Autonomous driving\n",
    "\n",
    "**Note**: This course focuses primarily on supervised and unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Machine Learning Workflow\n",
    "\n",
    "A typical ML project follows these steps:\n",
    "\n",
    "1. **Define the Problem**\n",
    "   - What are you trying to predict?\n",
    "   - Is it classification or regression?\n",
    "   - What is success?\n",
    "\n",
    "2. **Collect and Explore Data**\n",
    "   - Gather relevant data\n",
    "   - Visualize and understand distributions\n",
    "   - Check for missing values and outliers\n",
    "\n",
    "3. **Prepare Data**\n",
    "   - Handle missing values\n",
    "   - Encode categorical variables\n",
    "   - Scale/normalize features\n",
    "   - Split into training and test sets\n",
    "\n",
    "4. **Choose and Train Model**\n",
    "   - Select appropriate algorithm\n",
    "   - Train on training data\n",
    "   - Tune hyperparameters\n",
    "\n",
    "5. **Evaluate Model**\n",
    "   - Test on unseen data\n",
    "   - Calculate performance metrics\n",
    "   - Validate results\n",
    "\n",
    "6. **Deploy and Monitor**\n",
    "   - Put model into production\n",
    "   - Monitor performance over time\n",
    "   - Retrain as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Introduction to Scikit-learn\n",
    "\n",
    "**Scikit-learn** is the most popular Python library for machine learning. It provides:\n",
    "\n",
    "- **Simple and consistent API**: Most algorithms follow the same pattern\n",
    "- **Wide variety of algorithms**: Classification, regression, clustering, etc.\n",
    "- **Built-in datasets**: Perfect for learning and experimentation\n",
    "- **Preprocessing tools**: Scaling, encoding, feature selection\n",
    "- **Model evaluation**: Metrics, cross-validation, hyperparameter tuning\n",
    "\n",
    "### The Scikit-learn API Pattern\n",
    "\n",
    "Most scikit-learn models follow this consistent interface:\n",
    "\n",
    "```python\n",
    "# 1. Import the model class\n",
    "from sklearn.some_module import SomeModel\n",
    "\n",
    "# 2. Create a model instance (with hyperparameters)\n",
    "model = SomeModel(param1=value1, param2=value2)\n",
    "\n",
    "# 3. Train the model on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 5. Evaluate the model\n",
    "score = model.score(X_test, y_test)\n",
    "```\n",
    "\n",
    "This pattern makes it easy to swap between different algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Your First ML Model: Iris Classification\n",
    "\n",
    "Let's build a complete ML model using the famous Iris dataset. This dataset contains measurements of 150 iris flowers from three species.\n",
    "\n",
    "### 6.1 Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset (built into scikit-learn)\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Convert to pandas DataFrame for easier exploration\n",
    "iris_df = pd.DataFrame(\n",
    "    data=iris.data,\n",
    "    columns=iris.feature_names\n",
    ")\n",
    "iris_df['species'] = iris.target\n",
    "iris_df['species_name'] = iris_df['species'].map(\n",
    "    {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
    ")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"First 5 rows of the Iris dataset:\")\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset shape and info\n",
    "print(f\"Dataset shape: {iris_df.shape}\")\n",
    "print(f\"\\nFeatures: {iris.feature_names}\")\n",
    "print(f\"Target classes: {iris.target_names}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(iris_df['species_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot of two features\n",
    "for species in iris_df['species_name'].unique():\n",
    "    subset = iris_df[iris_df['species_name'] == species]\n",
    "    axes[0].scatter(\n",
    "        subset['sepal length (cm)'],\n",
    "        subset['sepal width (cm)'],\n",
    "        label=species,\n",
    "        alpha=0.7\n",
    "    )\n",
    "axes[0].set_xlabel('Sepal Length (cm)')\n",
    "axes[0].set_ylabel('Sepal Width (cm)')\n",
    "axes[0].set_title('Iris Species by Sepal Dimensions')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot of petal length\n",
    "iris_df.boxplot(\n",
    "    column='petal length (cm)',\n",
    "    by='species_name',\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_xlabel('Species')\n",
    "axes[1].set_ylabel('Petal Length (cm)')\n",
    "axes[1].set_title('Petal Length Distribution by Species')\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how different species have distinct patterns in their measurements!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Prepare Data for ML\n",
    "\n",
    "We need to split our data into features (X) and target (y), then create training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = iris.data  # Features: 4 measurements\n",
    "y = iris.target  # Target: species (0, 1, or 2)\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFirst sample features: {X[0]}\")\n",
    "print(f\"First sample target: {y[0]} ({iris.target_names[y[0]]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training (80%) and test (20%) sets\n",
    "# This is CRITICAL: we train on one set and test on another!\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,  # 20% for testing\n",
    "    random_state=42,  # For reproducibility\n",
    "    stratify=y  # Maintain class proportions\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)} samples\")\n",
    "print(f\"Test set size: {len(X_test)} samples\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(pd.Series(y_test).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Feature Scaling\n",
    "\n",
    "Many ML algorithms work better when features are on the same scale. We'll use **StandardScaler** to normalize our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# IMPORTANT: Fit scaler on training data only!\n",
    "# This prevents data leakage from test set\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform both training and test data using the same scaler\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Before scaling (first training sample):\")\n",
    "print(X_train[0])\n",
    "print(\"\\nAfter scaling (first training sample):\")\n",
    "print(X_train_scaled[0])\n",
    "print(\"\\nNotice how values are now centered around 0 with similar ranges!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Train a Model\n",
    "\n",
    "We'll use **K-Nearest Neighbors (KNN)**, a simple but effective algorithm that classifies based on the k closest training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KNN classifier with k=5\n",
    "# This means: classify based on the 5 nearest neighbors\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model on scaled training data\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(f\"Model type: {type(knn_model).__name__}\")\n",
    "print(f\"Number of neighbors: {knn_model.n_neighbors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Show first 10 predictions vs actual values\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual': [iris.target_names[y] for y in y_test[:10]],\n",
    "    'Predicted': [iris.target_names[y] for y in y_pred[:10]],\n",
    "    'Correct': y_test[:10] == y_pred[:10]\n",
    "})\n",
    "\n",
    "print(\"First 10 predictions:\")\n",
    "print(comparison_df)\n",
    "print(f\"\\nTotal correct predictions: {sum(y_test == y_pred)} out of {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2%}\")\n",
    "print(f\"This means the model correctly classified {accuracy:.1%} of test samples!\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nDetailed Performance Report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=iris.target_names\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix visualization\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=iris.target_names,\n",
    "    yticklabels=iris.target_names\n",
    ")\n",
    "plt.title('Confusion Matrix: Iris Classification', fontsize=14)\n",
    "plt.ylabel('Actual Species')\n",
    "plt.xlabel('Predicted Species')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The diagonal shows correct predictions.\")\n",
    "print(\"Off-diagonal values show misclassifications.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key ML Terminology\n",
    "\n",
    "Let's review important terms you'll encounter throughout this course:\n",
    "\n",
    "### Data-Related Terms\n",
    "\n",
    "- **Features (X)**: Input variables used for prediction (also called predictors, independent variables)\n",
    "- **Target (y)**: Output variable we want to predict (also called label, dependent variable)\n",
    "- **Sample**: A single data point (row in a dataset)\n",
    "- **Training Set**: Data used to train the model\n",
    "- **Test Set**: Data used to evaluate model performance (never seen during training!)\n",
    "- **Validation Set**: Data used to tune hyperparameters (we'll cover this later)\n",
    "\n",
    "### Model-Related Terms\n",
    "\n",
    "- **Model**: The learned pattern/function that maps features to target\n",
    "- **Algorithm**: The method used to learn the model (e.g., KNN, Linear Regression)\n",
    "- **Training/Fitting**: The process of learning from data\n",
    "- **Prediction**: Using a trained model to make outputs for new inputs\n",
    "- **Hyperparameters**: Settings you choose before training (e.g., k=5 in KNN)\n",
    "- **Parameters**: Values learned during training (e.g., weights in linear regression)\n",
    "\n",
    "### Performance-Related Terms\n",
    "\n",
    "- **Accuracy**: Percentage of correct predictions\n",
    "- **Overfitting**: Model performs great on training data but poorly on test data\n",
    "- **Underfitting**: Model performs poorly on both training and test data\n",
    "- **Generalization**: Model's ability to perform well on unseen data\n",
    "- **Bias-Variance Tradeoff**: Balance between model complexity and generalization (we'll dive deep into this later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Practice Exercises\n",
    "\n",
    "### Exercise 1: Try Different k Values\n",
    "\n",
    "Train KNN models with k=3 and k=7. Which performs better? Why might that be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Create two models with different n_neighbors values\n",
    "# Train both and compare their accuracy scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Effect of Feature Scaling\n",
    "\n",
    "Train a KNN model WITHOUT scaling the features (use X_train and X_test directly). Compare accuracy to the scaled version. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Train KNN on unscaled data and compare accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Predict New Samples\n",
    "\n",
    "Create a new iris flower with these measurements:\n",
    "- Sepal length: 5.0 cm\n",
    "- Sepal width: 3.5 cm\n",
    "- Petal length: 1.5 cm\n",
    "- Petal width: 0.3 cm\n",
    "\n",
    "Use your trained model to predict which species it belongs to. (Remember to scale it first!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Create a new sample, scale it, and make a prediction\n",
    "# Hint: new_sample = np.array([[5.0, 3.5, 1.5, 0.3]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Explore Wine Dataset\n",
    "\n",
    "Scikit-learn has another built-in dataset: `datasets.load_wine()`. Load it, explore it, and build a KNN classifier. What accuracy do you achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Load wine dataset, split it, scale it, train KNN, evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "Congratulations on building your first machine learning model! Let's recap what we covered:\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Machine Learning** enables computers to learn from data without explicit programming\n",
    "2. **Three types of ML**:\n",
    "   - Supervised (labeled data): Classification and Regression\n",
    "   - Unsupervised (unlabeled data): Clustering and Dimensionality Reduction\n",
    "   - Reinforcement (learning through interaction)\n",
    "\n",
    "3. **ML Workflow**:\n",
    "   - Define problem → Collect data → Prepare data → Train model → Evaluate → Deploy\n",
    "\n",
    "4. **Scikit-learn API**:\n",
    "   - Import → Create → Fit → Predict → Score\n",
    "\n",
    "5. **Critical Practices**:\n",
    "   - Always split data into train/test sets\n",
    "   - Fit preprocessing (scalers) on training data only\n",
    "   - Evaluate on unseen test data\n",
    "\n",
    "### What You Built\n",
    "\n",
    "You created a complete ML pipeline:\n",
    "- Loaded and explored data\n",
    "- Split into train/test sets\n",
    "- Scaled features\n",
    "- Trained a KNN classifier\n",
    "- Made predictions and evaluated performance\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next module, we'll dive deeper into:\n",
    "- Understanding supervised vs unsupervised learning\n",
    "- Different types of ML problems\n",
    "- How to choose the right algorithm\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)\n",
    "- [Scikit-learn Tutorials](https://scikit-learn.org/stable/tutorial/index.html)\n",
    "- [Machine Learning Glossary](https://developers.google.com/machine-learning/glossary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Bonus: Quick Reference\n",
    "\n",
    "### Common Scikit-learn Imports\n",
    "\n",
    "```python\n",
    "# Data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "```\n",
    "\n",
    "### Basic ML Checklist\n",
    "\n",
    "- [ ] Load and explore data\n",
    "- [ ] Handle missing values\n",
    "- [ ] Split into train/test sets (BEFORE any preprocessing)\n",
    "- [ ] Preprocess features (scaling, encoding)\n",
    "- [ ] Choose and train model\n",
    "- [ ] Make predictions on test set\n",
    "- [ ] Evaluate performance with appropriate metrics\n",
    "- [ ] Iterate and improve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
