{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 00: Introduction to Machine Learning and scikit-learn\n",
    "\n",
    "**Difficulty**: ⭐ Beginner  \n",
    "**Estimated Time**: 45 minutes  \n",
    "**Prerequisites**: \n",
    "- Python fundamentals\n",
    "- NumPy and Pandas basics\n",
    "- Basic statistics knowledge\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Explain what machine learning is and identify different types of ML problems\n",
    "2. Understand the typical machine learning workflow\n",
    "3. Set up and verify your scikit-learn environment\n",
    "4. Load and explore datasets using scikit-learn\n",
    "5. Understand the basic structure of scikit-learn's API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Machine Learning?\n",
    "\n",
    "**Machine Learning** is a field of artificial intelligence that enables computers to learn patterns from data without being explicitly programmed. Instead of writing rules manually, we let the computer discover patterns and relationships in the data.\n",
    "\n",
    "### Traditional Programming vs Machine Learning\n",
    "\n",
    "**Traditional Programming:**\n",
    "- Input: Data + Rules\n",
    "- Output: Answers\n",
    "- Example: You write code to classify emails as spam if they contain certain keywords\n",
    "\n",
    "**Machine Learning:**\n",
    "- Input: Data + Answers\n",
    "- Output: Rules (Model)\n",
    "- Example: The computer learns what makes an email spam by looking at thousands of examples\n",
    "\n",
    "### Types of Machine Learning\n",
    "\n",
    "1. **Supervised Learning**: Learning from labeled data\n",
    "   - Classification: Predicting categories (spam/not spam, cat/dog)\n",
    "   - Regression: Predicting continuous values (house prices, temperature)\n",
    "\n",
    "2. **Unsupervised Learning**: Finding patterns in unlabeled data\n",
    "   - Clustering: Grouping similar items together\n",
    "   - Dimensionality Reduction: Simplifying complex data\n",
    "\n",
    "3. **Reinforcement Learning**: Learning through trial and error with rewards\n",
    "   - Game playing, robotics, recommendation systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Machine Learning Workflow\n",
    "\n",
    "A typical ML project follows these steps:\n",
    "\n",
    "1. **Define the Problem**: What are you trying to predict or understand?\n",
    "2. **Collect Data**: Gather relevant data for your problem\n",
    "3. **Explore and Visualize**: Understand your data's characteristics\n",
    "4. **Prepare Data**: Clean, transform, and split your data\n",
    "5. **Choose a Model**: Select an appropriate algorithm\n",
    "6. **Train the Model**: Let the algorithm learn from the data\n",
    "7. **Evaluate Performance**: Measure how well the model works\n",
    "8. **Tune and Optimize**: Improve the model's performance\n",
    "9. **Deploy and Monitor**: Use the model in production and track its performance\n",
    "\n",
    "In this course, we'll focus on steps 4-8, which are the core of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup and Environment Verification\n",
    "\n",
    "Let's verify that all necessary libraries are installed and working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "# This ensures our results are consistent across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure visualization settings\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Display settings for pandas\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "print(\"Environment Setup Complete!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Introduction to scikit-learn\n",
    "\n",
    "**scikit-learn** (sklearn) is the most popular machine learning library in Python. It provides:\n",
    "- Simple and consistent API\n",
    "- Wide variety of algorithms\n",
    "- Excellent documentation\n",
    "- Built-in datasets for practice\n",
    "- Tools for model evaluation and selection\n",
    "\n",
    "### The scikit-learn API Pattern\n",
    "\n",
    "All scikit-learn estimators (models) follow the same pattern:\n",
    "\n",
    "```python\n",
    "# 1. Import the model class\n",
    "from sklearn.some_module import SomeModel\n",
    "\n",
    "# 2. Instantiate the model with parameters\n",
    "model = SomeModel(parameter1=value1, parameter2=value2)\n",
    "\n",
    "# 3. Fit the model to training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Make predictions on new data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 5. Evaluate the model\n",
    "score = model.score(X_test, y_test)\n",
    "```\n",
    "\n",
    "This consistent interface makes it easy to try different algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loading and Exploring a Dataset\n",
    "\n",
    "Let's load the famous **Iris dataset**, which contains measurements of iris flowers. This is a perfect dataset for learning ML basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset from our prepared CSV file\n",
    "from pathlib import Path\n",
    "\n",
    "# Use relative path so notebook works on any computer\n",
    "data_path = Path('data/sample/iris.csv')\n",
    "\n",
    "# Verify file exists\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Data file not found: {data_path}\\n\"\n",
    "        \"Please ensure you've run scripts/prepare_datasets.py first.\"\n",
    "    )\n",
    "\n",
    "# Load data\n",
    "iris_df = pd.read_csv(data_path)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {iris_df.shape}\")\n",
    "print(f\"Number of samples: {len(iris_df)}\")\n",
    "print(f\"Number of features: {len(iris_df.columns) - 2}\")  # Exclude target columns\n",
    "print(f\"\\nFirst few rows:\")\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the dataset structure\n",
    "print(\"Dataset Information:\")\n",
    "print(iris_df.info())\n",
    "\n",
    "print(\"\\nBasic Statistics:\")\n",
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of target classes\n",
    "print(\"Class Distribution:\")\n",
    "print(iris_df['species_name'].value_counts())\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "iris_df['species_name'].value_counts().plot(kind='bar', color='steelblue')\n",
    "plt.title('Distribution of Iris Species', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Species', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ The dataset is balanced - each class has equal representation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Understanding Features and Targets\n",
    "\n",
    "In machine learning:\n",
    "- **Features (X)**: The input variables we use to make predictions (also called independent variables)\n",
    "- **Target (y)**: The output variable we want to predict (also called dependent variable or label)\n",
    "\n",
    "For the Iris dataset:\n",
    "- **Features**: sepal length, sepal width, petal length, petal width (measurements in cm)\n",
    "- **Target**: species (setosa, versicolor, or virginica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "feature_columns = ['sepal length (cm)', 'sepal width (cm)', \n",
    "                  'petal length (cm)', 'petal width (cm)']\n",
    "\n",
    "X = iris_df[feature_columns]\n",
    "y = iris_df['species']\n",
    "\n",
    "print(\"Features (X):\")\n",
    "print(f\"Shape: {X.shape}\")\n",
    "print(X.head(3))\n",
    "\n",
    "print(\"\\nTarget (y):\")\n",
    "print(f\"Shape: {y.shape}\")\n",
    "print(y.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing Relationships in Data\n",
    "\n",
    "Before building models, it's crucial to visualize your data to understand relationships between features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairplot to visualize relationships\n",
    "# This shows how different features relate to each other and the target\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(iris_df, hue='species_name', markers=['o', 's', 'D'],\n",
    "            diag_kind='kde', height=2.5)\n",
    "plt.suptitle('Iris Dataset - Feature Relationships', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- Petal measurements (length and width) show clear separation between species\")\n",
    "print(\"- Setosa is distinctly different from the other two species\")\n",
    "print(\"- Versicolor and virginica have some overlap, making them harder to distinguish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Your First ML Model Preview\n",
    "\n",
    "Let's get a sneak peek at how simple it is to build a model with scikit-learn. Don't worry about understanding every detail yet - we'll cover this thoroughly in upcoming modules!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a simple classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)} samples\")\n",
    "print(f\"Testing set size: {len(X_test)} samples\")\n",
    "\n",
    "# Create and train a decision tree model\n",
    "model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = model.score(X_train, y_train)\n",
    "test_accuracy = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.1%}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.1%}\")\n",
    "\n",
    "# Make a prediction on a new sample\n",
    "sample = X_test.iloc[0:1]\n",
    "prediction = model.predict(sample)\n",
    "actual = y_test.iloc[0]\n",
    "\n",
    "print(f\"\\nExample Prediction:\")\n",
    "print(f\"Features: {sample.values[0]}\")\n",
    "print(f\"Predicted class: {prediction[0]}\")\n",
    "print(f\"Actual class: {actual}\")\n",
    "print(f\"Correct: {prediction[0] == actual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Now it's your turn! Complete these exercises to reinforce your learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Load and Explore the Wine Dataset\n",
    "\n",
    "Load the wine dataset from `data/sample/wine.csv` and answer the following questions:\n",
    "1. How many samples are in the dataset?\n",
    "2. How many features does it have?\n",
    "3. How many classes (wine types) are there?\n",
    "4. Is the dataset balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Load the wine dataset and explore its characteristics\n",
    "\n",
    "# Hint: Use pd.read_csv() and explore with .shape, .info(), .describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Identify Problem Types\n",
    "\n",
    "For each of the following scenarios, identify whether it's a:\n",
    "- **Classification** problem (predicting categories)\n",
    "- **Regression** problem (predicting continuous values)\n",
    "- **Clustering** problem (grouping similar items)\n",
    "\n",
    "Write your answers as comments in the code cell below:\n",
    "\n",
    "1. Predicting house prices based on size, location, and age\n",
    "2. Grouping customers by purchasing behavior without predefined categories\n",
    "3. Determining if an email is spam or not spam\n",
    "4. Forecasting tomorrow's temperature\n",
    "5. Categorizing news articles into topics (sports, politics, technology)\n",
    "6. Segmenting website visitors into groups based on browsing patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answers here:\n",
    "# 1. \n",
    "# 2. \n",
    "# 3. \n",
    "# 4. \n",
    "# 5. \n",
    "# 6. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Visualize Feature Relationships\n",
    "\n",
    "Create a scatter plot showing the relationship between two features of your choice from the Iris dataset. Color the points by species. Add appropriate labels and a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Create a scatter plot with two features\n",
    "\n",
    "# Hint: Use plt.scatter() or sns.scatterplot()\n",
    "# Remember to add labels, title, and legend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Understanding the sklearn API\n",
    "\n",
    "Fill in the blanks in the code below to complete the scikit-learn workflow pattern:\n",
    "\n",
    "```python\n",
    "# 1. Import\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 2. Instantiate\n",
    "model = _____(n_neighbors=5)\n",
    "\n",
    "# 3. Fit\n",
    "model._____(X_train, y_train)\n",
    "\n",
    "# 4. Predict\n",
    "predictions = model._____(X_test)\n",
    "\n",
    "# 5. Evaluate\n",
    "accuracy = model._____(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the code and run it\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Your code here - fill in the blanks\n",
    "# model = \n",
    "# model.\n",
    "# predictions = \n",
    "# accuracy = \n",
    "\n",
    "# print(f\"Model accuracy: {accuracy:.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've completed Module 00. Here's what you learned:\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Machine Learning Fundamentals**:\n",
    "   - ML learns patterns from data instead of following explicit rules\n",
    "   - Three main types: Supervised, Unsupervised, and Reinforcement Learning\n",
    "   - ML workflow: Problem → Data → Explore → Prepare → Model → Evaluate → Deploy\n",
    "\n",
    "2. **scikit-learn Library**:\n",
    "   - Consistent API pattern across all algorithms\n",
    "   - Steps: Import → Instantiate → Fit → Predict → Evaluate\n",
    "   - Rich ecosystem with built-in datasets and evaluation tools\n",
    "\n",
    "3. **Data Exploration**:\n",
    "   - Always explore your data before modeling\n",
    "   - Understand feature distributions and relationships\n",
    "   - Check for class balance in classification problems\n",
    "\n",
    "4. **Features and Targets**:\n",
    "   - Features (X): Input variables for predictions\n",
    "   - Target (y): Output variable to predict\n",
    "   - Proper separation is crucial for model building\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 01: Supervised vs Unsupervised Learning**, you'll learn:\n",
    "- Deep dive into different learning paradigms\n",
    "- When to use supervised vs unsupervised approaches\n",
    "- Real-world examples of each type\n",
    "- How to choose the right approach for your problem\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)\n",
    "- [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course)\n",
    "- [Kaggle Learn - Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
