{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 03: Linear Regression\n",
    "\n",
    "**Difficulty**: ⭐ Beginner  \n",
    "**Estimated Time**: 60 minutes  \n",
    "**Prerequisites**: \n",
    "- [Module 00: Introduction to ML and scikit-learn](00_introduction_to_ml_and_sklearn.ipynb)\n",
    "- [Module 01: Supervised vs Unsupervised Learning](01_supervised_vs_unsupervised_learning.ipynb)\n",
    "- [Module 02: Data Preparation and Train/Test Split](02_data_preparation_train_test_split.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand the mathematical concept behind linear regression\n",
    "2. Build simple linear regression models (one feature)\n",
    "3. Build multiple linear regression models (many features)\n",
    "4. Interpret coefficients and intercepts\n",
    "5. Evaluate regression models using R², MSE, and RMSE\n",
    "6. Make predictions on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Linear Regression?\n",
    "\n",
    "**Linear Regression** is one of the simplest and most widely used machine learning algorithms. It models the relationship between features and a target variable using a straight line (or hyperplane in multiple dimensions).\n",
    "\n",
    "### The Big Idea\n",
    "Find the \"best fit\" line through your data points that minimizes prediction errors.\n",
    "\n",
    "### Real-World Examples\n",
    "- Predicting house prices based on size\n",
    "- Estimating sales based on advertising spend\n",
    "- Forecasting temperature based on historical data\n",
    "- Predicting salary based on years of experience\n",
    "\n",
    "### The Mathematical Formula\n",
    "\n",
    "**Simple Linear Regression** (one feature):\n",
    "```\n",
    "y = mx + b\n",
    "or\n",
    "y = β₀ + β₁x\n",
    "```\n",
    "\n",
    "**Multiple Linear Regression** (many features):\n",
    "```\n",
    "y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ\n",
    "```\n",
    "\n",
    "Where:\n",
    "- **y** = predicted value (target)\n",
    "- **x** = feature value(s)\n",
    "- **β₀** (beta zero) = intercept (where line crosses y-axis)\n",
    "- **β₁, β₂, ...** = coefficients (slopes) showing feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Visualization settings\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple Linear Regression (One Feature)\n",
    "\n",
    "Let's start with the simplest case: predicting house value using just one feature (median income).\n",
    "\n",
    "**Goal**: Find the best line: `house_value = β₀ + β₁ × median_income`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load California housing dataset\n",
    "housing_df = pd.read_csv('data/sample/california_housing.csv')\n",
    "\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Shape: {housing_df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simple linear regression, use only ONE feature\n",
    "X_simple = housing_df[['MedInc']]  # Double brackets to keep as DataFrame\n",
    "y = housing_df['median_house_value']\n",
    "\n",
    "print(f\"Feature (X): {X_simple.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"\\nFeature name: {X_simple.columns[0]}\")\n",
    "print(f\"Target name: median_house_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_simple, y, alpha=0.3, s=20)\n",
    "plt.xlabel('Median Income (in $10,000s)', fontsize=12)\n",
    "plt.ylabel('Median House Value ($)', fontsize=12)\n",
    "plt.title('House Value vs Median Income\\n(Looking for a linear relationship)', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: There's a clear positive linear trend!\")\n",
    "print(\"As income increases, house values tend to increase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple linear regression model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_simple, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data Split:\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "\n",
    "# Create and train the model\n",
    "simple_model = LinearRegression()\n",
    "simple_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✓ Model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the learned parameters\n",
    "intercept = simple_model.intercept_\n",
    "coefficient = simple_model.coef_[0]\n",
    "\n",
    "print(\"Learned Model Parameters:\")\n",
    "print(f\"Intercept (β₀): ${intercept:,.2f}\")\n",
    "print(f\"Coefficient (β₁): ${coefficient:,.2f}\")\n",
    "print(f\"\\nModel Equation:\")\n",
    "print(f\"house_value = {intercept:,.2f} + {coefficient:,.2f} × median_income\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"- Base house value (when income=0): ${intercept:,.2f}\")\n",
    "print(f\"- For each $10,000 increase in median income,\")\n",
    "print(f\"  house value increases by ${coefficient:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot of actual data\n",
    "plt.scatter(X_test, y_test, alpha=0.3, s=20, label='Actual Data')\n",
    "\n",
    "# Regression line\n",
    "# Create points for the line\n",
    "X_line = np.linspace(X_simple.min(), X_simple.max(), 100).reshape(-1, 1)\n",
    "y_line = simple_model.predict(X_line)\n",
    "plt.plot(X_line, y_line, 'r-', linewidth=3, label='Regression Line')\n",
    "\n",
    "plt.xlabel('Median Income (in $10,000s)', fontsize=12)\n",
    "plt.ylabel('Median House Value ($)', fontsize=12)\n",
    "plt.title('Simple Linear Regression: Best Fit Line', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The red line represents the model's predictions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = simple_model.predict(X_test)\n",
    "\n",
    "# Show some example predictions\n",
    "results_df = pd.DataFrame({\n",
    "    'Median_Income': X_test['MedInc'].values[:5],\n",
    "    'Actual_Value': y_test.values[:5],\n",
    "    'Predicted_Value': y_pred[:5],\n",
    "    'Error': y_test.values[:5] - y_pred[:5]\n",
    "})\n",
    "\n",
    "print(\"Example Predictions:\")\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"\\nNote: Error = Actual - Predicted\")\n",
    "print(\"Positive error = Model underestimated\")\n",
    "print(\"Negative error = Model overestimated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluating Regression Models\n",
    "\n",
    "How do we know if our model is good? We use evaluation metrics:\n",
    "\n",
    "### 1. Mean Squared Error (MSE)\n",
    "- Average of squared errors\n",
    "- Formula: MSE = (1/n) × Σ(actual - predicted)²\n",
    "- **Lower is better** (0 is perfect)\n",
    "- Units are squared (hard to interpret)\n",
    "\n",
    "### 2. Root Mean Squared Error (RMSE)\n",
    "- Square root of MSE\n",
    "- Formula: RMSE = √MSE\n",
    "- **Lower is better** (0 is perfect)\n",
    "- Same units as target (easier to interpret)\n",
    "- \"On average, predictions are off by X units\"\n",
    "\n",
    "### 3. R² Score (Coefficient of Determination)\n",
    "- Proportion of variance explained by the model\n",
    "- Range: 0 to 1 (can be negative for bad models)\n",
    "- **Higher is better** (1 is perfect)\n",
    "- Interpretation: \"Model explains X% of the variance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Metrics on test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Simple Linear Regression Performance:\")\n",
    "print(f\"\\nMean Squared Error (MSE): ${mse:,.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): ${rmse:,.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
    "print(f\"R² Score: {r2:.3f}\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"- On average, predictions are off by ${rmse:,.2f}\")\n",
    "print(f\"- Model explains {r2*100:.1f}% of the variance in house values\")\n",
    "print(f\"- Using only ONE feature (median income), we achieve decent performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multiple Linear Regression (Many Features)\n",
    "\n",
    "Real-world problems usually involve multiple features. Let's use ALL features to improve our predictions.\n",
    "\n",
    "**Hypothesis**: Using more relevant features should improve accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data with ALL features\n",
    "X_multiple = housing_df.drop('median_house_value', axis=1)\n",
    "y = housing_df['median_house_value']\n",
    "\n",
    "print(\"Multiple Linear Regression Setup:\")\n",
    "print(f\"Number of features: {X_multiple.shape[1]}\")\n",
    "print(f\"Features: {list(X_multiple.columns)}\")\n",
    "print(f\"Number of samples: {len(X_multiple)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "    X_multiple, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "multi_model = LinearRegression()\n",
    "multi_model.fit(X_train_m, y_train_m)\n",
    "\n",
    "print(\"✓ Multiple linear regression model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine coefficients for each feature\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': X_multiple.columns,\n",
    "    'Coefficient': multi_model.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"Feature Importance (by coefficient magnitude):\")\n",
    "print(coefficients_df.to_string(index=False))\n",
    "print(f\"\\nIntercept: ${multi_model.intercept_:,.2f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"- Positive coefficient = feature increases house value\")\n",
    "print(f\"- Negative coefficient = feature decreases house value\")\n",
    "print(f\"- Larger magnitude = stronger effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green' if c > 0 else 'red' for c in coefficients_df['Coefficient']]\n",
    "plt.barh(coefficients_df['Feature'], coefficients_df['Coefficient'], color=colors, alpha=0.7)\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Feature Coefficients in Multiple Linear Regression\\n(Green=Positive, Red=Negative)', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insights:\")\n",
    "print(f\"- MedInc (median income) has the strongest positive effect\")\n",
    "print(f\"- Latitude has a strong negative effect (location matters!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate multiple regression model\n",
    "y_pred_m = multi_model.predict(X_test_m)\n",
    "\n",
    "mse_m = mean_squared_error(y_test_m, y_pred_m)\n",
    "rmse_m = np.sqrt(mse_m)\n",
    "mae_m = mean_absolute_error(y_test_m, y_pred_m)\n",
    "r2_m = r2_score(y_test_m, y_pred_m)\n",
    "\n",
    "print(\"Multiple Linear Regression Performance:\")\n",
    "print(f\"\\nMean Squared Error (MSE): ${mse_m:,.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): ${rmse_m:,.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): ${mae_m:,.2f}\")\n",
    "print(f\"R² Score: {r2_m:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare simple vs multiple regression\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['RMSE', 'R² Score', 'Number of Features'],\n",
    "    'Simple Regression': [f'${rmse:,.2f}', f'{r2:.3f}', '1'],\n",
    "    'Multiple Regression': [f'${rmse_m:,.2f}', f'{r2_m:.3f}', f'{X_multiple.shape[1]}']\n",
    "})\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "improvement_rmse = ((rmse - rmse_m) / rmse) * 100\n",
    "improvement_r2 = ((r2_m - r2) / r2) * 100\n",
    "\n",
    "print(f\"\\nImprovement:\")\n",
    "print(f\"- RMSE reduced by {improvement_rmse:.1f}%\")\n",
    "print(f\"- R² increased by {improvement_r2:.1f}%\")\n",
    "print(f\"\\n✓ Using multiple features significantly improves predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizing Predictions vs Actuals\n",
    "\n",
    "A perfect model would have all points on the diagonal line (predicted = actual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction comparison plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Simple regression\n",
    "axes[0].scatter(y_test, y_pred, alpha=0.3, s=20)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "            'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual House Value ($)', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted House Value ($)', fontsize=12)\n",
    "axes[0].set_title(f'Simple Regression\\nR² = {r2:.3f}', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Multiple regression\n",
    "axes[1].scatter(y_test_m, y_pred_m, alpha=0.3, s=20)\n",
    "axes[1].plot([y_test_m.min(), y_test_m.max()], [y_test_m.min(), y_test_m.max()], \n",
    "            'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[1].set_xlabel('Actual House Value ($)', fontsize=12)\n",
    "axes[1].set_ylabel('Predicted House Value ($)', fontsize=12)\n",
    "axes[1].set_title(f'Multiple Regression\\nR² = {r2_m:.3f}', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insight: Points closer to the diagonal line = better predictions!\")\n",
    "print(\"Multiple regression has less scatter (tighter fit).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Making Predictions on New Data\n",
    "\n",
    "Once trained, we can use the model to predict house values for new properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new house example\n",
    "new_house = pd.DataFrame({\n",
    "    'MedInc': [5.0],\n",
    "    'HouseAge': [25.0],\n",
    "    'AveRooms': [6.0],\n",
    "    'AveBedrms': [1.2],\n",
    "    'Population': [1500.0],\n",
    "    'AveOccup': [3.0],\n",
    "    'Latitude': [37.5],\n",
    "    'Longitude': [-122.0]\n",
    "})\n",
    "\n",
    "# Make prediction\n",
    "predicted_value = multi_model.predict(new_house)[0]\n",
    "\n",
    "print(\"New House Characteristics:\")\n",
    "for col in new_house.columns:\n",
    "    print(f\"  {col}: {new_house[col].values[0]}\")\n",
    "\n",
    "print(f\"\\nPredicted House Value: ${predicted_value:,.2f}\")\n",
    "print(f\"\\nThis prediction is based on learned patterns from {len(X_train_m)} training examples!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Practice building and evaluating linear regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Simple Regression with Different Features\n",
    "\n",
    "Build a simple linear regression model using only the 'HouseAge' feature instead of 'MedInc'.\n",
    "\n",
    "Steps:\n",
    "1. Create X with only 'HouseAge' column\n",
    "2. Split data (70/30)\n",
    "3. Train a LinearRegression model\n",
    "4. Calculate and print the R² score\n",
    "5. Compare it to the R² score we got with 'MedInc' (printed above)\n",
    "6. Which feature is better for prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Interpreting Coefficients\n",
    "\n",
    "Using the multiple regression model we built (multi_model), answer these questions:\n",
    "\n",
    "1. What is the coefficient for 'AveRooms'?\n",
    "2. If a house has 1 additional room on average, by how much does the predicted value change?\n",
    "3. Which feature has the largest positive impact on house value?\n",
    "4. Which feature has the largest negative impact?\n",
    "\n",
    "Print the answers using the coefficients from multi_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Regression on Diabetes Dataset\n",
    "\n",
    "Build a multiple linear regression model to predict disease progression.\n",
    "\n",
    "Steps:\n",
    "1. Load the diabetes dataset from 'data/sample/diabetes.csv'\n",
    "2. Separate features (all columns except 'progression') and target ('progression')\n",
    "3. Split data (70/30)\n",
    "4. Train a LinearRegression model\n",
    "5. Calculate and print RMSE and R² score\n",
    "6. Create a scatter plot of actual vs predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Residual Analysis\n",
    "\n",
    "Residuals are the differences between actual and predicted values: `residual = actual - predicted`\n",
    "\n",
    "Using the multiple regression model (multi_model) and test predictions:\n",
    "1. Calculate residuals\n",
    "2. Create a histogram of residuals\n",
    "3. Calculate mean and standard deviation of residuals\n",
    "4. What does the distribution of residuals tell you about the model?\n",
    "\n",
    "Hint: Ideally, residuals should be normally distributed around zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've mastered linear regression, one of the most fundamental ML algorithms.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Linear Regression**:\n",
    "   - Models relationship between features and target using a linear equation\n",
    "   - Simple: y = β₀ + β₁x (one feature)\n",
    "   - Multiple: y = β₀ + β₁x₁ + β₂x₂ + ... (many features)\n",
    "   - Goal: Find coefficients that minimize prediction errors\n",
    "\n",
    "2. **Model Parameters**:\n",
    "   - **Intercept (β₀)**: Base value when all features are zero\n",
    "   - **Coefficients (β₁, β₂, ...)**: How much each feature affects the target\n",
    "   - Positive coefficient = feature increases target\n",
    "   - Negative coefficient = feature decreases target\n",
    "\n",
    "3. **Evaluation Metrics**:\n",
    "   - **MSE**: Mean Squared Error (lower is better)\n",
    "   - **RMSE**: Root MSE, same units as target (lower is better)\n",
    "   - **R²**: Proportion of variance explained (0-1, higher is better)\n",
    "   - \"Model explains X% of variance\" interpretation\n",
    "\n",
    "4. **Simple vs Multiple Regression**:\n",
    "   - Simple uses one feature (easier to visualize)\n",
    "   - Multiple uses many features (usually better performance)\n",
    "   - More relevant features generally improve predictions\n",
    "\n",
    "5. **Best Practices**:\n",
    "   - Always split data before training\n",
    "   - Visualize relationships before modeling\n",
    "   - Examine coefficients to understand feature importance\n",
    "   - Compare predicted vs actual values\n",
    "   - Use multiple metrics for comprehensive evaluation\n",
    "\n",
    "### When to Use Linear Regression\n",
    "\n",
    "**Good for:**\n",
    "- Continuous target variables\n",
    "- Linear relationships between features and target\n",
    "- Need for interpretable models\n",
    "- Quick baseline models\n",
    "\n",
    "**Not good for:**\n",
    "- Non-linear relationships (use polynomial features or other algorithms)\n",
    "- Classification problems (use logistic regression instead)\n",
    "- Complex interactions between features (try tree-based methods)\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 04: Logistic Regression**, you'll learn:\n",
    "- How to adapt regression for classification problems\n",
    "- Understanding the sigmoid function and decision boundaries\n",
    "- Binary and multiclass classification\n",
    "- Probability predictions and class prediction\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Linear Regression - StatQuest](https://www.youtube.com/watch?v=nk2CQITm_eo)\n",
    "- [scikit-learn Linear Models](https://scikit-learn.org/stable/modules/linear_model.html)\n",
    "- [Understanding R-squared](https://blog.minitab.com/en/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
