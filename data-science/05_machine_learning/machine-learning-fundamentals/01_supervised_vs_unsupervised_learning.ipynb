{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 01: Supervised vs Unsupervised Learning\n",
    "\n",
    "**Difficulty**: ⭐ Beginner  \n",
    "**Estimated Time**: 50 minutes  \n",
    "**Prerequisites**: \n",
    "- [Module 00: Introduction to ML and scikit-learn](00_introduction_to_ml_and_sklearn.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Distinguish between supervised and unsupervised learning\n",
    "2. Identify when to use classification vs regression\n",
    "3. Understand common supervised learning algorithms and their use cases\n",
    "4. Understand common unsupervised learning algorithms and their use cases\n",
    "5. Apply both paradigms to real datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Two Main Learning Paradigms\n",
    "\n",
    "Machine learning algorithms can be grouped into two main categories based on how they learn:\n",
    "\n",
    "### Supervised Learning\n",
    "**Definition**: Learning from labeled data where we know the correct answers.\n",
    "\n",
    "**Analogy**: Like learning with a teacher who provides correct answers:\n",
    "- You study example problems with solutions\n",
    "- You learn patterns from these examples\n",
    "- You apply learned patterns to solve new problems\n",
    "\n",
    "**Key Characteristic**: Training data includes both features (X) and labels (y)\n",
    "\n",
    "### Unsupervised Learning\n",
    "**Definition**: Learning from unlabeled data where we don't know the answers.\n",
    "\n",
    "**Analogy**: Like exploring a subject on your own:\n",
    "- No teacher provides correct answers\n",
    "- You find patterns and structure in the data yourself\n",
    "- You group similar things together based on characteristics\n",
    "\n",
    "**Key Characteristic**: Training data includes only features (X), no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Visualization settings\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supervised Learning: Classification vs Regression\n",
    "\n",
    "Supervised learning has two main sub-types:\n",
    "\n",
    "### Classification\n",
    "**Task**: Predict discrete categories or classes\n",
    "\n",
    "**Examples**:\n",
    "- Email: spam or not spam (binary)\n",
    "- Iris flower: setosa, versicolor, or virginica (multiclass)\n",
    "- Image: contains cat, dog, bird, or none (multiclass)\n",
    "- Medical diagnosis: disease present or absent (binary)\n",
    "\n",
    "**Output**: Category label (discrete values)\n",
    "\n",
    "### Regression\n",
    "**Task**: Predict continuous numerical values\n",
    "\n",
    "**Examples**:\n",
    "- House price: $250,000\n",
    "- Temperature tomorrow: 23.5°C\n",
    "- Stock price: $142.35\n",
    "- Age of a person: 34 years\n",
    "\n",
    "**Output**: Numerical value (continuous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification Example: Iris Species\n",
    "\n",
    "Let's demonstrate classification with the Iris dataset. We'll predict the species based on flower measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris_df = pd.read_csv('data/sample/iris.csv')\n",
    "\n",
    "# Prepare features and target\n",
    "feature_cols = ['sepal length (cm)', 'sepal width (cm)', \n",
    "                'petal length (cm)', 'petal width (cm)']\n",
    "X = iris_df[feature_cols]\n",
    "y = iris_df['species_name']\n",
    "\n",
    "print(\"Classification Problem Setup:\")\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"\\nClasses to predict: {y.unique()}\")\n",
    "print(f\"Number of classes: {y.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the classification problem\n",
    "# We'll use two features for easy visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "for species in iris_df['species_name'].unique():\n",
    "    subset = iris_df[iris_df['species_name'] == species]\n",
    "    plt.scatter(subset['petal length (cm)'], subset['petal width (cm)'], \n",
    "               label=species, s=100, alpha=0.6, edgecolors='black')\n",
    "\n",
    "plt.xlabel('Petal Length (cm)', fontsize=12)\n",
    "plt.ylabel('Petal Width (cm)', fontsize=12)\n",
    "plt.title('Classification: Predicting Iris Species\\n(Each color represents a different class)', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.legend(title='Species', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: The classes are well-separated based on petal measurements.\")\n",
    "print(\"This suggests classification should work well!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple classification model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train classifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Classification Results:\")\n",
    "print(f\"Accuracy: {accuracy:.1%}\\n\")\n",
    "print(\"Detailed Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regression Example: Diabetes Progression\n",
    "\n",
    "Now let's demonstrate regression by predicting disease progression (a continuous value) based on medical measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Diabetes dataset\n",
    "diabetes_df = pd.read_csv('data/sample/diabetes.csv')\n",
    "\n",
    "# Prepare features and target\n",
    "feature_cols = [col for col in diabetes_df.columns if col != 'progression']\n",
    "X_reg = diabetes_df[feature_cols]\n",
    "y_reg = diabetes_df['progression']\n",
    "\n",
    "print(\"Regression Problem Setup:\")\n",
    "print(f\"Features (X): {X_reg.shape}\")\n",
    "print(f\"Target (y): {y_reg.shape}\")\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"  Min: {y_reg.min():.2f}\")\n",
    "print(f\"  Max: {y_reg.max():.2f}\")\n",
    "print(f\"  Mean: {y_reg.mean():.2f}\")\n",
    "print(f\"  Std: {y_reg.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the regression problem\n",
    "# Show target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(y_reg, bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(y_reg.mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "axes[0].set_xlabel('Disease Progression', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Target Distribution (Continuous Values)', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot with one feature\n",
    "axes[1].scatter(X_reg['bmi'], y_reg, alpha=0.5, s=50, edgecolors='black')\n",
    "axes[1].set_xlabel('BMI (Body Mass Index)', fontsize=12)\n",
    "axes[1].set_ylabel('Disease Progression', fontsize=12)\n",
    "axes[1].set_title('Regression: Predicting Continuous Values', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: The target is a continuous numerical value, not discrete classes.\")\n",
    "print(\"This is a regression problem!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split data\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train regressor\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_reg = regressor.predict(X_test_reg)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"Regression Results:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R² Score: {r2:.3f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"- On average, predictions are off by {rmse:.2f} units\")\n",
    "print(f\"- Model explains {r2*100:.1f}% of the variance in disease progression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Unsupervised Learning: Clustering\n",
    "\n",
    "Unlike supervised learning, unsupervised learning works with unlabeled data. A common task is **clustering** - grouping similar data points together.\n",
    "\n",
    "**Key Difference**: We don't tell the algorithm what groups exist; it finds them on its own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clustering dataset\n",
    "blobs_df = pd.read_csv('data/sample/blobs_clustering.csv')\n",
    "\n",
    "# For unsupervised learning, we use ONLY features (no labels)\n",
    "X_cluster = blobs_df[['feature_1', 'feature_2']]\n",
    "\n",
    "print(\"Unsupervised Learning Setup:\")\n",
    "print(f\"Features (X): {X_cluster.shape}\")\n",
    "print(\"\\nNotice: No target variable (y) is used!\")\n",
    "print(\"The algorithm will find patterns on its own.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the unlabeled data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_cluster['feature_1'], X_cluster['feature_2'], \n",
    "           s=100, alpha=0.6, edgecolors='black', color='gray')\n",
    "plt.xlabel('Feature 1', fontsize=12)\n",
    "plt.ylabel('Feature 2', fontsize=12)\n",
    "plt.title('Unsupervised Learning: Data Without Labels\\n(Can you see natural groups?)', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nQuestion: Can you visually identify distinct groups in the data?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-Means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create clustering model\n",
    "# We specify 4 clusters (in real scenarios, we'd need to determine this)\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "\n",
    "# Fit and predict clusters\n",
    "# Note: In unsupervised learning, we don't split into train/test\n",
    "cluster_labels = kmeans.fit_predict(X_cluster)\n",
    "\n",
    "# Add predictions to dataframe\n",
    "blobs_df['predicted_cluster'] = cluster_labels\n",
    "\n",
    "print(f\"Clustering complete!\")\n",
    "print(f\"Found {len(np.unique(cluster_labels))} clusters\")\n",
    "print(f\"\\nCluster sizes:\")\n",
    "print(blobs_df['predicted_cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clustering results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Original (unlabeled) data\n",
    "axes[0].scatter(X_cluster['feature_1'], X_cluster['feature_2'], \n",
    "               s=100, alpha=0.6, edgecolors='black', color='gray')\n",
    "axes[0].set_xlabel('Feature 1', fontsize=12)\n",
    "axes[0].set_ylabel('Feature 2', fontsize=12)\n",
    "axes[0].set_title('Before: Unlabeled Data', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Clustered data\n",
    "scatter = axes[1].scatter(X_cluster['feature_1'], X_cluster['feature_2'], \n",
    "                         c=cluster_labels, cmap='viridis',\n",
    "                         s=100, alpha=0.6, edgecolors='black')\n",
    "# Plot cluster centers\n",
    "centers = kmeans.cluster_centers_\n",
    "axes[1].scatter(centers[:, 0], centers[:, 1], \n",
    "               marker='X', s=300, c='red', edgecolors='black', linewidths=2,\n",
    "               label='Cluster Centers')\n",
    "axes[1].set_xlabel('Feature 1', fontsize=12)\n",
    "axes[1].set_ylabel('Feature 2', fontsize=12)\n",
    "axes[1].set_title('After: Discovered Clusters', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.colorbar(scatter, ax=axes[1], label='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight: The algorithm found natural groupings WITHOUT being told what to look for!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparing the Paradigms\n",
    "\n",
    "| Aspect | Supervised Learning | Unsupervised Learning |\n",
    "|--------|--------------------|-----------------------|\n",
    "| **Training Data** | Labeled (X and y) | Unlabeled (only X) |\n",
    "| **Goal** | Predict labels for new data | Find hidden patterns/structure |\n",
    "| **Evaluation** | Compare predictions to true labels | Measure cluster quality, coherence |\n",
    "| **Examples** | Classification, Regression | Clustering, Dimensionality Reduction |\n",
    "| **Use Case** | Spam detection, Price prediction | Customer segmentation, Anomaly detection |\n",
    "| **Difficulty** | Easier to evaluate | Harder to validate results |\n",
    "\n",
    "### When to Use Each?\n",
    "\n",
    "**Use Supervised Learning when:**\n",
    "- You have labeled data (know the correct answers)\n",
    "- You want to predict specific outcomes\n",
    "- You can clearly define what you're looking for\n",
    "- Examples: Medical diagnosis, fraud detection, price prediction\n",
    "\n",
    "**Use Unsupervised Learning when:**\n",
    "- You don't have labels (or labeling is too expensive)\n",
    "- You want to explore and understand your data\n",
    "- You're looking for hidden patterns\n",
    "- Examples: Market segmentation, recommendation systems, data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Practice identifying and working with different learning paradigms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Identify the Problem Type\n",
    "\n",
    "For each scenario below, identify:\n",
    "1. Is it supervised or unsupervised?\n",
    "2. If supervised, is it classification or regression?\n",
    "\n",
    "Write your answers in the code cell:\n",
    "\n",
    "**Scenarios:**\n",
    "1. Predicting whether a loan application will be approved (historical data available)\n",
    "2. Grouping news articles by topic without predefined categories\n",
    "3. Estimating the number of sales for next month\n",
    "4. Identifying different types of flowers from petal measurements (labeled dataset)\n",
    "5. Finding groups of similar customers based on purchasing behavior\n",
    "6. Predicting student exam scores based on study hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answers:\n",
    "# 1. \n",
    "# 2. \n",
    "# 3. \n",
    "# 4. \n",
    "# 5. \n",
    "# 6. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Classification on Wine Dataset\n",
    "\n",
    "Load the wine dataset and build a classification model to predict wine types.\n",
    "\n",
    "Steps:\n",
    "1. Load data from `data/sample/wine.csv`\n",
    "2. Separate features and target (target column name is 'target')\n",
    "3. Split into train/test sets (70/30 split)\n",
    "4. Train a KNeighborsClassifier with n_neighbors=7\n",
    "5. Calculate and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Regression on Housing Data\n",
    "\n",
    "Build a regression model to predict house values using the California housing dataset.\n",
    "\n",
    "Steps:\n",
    "1. Load data from `data/sample/california_housing.csv`\n",
    "2. Separate features and target (target is 'median_house_value')\n",
    "3. Split into train/test sets (70/30 split)\n",
    "4. Train a LinearRegression model\n",
    "5. Calculate and print the R² score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Clustering Analysis\n",
    "\n",
    "Apply K-Means clustering to the Iris dataset (WITHOUT using the species labels).\n",
    "\n",
    "Steps:\n",
    "1. Load the Iris dataset\n",
    "2. Use only the feature columns (ignore species)\n",
    "3. Apply KMeans with n_clusters=3\n",
    "4. Create a scatter plot of petal length vs petal width, colored by predicted clusters\n",
    "5. Compare: How do the discovered clusters relate to the actual species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've mastered the fundamental learning paradigms in machine learning.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Supervised Learning**:\n",
    "   - Learns from labeled data (features + correct answers)\n",
    "   - Two types: Classification (categories) and Regression (continuous values)\n",
    "   - Used when you want to predict specific outcomes\n",
    "   - Evaluation: Compare predictions to true labels\n",
    "\n",
    "2. **Classification**:\n",
    "   - Predicts discrete categories/classes\n",
    "   - Examples: Iris species, spam detection, disease diagnosis\n",
    "   - Metrics: Accuracy, precision, recall, F1-score\n",
    "\n",
    "3. **Regression**:\n",
    "   - Predicts continuous numerical values\n",
    "   - Examples: House prices, temperature, disease progression\n",
    "   - Metrics: RMSE, MAE, R² score\n",
    "\n",
    "4. **Unsupervised Learning**:\n",
    "   - Learns from unlabeled data (only features)\n",
    "   - Discovers hidden patterns and structure\n",
    "   - Examples: Clustering, dimensionality reduction\n",
    "   - Used for exploration and pattern discovery\n",
    "\n",
    "5. **Choosing the Right Approach**:\n",
    "   - Have labels + want predictions → Supervised\n",
    "   - No labels + explore patterns → Unsupervised\n",
    "   - Predict categories → Classification\n",
    "   - Predict numbers → Regression\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 02: Data Preparation and Train/Test Split**, you'll learn:\n",
    "- How to properly prepare data for machine learning\n",
    "- Why and how to split data into training and testing sets\n",
    "- Common data preprocessing techniques\n",
    "- Avoiding data leakage and other pitfalls\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Supervised vs Unsupervised Learning - Google ML Course](https://developers.google.com/machine-learning/crash-course/framing/ml-terminology)\n",
    "- [Classification vs Regression - StatQuest](https://www.youtube.com/watch?v=i_LwzRVP7bg)\n",
    "- [K-Means Clustering Explained](https://www.youtube.com/watch?v=4b5d3muPQmA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
