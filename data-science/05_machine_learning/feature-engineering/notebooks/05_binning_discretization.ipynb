{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 05: Binning and Discretization\n",
    "\n",
    "**Difficulty**: ⭐⭐ Intermediate  \n",
    "**Estimated Time**: 50 minutes  \n",
    "**Prerequisites**: [Module 04: Polynomial Features and Interactions](04_polynomial_features_interactions.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Understand when and why to discretize continuous features\n",
    "2. Apply equal-width binning to create uniform intervals\n",
    "3. Use equal-frequency binning for balanced distribution\n",
    "4. Create custom bins based on domain knowledge\n",
    "5. Use sklearn's KBinsDiscretizer for automatic binning\n",
    "6. Recognize when discretization helps vs hurts model performance\n",
    "7. Choose appropriate number of bins for your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Binning/Discretization?\n",
    "\n",
    "**Binning** (also called **discretization**) converts continuous features into categorical bins.\n",
    "\n",
    "### Example: Age\n",
    "\n",
    "**Continuous**: 23, 45, 67, 18, 52, 71...\n",
    "\n",
    "**Binned**:\n",
    "```\n",
    "18-30: Young Adult\n",
    "31-50: Middle Aged\n",
    "51-70: Senior\n",
    "70+:   Elderly\n",
    "```\n",
    "\n",
    "### Why Discretize?\n",
    "\n",
    "#### ✅ Benefits:\n",
    "\n",
    "1. **Capture non-linear patterns**: Age 25 vs 27 might not matter, but 25 vs 65 does\n",
    "2. **Handle outliers**: Extreme values get grouped with similar values\n",
    "3. **Interpretability**: \"Senior citizens\" is clearer than \"age > 60\"\n",
    "4. **Match domain knowledge**: Income brackets, age groups already exist\n",
    "5. **Reduce noise**: Small variations within bins are ignored\n",
    "6. **Help linear models**: Can approximate non-linear relationships\n",
    "\n",
    "#### ❌ Drawbacks:\n",
    "\n",
    "1. **Loss of information**: 25 and 29 treated identically in \"20-30\" bin\n",
    "2. **Arbitrary boundaries**: Is 30 really different from 31?\n",
    "3. **Fewer features for learning**: Less granular data\n",
    "4. **May not help tree models**: Trees already split optimally\n",
    "\n",
    "### When to Use Binning?\n",
    "\n",
    "- ✅ **Linear models** with non-linear relationships\n",
    "- ✅ **Domain knowledge** suggests natural categories\n",
    "- ✅ **Outliers** are problematic\n",
    "- ✅ **Interpretability** is important\n",
    "- ❌ **Tree-based models** (usually not needed)\n",
    "- ❌ **Small datasets** (losing information is costly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Binning methods\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Models for comparison\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Sample Dataset\n",
    "\n",
    "Let's create a customer dataset for credit card approval prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Create customer data\n",
    "customer_data = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 80, n_samples),\n",
    "    'income': np.random.gamma(5, 10000, n_samples).clip(15000, 200000),\n",
    "    'credit_score': np.random.randint(400, 850, n_samples),\n",
    "    'years_employed': np.random.exponential(5, n_samples).clip(0, 40),\n",
    "    'debt': np.random.gamma(3, 5000, n_samples).clip(0, 100000)\n",
    "})\n",
    "\n",
    "# Create target: credit card approval\n",
    "# Non-linear relationship: middle-aged with stable income most likely to be approved\n",
    "approval_prob = (\n",
    "    # Age: peak approval at 30-50\n",
    "    0.3 * np.exp(-((customer_data['age'] - 40)**2) / 500) +\n",
    "    # Income: higher is better\n",
    "    0.3 * (customer_data['income'] - customer_data['income'].min()) / \n",
    "          (customer_data['income'].max() - customer_data['income'].min()) +\n",
    "    # Credit score: higher is better\n",
    "    0.2 * (customer_data['credit_score'] - 400) / 450 +\n",
    "    # Employment: more years is better\n",
    "    0.1 * (customer_data['years_employed'] / 40) +\n",
    "    # Debt: lower is better\n",
    "    0.1 * (1 - customer_data['debt'] / customer_data['debt'].max()) +\n",
    "    np.random.normal(0, 0.1, n_samples)\n",
    ")\n",
    "\n",
    "customer_data['approved'] = (approval_prob > 0.5).astype(int)\n",
    "\n",
    "print(f\"Created dataset with {len(customer_data)} customers\")\n",
    "print(f\"Approval rate: {customer_data['approved'].mean():.1%}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize continuous features\n",
    "features = ['age', 'income', 'credit_score', 'years_employed', 'debt']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    axes[idx].hist(customer_data[feature], bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].set_title(f'Distribution of {feature}')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].axis('off')  # Hide last subplot\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"These continuous features will be binned into categories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Method 1: Equal-Width Binning\n",
    "\n",
    "**Strategy**: Divide the range into bins of equal width\n",
    "\n",
    "**Formula**: \n",
    "```\n",
    "bin_width = (max - min) / n_bins\n",
    "```\n",
    "\n",
    "**Example**: Age 18-80 with 4 bins\n",
    "- Bin 1: 18-33.5\n",
    "- Bin 2: 33.5-49\n",
    "- Bin 3: 49-64.5\n",
    "- Bin 4: 64.5-80\n",
    "\n",
    "**Pros**: \n",
    "- Simple and intuitive\n",
    "- Equal-sized intervals\n",
    "\n",
    "**Cons**: \n",
    "- May create imbalanced bins (some bins have very few samples)\n",
    "- Sensitive to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal-width binning for age using pandas.cut()\n",
    "age_bins_uniform = pd.cut(\n",
    "    customer_data['age'], \n",
    "    bins=4,  # 4 equal-width bins\n",
    "    labels=['Young', 'Adult', 'Middle-Aged', 'Senior']\n",
    ")\n",
    "\n",
    "print(\"Equal-Width Binning for Age:\\n\")\n",
    "print(\"Value counts:\")\n",
    "print(age_bins_uniform.value_counts().sort_index())\n",
    "\n",
    "print(\"\\nBin intervals:\")\n",
    "print(pd.cut(customer_data['age'], bins=4).value_counts().sort_index())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Original distribution\n",
    "axes[0].hist(customer_data['age'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Age')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Original Age Distribution')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# After binning\n",
    "age_bins_uniform.value_counts().sort_index().plot(kind='bar', ax=axes[1], edgecolor='black')\n",
    "axes[1].set_xlabel('Age Group')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Equal-Width Binning (4 bins)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNotice: Bins have roughly similar counts because age is uniformly distributed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal-width binning for income (skewed distribution)\n",
    "income_bins_uniform = pd.cut(\n",
    "    customer_data['income'],\n",
    "    bins=5,\n",
    "    labels=['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    ")\n",
    "\n",
    "print(\"Equal-Width Binning for Income:\\n\")\n",
    "print(\"Value counts:\")\n",
    "print(income_bins_uniform.value_counts().sort_index())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(customer_data['income'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Income ($)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Original Income Distribution\\n(Right-skewed)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "income_bins_uniform.value_counts().sort_index().plot(kind='bar', ax=axes[1], edgecolor='black')\n",
    "axes[1].set_xlabel('Income Group')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Equal-Width Binning (5 bins)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n⚠️  Problem: Most data in first few bins, last bins nearly empty!\")\n",
    "print(\"This happens with skewed distributions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Method 2: Equal-Frequency Binning (Quantile-Based)\n",
    "\n",
    "**Strategy**: Create bins with approximately equal number of samples\n",
    "\n",
    "**How**: Use quantiles/percentiles as bin edges\n",
    "\n",
    "**Example**: 1000 samples, 4 bins → each bin has ~250 samples\n",
    "\n",
    "**Pros**: \n",
    "- Balanced bins\n",
    "- Works well with skewed data\n",
    "- Each bin has enough samples\n",
    "\n",
    "**Cons**: \n",
    "- Bin widths vary (can be counterintuitive)\n",
    "- May group very different values together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal-frequency binning for income using pandas.qcut()\n",
    "income_bins_quantile = pd.qcut(\n",
    "    customer_data['income'],\n",
    "    q=5,  # 5 bins with equal frequency\n",
    "    labels=['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    ")\n",
    "\n",
    "print(\"Equal-Frequency Binning for Income:\\n\")\n",
    "print(\"Value counts:\")\n",
    "print(income_bins_quantile.value_counts().sort_index())\n",
    "\n",
    "print(\"\\nBin intervals:\")\n",
    "print(pd.qcut(customer_data['income'], q=5).value_counts().sort_index())\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Equal-width\n",
    "income_bins_uniform.value_counts().sort_index().plot(kind='bar', ax=axes[0], edgecolor='black', color='coral')\n",
    "axes[0].set_xlabel('Income Group')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Equal-Width Binning\\n(Imbalanced)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Equal-frequency\n",
    "income_bins_quantile.value_counts().sort_index().plot(kind='bar', ax=axes[1], edgecolor='black', color='lightgreen')\n",
    "axes[1].set_xlabel('Income Group')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Equal-Frequency Binning\\n(Balanced)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Equal-frequency creates balanced bins even with skewed data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Method 3: Custom Binning (Domain Knowledge)\n",
    "\n",
    "**Strategy**: Use domain knowledge to create meaningful bins\n",
    "\n",
    "**Examples**:\n",
    "- **Age**: 0-17 (minor), 18-64 (adult), 65+ (senior)\n",
    "- **Income**: Based on tax brackets\n",
    "- **Credit score**: Poor (<580), Fair (580-669), Good (670-739), Very Good (740-799), Excellent (800+)\n",
    "\n",
    "**Pros**: \n",
    "- Most interpretable\n",
    "- Aligned with business logic\n",
    "- Can leverage expert knowledge\n",
    "\n",
    "**Cons**: \n",
    "- Requires domain expertise\n",
    "- May not be optimal for model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom binning for credit score based on industry standards\n",
    "credit_score_bins = pd.cut(\n",
    "    customer_data['credit_score'],\n",
    "    bins=[400, 580, 670, 740, 800, 850],\n",
    "    labels=['Poor', 'Fair', 'Good', 'Very Good', 'Excellent'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "print(\"Custom Credit Score Binning (Industry Standard):\\n\")\n",
    "print(\"Value counts:\")\n",
    "print(credit_score_bins.value_counts().sort_index())\n",
    "\n",
    "# Show relationship to approval\n",
    "approval_by_credit = pd.crosstab(\n",
    "    credit_score_bins, \n",
    "    customer_data['approved'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "print(\"\\nApproval rate by credit score category:\")\n",
    "print(approval_by_credit[1].sort_index())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution\n",
    "credit_score_bins.value_counts().sort_index().plot(kind='bar', ax=axes[0], edgecolor='black')\n",
    "axes[0].set_xlabel('Credit Score Category')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Custom Binning: Credit Score Distribution')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Approval rate\n",
    "approval_by_credit[1].sort_index().plot(kind='bar', ax=axes[1], color='green', edgecolor='black')\n",
    "axes[1].set_xlabel('Credit Score Category')\n",
    "axes[1].set_ylabel('Approval Rate (%)')\n",
    "axes[1].set_title('Approval Rate by Credit Score')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Custom bins align with domain knowledge and show clear relationship to target!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom age groups\n",
    "age_bins_custom = pd.cut(\n",
    "    customer_data['age'],\n",
    "    bins=[0, 25, 40, 60, 100],\n",
    "    labels=['Young (18-25)', 'Adult (26-40)', 'Middle Age (41-60)', 'Senior (60+)']\n",
    ")\n",
    "\n",
    "print(\"Custom Age Grouping:\\n\")\n",
    "print(age_bins_custom.value_counts().sort_index())\n",
    "\n",
    "# Approval rate by age group\n",
    "approval_by_age = customer_data.groupby(age_bins_custom)['approved'].agg(['mean', 'count'])\n",
    "approval_by_age['approval_rate_%'] = approval_by_age['mean'] * 100\n",
    "\n",
    "print(\"\\nApproval statistics by age group:\")\n",
    "print(approval_by_age[['count', 'approval_rate_%']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Method 4: KBinsDiscretizer from sklearn\n",
    "\n",
    "**sklearn's unified interface** for binning with multiple strategies.\n",
    "\n",
    "**Strategies**:\n",
    "1. `uniform`: Equal-width binning\n",
    "2. `quantile`: Equal-frequency binning\n",
    "3. `kmeans`: K-means clustering to find optimal bin edges\n",
    "\n",
    "**Encoding options**:\n",
    "- `ordinal`: 0, 1, 2, 3... (preserves order)\n",
    "- `onehot`: Binary columns for each bin\n",
    "- `onehot-dense`: Same as onehot but dense array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = customer_data[['age', 'income', 'credit_score', 'years_employed', 'debt']]\n",
    "y = customer_data['approved']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KBinsDiscretizer with uniform strategy\n",
    "binner_uniform = KBinsDiscretizer(\n",
    "    n_bins=5,\n",
    "    encode='ordinal',\n",
    "    strategy='uniform'\n",
    ")\n",
    "\n",
    "X_train_binned_uniform = binner_uniform.fit_transform(X_train)\n",
    "X_test_binned_uniform = binner_uniform.transform(X_test)\n",
    "\n",
    "print(\"KBinsDiscretizer (uniform strategy):\\n\")\n",
    "print(\"Original data (first 5 rows):\")\n",
    "print(X_train.head())\n",
    "print(\"\\nBinned data (first 5 rows):\")\n",
    "print(pd.DataFrame(X_train_binned_uniform[:5], columns=X.columns))\n",
    "print(\"\\nValues are now 0, 1, 2, 3, 4 representing the bin index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different strategies\n",
    "strategies = ['uniform', 'quantile', 'kmeans']\n",
    "\n",
    "fig, axes = plt.subplots(len(strategies), 1, figsize=(12, 12))\n",
    "\n",
    "for idx, strategy in enumerate(strategies):\n",
    "    binner = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy=strategy)\n",
    "    X_binned = binner.fit_transform(X_train[['income']])\n",
    "    \n",
    "    # Plot\n",
    "    axes[idx].hist(X_binned, bins=5, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_xlabel('Bin Index')\n",
    "    axes[idx].set_ylabel('Count')\n",
    "    axes[idx].set_title(f'Strategy: {strategy}')\n",
    "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    axes[idx].set_xticks([0, 1, 2, 3, 4])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(\"- uniform: Imbalanced (most in first bins)\")\n",
    "print(\"- quantile: Balanced (equal counts per bin)\")\n",
    "print(\"- kmeans: Clusters data points, somewhat balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Impact on Model Performance\n",
    "\n",
    "Let's compare how binning affects different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: No binning vs Binning for different models\n",
    "\n",
    "# Prepare binned data (quantile strategy, 5 bins)\n",
    "binner = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "X_train_binned = binner.fit_transform(X_train)\n",
    "X_test_binned = binner.transform(X_test)\n",
    "\n",
    "# Models to test\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Without binning\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy_no_bin = model.score(X_test, y_test)\n",
    "    \n",
    "    # With binning\n",
    "    model_binned = models[model_name]  # Create new instance\n",
    "    model_binned.fit(X_train_binned, y_train)\n",
    "    accuracy_with_bin = model_binned.score(X_test_binned, y_test)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Without Binning': accuracy_no_bin,\n",
    "        'With Binning': accuracy_with_bin,\n",
    "        'Difference': accuracy_with_bin - accuracy_no_bin\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Impact of Binning on Model Performance:\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "results_df.set_index('Model')[['Without Binning', 'With Binning']].plot(\n",
    "    kind='bar', figsize=(10, 6), edgecolor='black'\n",
    ")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance: Binning vs No Binning')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim([0.5, 1.0])\n",
    "plt.legend(['Without Binning', 'With Binning'])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"1. Logistic Regression may benefit from binning (handles non-linearity)\")\n",
    "print(\"2. Tree-based models usually don't need binning (split optimally anyway)\")\n",
    "print(\"3. Binning can help with outliers and noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Choosing the Number of Bins\n",
    "\n",
    "How many bins should you create?\n",
    "\n",
    "### Rules of Thumb:\n",
    "\n",
    "1. **Sturges' Rule**: $bins = \\lceil \\log_2(n) + 1 \\rceil$\n",
    "   - Good for normal distributions\n",
    "   \n",
    "2. **Rice's Rule**: $bins = \\lceil 2n^{1/3} \\rceil$\n",
    "   - More bins than Sturges'\n",
    "   \n",
    "3. **Domain Knowledge**: Use meaningful categories\n",
    "   - Age: Young, Adult, Middle-aged, Senior (4 bins)\n",
    "   - Income: Based on tax brackets\n",
    "   \n",
    "4. **Cross-Validation**: Try different numbers, pick best\n",
    "\n",
    "### Guidelines:\n",
    "\n",
    "- **Too few bins** (2-3): May lose too much information\n",
    "- **Too many bins** (20+): Defeats the purpose of binning\n",
    "- **Sweet spot**: Usually 4-10 bins\n",
    "- **Consider sample size**: More data → can support more bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different numbers of bins\n",
    "n_bins_range = [3, 5, 7, 10, 15, 20]\n",
    "scores = []\n",
    "\n",
    "for n_bins in n_bins_range:\n",
    "    # Create bins\n",
    "    binner = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
    "    X_train_temp = binner.fit_transform(X_train)\n",
    "    X_test_temp = binner.transform(X_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_temp, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = model.score(X_test_temp, y_test)\n",
    "    scores.append(accuracy)\n",
    "    \n",
    "    print(f\"n_bins = {n_bins:2d}: Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_bins_range, scores, 'o-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Bins')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance vs Number of Bins')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(n_bins_range)\n",
    "plt.ylim([min(scores) - 0.01, max(scores) + 0.01])\n",
    "plt.show()\n",
    "\n",
    "optimal_bins = n_bins_range[np.argmax(scores)]\n",
    "print(f\"\\nOptimal number of bins: {optimal_bins}\")\n",
    "print(\"\\nNote: Performance usually plateaus after certain number of bins.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Best Practices\n",
    "\n",
    "### ✅ DO:\n",
    "\n",
    "1. **Use domain knowledge**\n",
    "   - Create bins that make business sense\n",
    "   - Align with industry standards\n",
    "\n",
    "2. **Choose appropriate binning strategy**\n",
    "   - Uniform: When data is evenly distributed\n",
    "   - Quantile: When data is skewed\n",
    "   - Custom: When domain knowledge exists\n",
    "\n",
    "3. **Bin AFTER splitting**\n",
    "   - Fit binner on training data\n",
    "   - Transform both train and test\n",
    "   - Avoid data leakage\n",
    "\n",
    "4. **Experiment with number of bins**\n",
    "   - Try 3-10 bins\n",
    "   - Use cross-validation\n",
    "   - Balance granularity and simplicity\n",
    "\n",
    "5. **Consider for linear models**\n",
    "   - Helps capture non-linearity\n",
    "   - Makes features more interpretable\n",
    "\n",
    "### ❌ DON'T:\n",
    "\n",
    "1. **Don't bin with tree models** (usually)\n",
    "   - Trees find optimal splits\n",
    "   - Binning may reduce performance\n",
    "\n",
    "2. **Don't create too many bins**\n",
    "   - Defeats purpose of discretization\n",
    "   - May lead to overfitting\n",
    "\n",
    "3. **Don't ignore bin distribution**\n",
    "   - Check if bins are balanced\n",
    "   - Avoid bins with very few samples\n",
    "\n",
    "4. **Don't forget to encode**\n",
    "   - Use ordinal for ordered bins\n",
    "   - Use one-hot for nominal bins\n",
    "\n",
    "5. **Don't bin everything**\n",
    "   - Only bin when it makes sense\n",
    "   - Keep continuous when relationship is linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Exercise Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Choose the Right Binning Strategy\n",
    "\n",
    "For each scenario, choose the best binning approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Match scenarios to binning strategies\n",
    "\n",
    "scenarios = {\n",
    "    'A': 'Age for insurance risk categories (industry has standard groups)',\n",
    "    'B': 'Website response time in milliseconds (heavily right-skewed)',\n",
    "    'C': 'Test scores from 0-100 (evenly distributed)',\n",
    "    'D': 'Income for tax bracket analysis (specific thresholds exist)',\n",
    "    'E': 'Temperature readings (normally distributed)'\n",
    "}\n",
    "\n",
    "strategies_options = {\n",
    "    '1': 'Equal-width (uniform)',\n",
    "    '2': 'Equal-frequency (quantile)',\n",
    "    '3': 'Custom bins (domain knowledge)',\n",
    "    '4': \"Don't bin (keep continuous)\"\n",
    "}\n",
    "\n",
    "print(\"Scenarios:\")\n",
    "for key, scenario in scenarios.items():\n",
    "    print(f\"{key}. {scenario}\")\n",
    "\n",
    "print(\"\\nBinning Strategies:\")\n",
    "for key, strategy in strategies_options.items():\n",
    "    print(f\"{key}. {strategy}\")\n",
    "\n",
    "print(\"\\nYour answers:\")\n",
    "# A: ?\n",
    "# B: ?\n",
    "# C: ?\n",
    "# D: ?\n",
    "# E: ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Exercise 1\n",
    "\n",
    "print(\"Solutions:\\n\")\n",
    "print(\"A: 3 - Custom bins\")\n",
    "print(\"   Insurance industry has standard age groups (e.g., 18-25, 26-40, 41-60, 60+)\\n\")\n",
    "\n",
    "print(\"B: 2 - Equal-frequency (quantile)\")\n",
    "print(\"   Skewed data needs quantile binning to avoid imbalanced bins\\n\")\n",
    "\n",
    "print(\"C: 1 - Equal-width (uniform)\")\n",
    "print(\"   Evenly distributed data works well with uniform bins (e.g., 0-20, 21-40, 41-60, 61-80, 81-100)\\n\")\n",
    "\n",
    "print(\"D: 3 - Custom bins\")\n",
    "print(\"   Tax brackets are legally defined, use those exact thresholds\\n\")\n",
    "\n",
    "print(\"E: 1 or 4 - Equal-width or Don't bin\")\n",
    "print(\"   Normally distributed data doesn't need special handling. May not need binning at all.\\n\")\n",
    "\n",
    "print(\"Key principle: Use domain knowledge when available, otherwise choose based on distribution!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Create Custom Bins\n",
    "\n",
    "Create meaningful income brackets for financial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Create custom income brackets\n",
    "\n",
    "# Income data\n",
    "incomes = customer_data['income'].copy()\n",
    "\n",
    "print(\"Income statistics:\")\n",
    "print(incomes.describe())\n",
    "\n",
    "# TODO: Create meaningful income brackets\n",
    "# Consider: Low, Lower-Middle, Middle, Upper-Middle, High\n",
    "# Choose thresholds that make sense (e.g., poverty line, median, etc.)\n",
    "\n",
    "# Your code here:\n",
    "# income_brackets = pd.cut(\n",
    "#     incomes,\n",
    "#     bins=[???, ???, ???, ???, ???, ???],\n",
    "#     labels=[???, ???, ???, ???, ???]\n",
    "# )\n",
    "\n",
    "# print(\"\\nIncome bracket distribution:\")\n",
    "# print(income_brackets.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Exercise 2\n",
    "\n",
    "# Create meaningful income brackets\n",
    "income_brackets = pd.cut(\n",
    "    incomes,\n",
    "    bins=[0, 30000, 50000, 75000, 100000, 300000],\n",
    "    labels=['Low (<30k)', 'Lower-Middle (30-50k)', 'Middle (50-75k)', \n",
    "            'Upper-Middle (75-100k)', 'High (>100k)'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "print(\"Solution: Income Brackets\\n\")\n",
    "print(\"Distribution:\")\n",
    "print(income_brackets.value_counts().sort_index())\n",
    "\n",
    "# Analyze approval rate by income bracket\n",
    "approval_by_income = pd.crosstab(\n",
    "    income_brackets, \n",
    "    customer_data['approved'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "print(\"\\nApproval rate by income bracket:\")\n",
    "print(approval_by_income[1].sort_index())\n",
    "\n",
    "# Visualize\n",
    "approval_by_income[1].sort_index().plot(\n",
    "    kind='bar', figsize=(10, 6), color='green', edgecolor='black'\n",
    ")\n",
    "plt.xlabel('Income Bracket')\n",
    "plt.ylabel('Approval Rate (%)')\n",
    "plt.title('Credit Card Approval Rate by Income Bracket')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nThresholds chosen based on:\")\n",
    "print(\"- $30k: Around poverty threshold\")\n",
    "print(\"- $50k: Near median household income\")\n",
    "print(\"- $75k: Upper-middle class threshold\")\n",
    "print(\"- $100k: High income threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Compare Binning Strategies\n",
    "\n",
    "Implement and compare all three binning strategies on the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Compare equal-width vs equal-frequency\n",
    "\n",
    "# Use debt data (likely skewed)\n",
    "debt_data = customer_data['debt'].copy()\n",
    "\n",
    "print(\"Debt statistics:\")\n",
    "print(debt_data.describe())\n",
    "\n",
    "# TODO:\n",
    "# 1. Create equal-width bins (5 bins)\n",
    "# 2. Create equal-frequency bins (5 bins)\n",
    "# 3. Compare the distributions\n",
    "# 4. Which is more balanced?\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Exercise 3\n",
    "\n",
    "# Equal-width binning\n",
    "debt_uniform = pd.cut(debt_data, bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "# Equal-frequency binning\n",
    "debt_quantile = pd.qcut(debt_data, q=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "print(\"Comparison of Binning Strategies:\\n\")\n",
    "print(\"Equal-Width Binning:\")\n",
    "print(debt_uniform.value_counts().sort_index())\n",
    "print(f\"\\nStandard deviation of counts: {debt_uniform.value_counts().std():.1f}\")\n",
    "\n",
    "print(\"\\nEqual-Frequency Binning:\")\n",
    "print(debt_quantile.value_counts().sort_index())\n",
    "print(f\"\\nStandard deviation of counts: {debt_quantile.value_counts().std():.1f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "debt_uniform.value_counts().sort_index().plot(kind='bar', ax=axes[0], edgecolor='black', color='coral')\n",
    "axes[0].set_xlabel('Debt Category')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Equal-Width Binning')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "debt_quantile.value_counts().sort_index().plot(kind='bar', ax=axes[1], edgecolor='black', color='lightgreen')\n",
    "axes[1].set_xlabel('Debt Category')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Equal-Frequency Binning')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "print(\"- Equal-width: Imbalanced, most data in first bin\")\n",
    "print(\"- Equal-frequency: Balanced, each bin has similar count\")\n",
    "print(\"- For skewed data, equal-frequency is usually better!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Prevent Data Leakage\n",
    "\n",
    "Identify and fix the data leakage problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Fix the data leakage\n",
    "\n",
    "print(\"Problematic code:\")\n",
    "print('''\n",
    "# Bin the data\n",
    "binner = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "X_binned = binner.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_binned, y)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "''')\n",
    "\n",
    "print(\"\\nWhat's wrong? How would you fix it?\")\n",
    "# Your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Exercise 4\n",
    "\n",
    "print(\"Problem: DATA LEAKAGE!\\n\")\n",
    "print(\"The binner is fit on ALL data before splitting.\")\n",
    "print(\"For quantile binning, bin edges are calculated using test set!\\n\")\n",
    "\n",
    "print(\"Why this is bad:\")\n",
    "print(\"- Test set statistics leak into training\")\n",
    "print(\"- Quantiles calculated using entire dataset\")\n",
    "print(\"- Model sees information it shouldn't have\")\n",
    "print(\"- Performance estimates are overly optimistic\\n\")\n",
    "\n",
    "print(\"Correct approach:\")\n",
    "print('''\n",
    "# Split FIRST\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Fit binner on training data only\n",
    "binner = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "X_train_binned = binner.fit_transform(X_train)\n",
    "\n",
    "# Apply same binning to test data\n",
    "X_test_binned = binner.transform(X_test)  # Note: transform, not fit_transform!\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train_binned, y_train)\n",
    "''')\n",
    "\n",
    "print(\"\\n✓ Always: Split → Fit on train → Transform both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Binning converts continuous features to categorical**\n",
    "   - Useful for capturing non-linear patterns\n",
    "   - Makes features more interpretable\n",
    "   - Can handle outliers better\n",
    "\n",
    "2. **Three main binning strategies**:\n",
    "   - **Equal-width**: Uniform intervals, good for evenly distributed data\n",
    "   - **Equal-frequency**: Balanced bins, better for skewed data\n",
    "   - **Custom bins**: Use domain knowledge for meaningful categories\n",
    "\n",
    "3. **sklearn's KBinsDiscretizer** provides unified interface\n",
    "   - Strategies: uniform, quantile, kmeans\n",
    "   - Encoding: ordinal, onehot\n",
    "   - Easy to integrate in pipelines\n",
    "\n",
    "4. **When binning helps**:\n",
    "   - ✅ Linear models with non-linear data\n",
    "   - ✅ Domain knowledge suggests categories\n",
    "   - ✅ Outliers are problematic\n",
    "   - ✅ Interpretability is important\n",
    "   - ❌ Tree-based models (usually don't need it)\n",
    "\n",
    "5. **Choosing number of bins**:\n",
    "   - Too few (2-3): Loss of information\n",
    "   - Too many (20+): Defeats purpose\n",
    "   - Sweet spot: 4-10 bins\n",
    "   - Use cross-validation to optimize\n",
    "\n",
    "6. **Always avoid data leakage**:\n",
    "   - Split data first\n",
    "   - Fit binner on training data only\n",
    "   - Transform both train and test\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Module 06**: Date and Time Features - Learn how to extract temporal features from timestamps\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Sklearn KBinsDiscretizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html)\n",
    "- [Pandas cut and qcut](https://pandas.pydata.org/docs/reference/api/pandas.cut.html)\n",
    "- \"Feature Engineering for Machine Learning\" by Alice Zheng & Amanda Casari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Congratulations!** You've completed Module 05. You now know:\n",
    "- What binning/discretization is and when to use it\n",
    "- How to apply equal-width and equal-frequency binning\n",
    "- How to create custom bins based on domain knowledge\n",
    "- How to use sklearn's KBinsDiscretizer\n",
    "- When binning helps vs hurts model performance\n",
    "- How to choose the right number of bins\n",
    "\n",
    "Ready to work with temporal data? Move to **Module 06: Date and Time Features**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
