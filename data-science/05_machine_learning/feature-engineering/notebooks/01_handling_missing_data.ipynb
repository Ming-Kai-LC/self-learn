{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 01: Handling Missing Data\n",
    "\n",
    "**Difficulty**: ⭐ Beginner  \n",
    "**Estimated Time**: 60 minutes  \n",
    "**Prerequisites**: [Module 00: Introduction to Feature Engineering](00_introduction_to_feature_engineering.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Identify different types of missing data (MCAR, MAR, MNAR)\n",
    "2. Visualize and analyze missing data patterns\n",
    "3. Apply simple imputation strategies (mean, median, mode, constant)\n",
    "4. Use advanced imputation techniques (KNN, iterative imputation)\n",
    "5. Decide when to delete vs. impute missing values\n",
    "6. Avoid data leakage when handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Missing Data Matters\n",
    "\n",
    "Real-world datasets are **messy**. Missing data is one of the most common issues:\n",
    "\n",
    "- Survey respondents skip questions\n",
    "- Sensors malfunction and fail to record\n",
    "- Data entry errors create gaps\n",
    "- Privacy restrictions remove sensitive information\n",
    "\n",
    "**Impact if not handled properly**:\n",
    "- Most ML algorithms can't handle missing values\n",
    "- Removing all rows with missing data can lose 50%+ of your dataset\n",
    "- Poor imputation can introduce bias and reduce model accuracy\n",
    "\n",
    "### Types of Missingness\n",
    "\n",
    "1. **MCAR (Missing Completely at Random)**\n",
    "   - Missing values have no relationship to any data\n",
    "   - Example: A sensor randomly fails\n",
    "   - **Safest to handle** - any method works\n",
    "\n",
    "2. **MAR (Missing at Random)**\n",
    "   - Missingness depends on other observed variables\n",
    "   - Example: Older people less likely to report income\n",
    "   - **Common in real data** - need careful imputation\n",
    "\n",
    "3. **MNAR (Missing Not at Random)**\n",
    "   - Missingness depends on the missing value itself\n",
    "   - Example: High earners don't report income\n",
    "   - **Hardest to handle** - need domain expertise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Missing data visualization\n",
    "import missingno as msno\n",
    "\n",
    "# Imputation methods\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Dataset with Missing Values\n",
    "\n",
    "Let's create a realistic dataset to practice handling missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer dataset for loan approval prediction\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "\n",
    "# Generate complete data first\n",
    "data = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 70, n_samples),\n",
    "    'income': np.random.normal(50000, 20000, n_samples),\n",
    "    'credit_score': np.random.randint(300, 850, n_samples),\n",
    "    'employment_years': np.random.randint(0, 40, n_samples),\n",
    "    'loan_amount': np.random.normal(100000, 50000, n_samples),\n",
    "    'debt_to_income': np.random.uniform(0, 0.5, n_samples)\n",
    "})\n",
    "\n",
    "# Ensure positive values\n",
    "data['income'] = data['income'].clip(lower=15000)\n",
    "data['loan_amount'] = data['loan_amount'].clip(lower=5000)\n",
    "\n",
    "# Create target variable (loan approved)\n",
    "data['approved'] = (\n",
    "    (data['credit_score'] > 650) & \n",
    "    (data['debt_to_income'] < 0.4) &\n",
    "    (data['income'] > 30000)\n",
    ").astype(int)\n",
    "\n",
    "print(f\"Created dataset with {len(data)} samples and {len(data.columns)} features\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce missing values with different patterns\n",
    "\n",
    "# MCAR: Randomly remove 10% of income values\n",
    "mcar_mask = np.random.rand(len(data)) < 0.10\n",
    "data.loc[mcar_mask, 'income'] = np.nan\n",
    "\n",
    "# MAR: Older people less likely to report employment years\n",
    "# Missing depends on age (observed variable)\n",
    "mar_mask = (data['age'] > 50) & (np.random.rand(len(data)) < 0.25)\n",
    "data.loc[mar_mask, 'employment_years'] = np.nan\n",
    "\n",
    "# MNAR: High debt-to-income ratios less likely to be reported\n",
    "# Missing depends on the value itself\n",
    "mnar_mask = (data['debt_to_income'] > 0.4) & (np.random.rand(len(data)) < 0.30)\n",
    "data.loc[mnar_mask, 'debt_to_income'] = np.nan\n",
    "\n",
    "# Completely random missing in credit_score\n",
    "random_mask = np.random.rand(len(data)) < 0.05\n",
    "data.loc[random_mask, 'credit_score'] = np.nan\n",
    "\n",
    "print(\"Missing data summary:\")\n",
    "print(data.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {data.isnull().sum().sum()}\")\n",
    "print(f\"Percentage of data missing: {data.isnull().sum().sum() / (len(data) * len(data.columns)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing Missing Data\n",
    "\n",
    "Before handling missing data, **always visualize patterns**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic missing data summary\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': data.columns,\n",
    "    'Missing_Count': data.isnull().sum(),\n",
    "    'Missing_Percent': (data.isnull().sum() / len(data) * 100).round(2)\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(\"Missing Data Summary:\")\n",
    "print(missing_summary)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.barh(missing_summary['Column'], missing_summary['Missing_Percent'])\n",
    "ax.set_xlabel('Percentage Missing (%)')\n",
    "ax.set_title('Missing Data by Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using missingno library for advanced visualization\n",
    "\n",
    "# Matrix visualization shows patterns\n",
    "print(\"Missing Data Matrix:\")\n",
    "print(\"White lines indicate missing values\\n\")\n",
    "msno.matrix(data, figsize=(12, 5))\n",
    "plt.show()\n",
    "\n",
    "# Bar chart\n",
    "print(\"\\nMissing Data Bar Chart:\")\n",
    "msno.bar(data, figsize=(12, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Strategy 1: Deletion\n",
    "\n",
    "**When to use**: \n",
    "- Very small percentage missing (<5%)\n",
    "- Data is MCAR\n",
    "- You have abundant data\n",
    "\n",
    "**Risks**:\n",
    "- Loss of information\n",
    "- Introduces bias if not MCAR\n",
    "- Can lose most of your dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Drop rows with ANY missing values\n",
    "data_dropna = data.dropna()\n",
    "\n",
    "print(f\"Original dataset: {len(data)} rows\")\n",
    "print(f\"After dropping rows with ANY missing: {len(data_dropna)} rows\")\n",
    "print(f\"Lost {len(data) - len(data_dropna)} rows ({(len(data) - len(data_dropna))/len(data)*100:.1f}%)\")\n",
    "print(\"\\n⚠️ We lost almost a quarter of our data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Drop columns with >30% missing\n",
    "threshold = 0.30\n",
    "cols_to_drop = data.columns[data.isnull().mean() > threshold]\n",
    "\n",
    "print(f\"Columns with >{threshold*100}% missing:\")\n",
    "print(cols_to_drop.tolist() if len(cols_to_drop) > 0 else \"None\")\n",
    "\n",
    "# Option 3: Drop rows where specific critical columns are missing\n",
    "critical_columns = ['credit_score', 'income']\n",
    "data_critical = data.dropna(subset=critical_columns)\n",
    "\n",
    "print(f\"\\nAfter dropping rows missing critical columns {critical_columns}:\")\n",
    "print(f\"Remaining rows: {len(data_critical)} ({len(data_critical)/len(data)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Strategy 2: Simple Imputation\n",
    "\n",
    "Replace missing values with statistical measures.\n",
    "\n",
    "### Common Strategies:\n",
    "- **Mean**: Good for normally distributed data, sensitive to outliers\n",
    "- **Median**: Robust to outliers, good for skewed data\n",
    "- **Mode**: For categorical data\n",
    "- **Constant**: Domain-specific value (e.g., 0, -1, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Split data BEFORE imputation to avoid data leakage!\n",
    "X = data.drop('approved', axis=1)\n",
    "y = data['approved']\n",
    "\n",
    "# Remove rows where target is affected by missing features for this demo\n",
    "# In practice, you'd handle this more carefully\n",
    "valid_indices = X.index\n",
    "X = X.loc[valid_indices]\n",
    "y = y.loc[valid_indices]\n",
    "\n",
    "# Split first!\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Imputation\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit on training data only!\n",
    "X_train_mean = mean_imputer.fit_transform(X_train)\n",
    "\n",
    "# Apply same transformation to test data\n",
    "X_test_mean = mean_imputer.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for readability\n",
    "X_train_mean_df = pd.DataFrame(X_train_mean, columns=X.columns)\n",
    "X_test_mean_df = pd.DataFrame(X_test_mean, columns=X.columns)\n",
    "\n",
    "print(\"Mean Imputation completed!\")\n",
    "print(f\"Missing values in training set: {X_train_mean_df.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in test set: {X_test_mean_df.isnull().sum().sum()}\")\n",
    "\n",
    "print(\"\\nExample: Income column\")\n",
    "print(f\"Original mean (ignoring NaN): ${X_train['income'].mean():.2f}\")\n",
    "print(f\"Imputed value: ${mean_imputer.statistics_[X.columns.get_loc('income')]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Imputation (better for skewed data)\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "X_train_median = median_imputer.fit_transform(X_train)\n",
    "X_test_median = median_imputer.transform(X_test)\n",
    "\n",
    "print(\"Median Imputation completed!\")\n",
    "print(\"\\nComparison for 'income' column:\")\n",
    "print(f\"Mean imputation value: ${mean_imputer.statistics_[X.columns.get_loc('income')]:.2f}\")\n",
    "print(f\"Median imputation value: ${median_imputer.statistics_[X.columns.get_loc('income')]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant Imputation (domain-specific)\n",
    "# For example, missing employment_years for young people could be 0\n",
    "constant_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "\n",
    "X_train_constant = constant_imputer.fit_transform(X_train)\n",
    "X_test_constant = constant_imputer.transform(X_test)\n",
    "\n",
    "print(\"Constant Imputation completed!\")\n",
    "print(\"All missing values filled with 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Strategy 3: Advanced Imputation\n",
    "\n",
    "Use relationships between features to make better predictions of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Imputation\n",
    "# Finds k nearest neighbors and uses their average\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "X_train_knn = knn_imputer.fit_transform(X_train)\n",
    "X_test_knn = knn_imputer.transform(X_test)\n",
    "\n",
    "X_train_knn_df = pd.DataFrame(X_train_knn, columns=X.columns)\n",
    "\n",
    "print(\"KNN Imputation completed!\")\n",
    "print(\"Uses 5 nearest neighbors to predict missing values\")\n",
    "print(f\"Missing values: {X_train_knn_df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative Imputation (MICE - Multiple Imputation by Chained Equations)\n",
    "# Models each feature with missing values as a function of other features\n",
    "\n",
    "iterative_imputer = IterativeImputer(random_state=42, max_iter=10)\n",
    "\n",
    "X_train_iter = iterative_imputer.fit_transform(X_train)\n",
    "X_test_iter = iterative_imputer.transform(X_test)\n",
    "\n",
    "X_train_iter_df = pd.DataFrame(X_train_iter, columns=X.columns)\n",
    "\n",
    "print(\"Iterative Imputation completed!\")\n",
    "print(\"Uses regression models to predict missing values\")\n",
    "print(f\"Missing values: {X_train_iter_df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparing Imputation Methods\n",
    "\n",
    "Let's compare how different imputation methods affect model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with different imputation methods\n",
    "\n",
    "imputation_methods = {\n",
    "    'Mean': (X_train_mean, X_test_mean),\n",
    "    'Median': (X_train_median, X_test_median),\n",
    "    'Constant (0)': (X_train_constant, X_test_constant),\n",
    "    'KNN': (X_train_knn, X_test_knn),\n",
    "    'Iterative': (X_train_iter, X_test_iter)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for method_name, (X_tr, X_te) in imputation_methods.items():\n",
    "    # Train model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_tr, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_te)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Method': method_name,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).sort_values('Accuracy', ascending=False)\n",
    "print(\"Model Performance by Imputation Method:\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(results_df['Method'], results_df['Accuracy'])\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Model Performance by Imputation Method')\n",
    "plt.xlim([0.5, 1.0])\n",
    "for i, v in enumerate(results_df['Accuracy']):\n",
    "    plt.text(v + 0.01, i, f'{v:.3f}', va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Best Practices\n",
    "\n",
    "### ✅ DO:\n",
    "\n",
    "1. **Always split data before imputation**\n",
    "   - Fit imputer on training data\n",
    "   - Transform both train and test\n",
    "\n",
    "2. **Visualize missing patterns first**\n",
    "   - Understand WHY data is missing\n",
    "   - Check if missing is random\n",
    "\n",
    "3. **Consider adding indicator features**\n",
    "   - `was_missing` boolean column\n",
    "   - Sometimes missingness itself is predictive!\n",
    "\n",
    "4. **Try multiple methods**\n",
    "   - Compare performance\n",
    "   - Different methods work for different data\n",
    "\n",
    "5. **Document your decisions**\n",
    "   - Why this imputation method?\n",
    "   - What assumptions are you making?\n",
    "\n",
    "### ❌ DON'T:\n",
    "\n",
    "1. **Don't impute before splitting** (data leakage!)\n",
    "2. **Don't always use mean** (consider data distribution)\n",
    "3. **Don't ignore why data is missing**\n",
    "4. **Don't delete data unless necessary**\n",
    "5. **Don't forget to handle missing values in production**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exercise Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Identify Missing Data Type\n",
    "\n",
    "For each scenario, identify if it's MCAR, MAR, or MNAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Classify these missing data scenarios\n",
    "\n",
    "scenarios = {\n",
    "    'A': 'Survey responses about salary are missing for unemployed people',\n",
    "    'B': 'Temperature sensor randomly fails 1% of the time',\n",
    "    'C': 'People with depression less likely to report mental health status',\n",
    "    'D': 'Male respondents less likely to answer question about pregnancy',\n",
    "    'E': 'Very wealthy individuals don\\'t report their net worth'\n",
    "}\n",
    "\n",
    "print(\"Classify each scenario as MCAR, MAR, or MNAR:\\n\")\n",
    "for key, scenario in scenarios.items():\n",
    "    print(f\"{key}. {scenario}\")\n",
    "\n",
    "print(\"\\nYour answers (write as comment):\")\n",
    "# A: ???\n",
    "# B: ???\n",
    "# C: ???\n",
    "# D: ???\n",
    "# E: ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Exercise 1\n",
    "\n",
    "print(\"Solutions:\\n\")\n",
    "print(\"A: MAR - Missing depends on employment status (observed variable)\")\n",
    "print(\"B: MCAR - Completely random failure\")\n",
    "print(\"C: MNAR - Missing depends on the value itself (depression level)\")\n",
    "print(\"D: MAR - Missing depends on gender (observed variable)\")\n",
    "print(\"E: MNAR - Missing depends on the value itself (wealth level)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Implement Missing Value Indicator\n",
    "\n",
    "Create indicator features that show where data was missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Create missing value indicators\n",
    "\n",
    "# Create a sample dataset\n",
    "sample_data = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [10, np.nan, 30, 40, np.nan],\n",
    "    'C': [100, 200, 300, 400, 500]\n",
    "})\n",
    "\n",
    "print(\"Original data:\")\n",
    "print(sample_data)\n",
    "\n",
    "# TODO: Create indicator features for columns A and B\n",
    "# Indicator should be 1 if value was missing, 0 otherwise\n",
    "\n",
    "# Your code here:\n",
    "# sample_data['A_was_missing'] = ???\n",
    "# sample_data['B_was_missing'] = ???\n",
    "\n",
    "# Then impute missing values with median\n",
    "# Your code here:\n",
    "\n",
    "print(\"\\nData with indicators and imputation:\")\n",
    "# print(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Exercise 2\n",
    "\n",
    "sample_data = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [10, np.nan, 30, 40, np.nan],\n",
    "    'C': [100, 200, 300, 400, 500]\n",
    "})\n",
    "\n",
    "# Create indicators BEFORE imputing\n",
    "sample_data['A_was_missing'] = sample_data['A'].isnull().astype(int)\n",
    "sample_data['B_was_missing'] = sample_data['B'].isnull().astype(int)\n",
    "\n",
    "# Now impute\n",
    "sample_data['A'] = sample_data['A'].fillna(sample_data['A'].median())\n",
    "sample_data['B'] = sample_data['B'].fillna(sample_data['B'].median())\n",
    "\n",
    "print(\"Solution:\")\n",
    "print(sample_data)\n",
    "print(\"\\nNotice: Indicator columns preserve information about WHERE data was missing!\")\n",
    "print(\"This can be valuable for the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Spot the Data Leakage\n",
    "\n",
    "Identify what's wrong with this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: What's wrong with this code?\n",
    "\n",
    "print(\"Code snippet:\")\n",
    "print('''\n",
    "# Load data\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "''')\n",
    "\n",
    "print(\"\\nWhat's wrong? (Write answer as comment)\")\n",
    "# Your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Exercise 3\n",
    "\n",
    "print(\"Problem: DATA LEAKAGE!\")\n",
    "print(\"\\nThe imputer is fit on ALL data (including test set) before splitting.\")\n",
    "print(\"This means the test set statistics leak into the training process.\")\n",
    "print(\"\\nCorrect approach:\")\n",
    "print('''\n",
    "# 1. Split FIRST\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# 2. Fit imputer on training data only\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "\n",
    "# 3. Apply to test data\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Missing data is common** in real-world datasets\n",
    "   - Understand WHY data is missing (MCAR, MAR, MNAR)\n",
    "   - Visualize patterns before handling\n",
    "\n",
    "2. **Multiple strategies exist**:\n",
    "   - **Deletion**: Only when <5% missing and MCAR\n",
    "   - **Simple imputation**: Mean, median, mode, constant\n",
    "   - **Advanced imputation**: KNN, iterative (MICE)\n",
    "\n",
    "3. **Always avoid data leakage**:\n",
    "   - Split data FIRST\n",
    "   - Fit imputer on training data only\n",
    "   - Transform both train and test\n",
    "\n",
    "4. **Consider missing indicators**:\n",
    "   - Sometimes missingness is informative\n",
    "   - Create `was_missing` features\n",
    "\n",
    "5. **No single best method**:\n",
    "   - Try multiple approaches\n",
    "   - Compare model performance\n",
    "   - Consider computational cost\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Module 02**: Encoding Categorical Variables - Learn how to convert categories to numbers for ML models\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Sklearn Imputation Documentation](https://scikit-learn.org/stable/modules/impute.html)\n",
    "- [Missingno Library](https://github.com/ResidentMario/missingno)\n",
    "- \"Flexible Imputation of Missing Data\" by Stef van Buuren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Congratulations!** You've completed Module 01. You now know how to:\n",
    "- Identify and visualize missing data patterns\n",
    "- Apply appropriate imputation strategies\n",
    "- Avoid data leakage when handling missing values\n",
    "- Compare imputation methods systematically\n",
    "\n",
    "Ready for the next challenge? Move to **Module 02: Encoding Categorical Variables**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
