{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 09: Feature Importance and Interpretability\n",
    "\n",
    "**Difficulty**: ⭐⭐ Intermediate  \n",
    "**Estimated Time**: 60 minutes  \n",
    "**Prerequisites**: Module 08 (Feature Selection Methods)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Calculate and interpret permutation importance for any model\n",
    "2. Extract feature importance from tree-based models\n",
    "3. Understand SHAP values and their role in model interpretability\n",
    "4. Compare different feature importance methods\n",
    "5. Visualize feature importance rankings effectively\n",
    "6. Use feature importance to improve model understanding and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Feature Importance Matters\n",
    "\n",
    "**Understanding which features drive predictions is critical for**:\n",
    "- **Model debugging**: Identify if model learned correct patterns\n",
    "- **Trust**: Stakeholders need to understand model decisions\n",
    "- **Feature engineering**: Focus efforts on impactful features\n",
    "- **Compliance**: Some industries require explainable models\n",
    "- **Domain insights**: Learn about underlying patterns in data\n",
    "\n",
    "**Different methods reveal different insights**:\n",
    "1. **Permutation Importance**: How much does performance drop if we shuffle a feature?\n",
    "2. **Tree-based Importance**: How often and how much does a feature split data?\n",
    "3. **Coefficient Magnitude**: How strongly does a feature influence linear models?\n",
    "4. **SHAP Values**: Individual feature contributions to predictions\n",
    "\n",
    "In this module, we'll explore these methods and understand when to use each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_diabetes, load_breast_cancer\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Feature importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset\n",
    "\n",
    "We'll use the diabetes dataset - predicting disease progression from medical measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "X = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "y = diabetes.target\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"  - {X.shape[0]} patients\")\n",
    "print(f\"  - {X.shape[1]} features\")\n",
    "print(f\"\\nFeatures: {list(X.columns)}\")\n",
    "print(f\"\\nTarget: Disease progression (quantitative measure)\")\n",
    "print(f\"Target range: {y.min():.1f} to {y.max():.1f}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_score = r2_score(y_train, rf_model.predict(X_train))\n",
    "test_score = r2_score(y_test, rf_model.predict(X_test))\n",
    "\n",
    "print(f\"Random Forest Performance:\")\n",
    "print(f\"  Train R²: {train_score:.3f}\")\n",
    "print(f\"  Test R²: {test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Method 1: Tree-Based Feature Importance\n",
    "\n",
    "**How it works**:\n",
    "- Trees split on features that reduce impurity most\n",
    "- Feature importance = total impurity reduction from that feature\n",
    "- Averaged across all trees in forest\n",
    "\n",
    "**Advantages**:\n",
    "- ✅ Fast (calculated during training)\n",
    "- ✅ Built into tree models\n",
    "- ✅ Captures non-linear relationships\n",
    "\n",
    "**Limitations**:\n",
    "- ❌ Biased toward high-cardinality features\n",
    "- ❌ Can be unreliable with correlated features\n",
    "- ❌ Only available for tree-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from Random Forest\n",
    "importances_rf = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "importances_rf_sorted = importances_rf.sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importance:\")\n",
    "print(importances_rf_sorted)\n",
    "print(f\"\\nSum of importances: {importances_rf_sorted.sum():.3f} (should be 1.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize tree-based importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "importances_rf_sorted.plot(kind='barh', color='forestgreen', edgecolor='black')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest Feature Importance\\n(Based on Gini Impurity Reduction)', \n",
    "         fontsize=12, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop 3 most important features:\")\n",
    "for i, (feature, importance) in enumerate(importances_rf_sorted.head(3).items(), 1):\n",
    "    print(f\"{i}. {feature}: {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Method 2: Permutation Importance\n",
    "\n",
    "**How it works**:\n",
    "1. Train model on original data\n",
    "2. For each feature:\n",
    "   - Randomly shuffle that feature's values\n",
    "   - Measure how much performance drops\n",
    "3. Larger drop = more important feature\n",
    "\n",
    "**Advantages**:\n",
    "- ✅ Works with any model (model-agnostic)\n",
    "- ✅ Intuitive interpretation\n",
    "- ✅ Reliable with correlated features\n",
    "- ✅ Based on actual performance metric\n",
    "\n",
    "**Limitations**:\n",
    "- ❌ Slower (requires re-prediction)\n",
    "- ❌ Can be unstable with small datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate permutation importance\n",
    "perm_importance = permutation_importance(\n",
    "    rf_model, \n",
    "    X_test, \n",
    "    y_test, \n",
    "    n_repeats=10,  # Repeat shuffling 10 times for stability\n",
    "    random_state=42,\n",
    "    scoring='r2'\n",
    ")\n",
    "\n",
    "# Create dataframe with results\n",
    "perm_imp_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance_mean': perm_importance.importances_mean,\n",
    "    'importance_std': perm_importance.importances_std\n",
    "}).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "print(\"Permutation Importance (on test set):\")\n",
    "print(perm_imp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize permutation importance with error bars\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "y_pos = np.arange(len(perm_imp_df))\n",
    "ax.barh(y_pos, perm_imp_df['importance_mean'], \n",
    "       xerr=perm_imp_df['importance_std'],\n",
    "       color='steelblue', edgecolor='black', capsize=5)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(perm_imp_df['feature'])\n",
    "ax.set_xlabel('Importance (Drop in R² when shuffled)')\n",
    "ax.set_title('Permutation Importance with Standard Deviation', \n",
    "            fontsize=12, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation: If shuffling 'bmi' drops R² by 0.3, then 'bmi' explains ~30% of model performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Method 3: Linear Model Coefficients\n",
    "\n",
    "**For linear models**: Feature importance = absolute coefficient value\n",
    "\n",
    "**Important**: Must standardize features first for fair comparison!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (important for coefficient comparison!)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train linear regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = pd.Series(linear_model.coef_, index=X.columns)\n",
    "coefficients_abs = coefficients.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Linear Regression Coefficients (on standardized features):\")\n",
    "print(coefficients.sort_values(key=abs, ascending=False))\n",
    "\n",
    "# Model performance\n",
    "linear_score = r2_score(y_test, linear_model.predict(X_test_scaled))\n",
    "print(f\"\\nLinear Model Test R²: {linear_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coefficients\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Raw coefficients (with sign)\n",
    "coefficients_sorted = coefficients.sort_values()\n",
    "colors = ['red' if x < 0 else 'green' for x in coefficients_sorted.values]\n",
    "axes[0].barh(range(len(coefficients_sorted)), coefficients_sorted.values, \n",
    "            color=colors, edgecolor='black')\n",
    "axes[0].set_yticks(range(len(coefficients_sorted)))\n",
    "axes[0].set_yticklabels(coefficients_sorted.index)\n",
    "axes[0].set_xlabel('Coefficient Value')\n",
    "axes[0].set_title('Linear Model Coefficients\\n(Red=Negative, Green=Positive)', \n",
    "                  fontweight='bold')\n",
    "axes[0].axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Absolute values (importance)\n",
    "axes[1].barh(range(len(coefficients_abs)), coefficients_abs.values, \n",
    "            color='coral', edgecolor='black')\n",
    "axes[1].set_yticks(range(len(coefficients_abs)))\n",
    "axes[1].set_yticklabels(coefficients_abs.index)\n",
    "axes[1].set_xlabel('Absolute Coefficient Value')\n",
    "axes[1].set_title('Feature Importance\\n(Absolute Coefficients)', fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Positive coefficient = feature increases target\")\n",
    "print(\"Negative coefficient = feature decreases target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Method 4: Correlation with Target\n",
    "\n",
    "**Simple but useful**: How strongly does each feature correlate with the target?\n",
    "\n",
    "**Limitations**: Only captures linear relationships!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation with target\n",
    "correlations = X_train.corrwith(pd.Series(y_train, index=X_train.index))\n",
    "correlations_abs = correlations.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Correlation with Target:\")\n",
    "print(correlations.sort_values(key=abs, ascending=False))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlations_sorted = correlations.sort_values()\n",
    "colors = ['red' if x < 0 else 'green' for x in correlations_sorted.values]\n",
    "plt.barh(range(len(correlations_sorted)), correlations_sorted.values, \n",
    "        color=colors, edgecolor='black')\n",
    "plt.yticks(range(len(correlations_sorted)), correlations_sorted.index)\n",
    "plt.xlabel('Correlation with Target')\n",
    "plt.title('Feature Correlation with Disease Progression', fontsize=12, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare All Methods\n",
    "\n",
    "Different methods can give different rankings! Let's compare them side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'RF Importance': importances_rf,\n",
    "    'Permutation Imp': perm_importance.importances_mean,\n",
    "    'Linear Coef (abs)': coefficients.abs(),\n",
    "    'Correlation (abs)': correlations.abs()\n",
    "})\n",
    "\n",
    "# Rank each method (1 = most important)\n",
    "for col in ['RF Importance', 'Permutation Imp', 'Linear Coef (abs)', 'Correlation (abs)']:\n",
    "    comparison_df[f'{col} Rank'] = comparison_df[col].rank(ascending=False)\n",
    "\n",
    "print(\"Feature Importance Comparison:\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.sort_values('RF Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ranking comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "methods = [\n",
    "    ('RF Importance', 'forestgreen', 'Random Forest Importance'),\n",
    "    ('Permutation Imp', 'steelblue', 'Permutation Importance'),\n",
    "    ('Linear Coef (abs)', 'coral', 'Linear Coefficients (abs)'),\n",
    "    ('Correlation (abs)', 'purple', 'Correlation with Target (abs)')\n",
    "]\n",
    "\n",
    "for idx, (col, color, title) in enumerate(methods):\n",
    "    row = idx // 2\n",
    "    col_idx = idx % 2\n",
    "    \n",
    "    data = comparison_df.sort_values(col, ascending=False)\n",
    "    axes[row, col_idx].barh(range(len(data)), data[col].values, \n",
    "                            color=color, edgecolor='black')\n",
    "    axes[row, col_idx].set_yticks(range(len(data)))\n",
    "    axes[row, col_idx].set_yticklabels(data['Feature'])\n",
    "    axes[row, col_idx].set_xlabel('Importance Score')\n",
    "    axes[row, col_idx].set_title(title, fontweight='bold')\n",
    "    axes[row, col_idx].invert_yaxis()\n",
    "    axes[row, col_idx].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNotice: Different methods prioritize different features!\")\n",
    "print(\"- Tree methods capture non-linear patterns\")\n",
    "print(\"- Linear methods capture linear relationships\")\n",
    "print(\"- Permutation shows actual impact on predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rank correlation between methods\n",
    "rank_cols = ['RF Importance Rank', 'Permutation Imp Rank', \n",
    "             'Linear Coef (abs) Rank', 'Correlation (abs) Rank']\n",
    "rank_corr = comparison_df[rank_cols].corr()\n",
    "\n",
    "print(\"Rank Correlation Between Methods:\")\n",
    "print(\"(1.0 = perfect agreement, 0.0 = no agreement)\")\n",
    "print(rank_corr)\n",
    "\n",
    "# Visualize correlation\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(rank_corr, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "           square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Agreement Between Feature Importance Methods\\n(Rank Correlation)', \n",
    "         fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHigh correlation = methods agree on important features\")\n",
    "print(\"Low correlation = methods disagree (different perspectives!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Introduction to SHAP Values\n",
    "\n",
    "**SHAP (SHapley Additive exPlanations)** provides individual feature contributions:\n",
    "- Not just global importance, but per-prediction explanations\n",
    "- Based on game theory (Shapley values)\n",
    "- Shows both magnitude and direction of impact\n",
    "\n",
    "**Note**: SHAP requires external library (`shap`). Here we demonstrate the concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual SHAP demonstration (simplified)\n",
    "print(\"SHAP Values - Conceptual Overview\\n\")\n",
    "print(\"While other methods give global feature importance,\")\n",
    "print(\"SHAP values explain individual predictions.\\n\")\n",
    "\n",
    "print(\"Example prediction breakdown:\")\n",
    "print(\"=\"*60)\n",
    "print(\"Patient ID: 42\")\n",
    "print(\"Predicted disease progression: 185\")\n",
    "print(\"\\nFeature contributions (SHAP values):\")\n",
    "print(\"  Base value (average): 150\")\n",
    "print(\"  + bmi contribution: +30\")\n",
    "print(\"  + bp contribution: +15\")\n",
    "print(\"  + s5 contribution: -10\")\n",
    "print(\"  + other features: 0\")\n",
    "print(\"  = Final prediction: 185\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nSHAP advantages:\")\n",
    "print(\"✅ Individual prediction explanations\")\n",
    "print(\"✅ Shows positive/negative contributions\")\n",
    "print(\"✅ Theoretically sound (game theory)\")\n",
    "print(\"✅ Works with any model\")\n",
    "\n",
    "print(\"\\nTo use SHAP in practice:\")\n",
    "print(\"  pip install shap\")\n",
    "print(\"  import shap\")\n",
    "print(\"  explainer = shap.TreeExplainer(model)\")\n",
    "print(\"  shap_values = explainer.shap_values(X)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exercise Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Feature Importance for Classification\n",
    "\n",
    "Apply feature importance methods to the breast cancer classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Classification feature importance\n",
    "\n",
    "# Load breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X_cancer = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y_cancer = cancer.target\n",
    "\n",
    "print(f\"Breast Cancer Dataset: {X_cancer.shape}\")\n",
    "print(f\"Features: {list(X_cancer.columns[:5])} ...\")\n",
    "\n",
    "# TODO:\n",
    "# 1. Split the data\n",
    "# 2. Train a Random Forest Classifier\n",
    "# 3. Extract feature importance\n",
    "# 4. Calculate permutation importance\n",
    "# 5. Compare the top 5 features from each method\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Exercise 1\n",
    "\n",
    "# 1. Split data\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_cancer, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer\n",
    ")\n",
    "\n",
    "# 2. Train Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train_c, y_train_c)\n",
    "print(f\"Test Accuracy: {rf_clf.score(X_test_c, y_test_c):.3f}\\n\")\n",
    "\n",
    "# 3. Feature importance\n",
    "rf_imp = pd.Series(rf_clf.feature_importances_, index=X_cancer.columns).sort_values(ascending=False)\n",
    "\n",
    "# 4. Permutation importance\n",
    "perm_imp = permutation_importance(rf_clf, X_test_c, y_test_c, \n",
    "                                  n_repeats=10, random_state=42)\n",
    "perm_imp_series = pd.Series(perm_imp.importances_mean, \n",
    "                           index=X_cancer.columns).sort_values(ascending=False)\n",
    "\n",
    "# 5. Compare top 5\n",
    "print(\"Top 5 by Random Forest Importance:\")\n",
    "print(rf_imp.head(5))\n",
    "print(\"\\nTop 5 by Permutation Importance:\")\n",
    "print(perm_imp_series.head(5))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "rf_imp.head(10).plot(kind='barh', ax=axes[0], color='forestgreen', edgecolor='black')\n",
    "axes[0].set_title('Top 10 by RF Importance', fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "perm_imp_series.head(10).plot(kind='barh', ax=axes[1], color='steelblue', edgecolor='black')\n",
    "axes[1].set_title('Top 10 by Permutation Importance', fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Verify Feature Importance\n",
    "\n",
    "Manually verify that removing top features hurts performance more than removing bottom features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Verify importance by removal\n",
    "\n",
    "# Using the diabetes dataset\n",
    "# TODO:\n",
    "# 1. Train model with ALL features\n",
    "# 2. Train model WITHOUT top 3 most important features\n",
    "# 3. Train model WITHOUT bottom 3 least important features\n",
    "# 4. Compare R² scores\n",
    "#\n",
    "# Expected: Removing top features hurts more!\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Exercise 2\n",
    "\n",
    "# Get importance ranking\n",
    "importance_ranking = importances_rf_sorted\n",
    "top_3 = importance_ranking.head(3).index.tolist()\n",
    "bottom_3 = importance_ranking.tail(3).index.tolist()\n",
    "\n",
    "print(f\"Top 3 features: {top_3}\")\n",
    "print(f\"Bottom 3 features: {bottom_3}\\n\")\n",
    "\n",
    "# 1. All features\n",
    "model_all = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_all.fit(X_train, y_train)\n",
    "r2_all = r2_score(y_test, model_all.predict(X_test))\n",
    "\n",
    "# 2. Without top 3\n",
    "features_no_top = [f for f in X.columns if f not in top_3]\n",
    "model_no_top = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_no_top.fit(X_train[features_no_top], y_train)\n",
    "r2_no_top = r2_score(y_test, model_no_top.predict(X_test[features_no_top]))\n",
    "\n",
    "# 3. Without bottom 3\n",
    "features_no_bottom = [f for f in X.columns if f not in bottom_3]\n",
    "model_no_bottom = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_no_bottom.fit(X_train[features_no_bottom], y_train)\n",
    "r2_no_bottom = r2_score(y_test, model_no_bottom.predict(X_test[features_no_bottom]))\n",
    "\n",
    "# 4. Compare\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"All features:              R² = {r2_all:.3f}\")\n",
    "print(f\"Without TOP 3 features:    R² = {r2_no_top:.3f} (drop: {r2_all - r2_no_top:.3f})\")\n",
    "print(f\"Without BOTTOM 3 features: R² = {r2_no_bottom:.3f} (drop: {r2_all - r2_no_bottom:.3f})\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nRemoving top features hurts {(r2_all - r2_no_top) / (r2_all - r2_no_bottom):.1f}x more!\")\n",
    "print(\"This confirms our importance rankings are meaningful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Interpret Model Decisions\n",
    "\n",
    "Use feature importance to understand what drives predictions for specific samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Interpret specific predictions\n",
    "\n",
    "# Pick 3 test samples\n",
    "sample_indices = [0, 10, 20]\n",
    "\n",
    "# TODO:\n",
    "# 1. Show actual features values for these samples\n",
    "# 2. Show predicted vs actual target\n",
    "# 3. Identify which features are \"unusual\" (far from mean)\n",
    "# 4. Relate feature values to importance rankings\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Exercise 3\n",
    "\n",
    "sample_indices = [0, 10, 20]\n",
    "\n",
    "for idx in sample_indices:\n",
    "    sample = X_test.iloc[idx]\n",
    "    actual = y_test.iloc[idx]\n",
    "    predicted = rf_model.predict(sample.values.reshape(1, -1))[0]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Sample {idx}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Actual disease progression: {actual:.1f}\")\n",
    "    print(f\"Predicted: {predicted:.1f}\")\n",
    "    print(f\"Error: {abs(actual - predicted):.1f}\\n\")\n",
    "    \n",
    "    # Show feature values compared to mean\n",
    "    print(\"Feature values (deviation from training mean):\")\n",
    "    train_mean = X_train.mean()\n",
    "    deviations = (sample - train_mean).abs().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 5 most unusual features (far from average):\")\n",
    "    for feature in deviations.head(5).index:\n",
    "        value = sample[feature]\n",
    "        mean_val = train_mean[feature]\n",
    "        importance = importances_rf[feature]\n",
    "        print(f\"  {feature}: {value:.3f} (mean: {mean_val:.3f}, importance: {importance:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Interpretation:\")\n",
    "print(\"- High values in important features → higher predictions\")\n",
    "print(\"- Look for unusual values in top features to explain predictions\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Feature importance helps us understand models**\n",
    "   - Debug: Are we learning the right patterns?\n",
    "   - Trust: Explain predictions to stakeholders\n",
    "   - Improve: Focus engineering on important features\n",
    "\n",
    "2. **Four main methods for feature importance**:\n",
    "   - **Tree-based**: Built-in, fast, tree-specific\n",
    "   - **Permutation**: Model-agnostic, intuitive, slower\n",
    "   - **Coefficients**: Linear models only, interpretable\n",
    "   - **SHAP**: Individual predictions, theoretically sound\n",
    "\n",
    "3. **Different methods reveal different insights**:\n",
    "   - May disagree on rankings\n",
    "   - Linear vs non-linear patterns\n",
    "   - Global vs local importance\n",
    "\n",
    "4. **Best practices**:\n",
    "   - Use multiple methods to get full picture\n",
    "   - Standardize features for linear models\n",
    "   - Verify importance by removal experiments\n",
    "   - Consider domain knowledge\n",
    "\n",
    "### When to Use Each Method\n",
    "\n",
    "**Tree-based Importance**:\n",
    "- ✅ Using tree models (RF, XGBoost)\n",
    "- ✅ Need fast results\n",
    "- ✅ Global feature ranking\n",
    "- ⚠️  Can be biased with correlated features\n",
    "\n",
    "**Permutation Importance**:\n",
    "- ✅ Any model type\n",
    "- ✅ Want model-agnostic method\n",
    "- ✅ Correlated features present\n",
    "- ❌ Slow for large datasets\n",
    "\n",
    "**Linear Coefficients**:\n",
    "- ✅ Linear/logistic regression\n",
    "- ✅ Need interpretable weights\n",
    "- ✅ Understand direction of effect\n",
    "- ❌ Only linear relationships\n",
    "\n",
    "**SHAP Values**:\n",
    "- ✅ Need individual prediction explanations\n",
    "- ✅ Compliance/regulatory requirements\n",
    "- ✅ Want theoretically sound method\n",
    "- ❌ Requires additional library\n",
    "- ❌ Computationally expensive\n",
    "\n",
    "### Practical Workflow\n",
    "\n",
    "1. **Start with built-in importance** (tree-based or coefficients)\n",
    "2. **Validate with permutation importance**\n",
    "3. **Deep dive with SHAP** for critical features\n",
    "4. **Verify with domain experts**\n",
    "5. **Test by removal** to confirm impact\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Module 10**: Automated Feature Engineering - Learn to use tools like featuretools for automatic feature creation\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [SHAP Documentation](https://shap.readthedocs.io/)\n",
    "- [Permutation Importance](https://scikit-learn.org/stable/modules/permutation_importance.html)\n",
    "- [Interpretable ML Book](https://christophm.github.io/interpretable-ml-book/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Congratulations!** You've completed Module 09. You now understand:\n",
    "- How to calculate feature importance with multiple methods\n",
    "- When to use each importance method\n",
    "- How different methods can give different insights\n",
    "- How to interpret and visualize feature importance\n",
    "- How to verify importance rankings experimentally\n",
    "\n",
    "Ready to explore automated feature engineering? Let's move to **Module 10: Automated Feature Engineering**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
