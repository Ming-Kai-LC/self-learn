{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 06: Datetime Feature Engineering\n",
    "\n",
    "**Difficulty**: ⭐⭐ Intermediate  \n",
    "**Estimated Time**: 60 minutes  \n",
    "**Prerequisites**: Module 05 (Binning and Discretization)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Extract meaningful datetime components (year, month, day, hour, dayofweek) from timestamps\n",
    "2. Create cyclical features using sine and cosine transformations for periodic patterns\n",
    "3. Engineer time-since-event features to capture temporal relationships\n",
    "4. Create binary time-based features (is_weekend, is_holiday) for categorical patterns\n",
    "5. Demonstrate how datetime features improve e-commerce sales prediction models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Datetime Features Matter\n",
    "\n",
    "**Temporal patterns are everywhere in real-world data**:\n",
    "- E-commerce sales peak on weekends and holidays\n",
    "- Traffic congestion follows hourly and daily patterns\n",
    "- Energy consumption varies by season and time of day\n",
    "- Customer behavior changes over time\n",
    "\n",
    "**Problem**: Machine learning models don't understand timestamps natively!\n",
    "\n",
    "**Solution**: Extract and engineer features that capture temporal patterns:\n",
    "- **Component extraction**: Year, month, day, hour, minute\n",
    "- **Cyclical encoding**: Handle periodic patterns (12 months, 24 hours)\n",
    "- **Time differences**: Days since event, time between events\n",
    "- **Binary indicators**: Weekend, holiday, business hours\n",
    "\n",
    "In this module, we'll use an **e-commerce sales dataset** to demonstrate these techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create E-commerce Sales Dataset\n",
    "\n",
    "We'll create a realistic e-commerce dataset with temporal patterns:\n",
    "- Higher sales on weekends\n",
    "- Peak hours during lunch (12-2pm) and evening (6-9pm)\n",
    "- Seasonal variations\n",
    "- Holiday spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2 years of hourly e-commerce data\n",
    "start_date = pd.Timestamp('2022-01-01')\n",
    "end_date = pd.Timestamp('2023-12-31 23:00:00')\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "# Create base dataframe\n",
    "ecommerce_data = pd.DataFrame({\n",
    "    'order_timestamp': date_range\n",
    "})\n",
    "\n",
    "# Base sales amount\n",
    "base_sales = 100\n",
    "\n",
    "# Add temporal patterns\n",
    "ecommerce_data['hour'] = ecommerce_data['order_timestamp'].dt.hour\n",
    "ecommerce_data['dayofweek'] = ecommerce_data['order_timestamp'].dt.dayofweek\n",
    "ecommerce_data['month'] = ecommerce_data['order_timestamp'].dt.month\n",
    "ecommerce_data['is_weekend'] = ecommerce_data['dayofweek'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Weekend boost (30% higher on weekends)\n",
    "weekend_multiplier = 1 + (0.3 * ecommerce_data['is_weekend'])\n",
    "\n",
    "# Hour pattern (peak at lunch and evening)\n",
    "hour_boost = np.where(\n",
    "    ecommerce_data['hour'].between(12, 14) | ecommerce_data['hour'].between(18, 21),\n",
    "    1.4,  # 40% boost during peak hours\n",
    "    1.0\n",
    ")\n",
    "\n",
    "# Seasonal pattern (higher in Nov-Dec holiday season)\n",
    "month_boost = np.where(\n",
    "    ecommerce_data['month'].isin([11, 12]),\n",
    "    1.5,  # 50% boost in holiday season\n",
    "    1.0\n",
    ")\n",
    "\n",
    "# Combine all patterns with some random noise\n",
    "ecommerce_data['sales_amount'] = (\n",
    "    base_sales * \n",
    "    weekend_multiplier * \n",
    "    hour_boost * \n",
    "    month_boost * \n",
    "    np.random.uniform(0.8, 1.2, len(ecommerce_data))\n",
    ").round(2)\n",
    "\n",
    "# Keep only timestamp and sales for realistic scenario\n",
    "ecommerce_data = ecommerce_data[['order_timestamp', 'sales_amount']]\n",
    "\n",
    "print(f\"Created e-commerce dataset with {len(ecommerce_data):,} hourly records\")\n",
    "print(f\"Date range: {ecommerce_data['order_timestamp'].min()} to {ecommerce_data['order_timestamp'].max()}\")\n",
    "print(f\"\\nFirst few orders:\")\n",
    "ecommerce_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sales over time\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "# Full timeline\n",
    "axes[0].plot(ecommerce_data['order_timestamp'], ecommerce_data['sales_amount'], alpha=0.6, linewidth=0.5)\n",
    "axes[0].set_title('E-commerce Sales Over Time (2 Years)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Sales Amount ($)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Zoom into one week to see patterns\n",
    "one_week = ecommerce_data[ecommerce_data['order_timestamp'].between('2023-01-01', '2023-01-07')]\n",
    "axes[1].plot(one_week['order_timestamp'], one_week['sales_amount'], marker='o', linewidth=2)\n",
    "axes[1].set_title('Sales Patterns in One Week (Notice weekend spikes and daily cycles)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Sales Amount ($)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice the patterns:\")\n",
    "print(\"- Daily fluctuations (hour-of-day pattern)\")\n",
    "print(\"- Weekly fluctuations (weekend effect)\")\n",
    "print(\"- Seasonal trends (holiday season spikes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Technique 1: Extract Datetime Components\n",
    "\n",
    "**Extract basic time units** from timestamps using pandas `.dt` accessor:\n",
    "- Year, month, day\n",
    "- Hour, minute, second\n",
    "- Day of week (0=Monday, 6=Sunday)\n",
    "- Day of year, week of year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for feature engineering\n",
    "df = ecommerce_data.copy()\n",
    "\n",
    "# Extract datetime components\n",
    "df['year'] = df['order_timestamp'].dt.year\n",
    "df['month'] = df['order_timestamp'].dt.month\n",
    "df['day'] = df['order_timestamp'].dt.day\n",
    "df['hour'] = df['order_timestamp'].dt.hour\n",
    "df['dayofweek'] = df['order_timestamp'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "df['quarter'] = df['order_timestamp'].dt.quarter\n",
    "df['dayofyear'] = df['order_timestamp'].dt.dayofyear\n",
    "df['weekofyear'] = df['order_timestamp'].dt.isocalendar().week\n",
    "\n",
    "print(\"Extracted datetime components:\")\n",
    "df[['order_timestamp', 'year', 'month', 'day', 'hour', 'dayofweek', 'quarter']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze patterns by different time components\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Sales by hour of day\n",
    "hourly_avg = df.groupby('hour')['sales_amount'].mean()\n",
    "axes[0, 0].bar(hourly_avg.index, hourly_avg.values, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Average Sales by Hour of Day', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Hour')\n",
    "axes[0, 0].set_ylabel('Average Sales ($)')\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Sales by day of week\n",
    "dow_avg = df.groupby('dayofweek')['sales_amount'].mean()\n",
    "dow_labels = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[0, 1].bar(dow_avg.index, dow_avg.values, color='lightcoral', edgecolor='black')\n",
    "axes[0, 1].set_title('Average Sales by Day of Week', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Day of Week')\n",
    "axes[0, 1].set_ylabel('Average Sales ($)')\n",
    "axes[0, 1].set_xticks(range(7))\n",
    "axes[0, 1].set_xticklabels(dow_labels)\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Sales by month\n",
    "monthly_avg = df.groupby('month')['sales_amount'].mean()\n",
    "axes[1, 0].bar(monthly_avg.index, monthly_avg.values, color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_title('Average Sales by Month', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Average Sales ($)')\n",
    "axes[1, 0].set_xticks(range(1, 13))\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Sales by quarter\n",
    "quarterly_avg = df.groupby('quarter')['sales_amount'].mean()\n",
    "axes[1, 1].bar(quarterly_avg.index, quarterly_avg.values, color='plum', edgecolor='black')\n",
    "axes[1, 1].set_title('Average Sales by Quarter', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Quarter')\n",
    "axes[1, 1].set_ylabel('Average Sales ($)')\n",
    "axes[1, 1].set_xticks(range(1, 5))\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key insights from datetime components:\")\n",
    "print(f\"- Peak sales hours: {hourly_avg.nlargest(3).index.tolist()}\")\n",
    "print(f\"- Highest sales day: {dow_labels[dow_avg.idxmax()]}\")\n",
    "print(f\"- Best performing months: {monthly_avg.nlargest(2).index.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Technique 2: Cyclical Features (Sine/Cosine Encoding)\n",
    "\n",
    "**Problem**: Month=1 (January) and Month=12 (December) are actually adjacent, but the model sees them as far apart!\n",
    "\n",
    "**Solution**: Use sine and cosine transformations to encode cyclical nature:\n",
    "- Captures that December (12) and January (1) are close\n",
    "- Preserves periodic patterns\n",
    "- Two features (sin and cos) fully encode the cycle\n",
    "\n",
    "**Formula**:\n",
    "```python\n",
    "sin_feature = sin(2 * π * value / max_value)\n",
    "cos_feature = cos(2 * π * value / max_value)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cyclical features for month (12 months cycle)\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "# Create cyclical features for hour (24 hour cycle)\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "\n",
    "# Create cyclical features for day of week (7 day cycle)\n",
    "df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "\n",
    "print(\"Cyclical features created:\")\n",
    "df[['month', 'month_sin', 'month_cos', 'hour', 'hour_sin', 'hour_cos']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cyclical encoding\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Month cyclical encoding\n",
    "months = np.arange(1, 13)\n",
    "month_sin = np.sin(2 * np.pi * months / 12)\n",
    "month_cos = np.cos(2 * np.pi * months / 12)\n",
    "\n",
    "axes[0].plot(months, month_sin, marker='o', label='sin(month)', linewidth=2)\n",
    "axes[0].plot(months, month_cos, marker='s', label='cos(month)', linewidth=2)\n",
    "axes[0].set_title('Cyclical Encoding of Months', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Month')\n",
    "axes[0].set_ylabel('Encoded Value')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(months)\n",
    "\n",
    "# Circular representation\n",
    "angles = 2 * np.pi * months / 12\n",
    "axes[1] = plt.subplot(1, 2, 2, projection='polar')\n",
    "axes[1].plot(angles, np.ones(len(months)), 'o', markersize=10)\n",
    "axes[1].set_title('Months on Unit Circle\\n(Shows cyclical nature)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xticks(angles)\n",
    "axes[1].set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                         'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Benefits of cyclical encoding:\")\n",
    "print(\"- January and December are now close in feature space\")\n",
    "print(\"- Preserves periodic patterns\")\n",
    "print(\"- Works for any cyclical variable (hours, days, months, seasons)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Technique 3: Time-Since-Event Features\n",
    "\n",
    "**Capture how long ago something happened**:\n",
    "- Days since last purchase\n",
    "- Hours since campaign launch\n",
    "- Weeks since account creation\n",
    "\n",
    "These features help models understand **recency effects**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference date: beginning of dataset\n",
    "start_of_data = df['order_timestamp'].min()\n",
    "\n",
    "# Calculate days since start of dataset\n",
    "df['days_since_start'] = (df['order_timestamp'] - start_of_data).dt.total_seconds() / (24 * 3600)\n",
    "\n",
    "# Calculate hours since start of dataset\n",
    "df['hours_since_start'] = (df['order_timestamp'] - start_of_data).dt.total_seconds() / 3600\n",
    "\n",
    "# Reference: beginning of each year (to capture yearly cycles)\n",
    "df['year_start'] = pd.to_datetime(df['year'].astype(str) + '-01-01')\n",
    "df['days_into_year'] = (df['order_timestamp'] - df['year_start']).dt.days\n",
    "\n",
    "print(\"Time-since-event features:\")\n",
    "df[['order_timestamp', 'days_since_start', 'hours_since_start', 'days_into_year']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize relationship between time elapsed and sales\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Sales vs days since start\n",
    "sample = df.sample(1000, random_state=42)  # Sample for clearer visualization\n",
    "axes[0].scatter(sample['days_since_start'], sample['sales_amount'], alpha=0.5, s=10)\n",
    "axes[0].set_title('Sales vs Days Since Start', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Days Since Start')\n",
    "axes[0].set_ylabel('Sales Amount ($)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Sales vs days into year (shows annual pattern)\n",
    "axes[1].scatter(sample['days_into_year'], sample['sales_amount'], alpha=0.5, s=10, color='orange')\n",
    "axes[1].set_title('Sales vs Days Into Year (Shows Seasonal Pattern)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Days Into Year')\n",
    "axes[1].set_ylabel('Sales Amount ($)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice the holiday season spike around day 330 (late November/December)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Technique 4: Binary Time Indicators\n",
    "\n",
    "**Create binary (0/1) features** for categorical time patterns:\n",
    "- is_weekend\n",
    "- is_holiday\n",
    "- is_business_hours\n",
    "- is_peak_season\n",
    "\n",
    "These are simple but powerful features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is weekend (Saturday=5, Sunday=6)\n",
    "df['is_weekend'] = df['dayofweek'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Is business hours (9 AM - 5 PM)\n",
    "df['is_business_hours'] = df['hour'].between(9, 17).astype(int)\n",
    "\n",
    "# Is peak hours (lunch 12-2pm or evening 6-9pm)\n",
    "df['is_peak_hours'] = (\n",
    "    df['hour'].between(12, 14) | df['hour'].between(18, 21)\n",
    ").astype(int)\n",
    "\n",
    "# Is holiday season (November-December)\n",
    "df['is_holiday_season'] = df['month'].isin([11, 12]).astype(int)\n",
    "\n",
    "# Is summer (June-August)\n",
    "df['is_summer'] = df['month'].isin([6, 7, 8]).astype(int)\n",
    "\n",
    "# Is Q4 (often highest sales quarter)\n",
    "df['is_q4'] = (df['quarter'] == 4).astype(int)\n",
    "\n",
    "print(\"Binary time indicator features:\")\n",
    "df[['order_timestamp', 'is_weekend', 'is_business_hours', \n",
    "    'is_peak_hours', 'is_holiday_season']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare sales across binary indicators\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "binary_features = [\n",
    "    ('is_weekend', 'Weekend vs Weekday'),\n",
    "    ('is_peak_hours', 'Peak Hours vs Off-Peak'),\n",
    "    ('is_holiday_season', 'Holiday Season vs Regular'),\n",
    "    ('is_business_hours', 'Business Hours vs Off-Hours')\n",
    "]\n",
    "\n",
    "for idx, (feature, title) in enumerate(binary_features):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    \n",
    "    comparison = df.groupby(feature)['sales_amount'].mean()\n",
    "    labels = ['No', 'Yes']\n",
    "    \n",
    "    bars = axes[row, col].bar(labels, comparison.values, \n",
    "                               color=['lightblue', 'salmon'], \n",
    "                               edgecolor='black')\n",
    "    axes[row, col].set_title(f'Average Sales: {title}', fontweight='bold')\n",
    "    axes[row, col].set_ylabel('Average Sales ($)')\n",
    "    axes[row, col].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[row, col].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                           f'${height:.2f}',\n",
    "                           ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Impact of binary features:\")\n",
    "for feature, title in binary_features:\n",
    "    means = df.groupby(feature)['sales_amount'].mean()\n",
    "    pct_increase = (means[1] - means[0]) / means[0] * 100\n",
    "    print(f\"- {title}: {pct_increase:+.1f}% difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Performance Comparison\n",
    "\n",
    "Let's compare model performance with different datetime feature sets:\n",
    "1. **Baseline**: No datetime features (predict average)\n",
    "2. **Basic**: Just raw components (month, hour, dayofweek)\n",
    "3. **Cyclical**: Add sine/cosine encoding\n",
    "4. **Full**: All features including time-since and binary indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (use last 3 months as test set for time series)\n",
    "split_date = '2023-10-01'\n",
    "train_data = df[df['order_timestamp'] < split_date].copy()\n",
    "test_data = df[df['order_timestamp'] >= split_date].copy()\n",
    "\n",
    "print(f\"Training set: {len(train_data):,} records ({train_data['order_timestamp'].min()} to {train_data['order_timestamp'].max()})\")\n",
    "print(f\"Test set: {len(test_data):,} records ({test_data['order_timestamp'].min()} to {test_data['order_timestamp'].max()})\")\n",
    "\n",
    "# Target variable\n",
    "y_train = train_data['sales_amount']\n",
    "y_test = test_data['sales_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature sets\n",
    "feature_sets = {\n",
    "    'Baseline (No datetime features)': [],\n",
    "    'Basic Components': ['year', 'month', 'day', 'hour', 'dayofweek', 'quarter'],\n",
    "    'Basic + Cyclical': [\n",
    "        'year', 'month', 'day', 'hour', 'dayofweek', 'quarter',\n",
    "        'month_sin', 'month_cos', 'hour_sin', 'hour_cos', \n",
    "        'dayofweek_sin', 'dayofweek_cos'\n",
    "    ],\n",
    "    'Full Feature Set': [\n",
    "        'year', 'month', 'day', 'hour', 'dayofweek', 'quarter',\n",
    "        'month_sin', 'month_cos', 'hour_sin', 'hour_cos', \n",
    "        'dayofweek_sin', 'dayofweek_cos',\n",
    "        'days_since_start', 'days_into_year',\n",
    "        'is_weekend', 'is_business_hours', 'is_peak_hours', \n",
    "        'is_holiday_season', 'is_q4'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = []\n",
    "\n",
    "for name, features in feature_sets.items():\n",
    "    if len(features) == 0:\n",
    "        # Baseline: predict mean\n",
    "        y_pred = np.full(len(y_test), y_train.mean())\n",
    "    else:\n",
    "        # Train model\n",
    "        X_train = train_data[features]\n",
    "        X_test = test_data[features]\n",
    "        \n",
    "        model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Feature Set': name,\n",
    "        'Num Features': len(features),\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R² Score': r2\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(\"=\"*80)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize improvement\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# RMSE comparison\n",
    "axes[0].barh(results_df['Feature Set'], results_df['RMSE'], color='coral', edgecolor='black')\n",
    "axes[0].set_xlabel('RMSE (Lower is Better)')\n",
    "axes[0].set_title('Model Error by Feature Set', fontsize=12, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# R² comparison\n",
    "axes[1].barh(results_df['Feature Set'], results_df['R² Score'], color='lightgreen', edgecolor='black')\n",
    "axes[1].set_xlabel('R² Score (Higher is Better)')\n",
    "axes[1].set_title('Model Performance by Feature Set', fontsize=12, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate improvement\n",
    "baseline_rmse = results_df.iloc[0]['RMSE']\n",
    "best_rmse = results_df.iloc[-1]['RMSE']\n",
    "improvement = (baseline_rmse - best_rmse) / baseline_rmse * 100\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"DATETIME FEATURE ENGINEERING IMPACT\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Error reduction: {improvement:.1f}%\")\n",
    "print(f\"R² improvement: {results_df.iloc[0]['R² Score']:.3f} → {results_df.iloc[-1]['R² Score']:.3f}\")\n",
    "print(f\"\\nBy engineering datetime features, we dramatically improved model performance!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exercise Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Traffic Volume Prediction\n",
    "\n",
    "Create datetime features for predicting hourly traffic volume. Think about what patterns exist in traffic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Traffic volume dataset\n",
    "\n",
    "# Generate hourly traffic data for 30 days\n",
    "dates = pd.date_range('2024-01-01', periods=24*30, freq='H')\n",
    "traffic_data = pd.DataFrame({'timestamp': dates})\n",
    "\n",
    "# Simulate traffic patterns\n",
    "hour = traffic_data['timestamp'].dt.hour\n",
    "dow = traffic_data['timestamp'].dt.dayofweek\n",
    "\n",
    "# Rush hour pattern (7-9 AM, 5-7 PM on weekdays)\n",
    "traffic_data['volume'] = (\n",
    "    1000 +  # Base traffic\n",
    "    500 * ((hour.between(7, 9) | hour.between(17, 19)) & (dow < 5)) +  # Rush hour\n",
    "    200 * (dow >= 5) +  # Weekend boost\n",
    "    np.random.normal(0, 100, len(traffic_data))  # Noise\n",
    ")\n",
    "\n",
    "print(\"Traffic dataset created:\")\n",
    "traffic_data.head()\n",
    "\n",
    "# TODO: Create these datetime features:\n",
    "# 1. Basic components (hour, dayofweek)\n",
    "# 2. Cyclical encoding for hour\n",
    "# 3. is_rush_hour (7-9 AM or 5-7 PM on weekdays)\n",
    "# 4. is_weekday\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Exercise 1\n",
    "\n",
    "# 1. Basic components\n",
    "traffic_data['hour'] = traffic_data['timestamp'].dt.hour\n",
    "traffic_data['dayofweek'] = traffic_data['timestamp'].dt.dayofweek\n",
    "\n",
    "# 2. Cyclical encoding for hour\n",
    "traffic_data['hour_sin'] = np.sin(2 * np.pi * traffic_data['hour'] / 24)\n",
    "traffic_data['hour_cos'] = np.cos(2 * np.pi * traffic_data['hour'] / 24)\n",
    "\n",
    "# 3. is_rush_hour\n",
    "traffic_data['is_rush_hour'] = (\n",
    "    (traffic_data['hour'].between(7, 9) | traffic_data['hour'].between(17, 19)) & \n",
    "    (traffic_data['dayofweek'] < 5)\n",
    ").astype(int)\n",
    "\n",
    "# 4. is_weekday\n",
    "traffic_data['is_weekday'] = (traffic_data['dayofweek'] < 5).astype(int)\n",
    "\n",
    "print(\"Traffic features created:\")\n",
    "traffic_data[['timestamp', 'volume', 'hour', 'hour_sin', 'hour_cos', \n",
    "              'is_rush_hour', 'is_weekday']].head(10)\n",
    "\n",
    "# Verify rush hour impact\n",
    "print(\"\\nAverage volume:\")\n",
    "print(f\"Rush hour: {traffic_data[traffic_data['is_rush_hour']==1]['volume'].mean():.0f}\")\n",
    "print(f\"Non-rush hour: {traffic_data[traffic_data['is_rush_hour']==0]['volume'].mean():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Customer Subscription Prediction\n",
    "\n",
    "Create time-since features to predict customer behavior based on account age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Customer subscription data\n",
    "\n",
    "# Simulate customer accounts created over 2 years\n",
    "account_created = pd.date_range('2022-01-01', '2024-01-01', periods=1000)\n",
    "current_date = pd.Timestamp('2024-03-01')\n",
    "\n",
    "customer_data = pd.DataFrame({\n",
    "    'customer_id': range(1000),\n",
    "    'account_created_date': account_created,\n",
    "    'last_purchase_date': account_created + pd.to_timedelta(np.random.randint(0, 365, 1000), unit='D')\n",
    "})\n",
    "\n",
    "print(\"Customer dataset:\")\n",
    "customer_data.head()\n",
    "\n",
    "# TODO: Create these time-since features (using current_date as reference):\n",
    "# 1. days_since_signup: Days between account creation and current date\n",
    "# 2. days_since_last_purchase: Days between last purchase and current date\n",
    "# 3. account_age_months: Account age in months\n",
    "# 4. is_new_customer: 1 if account < 90 days old, 0 otherwise\n",
    "# 5. is_dormant: 1 if last purchase > 180 days ago, 0 otherwise\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Exercise 2\n",
    "\n",
    "current_date = pd.Timestamp('2024-03-01')\n",
    "\n",
    "# 1. Days since signup\n",
    "customer_data['days_since_signup'] = (current_date - customer_data['account_created_date']).dt.days\n",
    "\n",
    "# 2. Days since last purchase\n",
    "customer_data['days_since_last_purchase'] = (current_date - customer_data['last_purchase_date']).dt.days\n",
    "\n",
    "# 3. Account age in months\n",
    "customer_data['account_age_months'] = customer_data['days_since_signup'] / 30.44  # Average days per month\n",
    "\n",
    "# 4. Is new customer\n",
    "customer_data['is_new_customer'] = (customer_data['days_since_signup'] < 90).astype(int)\n",
    "\n",
    "# 5. Is dormant\n",
    "customer_data['is_dormant'] = (customer_data['days_since_last_purchase'] > 180).astype(int)\n",
    "\n",
    "print(\"Customer time-since features:\")\n",
    "customer_data.head(10)\n",
    "\n",
    "print(\"\\nCustomer segments:\")\n",
    "print(f\"New customers: {customer_data['is_new_customer'].sum()} ({customer_data['is_new_customer'].mean()*100:.1f}%)\")\n",
    "print(f\"Dormant customers: {customer_data['is_dormant'].sum()} ({customer_data['is_dormant'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Energy Consumption Prediction\n",
    "\n",
    "Create a complete set of datetime features for predicting hourly energy consumption. Combine all techniques learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Energy consumption data\n",
    "\n",
    "# Generate hourly energy data for 1 year\n",
    "dates = pd.date_range('2023-01-01', '2023-12-31 23:00:00', freq='H')\n",
    "energy_data = pd.DataFrame({'timestamp': dates})\n",
    "\n",
    "# Simulate energy patterns (higher in winter/summer, peak hours, weekday patterns)\n",
    "hour = energy_data['timestamp'].dt.hour\n",
    "month = energy_data['timestamp'].dt.month\n",
    "dow = energy_data['timestamp'].dt.dayofweek\n",
    "\n",
    "energy_data['consumption_kwh'] = (\n",
    "    500 +  # Base consumption\n",
    "    200 * ((month <= 2) | (month >= 11)) +  # Winter heating\n",
    "    150 * (month.isin([6, 7, 8])) +  # Summer AC\n",
    "    100 * (hour.between(18, 22)) +  # Evening peak\n",
    "    -50 * (dow >= 5) +  # Lower on weekends\n",
    "    np.random.normal(0, 50, len(energy_data))  # Noise\n",
    ")\n",
    "\n",
    "print(\"Energy dataset created:\")\n",
    "energy_data.head()\n",
    "\n",
    "# TODO: Create a comprehensive datetime feature set:\n",
    "# 1. Basic components (hour, dayofweek, month)\n",
    "# 2. Cyclical features (hour_sin/cos, month_sin/cos)\n",
    "# 3. Binary indicators (is_weekend, is_winter, is_summer, is_peak_hours)\n",
    "# 4. Time-based (days_into_year)\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to Exercise 3\n",
    "\n",
    "# 1. Basic components\n",
    "energy_data['hour'] = energy_data['timestamp'].dt.hour\n",
    "energy_data['dayofweek'] = energy_data['timestamp'].dt.dayofweek\n",
    "energy_data['month'] = energy_data['timestamp'].dt.month\n",
    "energy_data['quarter'] = energy_data['timestamp'].dt.quarter\n",
    "\n",
    "# 2. Cyclical features\n",
    "energy_data['hour_sin'] = np.sin(2 * np.pi * energy_data['hour'] / 24)\n",
    "energy_data['hour_cos'] = np.cos(2 * np.pi * energy_data['hour'] / 24)\n",
    "energy_data['month_sin'] = np.sin(2 * np.pi * energy_data['month'] / 12)\n",
    "energy_data['month_cos'] = np.cos(2 * np.pi * energy_data['month'] / 12)\n",
    "\n",
    "# 3. Binary indicators\n",
    "energy_data['is_weekend'] = (energy_data['dayofweek'] >= 5).astype(int)\n",
    "energy_data['is_winter'] = energy_data['month'].isin([12, 1, 2]).astype(int)\n",
    "energy_data['is_summer'] = energy_data['month'].isin([6, 7, 8]).astype(int)\n",
    "energy_data['is_peak_hours'] = energy_data['hour'].between(18, 22).astype(int)\n",
    "\n",
    "# 4. Time-based features\n",
    "year_start = pd.Timestamp('2023-01-01')\n",
    "energy_data['days_into_year'] = (energy_data['timestamp'] - year_start).dt.days\n",
    "\n",
    "print(\"Complete feature set for energy prediction:\")\n",
    "print(f\"Total features created: {len(energy_data.columns) - 2}\")  # Minus timestamp and consumption\n",
    "energy_data.head()\n",
    "\n",
    "# Quick model test\n",
    "features = ['hour_sin', 'hour_cos', 'month_sin', 'month_cos', \n",
    "            'is_weekend', 'is_winter', 'is_summer', 'is_peak_hours']\n",
    "X = energy_data[features]\n",
    "y = energy_data['consumption_kwh']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\nModel R² Score with datetime features: {r2:.3f}\")\n",
    "print(\"Excellent! Datetime features captured the energy consumption patterns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Datetime features unlock temporal patterns** that models can't see in raw timestamps\n",
    "   - Improved our e-commerce sales prediction significantly\n",
    "   - Essential for any time-series or temporal prediction task\n",
    "\n",
    "2. **Four core techniques for datetime feature engineering**:\n",
    "   - **Component extraction**: Year, month, day, hour, dayofweek, quarter\n",
    "   - **Cyclical encoding**: Sin/cos transformations for periodic patterns\n",
    "   - **Time-since features**: Days since event, hours elapsed, account age\n",
    "   - **Binary indicators**: is_weekend, is_holiday, is_peak_hours\n",
    "\n",
    "3. **Cyclical encoding is critical** for truly periodic variables:\n",
    "   - Month 12 (December) and Month 1 (January) are adjacent!\n",
    "   - Use both sin and cos to fully encode the cycle\n",
    "   - Works for hours, days, months, seasons\n",
    "\n",
    "4. **Domain knowledge drives feature selection**:\n",
    "   - E-commerce: weekends, holidays, peak hours\n",
    "   - Traffic: rush hour, weekday patterns\n",
    "   - Energy: seasonal patterns, time of day\n",
    "\n",
    "5. **Time-based features capture relationships**:\n",
    "   - Recency effects (days since last event)\n",
    "   - Account age and lifecycle stages\n",
    "   - Temporal distance from important events\n",
    "\n",
    "### When to Use Datetime Features\n",
    "\n",
    "✅ **Use when**:\n",
    "- Data has timestamp information\n",
    "- Known periodic patterns exist (daily, weekly, seasonal)\n",
    "- Predicting time-dependent outcomes\n",
    "- Historical events matter (recency, frequency)\n",
    "\n",
    "❌ **Skip when**:\n",
    "- Data has no temporal component\n",
    "- Time is irrelevant to prediction\n",
    "- Very short time periods with no patterns\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Start with exploratory analysis**: Plot data over time to identify patterns\n",
    "2. **Use cyclical encoding** for truly periodic features (hours, months)\n",
    "3. **Create domain-specific features**: Think about what matters in your domain\n",
    "4. **Test incremental impact**: Add feature groups and measure improvement\n",
    "5. **Handle time zones carefully**: Be consistent with UTC or local time\n",
    "6. **Consider holidays**: Country-specific holidays often matter\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**Module 07**: Text Feature Engineering - Learn TF-IDF, n-grams, and text vectorization for NLP tasks\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Pandas datetime documentation](https://pandas.pydata.org/docs/user_guide/timeseries.html)\n",
    "- [Feature Engineering for Time Series](https://machinelearningmastery.com/basic-feature-engineering-time-series-data-python/)\n",
    "- [Cyclical Features Blog Post](https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Congratulations!** You've completed Module 06. You now understand:\n",
    "- How to extract datetime components from timestamps\n",
    "- Why and how to create cyclical features with sin/cos\n",
    "- How to engineer time-since-event features\n",
    "- When to use binary time indicators\n",
    "- The dramatic impact of datetime features on model performance\n",
    "\n",
    "Ready to work with text data? Let's move to **Module 07: Text Feature Engineering**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
