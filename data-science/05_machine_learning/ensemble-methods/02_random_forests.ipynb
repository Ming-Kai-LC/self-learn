{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 02: Random Forests\n",
    "\n",
    "**Difficulty**: ⭐⭐⭐ Advanced\n",
    "**Estimated Time**: 75 minutes\n",
    "**Prerequisites**: \n",
    "- Module 00: Introduction to Ensemble Learning\n",
    "- Module 01: Bagging and Bootstrap\n",
    "- Decision Trees fundamentals\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand how Random Forests extend bagging with feature randomness\n",
    "2. Tune key hyperparameters for optimal performance\n",
    "3. Extract and visualize feature importance\n",
    "4. Use out-of-bag evaluation for model validation\n",
    "5. Handle imbalanced datasets with Random Forests\n",
    "6. Compare Random Forest performance with standard bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.datasets import make_classification, load_breast_cancer, load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, \n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"Setup complete! All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What Makes Random Forests Special?\n",
    "\n",
    "### From Bagging to Random Forests\n",
    "\n",
    "Random Forests build on bagging with an additional layer of randomness:\n",
    "\n",
    "**Standard Bagging**:\n",
    "1. Create bootstrap samples (random rows)\n",
    "2. Train decision tree on each sample\n",
    "3. Each tree considers ALL features at every split\n",
    "\n",
    "**Random Forests**:\n",
    "1. Create bootstrap samples (random rows)\n",
    "2. Train decision tree on each sample\n",
    "3. **Each split considers random subset of features** ← Key difference!\n",
    "\n",
    "### Why Feature Randomness Matters\n",
    "\n",
    "**Problem with standard bagging**:\n",
    "- If one feature is very strong, most trees will split on it first\n",
    "- Trees become correlated (similar structure)\n",
    "- Averaging correlated predictions provides less benefit\n",
    "\n",
    "**Solution with Random Forests**:\n",
    "- Force trees to consider different features\n",
    "- Creates diverse trees with different structures\n",
    "- Reduces correlation → better ensemble performance\n",
    "\n",
    "**Mathematical insight**: \n",
    "- Variance of average of correlated variables: $\\text{Var}(\\bar{X}) = \\rho\\sigma^2 + \\frac{1-\\rho}{n}\\sigma^2$\n",
    "- Lower correlation ($\\rho$) → lower variance → better predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration: Bagging vs Random Forest tree correlation\n",
    "# Create dataset with one dominant feature\n",
    "X, y = make_classification(\n",
    "    n_samples=500,\n",
    "    n_features=10,\n",
    "    n_informative=10,\n",
    "    n_redundant=0,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Make first feature very strong by adding signal\n",
    "X[:, 0] = X[:, 0] + 2 * y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Standard Bagging (considers all features at each split)\n",
    "bagging_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    n_estimators=100,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest (considers sqrt(n_features) at each split)\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions from individual trees for correlation analysis\n",
    "bagging_tree_preds = np.array([tree.predict(X_test) for tree in bagging_model.estimators_])\n",
    "rf_tree_preds = np.array([tree.predict(X_test) for tree in rf_model.estimators_])\n",
    "\n",
    "# Calculate average pairwise correlation\n",
    "def calculate_avg_correlation(predictions):\n",
    "    \"\"\"Calculate average correlation between tree predictions.\"\"\"\n",
    "    corr_matrix = np.corrcoef(predictions)\n",
    "    # Get upper triangle (excluding diagonal)\n",
    "    upper_triangle = corr_matrix[np.triu_indices_from(corr_matrix, k=1)]\n",
    "    return np.mean(upper_triangle)\n",
    "\n",
    "bagging_corr = calculate_avg_correlation(bagging_tree_preds)\n",
    "rf_corr = calculate_avg_correlation(rf_tree_preds)\n",
    "\n",
    "print(\"Tree Correlation Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Bagging - Average tree correlation: {bagging_corr:.4f}\")\n",
    "print(f\"Random Forest - Average tree correlation: {rf_corr:.4f}\")\n",
    "print(f\"\\nCorrelation reduction: {((bagging_corr - rf_corr) / bagging_corr * 100):.1f}%\")\n",
    "print(\"\\nLower correlation means more diverse trees!\")\n",
    "\n",
    "# Compare performance\n",
    "bagging_score = accuracy_score(y_test, bagging_model.predict(X_test))\n",
    "rf_score = accuracy_score(y_test, rf_model.predict(X_test))\n",
    "\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Bagging accuracy: {bagging_score:.4f}\")\n",
    "print(f\"Random Forest accuracy: {rf_score:.4f}\")\n",
    "print(f\"Improvement: {((rf_score - bagging_score) / bagging_score * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Key Hyperparameters\n",
    "\n",
    "### Understanding Random Forest Parameters\n",
    "\n",
    "Random Forests have many tunable parameters. Here are the most important:\n",
    "\n",
    "#### 2.1 Ensemble Parameters\n",
    "\n",
    "**`n_estimators`**: Number of trees in the forest\n",
    "- **Higher** → Better performance (but diminishing returns)\n",
    "- **Higher** → Longer training time\n",
    "- Typical values: 100-500\n",
    "- Rule of thumb: Start with 100, increase if you have computational resources\n",
    "\n",
    "**`max_features`**: Number of features to consider at each split\n",
    "- **Lower** → More randomness, less correlation between trees\n",
    "- **Higher** → Each tree is stronger individually\n",
    "- Default for classification: `sqrt(n_features)`\n",
    "- Default for regression: `n_features / 3`\n",
    "- Most important parameter for controlling tree diversity!\n",
    "\n",
    "#### 2.2 Tree Parameters\n",
    "\n",
    "**`max_depth`**: Maximum depth of each tree\n",
    "- **Higher** → More complex trees, can capture intricate patterns\n",
    "- **Higher** → Risk of overfitting\n",
    "- Default: `None` (trees grow until pure)\n",
    "- Consider limiting if you have noisy data\n",
    "\n",
    "**`min_samples_split`**: Minimum samples required to split a node\n",
    "- **Higher** → Simpler trees, more regularization\n",
    "- Default: 2\n",
    "- Increase to prevent overfitting\n",
    "\n",
    "**`min_samples_leaf`**: Minimum samples required in a leaf node\n",
    "- **Higher** → Smoother decision boundaries\n",
    "- Default: 1\n",
    "- Useful for imbalanced datasets\n",
    "\n",
    "#### 2.3 Special Parameters\n",
    "\n",
    "**`oob_score`**: Use out-of-bag samples for validation\n",
    "- Set to `True` to get free validation score\n",
    "- No need for separate validation set!\n",
    "\n",
    "**`class_weight`**: Handle imbalanced classes\n",
    "- Set to `'balanced'` for automatic weighting\n",
    "- Or provide custom weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning demonstration\n",
    "# Load a real dataset for realistic tuning\n",
    "cancer_data = load_breast_cancer()\n",
    "X, y = cancer_data.data, cancer_data.target\n",
    "feature_names = cancer_data.feature_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Dataset: {len(X_train)} training samples, {len(X_test)} test samples\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Classes: {np.unique(y)}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of n_estimators\n",
    "n_estimators_range = [10, 25, 50, 100, 200, 300, 500]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for n_est in n_estimators_range:\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    train_scores.append(accuracy_score(y_train, rf.predict(X_train)))\n",
    "    test_scores.append(accuracy_score(y_test, rf.predict(X_test)))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_estimators_range, train_scores, marker='o', label='Training Accuracy', linewidth=2)\n",
    "plt.plot(n_estimators_range, test_scores, marker='s', label='Test Accuracy', linewidth=2)\n",
    "plt.xlabel('Number of Trees (n_estimators)', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Effect of Number of Trees on Performance', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(f\"- Performance stabilizes around {n_estimators_range[np.argmax(np.diff(test_scores) > -0.001)]} trees\")\n",
    "print(f\"- Best test accuracy: {max(test_scores):.4f}\")\n",
    "print(\"- Adding more trees after stabilization provides minimal benefit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of max_features\n",
    "n_features = X_train.shape[1]\n",
    "max_features_range = [2, 4, 6, int(np.sqrt(n_features)), 10, 15, 20, n_features]\n",
    "max_features_scores = []\n",
    "\n",
    "for max_feat in max_features_range:\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=100, \n",
    "        max_features=min(max_feat, n_features),\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    # Use cross-validation for more robust estimates\n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=5)\n",
    "    max_features_scores.append(scores.mean())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_features_range, max_features_scores, marker='o', linewidth=2, markersize=8)\n",
    "plt.axvline(int(np.sqrt(n_features)), color='red', linestyle='--', \n",
    "            label=f'Default (sqrt={int(np.sqrt(n_features))})', linewidth=2)\n",
    "plt.xlabel('Max Features per Split', fontsize=12)\n",
    "plt.ylabel('Cross-Validation Accuracy', fontsize=12)\n",
    "plt.title('Effect of Feature Randomness (max_features)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_idx = np.argmax(max_features_scores)\n",
    "print(f\"\\nBest max_features: {max_features_range[best_idx]}\")\n",
    "print(f\"Default (sqrt): {int(np.sqrt(n_features))}\")\n",
    "print(f\"\\nThe default sqrt value is often near-optimal!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for best hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['sqrt', 'log2', 10],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create base model\n",
    "rf_base = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "# Grid search with cross-validation\n",
    "print(\"Running grid search... This may take a minute.\")\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(\"=\" * 50)\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"{param:20s}: {value}\")\n",
    "\n",
    "print(f\"\\nBest CV Score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Test Score: {grid_search.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance\n",
    "\n",
    "Random Forests provide powerful feature importance metrics, helping us understand which features drive predictions.\n",
    "\n",
    "### Types of Feature Importance\n",
    "\n",
    "#### 3.1 Impurity-Based Importance (Default)\n",
    "- Measures average decrease in impurity (Gini or entropy) from splits on that feature\n",
    "- Fast to compute (available after training)\n",
    "- **Caveat**: Biased toward high-cardinality features\n",
    "\n",
    "#### 3.2 Permutation Importance\n",
    "- Measures performance drop when feature values are randomly shuffled\n",
    "- More reliable and unbiased\n",
    "- **Caveat**: Slower to compute (requires multiple predictions)\n",
    "\n",
    "### Why Feature Importance Matters\n",
    "\n",
    "1. **Model interpretation**: Understand what drives predictions\n",
    "2. **Feature selection**: Identify and remove irrelevant features\n",
    "3. **Domain validation**: Check if important features make sense\n",
    "4. **Debugging**: Detect data leakage or problematic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest for feature importance analysis\n",
    "rf_importance = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_importance.fit(X_train, y_train)\n",
    "\n",
    "# Method 1: Impurity-based importance\n",
    "impurity_importance = rf_importance.feature_importances_\n",
    "\n",
    "# Method 2: Permutation importance\n",
    "perm_importance = permutation_importance(\n",
    "    rf_importance, X_test, y_test, \n",
    "    n_repeats=10, random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Impurity_Importance': impurity_importance,\n",
    "    'Permutation_Importance': perm_importance.importances_mean,\n",
    "    'Permutation_Std': perm_importance.importances_std\n",
    "}).sort_values('Impurity_Importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(\"=\" * 80)\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Plot 1: Impurity-based importance\n",
    "top_features = importance_df.head(15)\n",
    "axes[0].barh(range(len(top_features)), top_features['Impurity_Importance'], color='steelblue')\n",
    "axes[0].set_yticks(range(len(top_features)))\n",
    "axes[0].set_yticklabels(top_features['Feature'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[0].set_title('Impurity-Based Feature Importance\\n(Fast, may be biased)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 2: Permutation importance with error bars\n",
    "top_perm = importance_df.sort_values('Permutation_Importance', ascending=False).head(15)\n",
    "axes[1].barh(range(len(top_perm)), top_perm['Permutation_Importance'], \n",
    "             xerr=top_perm['Permutation_Std'], color='coral', capsize=3)\n",
    "axes[1].set_yticks(range(len(top_perm)))\n",
    "axes[1].set_yticklabels(top_perm['Feature'])\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[1].set_title('Permutation Feature Importance\\n(Slower, more reliable)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Both methods identify similar top features (good sign!)\")\n",
    "print(\"- Permutation importance error bars show stability\")\n",
    "print(\"- Features with zero importance can be removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Out-of-Bag (OOB) Evaluation\n",
    "\n",
    "### Free Validation Without a Validation Set!\n",
    "\n",
    "**Key insight**: Each tree in a Random Forest is trained on a bootstrap sample (sampling with replacement). On average, each bootstrap sample contains ~63% of the data.\n",
    "\n",
    "**The remaining ~37% of samples** (out-of-bag samples) were never seen by that tree.\n",
    "\n",
    "**OOB evaluation**:\n",
    "1. For each sample, find all trees that didn't see it during training\n",
    "2. Use only those trees to make a prediction\n",
    "3. Compare predictions to true labels\n",
    "4. Result: unbiased performance estimate without separate validation set!\n",
    "\n",
    "### Benefits\n",
    "- No need to split off validation data\n",
    "- Get performance estimate during training\n",
    "- Particularly useful for small datasets\n",
    "- Almost as good as cross-validation but much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate OOB evaluation\n",
    "# Train Random Forest with OOB scoring enabled\n",
    "rf_oob = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    oob_score=True,  # Enable OOB evaluation\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_oob.fit(X_train, y_train)\n",
    "\n",
    "# Compare OOB score with test score\n",
    "oob_score = rf_oob.oob_score_\n",
    "test_score = rf_oob.score(X_test, y_test)\n",
    "train_score = rf_oob.score(X_train, y_train)\n",
    "\n",
    "print(\"Performance Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training Score:   {train_score:.4f}\")\n",
    "print(f\"OOB Score:        {oob_score:.4f}  ← Free validation!\")\n",
    "print(f\"Test Score:       {test_score:.4f}\")\n",
    "print(f\"\\nOOB vs Test difference: {abs(oob_score - test_score):.4f}\")\n",
    "print(\"\\nOOB score is very close to test score without using test data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOB score vs number of trees\n",
    "# Shows how OOB estimate stabilizes with more trees\n",
    "n_trees_range = range(10, 201, 10)\n",
    "oob_scores = []\n",
    "\n",
    "for n_trees in n_trees_range:\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n_trees,\n",
    "        oob_score=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    oob_scores.append(rf.oob_score_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_trees_range, oob_scores, marker='o', linewidth=2)\n",
    "plt.axhline(test_score, color='red', linestyle='--', \n",
    "            label=f'Actual Test Score: {test_score:.4f}', linewidth=2)\n",
    "plt.xlabel('Number of Trees', fontsize=12)\n",
    "plt.ylabel('OOB Score', fontsize=12)\n",
    "plt.title('OOB Score Stabilization', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOOB score converges to test score as we add more trees!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handling Imbalanced Data\n",
    "\n",
    "### The Imbalanced Class Problem\n",
    "\n",
    "**Problem**: When one class is much more common than another (e.g., fraud detection, disease diagnosis)\n",
    "- Model may achieve high accuracy by always predicting majority class\n",
    "- Fails to learn minority class patterns\n",
    "\n",
    "### Random Forest Solutions\n",
    "\n",
    "#### 5.1 Class Weighting\n",
    "- Set `class_weight='balanced'`\n",
    "- Automatically adjusts weights inversely proportional to class frequencies\n",
    "- Formula: $w_i = \\frac{n_{\\text{samples}}}{n_{\\text{classes}} \\times n_{\\text{samples in class } i}}$\n",
    "\n",
    "#### 5.2 Balanced Bootstrap Sampling\n",
    "- Set `class_weight='balanced_subsample'`\n",
    "- Adjusts weights for each bootstrap sample\n",
    "- More adaptive to local class distributions\n",
    "\n",
    "#### 5.3 Custom Sampling Strategy\n",
    "- Manually oversample minority class or undersample majority class\n",
    "- Use libraries like imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create imbalanced dataset\n",
    "X_imb, y_imb = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    weights=[0.95, 0.05],  # 95% class 0, 5% class 1\n",
    "    flip_y=0.01,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_train_imb, X_test_imb, y_train_imb, y_test_imb = train_test_split(\n",
    "    X_imb, y_imb, test_size=0.3, random_state=RANDOM_STATE, stratify=y_imb\n",
    ")\n",
    "\n",
    "print(\"Imbalanced Dataset:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training class distribution: {np.bincount(y_train_imb)}\")\n",
    "print(f\"Imbalance ratio: {np.bincount(y_train_imb)[0] / np.bincount(y_train_imb)[1]:.1f}:1\")\n",
    "print(f\"\\nMinority class: {np.bincount(y_train_imb)[1]} samples ({np.bincount(y_train_imb)[1]/len(y_train_imb)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different approaches\n",
    "# 1. Standard Random Forest (no balancing)\n",
    "rf_standard = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_standard.fit(X_train_imb, y_train_imb)\n",
    "\n",
    "# 2. Balanced class weights\n",
    "rf_balanced = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    class_weight='balanced',\n",
    "    random_state=RANDOM_STATE, \n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_balanced.fit(X_train_imb, y_train_imb)\n",
    "\n",
    "# 3. Balanced subsample\n",
    "rf_balanced_subsample = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=RANDOM_STATE, \n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_balanced_subsample.fit(X_train_imb, y_train_imb)\n",
    "\n",
    "# Evaluate all models\n",
    "models = [\n",
    "    ('Standard RF', rf_standard),\n",
    "    ('Balanced Weights', rf_balanced),\n",
    "    ('Balanced Subsample', rf_balanced_subsample)\n",
    "]\n",
    "\n",
    "print(\"\\nPerformance on Imbalanced Data:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, model in models:\n",
    "    y_pred = model.predict(X_test_imb)\n",
    "    y_pred_proba = model.predict_proba(X_test_imb)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_imb, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test_imb, y_pred_proba)\n",
    "    \n",
    "    # Get per-class metrics from classification report\n",
    "    report = classification_report(y_test_imb, y_pred, output_dict=True)\n",
    "    minority_recall = report['1']['recall']\n",
    "    minority_precision = report['1']['precision']\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Accuracy:           {accuracy:.4f}\")\n",
    "    print(f\"  ROC-AUC:            {roc_auc:.4f}\")\n",
    "    print(f\"  Minority Recall:    {minority_recall:.4f}  ← Can we find minority class?\")\n",
    "    print(f\"  Minority Precision: {minority_precision:.4f}  ← Are predictions reliable?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, model in models:\n",
    "    y_pred_proba = model.predict_proba(X_test_imb)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test_imb, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test_imb, y_pred_proba)\n",
    "    \n",
    "    plt.plot(fpr, tpr, linewidth=2, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves: Handling Imbalanced Data', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10, loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight:\")\n",
    "print(\"Balanced approaches improve minority class detection!\")\n",
    "print(\"Choose based on your use case:\")\n",
    "print(\"- High precision needed? Use standard or tune threshold\")\n",
    "print(\"- High recall needed? Use balanced weights\")\n",
    "print(\"- Best overall? Balanced subsample often wins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison: Bagging vs Random Forest\n",
    "\n",
    "Let's solidify understanding by directly comparing standard bagging with Random Forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive comparison on wine dataset\n",
    "wine_data = load_wine()\n",
    "X_wine, y_wine = wine_data.data, wine_data.target\n",
    "\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(\n",
    "    X_wine, y_wine, test_size=0.3, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Standard Bagging\n",
    "bagging = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    n_estimators=100,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Compare with cross-validation\n",
    "bagging_scores = cross_val_score(bagging, X_wine, y_wine, cv=10)\n",
    "rf_scores = cross_val_score(rf, X_wine, y_wine, cv=10)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison = pd.DataFrame({\n",
    "    'Method': ['Bagging', 'Random Forest'],\n",
    "    'Mean Accuracy': [bagging_scores.mean(), rf_scores.mean()],\n",
    "    'Std Accuracy': [bagging_scores.std(), rf_scores.std()],\n",
    "    'Min Accuracy': [bagging_scores.min(), rf_scores.min()],\n",
    "    'Max Accuracy': [bagging_scores.max(), rf_scores.max()]\n",
    "})\n",
    "\n",
    "print(\"Bagging vs Random Forest (10-Fold CV):\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot\n",
    "axes[0].boxplot([bagging_scores, rf_scores], labels=['Bagging', 'Random Forest'])\n",
    "axes[0].set_ylabel('Accuracy', fontsize=11)\n",
    "axes[0].set_title('Cross-Validation Score Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Bar plot with error bars\n",
    "x = np.arange(2)\n",
    "means = [bagging_scores.mean(), rf_scores.mean()]\n",
    "stds = [bagging_scores.std(), rf_scores.std()]\n",
    "axes[1].bar(x, means, yerr=stds, capsize=5, alpha=0.7, \n",
    "            color=['steelblue', 'coral'], edgecolor='black')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(['Bagging', 'Random Forest'])\n",
    "axes[1].set_ylabel('Accuracy', fontsize=11)\n",
    "axes[1].set_title('Mean Accuracy with Std Dev', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "improvement = (rf_scores.mean() - bagging_scores.mean()) / bagging_scores.mean() * 100\n",
    "print(f\"Random Forest improves over Bagging by {improvement:.2f}%\")\n",
    "print(\"Feature randomness creates more diverse trees → better ensemble!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Test your understanding of Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Optimal max_features Investigation\n",
    "\n",
    "Create a classification dataset with 50 features where:\n",
    "- 10 features are highly informative\n",
    "- 40 features are noise\n",
    "\n",
    "Train Random Forests with different `max_features` values (1, 5, 10, 'sqrt', 'log2', all features) and compare:\n",
    "1. Cross-validation accuracy\n",
    "2. Training time\n",
    "3. Tree correlation (use predictions to calculate correlation)\n",
    "\n",
    "**Questions**:\n",
    "- How does max_features affect tree diversity?\n",
    "- What's the optimal value for this dataset?\n",
    "- Why doesn't using all features give the best result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Feature Selection with Random Forests\n",
    "\n",
    "Use the breast cancer dataset and:\n",
    "1. Train a Random Forest and get feature importances\n",
    "2. Identify features with near-zero importance\n",
    "3. Train a new Random Forest using only top N most important features\n",
    "4. Compare performance and training time\n",
    "\n",
    "**Find the optimal N** that gives best validation accuracy with fewest features.\n",
    "\n",
    "Bonus: Plot the Pareto frontier showing accuracy vs number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Severe Imbalance Challenge\n",
    "\n",
    "Create an extremely imbalanced dataset (99:1 ratio) and implement three strategies:\n",
    "\n",
    "1. **Approach 1**: Random Forest with `class_weight='balanced'`\n",
    "2. **Approach 2**: Manual oversampling of minority class + standard Random Forest\n",
    "3. **Approach 3**: Adjust decision threshold on predicted probabilities\n",
    "\n",
    "For each approach, calculate and compare:\n",
    "- Accuracy\n",
    "- Precision and Recall for minority class\n",
    "- F1-score\n",
    "- ROC-AUC\n",
    "\n",
    "**Which approach works best and why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: OOB vs Cross-Validation\n",
    "\n",
    "Compare OOB evaluation with k-fold cross-validation:\n",
    "\n",
    "1. Use a dataset of your choice\n",
    "2. Train Random Forest with OOB scoring\n",
    "3. Perform 5-fold and 10-fold cross-validation\n",
    "4. Measure and compare:\n",
    "   - Performance estimates (how close are they?)\n",
    "   - Computation time\n",
    "   - Variance in estimates\n",
    "\n",
    "**When would you prefer OOB over cross-validation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Random Forest = Bagging + Feature Randomness**\n",
    "   - Each tree trained on bootstrap sample (random rows)\n",
    "   - Each split considers random subset of features (random columns)\n",
    "   - Creates diverse, decorrelated trees\n",
    "\n",
    "2. **Critical Hyperparameters**:\n",
    "   - `n_estimators`: More trees → better (but diminishing returns after ~100-200)\n",
    "   - `max_features`: Controls diversity (sqrt is often optimal)\n",
    "   - `max_depth`, `min_samples_split`: Control overfitting\n",
    "   - `class_weight`: Handle imbalanced data\n",
    "\n",
    "3. **Feature Importance**:\n",
    "   - Impurity-based: Fast but potentially biased\n",
    "   - Permutation-based: Slower but more reliable\n",
    "   - Use for interpretation, feature selection, debugging\n",
    "\n",
    "4. **Out-of-Bag Evaluation**:\n",
    "   - Free validation estimate without separate validation set\n",
    "   - Each sample validated on trees that didn't see it\n",
    "   - Nearly as good as cross-validation, much faster\n",
    "\n",
    "5. **Imbalanced Data**:\n",
    "   - Use `class_weight='balanced'` or `'balanced_subsample'`\n",
    "   - Focus on ROC-AUC and per-class metrics, not just accuracy\n",
    "   - Consider threshold tuning for production deployment\n",
    "\n",
    "### Strengths of Random Forests\n",
    "\n",
    "- Excellent out-of-box performance (minimal tuning needed)\n",
    "- Handles mixed data types and missing values well\n",
    "- Provides feature importance\n",
    "- Resistant to overfitting (thanks to averaging)\n",
    "- Parallelizable (fast training with n_jobs=-1)\n",
    "- Works well for both classification and regression\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- Can be slow on very large datasets\n",
    "- Large model size (N trees to store)\n",
    "- Less interpretable than single decision tree\n",
    "- May not capture linear relationships as well as linear models\n",
    "- Can struggle with extrapolation beyond training data range\n",
    "\n",
    "### When to Use Random Forests\n",
    "\n",
    "**Ideal for**:\n",
    "- Tabular data with mixed feature types\n",
    "- When you need good performance without extensive tuning\n",
    "- Feature importance is valuable\n",
    "- Baseline model before trying more complex methods\n",
    "\n",
    "**Consider alternatives when**:\n",
    "- Need maximum accuracy (try gradient boosting)\n",
    "- Need interpretability (try single tree or linear model)\n",
    "- Have very large datasets (try LightGBM/CatBoost)\n",
    "- Working with images/text (try neural networks)\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 03: Boosting Fundamentals and AdaBoost**, we'll explore:\n",
    "- Sequential ensemble learning (boosting)\n",
    "- How boosting reduces bias instead of variance\n",
    "- AdaBoost algorithm and adaptive sample weighting\n",
    "- Comparison with bagging approaches\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- **Original Paper**: \"Random Forests\" by Leo Breiman (2001)\n",
    "- **Documentation**: [Scikit-learn Random Forest Guide](https://scikit-learn.org/stable/modules/ensemble.html#forest)\n",
    "- **Book**: \"The Elements of Statistical Learning\" Chapter 15 (Hastie et al.)\n",
    "- **Practical Guide**: [Tuning Random Forests](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
