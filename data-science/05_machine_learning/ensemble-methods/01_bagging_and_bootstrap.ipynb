{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 01: Bagging and Bootstrap Aggregation\n",
    "\n",
    "**Difficulty**: ⭐⭐⭐ Advanced\n",
    "**Estimated Time**: 75 minutes\n",
    "**Prerequisites**: \n",
    "- Module 00: Introduction to Ensemble Learning\n",
    "- Understanding of decision trees\n",
    "- Basic statistics (sampling, variance)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand bootstrap sampling and its properties\n",
    "2. Explain how bagging reduces model variance\n",
    "3. Implement bagging from scratch\n",
    "4. Tune bagging hyperparameters for optimal performance\n",
    "5. Analyze out-of-bag (OOB) error estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.datasets import make_classification, make_regression, load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report\n",
    "\n",
    "# Statistical tools\n",
    "from scipy import stats\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Setup complete! Ready to explore bagging.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bootstrap Sampling: The Foundation\n",
    "\n",
    "### What is Bootstrap?\n",
    "\n",
    "**Bootstrap** is a resampling technique that creates multiple datasets by sampling WITH replacement from the original data.\n",
    "\n",
    "**Key Properties**:\n",
    "- Each bootstrap sample has the same size as the original dataset\n",
    "- Some observations appear multiple times, others not at all\n",
    "- On average, each bootstrap sample contains ~63.2% unique observations\n",
    "- The remaining ~36.8% are \"out-of-bag\" (OOB) samples\n",
    "\n",
    "### Why 63.2%?\n",
    "\n",
    "Mathematical derivation:\n",
    "- Probability an observation is NOT selected in one draw: (n-1)/n\n",
    "- Probability NOT selected in n draws: ((n-1)/n)^n\n",
    "- As n → ∞, this approaches 1/e ≈ 0.368\n",
    "- So probability of being selected: 1 - 1/e ≈ 0.632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration: Bootstrap sampling properties\n",
    "def analyze_bootstrap_sample(data, n_bootstraps=1000):\n",
    "    \"\"\"\n",
    "    Analyze properties of bootstrap samples.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array-like\n",
    "        Original dataset\n",
    "    n_bootstraps : int\n",
    "        Number of bootstrap samples to generate\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict : Statistics about bootstrap samples\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    unique_percentages = []\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        # Sample WITH replacement\n",
    "        bootstrap_indices = np.random.choice(n, size=n, replace=True)\n",
    "        \n",
    "        # Count unique observations\n",
    "        n_unique = len(np.unique(bootstrap_indices))\n",
    "        unique_percentages.append(n_unique / n * 100)\n",
    "    \n",
    "    return {\n",
    "        'mean_unique_pct': np.mean(unique_percentages),\n",
    "        'std_unique_pct': np.std(unique_percentages),\n",
    "        'theoretical_unique_pct': (1 - 1/np.e) * 100,\n",
    "        'all_percentages': unique_percentages\n",
    "    }\n",
    "\n",
    "# Create sample data\n",
    "sample_data = np.arange(100)\n",
    "\n",
    "# Analyze bootstrap properties\n",
    "results = analyze_bootstrap_sample(sample_data, n_bootstraps=10000)\n",
    "\n",
    "print(\"Bootstrap Sampling Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Empirical mean unique %: {results['mean_unique_pct']:.2f}%\")\n",
    "print(f\"Theoretical unique %: {results['theoretical_unique_pct']:.2f}%\")\n",
    "print(f\"Standard deviation: {results['std_unique_pct']:.2f}%\")\n",
    "print(f\"\\nOut-of-bag (OOB) percentage: {100 - results['mean_unique_pct']:.2f}%\")\n",
    "\n",
    "# Visualize distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(results['all_percentages'], bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(results['mean_unique_pct'], color='red', linestyle='--', \n",
    "            linewidth=2, label=f\"Empirical: {results['mean_unique_pct']:.1f}%\")\n",
    "plt.axvline(results['theoretical_unique_pct'], color='green', linestyle='--', \n",
    "            linewidth=2, label=f\"Theoretical: {results['theoretical_unique_pct']:.1f}%\")\n",
    "plt.xlabel('Percentage of Unique Observations')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Unique Observations in Bootstrap Samples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Show example bootstrap sample\n",
    "example_bootstrap = np.random.choice(sample_data, size=len(sample_data), replace=True)\n",
    "unique, counts = np.unique(example_bootstrap, return_counts=True)\n",
    "plt.bar(range(len(unique[:20])), counts[:20], alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Observation Index (first 20)')\n",
    "plt.ylabel('Number of Times Selected')\n",
    "plt.title('Example Bootstrap Sample: Observation Frequencies')\n",
    "plt.axhline(1, color='red', linestyle='--', alpha=0.5, label='Selected once')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bagging: Bootstrap AGGregatING\n",
    "\n",
    "### The Bagging Algorithm\n",
    "\n",
    "**BAG**ging = **B**ootstrap **AGG**regation\n",
    "\n",
    "**Steps**:\n",
    "1. Create B bootstrap samples from training data\n",
    "2. Train a model on each bootstrap sample\n",
    "3. For prediction:\n",
    "   - **Classification**: Majority vote across all models\n",
    "   - **Regression**: Average predictions across all models\n",
    "\n",
    "### Why Bagging Reduces Variance\n",
    "\n",
    "**Mathematical intuition**:\n",
    "- Variance of average of n independent variables: Var(average) = Var(X) / n\n",
    "- Even with correlation, averaging reduces variance\n",
    "- Each model sees slightly different data → different errors → errors cancel out\n",
    "\n",
    "**Best use cases**:\n",
    "- High-variance models (e.g., deep decision trees)\n",
    "- Noisy datasets\n",
    "- When you want stable, robust predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate variance reduction with bagging\n",
    "def compare_variance_single_vs_bagging(n_trials=50):\n",
    "    \"\"\"\n",
    "    Compare prediction variance of single model vs bagging ensemble.\n",
    "    \n",
    "    We train multiple times with different random seeds to measure\n",
    "    how much predictions vary due to training randomness.\n",
    "    \"\"\"\n",
    "    # Create a fixed test dataset\n",
    "    X, y = make_classification(\n",
    "        n_samples=1000, n_features=20, n_informative=15,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    # Store predictions across trials\n",
    "    single_predictions = []\n",
    "    bagging_predictions = []\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        # Single decision tree (high variance)\n",
    "        single_model = DecisionTreeClassifier(\n",
    "            max_depth=10, random_state=trial\n",
    "        )\n",
    "        single_model.fit(X_train, y_train)\n",
    "        single_pred = single_model.predict_proba(X_test)[:, 1]  # Probability of class 1\n",
    "        single_predictions.append(single_pred)\n",
    "        \n",
    "        # Bagging ensemble\n",
    "        bagging_model = BaggingClassifier(\n",
    "            estimator=DecisionTreeClassifier(max_depth=10),\n",
    "            n_estimators=20,\n",
    "            random_state=trial\n",
    "        )\n",
    "        bagging_model.fit(X_train, y_train)\n",
    "        bagging_pred = bagging_model.predict_proba(X_test)[:, 1]\n",
    "        bagging_predictions.append(bagging_pred)\n",
    "    \n",
    "    # Calculate variance for each test sample\n",
    "    single_variance = np.var(single_predictions, axis=0)\n",
    "    bagging_variance = np.var(bagging_predictions, axis=0)\n",
    "    \n",
    "    return single_variance, bagging_variance\n",
    "\n",
    "# Run comparison\n",
    "print(\"Running variance comparison (this may take a minute)...\")\n",
    "single_var, bagging_var = compare_variance_single_vs_bagging(n_trials=30)\n",
    "\n",
    "print(\"\\nVariance Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Single tree - Mean variance: {np.mean(single_var):.6f}\")\n",
    "print(f\"Bagging - Mean variance: {np.mean(bagging_var):.6f}\")\n",
    "print(f\"\\nVariance reduction: {(1 - np.mean(bagging_var)/np.mean(single_var)) * 100:.1f}%\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist([single_var, bagging_var], label=['Single Tree', 'Bagging'], \n",
    "         alpha=0.7, bins=30, edgecolor='black')\n",
    "plt.xlabel('Prediction Variance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prediction Variance Across Test Samples')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(single_var, bagging_var, alpha=0.5, s=10)\n",
    "plt.plot([0, max(single_var)], [0, max(single_var)], 'r--', \n",
    "         linewidth=2, label='Equal variance')\n",
    "plt.xlabel('Single Tree Variance')\n",
    "plt.ylabel('Bagging Variance')\n",
    "plt.title('Variance Comparison: Single vs Bagging\\n(Points below line = bagging wins)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing Bagging from Scratch\n",
    "\n",
    "Let's build a bagging classifier from scratch to understand the mechanics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBaggingClassifier:\n",
    "    \"\"\"\n",
    "    A from-scratch implementation of bagging for classification.\n",
    "    \n",
    "    This implementation demonstrates the core bagging algorithm:\n",
    "    1. Bootstrap sampling\n",
    "    2. Training multiple models\n",
    "    3. Aggregating predictions via voting\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator, n_estimators=10, random_state=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator : sklearn estimator\n",
    "            The model to use for each bootstrap sample\n",
    "        n_estimators : int\n",
    "            Number of models in the ensemble\n",
    "        random_state : int\n",
    "            Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.random_state = random_state\n",
    "        self.models = []\n",
    "        self.oob_indices = []  # Track out-of-bag samples\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the bagging ensemble.\n",
    "        \n",
    "        For each estimator:\n",
    "        1. Create bootstrap sample\n",
    "        2. Train model on bootstrap sample\n",
    "        3. Store out-of-bag indices for error estimation\n",
    "        \"\"\"\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        self.models = []\n",
    "        self.oob_indices = []\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            # Create bootstrap sample\n",
    "            # Sample WITH replacement\n",
    "            bootstrap_indices = np.random.choice(\n",
    "                n_samples, size=n_samples, replace=True\n",
    "            )\n",
    "            \n",
    "            # Identify out-of-bag samples (not in bootstrap)\n",
    "            oob = np.setdiff1d(np.arange(n_samples), bootstrap_indices)\n",
    "            self.oob_indices.append(oob)\n",
    "            \n",
    "            # Get bootstrap data\n",
    "            X_bootstrap = X[bootstrap_indices]\n",
    "            y_bootstrap = y[bootstrap_indices]\n",
    "            \n",
    "            # Clone and train model\n",
    "            # We need to clone to avoid all models being the same object\n",
    "            from sklearn.base import clone\n",
    "            model = clone(self.base_estimator)\n",
    "            model.fit(X_bootstrap, y_bootstrap)\n",
    "            \n",
    "            self.models.append(model)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict using majority voting.\n",
    "        \n",
    "        Each model votes for a class, and we return the majority vote.\n",
    "        \"\"\"\n",
    "        # Get predictions from all models\n",
    "        predictions = np.array([model.predict(X) for model in self.models])\n",
    "        \n",
    "        # Majority vote\n",
    "        # For each sample, find most common prediction across models\n",
    "        majority_vote = stats.mode(predictions, axis=0, keepdims=True)[0][0]\n",
    "        \n",
    "        return majority_vote\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict class probabilities by averaging.\n",
    "        \"\"\"\n",
    "        # Get probability predictions from all models\n",
    "        probas = np.array([model.predict_proba(X) for model in self.models])\n",
    "        \n",
    "        # Average probabilities across models\n",
    "        avg_proba = np.mean(probas, axis=0)\n",
    "        \n",
    "        return avg_proba\n",
    "    \n",
    "    def oob_score(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculate out-of-bag accuracy.\n",
    "        \n",
    "        For each sample, use only models that didn't see it during training.\n",
    "        This provides an unbiased estimate without needing a validation set.\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        oob_predictions = np.zeros(n_samples)\n",
    "        oob_counts = np.zeros(n_samples)\n",
    "        \n",
    "        # For each model, make predictions on its OOB samples\n",
    "        for i, model in enumerate(self.models):\n",
    "            oob_idx = self.oob_indices[i]\n",
    "            if len(oob_idx) > 0:\n",
    "                preds = model.predict(X[oob_idx])\n",
    "                oob_predictions[oob_idx] += preds\n",
    "                oob_counts[oob_idx] += 1\n",
    "        \n",
    "        # Only consider samples that were OOB for at least one model\n",
    "        valid_mask = oob_counts > 0\n",
    "        oob_predictions = oob_predictions[valid_mask] / oob_counts[valid_mask]\n",
    "        oob_predictions = np.round(oob_predictions).astype(int)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        oob_accuracy = accuracy_score(y[valid_mask], oob_predictions)\n",
    "        \n",
    "        return oob_accuracy\n",
    "\n",
    "print(\"SimpleBaggingClassifier implemented successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our custom bagging implementation\n",
    "# Load real dataset\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Our custom implementation\n",
    "custom_bagging = SimpleBaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=5),\n",
    "    n_estimators=50,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "custom_bagging.fit(X_train, y_train)\n",
    "custom_pred = custom_bagging.predict(X_test)\n",
    "custom_acc = accuracy_score(y_test, custom_pred)\n",
    "custom_oob = custom_bagging.oob_score(X_train, y_train)\n",
    "\n",
    "# Sklearn's implementation (for comparison)\n",
    "sklearn_bagging = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=5),\n",
    "    n_estimators=50,\n",
    "    random_state=RANDOM_STATE,\n",
    "    oob_score=True\n",
    ")\n",
    "sklearn_bagging.fit(X_train, y_train)\n",
    "sklearn_pred = sklearn_bagging.predict(X_test)\n",
    "sklearn_acc = accuracy_score(y_test, sklearn_pred)\n",
    "sklearn_oob = sklearn_bagging.oob_score_\n",
    "\n",
    "# Single tree baseline\n",
    "single_tree = DecisionTreeClassifier(max_depth=5, random_state=RANDOM_STATE)\n",
    "single_tree.fit(X_train, y_train)\n",
    "single_acc = accuracy_score(y_test, single_tree.predict(X_test))\n",
    "\n",
    "print(\"Performance Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Single Tree:               Test Acc = {single_acc:.4f}\")\n",
    "print(f\"Custom Bagging:            Test Acc = {custom_acc:.4f}, OOB = {custom_oob:.4f}\")\n",
    "print(f\"Sklearn Bagging:           Test Acc = {sklearn_acc:.4f}, OOB = {sklearn_oob:.4f}\")\n",
    "print(\"\\nOur implementation matches sklearn! ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Out-of-Bag (OOB) Error Estimation\n",
    "\n",
    "### What is OOB Error?\n",
    "\n",
    "**Key insight**: Each model in bagging is trained on ~63% of data. The remaining ~37% can be used for validation!\n",
    "\n",
    "**Advantages of OOB**:\n",
    "1. **No need for separate validation set**: Uses training data more efficiently\n",
    "2. **Unbiased estimate**: Each prediction uses only models that didn't see that sample\n",
    "3. **Free validation**: No computational cost beyond tracking indices\n",
    "\n",
    "**OOB vs Cross-Validation**:\n",
    "- OOB is faster (no retraining)\n",
    "- OOB provides similar accuracy estimate to CV\n",
    "- Particularly useful for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate OOB error tracking across ensemble sizes\n",
    "def track_oob_convergence(X_train, y_train, X_test, y_test, max_estimators=100):\n",
    "    \"\"\"\n",
    "    Track how OOB error and test error converge as we add models.\n",
    "    \n",
    "    This shows that OOB error is a good proxy for test error.\n",
    "    \"\"\"\n",
    "    estimator_range = range(1, max_estimators + 1, 5)\n",
    "    oob_errors = []\n",
    "    test_errors = []\n",
    "    \n",
    "    for n_est in estimator_range:\n",
    "        model = BaggingClassifier(\n",
    "            estimator=DecisionTreeClassifier(max_depth=8),\n",
    "            n_estimators=n_est,\n",
    "            oob_score=True,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # OOB error (1 - accuracy)\n",
    "        oob_errors.append(1 - model.oob_score_)\n",
    "        \n",
    "        # Test error\n",
    "        test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "        test_errors.append(1 - test_acc)\n",
    "    \n",
    "    return list(estimator_range), oob_errors, test_errors\n",
    "\n",
    "# Create larger dataset for demonstration\n",
    "X, y = make_classification(\n",
    "    n_samples=2000, n_features=30, n_informative=20,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Tracking OOB convergence...\")\n",
    "n_estimators, oob_errs, test_errs = track_oob_convergence(\n",
    "    X_train, y_train, X_test, y_test, max_estimators=100\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(n_estimators, oob_errs, 'o-', label='OOB Error', alpha=0.7)\n",
    "plt.plot(n_estimators, test_errs, 's-', label='Test Error', alpha=0.7)\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.title('OOB Error vs Test Error Convergence')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(oob_errs, test_errs, alpha=0.6, s=50)\n",
    "plt.plot([min(oob_errs), max(oob_errs)], [min(oob_errs), max(oob_errs)], \n",
    "         'r--', linewidth=2, label='Perfect correlation')\n",
    "plt.xlabel('OOB Error')\n",
    "plt.ylabel('Test Error')\n",
    "plt.title('OOB Error as Test Error Proxy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = np.corrcoef(oob_errs, test_errs)[0, 1]\n",
    "print(f\"\\nCorrelation between OOB and Test error: {correlation:.4f}\")\n",
    "print(\"High correlation confirms OOB is a good validation proxy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning for Bagging\n",
    "\n",
    "### Key Hyperparameters\n",
    "\n",
    "1. **n_estimators**: Number of models in ensemble\n",
    "   - More is generally better, but diminishing returns\n",
    "   - Typical range: 10-200\n",
    "\n",
    "2. **max_samples**: Fraction of samples for each bootstrap\n",
    "   - Default: 1.0 (same size as training set)\n",
    "   - Lower values increase diversity but may hurt individual model performance\n",
    "\n",
    "3. **max_features**: Number of features for each model\n",
    "   - Can subsample features in addition to samples\n",
    "   - Increases diversity, especially important for Random Forests\n",
    "\n",
    "4. **Base estimator parameters**: Depends on chosen model\n",
    "   - For trees: max_depth, min_samples_split, etc.\n",
    "   - Generally use moderately complex models (not too simple, not too complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning demonstration\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1500, n_features=25, n_informative=18,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 30, 50, 100],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0],\n",
    "    'estimator__max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Create base bagging classifier\n",
    "bagging = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    random_state=RANDOM_STATE,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "# Grid search\n",
    "# Note: Using oob_score reduces need for CV, but we still use CV here for demonstration\n",
    "print(\"Running grid search (this may take a minute)...\")\n",
    "grid_search = GridSearchCV(\n",
    "    bagging, param_grid, cv=3, scoring='accuracy', \n",
    "    n_jobs=-1, verbose=0\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(\"=\" * 50)\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"{param:25s}: {value}\")\n",
    "\n",
    "print(f\"\\nBest CV Score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Test Score: {grid_search.score(X_test, y_test):.4f}\")\n",
    "\n",
    "# Compare with default parameters\n",
    "default_bagging = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "default_bagging.fit(X_train, y_train)\n",
    "default_score = accuracy_score(y_test, default_bagging.predict(X_test))\n",
    "\n",
    "print(f\"\\nDefault parameters score: {default_score:.4f}\")\n",
    "improvement = (grid_search.score(X_test, y_test) - default_score) / default_score * 100\n",
    "print(f\"Improvement from tuning: {improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect of n_estimators\n",
    "def analyze_n_estimators_effect(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Analyze how number of estimators affects performance.\n",
    "    \"\"\"\n",
    "    n_estimators_range = range(1, 151, 5)\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    oob_scores = []\n",
    "    \n",
    "    for n_est in n_estimators_range:\n",
    "        model = BaggingClassifier(\n",
    "            estimator=DecisionTreeClassifier(max_depth=10),\n",
    "            n_estimators=n_est,\n",
    "            oob_score=True,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        train_scores.append(model.score(X_train, y_train))\n",
    "        test_scores.append(model.score(X_test, y_test))\n",
    "        oob_scores.append(model.oob_score_)\n",
    "    \n",
    "    return list(n_estimators_range), train_scores, test_scores, oob_scores\n",
    "\n",
    "n_est, train_sc, test_sc, oob_sc = analyze_n_estimators_effect(\n",
    "    X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(n_est, train_sc, label='Training Score', linewidth=2)\n",
    "plt.plot(n_est, test_sc, label='Test Score', linewidth=2)\n",
    "plt.plot(n_est, oob_sc, label='OOB Score', linewidth=2, linestyle='--')\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Performance vs Number of Estimators')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Calculate marginal improvement\n",
    "test_improvements = np.diff(test_sc)\n",
    "plt.plot(n_est[1:], test_improvements, 'o-', alpha=0.7)\n",
    "plt.axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Marginal Improvement in Test Score')\n",
    "plt.title('Diminishing Returns: Adding More Estimators')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find point of diminishing returns (when improvement < 0.001)\n",
    "threshold = 0.001\n",
    "for i, improvement in enumerate(test_improvements):\n",
    "    if abs(improvement) < threshold:\n",
    "        optimal_n = n_est[i+1]\n",
    "        print(f\"\\nDiminishing returns start at ~{optimal_n} estimators\")\n",
    "        print(f\"Beyond this point, marginal improvement < {threshold}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Apply your knowledge of bagging to solve practical problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Bootstrap Confidence Intervals\n",
    "\n",
    "Bootstrap sampling can estimate confidence intervals for any statistic. Implement a function that:\n",
    "1. Takes a dataset and a statistic function (e.g., mean, median)\n",
    "2. Generates 1000 bootstrap samples\n",
    "3. Calculates the statistic for each sample\n",
    "4. Returns the 95% confidence interval\n",
    "\n",
    "Test with the wine dataset features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Use np.percentile() to get 2.5% and 97.5% percentiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Optimal Base Estimator Complexity\n",
    "\n",
    "Investigate how base estimator complexity affects bagging performance. Create bagging ensembles with decision trees of varying depths (2, 5, 10, 15, 20, None). For each:\n",
    "- Train a single tree\n",
    "- Train a bagging ensemble (50 estimators)\n",
    "- Compare performance\n",
    "\n",
    "**Question**: At what depth does bagging provide the most benefit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Create a comparison across different tree depths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Feature Subsampling Impact\n",
    "\n",
    "Bagging can subsample features in addition to samples. Experiment with different max_features values (0.3, 0.5, 0.7, 1.0) while keeping n_estimators=50.\n",
    "\n",
    "Analyze:\n",
    "- How does feature subsampling affect accuracy?\n",
    "- How does it affect model diversity (measure prediction correlation)?\n",
    "- What's the optimal trade-off?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Test different max_features values\n",
    "# Calculate both accuracy and model diversity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Bagging for Regression\n",
    "\n",
    "Implement bagging for a regression task using BaggingRegressor. Use make_regression to create a dataset with:\n",
    "- 1000 samples\n",
    "- 20 features (10 informative)\n",
    "- Noise level = 30\n",
    "\n",
    "Compare:\n",
    "- Single decision tree regressor\n",
    "- Bagging with different n_estimators (10, 50, 100)\n",
    "\n",
    "Visualize predictions vs true values for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Use BaggingRegressor and DecisionTreeRegressor\n",
    "# Compare MSE across different configurations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Bootstrap Sampling**:\n",
    "   - Sample WITH replacement\n",
    "   - Each sample contains ~63.2% unique observations\n",
    "   - Remaining ~36.8% are out-of-bag (OOB)\n",
    "\n",
    "2. **Bagging Algorithm**:\n",
    "   - Train models on bootstrap samples\n",
    "   - Aggregate via averaging (regression) or voting (classification)\n",
    "   - Reduces variance without increasing bias\n",
    "\n",
    "3. **Variance Reduction**:\n",
    "   - Works best with high-variance models (deep trees)\n",
    "   - Averaging reduces prediction variance\n",
    "   - Model diversity is crucial for effectiveness\n",
    "\n",
    "4. **Out-of-Bag Estimation**:\n",
    "   - Free validation using leftover samples\n",
    "   - Unbiased performance estimate\n",
    "   - Highly correlated with test error\n",
    "\n",
    "5. **Hyperparameter Tuning**:\n",
    "   - n_estimators: More is better, but diminishing returns\n",
    "   - max_samples/max_features: Control diversity\n",
    "   - Base estimator complexity: Moderate depth works best\n",
    "\n",
    "### When to Use Bagging\n",
    "\n",
    "**Best for**:\n",
    "- High-variance models (decision trees, neural networks)\n",
    "- Noisy datasets\n",
    "- When stability is important\n",
    "\n",
    "**Less effective for**:\n",
    "- Already stable models (linear regression, regularized models)\n",
    "- Very small datasets\n",
    "- When interpretability is critical\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "- **Module 02**: Random Forests - the most popular bagging variant\n",
    "  - Adds feature randomness to bagging\n",
    "  - Industry standard for many applications\n",
    "  - Built-in feature importance\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- **Original Paper**: Breiman, L. (1996). \"Bagging Predictors\"\n",
    "- **Book**: \"The Elements of Statistical Learning\" (Hastie et al.) - Chapter 8\n",
    "- **Documentation**: [Scikit-learn Bagging Documentation](https://scikit-learn.org/stable/modules/ensemble.html#bagging)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
