{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 00: Introduction to Ensemble Learning\n",
    "\n",
    "**Difficulty**: â­â­â­ Advanced\n",
    "\n",
    "**Estimated Time**: 60 minutes\n",
    "\n",
    "**Prerequisites**: \n",
    "- Machine Learning Fundamentals (decision trees, model evaluation)\n",
    "- Feature Engineering basics\n",
    "- Understanding of bias-variance tradeoff\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Explain the fundamental principle of ensemble learning (\"wisdom of crowds\")\n",
    "2. Understand how combining weak learners creates strong models\n",
    "3. Differentiate between bagging, boosting, and stacking approaches\n",
    "4. Analyze bias-variance tradeoff in ensemble methods\n",
    "5. Determine when ensemble methods are appropriate for your problem\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Scikit-learn models and utilities\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    VotingClassifier,\n",
    "    BaggingClassifier,\n",
    "    RandomForestClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Wisdom of Crowds: A Simple Demonstration\n",
    "\n",
    "### The Core Principle\n",
    "\n",
    "Ensemble learning is based on the \"wisdom of crowds\" principle: **aggregating predictions from multiple models often produces better results than any single model.**\n",
    "\n",
    "Let's demonstrate this with a simple thought experiment:\n",
    "\n",
    "- **Scenario**: You ask 100 people to guess the number of jellybeans in a jar\n",
    "- **Result**: Individual guesses vary wildly (some too high, some too low)\n",
    "- **Magic**: The average of all guesses is often remarkably close to the true answer\n",
    "\n",
    "This works because:\n",
    "1. Individual errors tend to cancel out (averaging reduces variance)\n",
    "2. Each person brings unique perspective (diversity helps)\n",
    "3. No systematic bias exists (errors are random, not correlated)\n",
    "\n",
    "### Mathematical Foundation\n",
    "\n",
    "If we have $n$ models with predictions $y_1, y_2, ..., y_n$ and each has error $\\epsilon$:\n",
    "\n",
    "- Single model error: $\\epsilon$\n",
    "- Ensemble error (averaging): $\\frac{\\epsilon}{\\sqrt{n}}$\n",
    "\n",
    "**Key insight**: Error decreases as we add more diverse models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the \"jellybean jar\" problem\n",
    "true_count = 850  # Actual number of jellybeans\n",
    "\n",
    "# Simulate 100 people's guesses (normally distributed around truth)\n",
    "num_guessers = 100\n",
    "individual_guesses = np.random.normal(loc=true_count, scale=120, size=num_guessers)\n",
    "\n",
    "# Calculate ensemble prediction (average)\n",
    "ensemble_prediction = np.mean(individual_guesses)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Individual guesses distribution\n",
    "ax1.hist(individual_guesses, bins=30, alpha=0.7, edgecolor='black')\n",
    "ax1.axvline(true_count, color='green', linestyle='--', linewidth=2, label=f'True Count: {true_count}')\n",
    "ax1.axvline(ensemble_prediction, color='red', linestyle='-', linewidth=2, \n",
    "            label=f'Ensemble (Avg): {ensemble_prediction:.1f}')\n",
    "ax1.set_xlabel('Guess Count')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Individual Guesses vs Ensemble Prediction')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Error comparison\n",
    "individual_errors = np.abs(individual_guesses - true_count)\n",
    "ensemble_error = np.abs(ensemble_prediction - true_count)\n",
    "\n",
    "ax2.boxplot([individual_errors], labels=['Individual Errors'])\n",
    "ax2.scatter([1], [ensemble_error], color='red', s=200, zorder=10, \n",
    "            label=f'Ensemble Error: {ensemble_error:.1f}')\n",
    "ax2.set_ylabel('Absolute Error')\n",
    "ax2.set_title('Error Comparison: Individuals vs Ensemble')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "print(f\"True count: {true_count}\")\n",
    "print(f\"Ensemble prediction: {ensemble_prediction:.2f}\")\n",
    "print(f\"Ensemble error: {ensemble_error:.2f}\")\n",
    "print(f\"\\nIndividual statistics:\")\n",
    "print(f\"  Mean error: {individual_errors.mean():.2f}\")\n",
    "print(f\"  Median error: {np.median(individual_errors):.2f}\")\n",
    "print(f\"  Best individual error: {individual_errors.min():.2f}\")\n",
    "print(f\"\\nâœ… Ensemble beat {(individual_errors > ensemble_error).sum()} out of {num_guessers} individuals!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 1: Understanding Ensemble Benefits\n",
    "\n",
    "Modify the simulation above to answer these questions:\n",
    "\n",
    "1. What happens if we increase `num_guessers` to 500? Does the ensemble get better?\n",
    "2. What if individual guesses have higher variance (scale=200)? Does ensemble still help?\n",
    "3. What if there's systematic bias (loc=950 instead of 850)? How does ensemble perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. From Crowds to Machine Learning Models\n",
    "\n",
    "### Why Ensemble Multiple Models?\n",
    "\n",
    "Just like averaging human guesses, we can average predictions from multiple machine learning models. Benefits include:\n",
    "\n",
    "1. **Reduced Variance**: Individual models may overfit; averaging smooths predictions\n",
    "2. **Reduced Bias**: Boosting methods sequentially reduce bias\n",
    "3. **Improved Robustness**: Ensemble is less sensitive to outliers and noise\n",
    "4. **Better Generalization**: Combined model captures different aspects of data\n",
    "\n",
    "### Requirements for Effective Ensembles\n",
    "\n",
    "1. **Diversity**: Models must make different kinds of errors\n",
    "2. **Independence**: Models should use different algorithms or data subsets\n",
    "3. **Reasonable Accuracy**: Each model should perform better than random guessing\n",
    "\n",
    "Let's demonstrate with a simple classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic classification dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Class distribution: {np.bincount(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Individual Models vs Simple Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train individual models with different algorithms\n",
    "model_1 = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "model_2 = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_3 = GaussianNB()\n",
    "\n",
    "# Fit individual models\n",
    "model_1.fit(X_train, y_train)\n",
    "model_2.fit(X_train, y_train)\n",
    "model_3.fit(X_train, y_train)\n",
    "\n",
    "# Get individual predictions\n",
    "pred_1 = model_1.predict(X_test)\n",
    "pred_2 = model_2.predict(X_test)\n",
    "pred_3 = model_3.predict(X_test)\n",
    "\n",
    "# Calculate individual accuracies\n",
    "acc_1 = accuracy_score(y_test, pred_1)\n",
    "acc_2 = accuracy_score(y_test, pred_2)\n",
    "acc_3 = accuracy_score(y_test, pred_3)\n",
    "\n",
    "# Create simple ensemble using majority voting\n",
    "# Stack predictions and take mode (most common prediction)\n",
    "ensemble_pred = stats.mode(\n",
    "    np.vstack([pred_1, pred_2, pred_3]), \n",
    "    axis=0, \n",
    "    keepdims=True\n",
    ")[0].flatten()\n",
    "acc_ensemble = accuracy_score(y_test, ensemble_pred)\n",
    "\n",
    "# Visualize results\n",
    "models = ['Decision Tree', 'Logistic Reg', 'Naive Bayes', 'Ensemble\\n(Voting)']\n",
    "accuracies = [acc_1, acc_2, acc_3, acc_ensemble]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(models, accuracies, color=['skyblue', 'lightgreen', 'salmon', 'gold'])\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Individual Models vs Simple Ensemble Performance', fontsize=14, fontweight='bold')\n",
    "plt.ylim(0.75, 1.0)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, acc) in enumerate(zip(bars, accuracies)):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, acc + 0.005, \n",
    "             f'{acc:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Performance Comparison:\")\n",
    "print(f\"Decision Tree:     {acc_1:.4f}\")\n",
    "print(f\"Logistic Regression: {acc_2:.4f}\")\n",
    "print(f\"Naive Bayes:       {acc_3:.4f}\")\n",
    "print(f\"Ensemble (Voting): {acc_ensemble:.4f}\")\n",
    "print(f\"\\nâœ… Ensemble improvement: {(acc_ensemble - np.mean([acc_1, acc_2, acc_3])):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 2: Model Diversity Analysis\n",
    "\n",
    "Analyze how model diversity affects ensemble performance:\n",
    "\n",
    "1. Calculate the disagreement rate between models (how often they make different predictions)\n",
    "2. Create an ensemble with 3 decision trees that have the same hyperparameters\n",
    "3. Compare this \"low diversity\" ensemble with the \"high diversity\" ensemble above\n",
    "4. Which performs better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Three Main Ensemble Strategies\n",
    "\n",
    "### 4.1 Bagging (Bootstrap Aggregating)\n",
    "\n",
    "**Strategy**: Train multiple models on different random subsets of training data, then average predictions.\n",
    "\n",
    "**Key Characteristics**:\n",
    "- Models trained in **parallel** (independent)\n",
    "- Uses **bootstrap sampling** (random sampling with replacement)\n",
    "- **Reduces variance** without increasing bias\n",
    "- Works best with **high-variance models** (deep decision trees)\n",
    "\n",
    "**Examples**: Random Forest, Bagged Decision Trees\n",
    "\n",
    "**When to use**:\n",
    "- When base model tends to overfit\n",
    "- When you have sufficient training data\n",
    "- When model variance is the main problem\n",
    "\n",
    "### 4.2 Boosting\n",
    "\n",
    "**Strategy**: Train models sequentially, where each new model focuses on errors made by previous models.\n",
    "\n",
    "**Key Characteristics**:\n",
    "- Models trained **sequentially** (dependent)\n",
    "- Each model tries to **correct previous errors**\n",
    "- **Reduces both bias and variance**\n",
    "- Works best with **high-bias models** (shallow trees)\n",
    "\n",
    "**Examples**: AdaBoost, Gradient Boosting, XGBoost, LightGBM, CatBoost\n",
    "\n",
    "**When to use**:\n",
    "- When base model is too simple (underfitting)\n",
    "- When you need maximum predictive accuracy\n",
    "- When model bias is the main problem\n",
    "\n",
    "### 4.3 Stacking (Stacked Generalization)\n",
    "\n",
    "**Strategy**: Train multiple diverse models, then train a meta-model to combine their predictions optimally.\n",
    "\n",
    "**Key Characteristics**:\n",
    "- Uses **diverse base models** (different algorithms)\n",
    "- **Meta-model learns** how to best combine predictions\n",
    "- **Most flexible** but also most complex\n",
    "- Can combine strengths of different model types\n",
    "\n",
    "**Examples**: Stacked models with various base learners + meta-learner\n",
    "\n",
    "**When to use**:\n",
    "- Kaggle competitions (maximum accuracy needed)\n",
    "- When you have diverse models with complementary strengths\n",
    "- When computational cost is not a primary concern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Comparison of Ensemble Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visual comparison of ensemble strategies\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "strategies = ['Bagging', 'Boosting', 'Stacking']\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "\n",
    "# Bagging diagram\n",
    "ax = axes[0]\n",
    "ax.text(0.5, 0.9, 'Training Data', ha='center', fontsize=12, fontweight='bold')\n",
    "for i in range(3):\n",
    "    ax.add_patch(plt.Rectangle((0.15 + i*0.25, 0.65), 0.15, 0.15, \n",
    "                                fill=True, color=colors[0], alpha=0.6))\n",
    "    ax.text(0.225 + i*0.25, 0.72, f'Sample {i+1}', ha='center', fontsize=9)\n",
    "    ax.arrow(0.225 + i*0.25, 0.65, 0, -0.1, head_width=0.03, head_length=0.02, fc='black')\n",
    "    ax.add_patch(plt.Rectangle((0.15 + i*0.25, 0.35), 0.15, 0.15, \n",
    "                                fill=True, color='orange', alpha=0.6))\n",
    "    ax.text(0.225 + i*0.25, 0.42, f'Model {i+1}', ha='center', fontsize=9)\n",
    "    ax.arrow(0.225 + i*0.25, 0.35, 0, -0.1, head_width=0.03, head_length=0.02, fc='black')\n",
    "ax.add_patch(plt.Rectangle((0.35, 0.05), 0.3, 0.15, fill=True, color='gold', alpha=0.8))\n",
    "ax.text(0.5, 0.125, 'Average', ha='center', fontsize=11, fontweight='bold')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title('Bagging\\n(Parallel Training)', fontweight='bold')\n",
    "\n",
    "# Boosting diagram\n",
    "ax = axes[1]\n",
    "ax.text(0.5, 0.9, 'Training Data', ha='center', fontsize=12, fontweight='bold')\n",
    "for i in range(3):\n",
    "    y_pos = 0.65 - i*0.2\n",
    "    ax.add_patch(plt.Rectangle((0.35, y_pos), 0.3, 0.12, \n",
    "                                fill=True, color=colors[1], alpha=0.6))\n",
    "    ax.text(0.5, y_pos + 0.06, f'Model {i+1}', ha='center', fontsize=9)\n",
    "    if i < 2:\n",
    "        ax.arrow(0.5, y_pos, 0, -0.06, head_width=0.03, head_length=0.02, fc='black')\n",
    "        ax.text(0.73, y_pos - 0.03, 'Fix errors', fontsize=8, style='italic')\n",
    "ax.add_patch(plt.Rectangle((0.35, 0.05), 0.3, 0.12, fill=True, color='gold', alpha=0.8))\n",
    "ax.text(0.5, 0.11, 'Weighted Sum', ha='center', fontsize=10, fontweight='bold')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title('Boosting\\n(Sequential Training)', fontweight='bold')\n",
    "\n",
    "# Stacking diagram\n",
    "ax = axes[2]\n",
    "ax.text(0.5, 0.9, 'Training Data', ha='center', fontsize=12, fontweight='bold')\n",
    "model_names = ['Tree', 'LogReg', 'NB']\n",
    "for i, name in enumerate(model_names):\n",
    "    ax.add_patch(plt.Rectangle((0.1 + i*0.27, 0.6), 0.2, 0.15, \n",
    "                                fill=True, color=colors[2], alpha=0.6))\n",
    "    ax.text(0.2 + i*0.27, 0.675, name, ha='center', fontsize=8)\n",
    "    ax.arrow(0.2 + i*0.27, 0.6, (0.5 - (0.2 + i*0.27))*0.7, -0.2, \n",
    "             head_width=0.02, head_length=0.02, fc='black', alpha=0.5)\n",
    "ax.add_patch(plt.Rectangle((0.35, 0.3), 0.3, 0.15, fill=True, color='purple', alpha=0.6))\n",
    "ax.text(0.5, 0.375, 'Meta-Model', ha='center', fontsize=10, fontweight='bold')\n",
    "ax.arrow(0.5, 0.3, 0, -0.08, head_width=0.03, head_length=0.02, fc='black')\n",
    "ax.add_patch(plt.Rectangle((0.35, 0.05), 0.3, 0.12, fill=True, color='gold', alpha=0.8))\n",
    "ax.text(0.5, 0.11, 'Final Prediction', ha='center', fontsize=9, fontweight='bold')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title('Stacking\\n(Meta-Learning)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 3: Comparing Ensemble Strategies\n",
    "\n",
    "Implement a simple version of each ensemble strategy:\n",
    "\n",
    "1. **Bagging**: Use `BaggingClassifier` with decision trees\n",
    "2. **Boosting**: Use `AdaBoostClassifier` with decision trees\n",
    "3. **Stacking**: Use `VotingClassifier` with diverse base models\n",
    "\n",
    "Compare their performance on the test set. Which works best? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bias-Variance Tradeoff in Ensembles\n",
    "\n",
    "### Understanding the Tradeoff\n",
    "\n",
    "Total Error = BiasÂ² + Variance + Irreducible Error\n",
    "\n",
    "**Bias**: How far off predictions are on average (underfitting)\n",
    "**Variance**: How much predictions vary for different training sets (overfitting)\n",
    "\n",
    "### How Ensembles Help\n",
    "\n",
    "| Ensemble Type | Effect on Bias | Effect on Variance | Best Base Model |\n",
    "|---------------|----------------|--------------------|-----------------|\n",
    "| **Bagging** | No change | â¬‡ï¸ Reduces | High variance (deep trees) |\n",
    "| **Boosting** | â¬‡ï¸ Reduces | â¬†ï¸ May increase slightly | High bias (shallow trees) |\n",
    "| **Stacking** | â¬‡ï¸ Reduces | â¬‡ï¸ Reduces | Diverse models |\n",
    "\n",
    "### Practical Implications\n",
    "\n",
    "**For Bagging**:\n",
    "- Use complex base models (deep trees, high variance)\n",
    "- Averaging reduces overfitting\n",
    "- Example: Random Forest with deep trees\n",
    "\n",
    "**For Boosting**:\n",
    "- Use simple base models (shallow trees, high bias)\n",
    "- Sequential correction reduces underfitting\n",
    "- Example: XGBoost with max_depth=3-6\n",
    "\n",
    "**For Stacking**:\n",
    "- Use diverse models with different bias-variance profiles\n",
    "- Meta-model learns optimal combination\n",
    "- Example: Combine linear models + tree models + neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate bias-variance tradeoff with different ensemble approaches\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Create models with different bias-variance profiles\n",
    "models = {\n",
    "    'Single Deep Tree\\n(High Variance)': DecisionTreeClassifier(max_depth=20, random_state=42),\n",
    "    'Bagging Deep Trees\\n(Reduced Variance)': BaggingClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=20, random_state=42),\n",
    "        n_estimators=10,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Single Shallow Tree\\n(High Bias)': DecisionTreeClassifier(max_depth=2, random_state=42),\n",
    "    'Boosting Shallow Trees\\n(Reduced Bias)': AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=2, random_state=42),\n",
    "        n_estimators=50,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Plot learning curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, model) in enumerate(models.items()):\n",
    "    # Calculate learning curve\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X_train, y_train, \n",
    "        cv=5, \n",
    "        n_jobs=-1,\n",
    "        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Calculate mean and std\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    ax.plot(train_sizes, train_mean, label='Training Score', marker='o', color='blue')\n",
    "    ax.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "    ax.plot(train_sizes, val_mean, label='Validation Score', marker='s', color='red')\n",
    "    ax.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')\n",
    "    \n",
    "    # Calculate bias and variance indicators\n",
    "    final_gap = train_mean[-1] - val_mean[-1]\n",
    "    final_val_score = val_mean[-1]\n",
    "    \n",
    "    ax.set_xlabel('Training Set Size')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title(f'{name}\\nGap: {final_gap:.3f} | Val: {final_val_score:.3f}')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0.5, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Interpretation Guide:\")\n",
    "print(\"  Large gap between training & validation = High VARIANCE (overfitting)\")\n",
    "print(\"  Low validation score overall = High BIAS (underfitting)\")\n",
    "print(\"  Small gap + high validation score = Good balance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. When to Use Ensemble Methods\n",
    "\n",
    "### âœ… Use Ensemble Methods When:\n",
    "\n",
    "1. **Maximum Accuracy Needed**\n",
    "   - Kaggle competitions\n",
    "   - Critical predictions (medical, financial)\n",
    "   - When small improvements matter\n",
    "\n",
    "2. **You Have Sufficient Data**\n",
    "   - Ensemble methods need enough data to train multiple models\n",
    "   - Rule of thumb: 10Ã— the minimum required for single model\n",
    "\n",
    "3. **Model Interpretability Is Not Primary Concern**\n",
    "   - Ensembles are harder to interpret than single models\n",
    "   - Trade interpretability for accuracy\n",
    "\n",
    "4. **Computational Resources Available**\n",
    "   - Training and inference are more expensive\n",
    "   - Need more memory and CPU/GPU time\n",
    "\n",
    "### âŒ Avoid Ensemble Methods When:\n",
    "\n",
    "1. **Interpretability Is Critical**\n",
    "   - Regulatory requirements (banking, healthcare)\n",
    "   - Need to explain individual predictions\n",
    "   - Use single decision tree or linear model instead\n",
    "\n",
    "2. **Real-Time Low-Latency Needed**\n",
    "   - High-frequency trading\n",
    "   - Real-time recommendations with strict SLAs\n",
    "   - Use simpler, faster models\n",
    "\n",
    "3. **Limited Data Available**\n",
    "   - Small datasets may not support multiple models\n",
    "   - Risk of overfitting increases\n",
    "   - Use regularized single models instead\n",
    "\n",
    "4. **Computational Budget Is Limited**\n",
    "   - Embedded systems\n",
    "   - Mobile applications\n",
    "   - IoT devices\n",
    "\n",
    "### Industry Applications\n",
    "\n",
    "| Industry | Use Case | Typical Ensemble |\n",
    "|----------|----------|------------------|\n",
    "| **E-commerce** | Product recommendations | Stacking (collaborative + content-based) |\n",
    "| **Finance** | Credit scoring | Gradient Boosting (XGBoost/LightGBM) |\n",
    "| **Healthcare** | Disease prediction | Random Forest (interpretable) |\n",
    "| **Marketing** | Customer churn | Boosting + calibration |\n",
    "| **Insurance** | Claim prediction | Stacking (GLM + GBM) |\n",
    "| **Tech** | Click-through rate | LightGBM (speed + accuracy) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 4: Decision Framework\n",
    "\n",
    "For each scenario, decide:\n",
    "1. Should you use an ensemble? Why or why not?\n",
    "2. If yes, which type (bagging/boosting/stacking)?\n",
    "\n",
    "**Scenarios**:\n",
    "\n",
    "A. Building a spam filter for email with 1M labeled emails\n",
    "\n",
    "B. Predicting house prices for a real estate app (need explanations for users)\n",
    "\n",
    "C. Detecting fraud in credit card transactions (imbalanced, real-time)\n",
    "\n",
    "D. Kaggle competition with tabular data (no constraints)\n",
    "\n",
    "E. Medical diagnosis system (regulatory approval needed)\n",
    "\n",
    "Write your analysis in the cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Analysis Here:**\n",
    "\n",
    "A. Spam Filter:\n",
    "- \n",
    "\n",
    "B. House Prices:\n",
    "- \n",
    "\n",
    "C. Fraud Detection:\n",
    "- \n",
    "\n",
    "D. Kaggle Competition:\n",
    "- \n",
    "\n",
    "E. Medical Diagnosis:\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps\n",
    "\n",
    "### ðŸŽ“ Key Takeaways\n",
    "\n",
    "1. **Wisdom of Crowds**: Multiple models often outperform individual models when diverse and reasonably accurate\n",
    "\n",
    "2. **Three Main Strategies**:\n",
    "   - **Bagging**: Parallel training, reduces variance (Random Forest)\n",
    "   - **Boosting**: Sequential training, reduces bias (XGBoost, LightGBM)\n",
    "   - **Stacking**: Meta-learning, reduces both (competition winner)\n",
    "\n",
    "3. **Bias-Variance**:\n",
    "   - Bagging: Reduces variance, use complex base models\n",
    "   - Boosting: Reduces bias, use simple base models\n",
    "   - Stacking: Reduces both, use diverse models\n",
    "\n",
    "4. **When to Use**:\n",
    "   - âœ… Maximum accuracy needed, sufficient data, computational resources\n",
    "   - âŒ Interpretability critical, real-time constraints, limited resources\n",
    "\n",
    "### ðŸ“š What's Next?\n",
    "\n",
    "In the upcoming modules, you'll master:\n",
    "\n",
    "- **Module 01**: Bagging and Bootstrap Aggregation (Random Forest fundamentals)\n",
    "- **Module 02**: Random Forests (hyperparameter tuning, feature importance)\n",
    "- **Module 03**: Boosting Fundamentals (AdaBoost algorithm)\n",
    "- **Module 04**: Gradient Boosting Machines (GBM theory)\n",
    "- **Modules 05-07**: XGBoost, LightGBM, CatBoost (industry-standard tools)\n",
    "- **Modules 08-10**: Advanced techniques (stacking, voting, model selection)\n",
    "- **Module 11**: Kaggle-style competition project\n",
    "\n",
    "### ðŸŽ¯ Practice Recommendations\n",
    "\n",
    "1. Implement simple voting ensemble on your own dataset\n",
    "2. Compare single model vs ensemble performance\n",
    "3. Analyze when ensemble helps most (noisy data, complex patterns)\n",
    "4. Experiment with model diversity (different algorithms, hyperparameters)\n",
    "\n",
    "### ðŸ“– Additional Resources\n",
    "\n",
    "- **\"Ensemble Methods\" by Zhou, Z-H** (comprehensive theory)\n",
    "- **Kaggle Ensembling Guide**: https://mlwave.com/kaggle-ensembling-guide/\n",
    "- **Scikit-learn Ensemble Guide**: https://scikit-learn.org/stable/modules/ensemble.html\n",
    "- **Netflix Prize** case study (stacking in action)\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸš€ Ready to dive deeper? Let's move to Module 01: Bagging and Bootstrap Aggregation!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
