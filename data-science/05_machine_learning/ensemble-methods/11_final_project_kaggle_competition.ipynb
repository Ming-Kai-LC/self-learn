{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 11: Final Project - Kaggle-Style Competition\n",
    "\n",
    "**Difficulty**: ⭐⭐⭐\n",
    "**Estimated Time**: 90-120 minutes\n",
    "**Prerequisites**: All previous modules (00-10)\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this final project, you'll complete an end-to-end machine learning workflow using ensemble methods. This simulates a real Kaggle competition environment where you'll:\n",
    "\n",
    "1. **Perform Exploratory Data Analysis (EDA)**\n",
    "2. **Engineer features** to improve model performance\n",
    "3. **Build and compare** multiple ensemble models\n",
    "4. **Tune hyperparameters** for optimal performance\n",
    "5. **Create a stacked ensemble** for final predictions\n",
    "6. **Prepare a submission** in competition format\n",
    "\n",
    "## Learning Objectives\n",
    "By completing this project, you will:\n",
    "1. Apply all ensemble methods learned in this course\n",
    "2. Conduct thorough exploratory data analysis\n",
    "3. Create meaningful features through feature engineering\n",
    "4. Build and compare multiple models systematically\n",
    "5. Optimize hyperparameters effectively\n",
    "6. Create a production-ready ensemble solution\n",
    "7. Document your work clearly and professionally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Titanic Survival Prediction\n",
    "\n",
    "**Task**: Predict whether a passenger survived the Titanic disaster\n",
    "\n",
    "**Features**:\n",
    "- PassengerId: Unique ID\n",
    "- Pclass: Ticket class (1, 2, 3)\n",
    "- Name: Passenger name\n",
    "- Sex: Gender\n",
    "- Age: Age in years\n",
    "- SibSp: Number of siblings/spouses aboard\n",
    "- Parch: Number of parents/children aboard\n",
    "- Ticket: Ticket number\n",
    "- Fare: Passenger fare\n",
    "- Cabin: Cabin number\n",
    "- Embarked: Port of embarkation (C, Q, S)\n",
    "\n",
    "**Target**: Survived (0 = No, 1 = Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    VotingClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# Boosting libraries\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    CATBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CATBOOST_AVAILABLE = False\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic dataset\n",
    "# Note: Download from https://www.kaggle.com/c/titanic/data or use seaborn\n",
    "try:\n",
    "    # Try loading from seaborn\n",
    "    df = sns.load_dataset('titanic')\n",
    "    print(\"Dataset loaded from seaborn\")\n",
    "except:\n",
    "    # If seaborn dataset not available, create sample data\n",
    "    print(\"Creating sample Titanic-like dataset\")\n",
    "    np.random.seed(42)\n",
    "    n_samples = 891\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'survived': np.random.binomial(1, 0.38, n_samples),\n",
    "        'pclass': np.random.choice([1, 2, 3], n_samples, p=[0.24, 0.21, 0.55]),\n",
    "        'sex': np.random.choice(['male', 'female'], n_samples, p=[0.65, 0.35]),\n",
    "        'age': np.random.normal(30, 14, n_samples).clip(0.4, 80),\n",
    "        'sibsp': np.random.poisson(0.5, n_samples),\n",
    "        'parch': np.random.poisson(0.4, n_samples),\n",
    "        'fare': np.random.exponential(32, n_samples),\n",
    "        'embarked': np.random.choice(['S', 'C', 'Q'], n_samples, p=[0.72, 0.19, 0.09]),\n",
    "        'class': np.random.choice(['First', 'Second', 'Third'], n_samples, p=[0.24, 0.21, 0.55])\n",
    "    })\n",
    "    # Add some missing values\n",
    "    df.loc[np.random.choice(n_samples, 177, replace=False), 'age'] = np.nan\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information\n",
    "print(\"Dataset Info:\")\n",
    "print(\"=\" * 60)\n",
    "print(df.info())\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "}).sort_values('Percentage', ascending=False)\n",
    "\n",
    "print(\"\\nMissing Values Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# Visualize missing values\n",
    "plt.figure(figsize=(10, 6))\n",
    "missing_cols = missing_df[missing_df['Missing Count'] > 0]\n",
    "if len(missing_cols) > 0:\n",
    "    plt.barh(missing_cols.index, missing_cols['Percentage'])\n",
    "    plt.xlabel('Percentage Missing')\n",
    "    plt.title('Missing Values by Feature')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count plot\n",
    "survival_counts = df['survived'].value_counts()\n",
    "axes[0].bar(['Did not survive', 'Survived'], survival_counts.values, \n",
    "           color=['#e74c3c', '#2ecc71'], alpha=0.7)\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Survival Distribution')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(survival_counts.values):\n",
    "    axes[0].text(i, v + 10, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(survival_counts.values, labels=['Did not survive', 'Survived'],\n",
    "           autopct='%1.1f%%', colors=['#e74c3c', '#2ecc71'], startangle=90)\n",
    "axes[1].set_title('Survival Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Survival Rate: {(df['survived'].sum() / len(df) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature relationships with survival\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# 1. Sex vs Survival\n",
    "if 'sex' in df.columns:\n",
    "    pd.crosstab(df['sex'], df['survived'], normalize='index').plot(\n",
    "        kind='bar', ax=axes[0], color=['#e74c3c', '#2ecc71'], alpha=0.7\n",
    "    )\n",
    "    axes[0].set_title('Survival by Sex')\n",
    "    axes[0].set_xlabel('Sex')\n",
    "    axes[0].set_ylabel('Survival Rate')\n",
    "    axes[0].legend(['Did not survive', 'Survived'])\n",
    "    axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "# 2. Pclass vs Survival\n",
    "if 'pclass' in df.columns:\n",
    "    pd.crosstab(df['pclass'], df['survived'], normalize='index').plot(\n",
    "        kind='bar', ax=axes[1], color=['#e74c3c', '#2ecc71'], alpha=0.7\n",
    "    )\n",
    "    axes[1].set_title('Survival by Passenger Class')\n",
    "    axes[1].set_xlabel('Class')\n",
    "    axes[1].set_ylabel('Survival Rate')\n",
    "    axes[1].legend(['Did not survive', 'Survived'])\n",
    "    axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=0)\n",
    "\n",
    "# 3. Age distribution\n",
    "if 'age' in df.columns:\n",
    "    df[df['survived']==0]['age'].hist(bins=20, ax=axes[2], alpha=0.6, \n",
    "                                      color='#e74c3c', label='Did not survive')\n",
    "    df[df['survived']==1]['age'].hist(bins=20, ax=axes[2], alpha=0.6, \n",
    "                                      color='#2ecc71', label='Survived')\n",
    "    axes[2].set_title('Age Distribution by Survival')\n",
    "    axes[2].set_xlabel('Age')\n",
    "    axes[2].set_ylabel('Count')\n",
    "    axes[2].legend()\n",
    "\n",
    "# 4. Fare distribution\n",
    "if 'fare' in df.columns:\n",
    "    df[df['survived']==0]['fare'].hist(bins=30, ax=axes[3], alpha=0.6, \n",
    "                                       color='#e74c3c', label='Did not survive')\n",
    "    df[df['survived']==1]['fare'].hist(bins=30, ax=axes[3], alpha=0.6, \n",
    "                                       color='#2ecc71', label='Survived')\n",
    "    axes[3].set_title('Fare Distribution by Survival')\n",
    "    axes[3].set_xlabel('Fare')\n",
    "    axes[3].set_ylabel('Count')\n",
    "    axes[3].legend()\n",
    "    axes[3].set_xlim(0, 200)  # Limit x-axis for better visualization\n",
    "\n",
    "# 5. SibSp vs Survival\n",
    "if 'sibsp' in df.columns:\n",
    "    pd.crosstab(df['sibsp'], df['survived'], normalize='index').plot(\n",
    "        kind='bar', ax=axes[4], color=['#e74c3c', '#2ecc71'], alpha=0.7\n",
    "    )\n",
    "    axes[4].set_title('Survival by Siblings/Spouses')\n",
    "    axes[4].set_xlabel('Number of Siblings/Spouses')\n",
    "    axes[4].set_ylabel('Survival Rate')\n",
    "    axes[4].legend(['Did not survive', 'Survived'])\n",
    "    axes[4].set_xticklabels(axes[4].get_xticklabels(), rotation=0)\n",
    "\n",
    "# 6. Embarked vs Survival\n",
    "if 'embarked' in df.columns:\n",
    "    pd.crosstab(df['embarked'].fillna('Unknown'), df['survived'], \n",
    "               normalize='index').plot(\n",
    "        kind='bar', ax=axes[5], color=['#e74c3c', '#2ecc71'], alpha=0.7\n",
    "    )\n",
    "    axes[5].set_title('Survival by Embarkation Port')\n",
    "    axes[5].set_xlabel('Port')\n",
    "    axes[5].set_ylabel('Survival Rate')\n",
    "    axes[5].legend(['Did not survive', 'Survived'])\n",
    "    axes[5].set_xticklabels(axes[5].get_xticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for feature engineering\n",
    "df_fe = df.copy()\n",
    "\n",
    "print(\"Feature Engineering Steps:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Family size\n",
    "if 'sibsp' in df_fe.columns and 'parch' in df_fe.columns:\n",
    "    df_fe['family_size'] = df_fe['sibsp'] + df_fe['parch'] + 1\n",
    "    print(\"✓ Created: family_size = sibsp + parch + 1\")\n",
    "\n",
    "# 2. Is alone\n",
    "    df_fe['is_alone'] = (df_fe['family_size'] == 1).astype(int)\n",
    "    print(\"✓ Created: is_alone (binary indicator)\")\n",
    "\n",
    "# 3. Age groups\n",
    "if 'age' in df_fe.columns:\n",
    "    df_fe['age_group'] = pd.cut(df_fe['age'], bins=[0, 12, 18, 35, 60, 100],\n",
    "                                labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
    "    print(\"✓ Created: age_group (5 categories)\")\n",
    "\n",
    "# 4. Fare per person\n",
    "if 'fare' in df_fe.columns and 'family_size' in df_fe.columns:\n",
    "    df_fe['fare_per_person'] = df_fe['fare'] / df_fe['family_size']\n",
    "    print(\"✓ Created: fare_per_person\")\n",
    "\n",
    "# 5. Encode categorical variables\n",
    "if 'sex' in df_fe.columns:\n",
    "    df_fe['sex_encoded'] = (df_fe['sex'] == 'male').astype(int)\n",
    "    print(\"✓ Encoded: sex (male=1, female=0)\")\n",
    "\n",
    "if 'embarked' in df_fe.columns:\n",
    "    df_fe['embarked'].fillna('S', inplace=True)  # Fill missing with most common\n",
    "    embarked_dummies = pd.get_dummies(df_fe['embarked'], prefix='embarked')\n",
    "    df_fe = pd.concat([df_fe, embarked_dummies], axis=1)\n",
    "    print(\"✓ One-hot encoded: embarked\")\n",
    "\n",
    "print(f\"\\nNew shape after feature engineering: {df_fe.shape}\")\n",
    "print(f\"\\nNew features created:\")\n",
    "new_cols = set(df_fe.columns) - set(df.columns)\n",
    "for col in sorted(new_cols):\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"\\nHandling Missing Values:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Fill age with median\n",
    "if 'age' in df_fe.columns:\n",
    "    median_age = df_fe['age'].median()\n",
    "    df_fe['age'].fillna(median_age, inplace=True)\n",
    "    print(f\"✓ Filled age missing values with median: {median_age:.1f}\")\n",
    "\n",
    "# Fill fare with median\n",
    "if 'fare' in df_fe.columns:\n",
    "    median_fare = df_fe['fare'].median()\n",
    "    df_fe['fare'].fillna(median_fare, inplace=True)\n",
    "    print(f\"✓ Filled fare missing values with median: {median_fare:.2f}\")\n",
    "\n",
    "print(f\"\\nRemaining missing values: {df_fe.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "# Define feature columns (numerical and encoded categorical)\n",
    "feature_cols = []\n",
    "\n",
    "# Add numerical features\n",
    "for col in ['pclass', 'age', 'sibsp', 'parch', 'fare', 'family_size', \n",
    "            'is_alone', 'fare_per_person', 'sex_encoded']:\n",
    "    if col in df_fe.columns:\n",
    "        feature_cols.append(col)\n",
    "\n",
    "# Add one-hot encoded features\n",
    "for col in df_fe.columns:\n",
    "    if col.startswith('embarked_'):\n",
    "        feature_cols.append(col)\n",
    "\n",
    "X = df_fe[feature_cols].fillna(0)  # Fill any remaining NaN with 0\n",
    "y = df_fe['survived']\n",
    "\n",
    "print(f\"Final feature set: {len(feature_cols)} features\")\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nTraining set survival rate: {y_train.mean():.2%}\")\n",
    "print(f\"Test set survival rate: {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Model Building and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to compare\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=5),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'),\n",
    "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "if CATBOOST_AVAILABLE:\n",
    "    models['CatBoost'] = CatBoostClassifier(iterations=100, random_state=42, verbose=False)\n",
    "\n",
    "# Train and evaluate all models\n",
    "results = []\n",
    "\n",
    "print(\"Training models...\\n\")\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\", end=' ')\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Scores\n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train Acc': train_acc,\n",
    "        'Test Acc': test_acc,\n",
    "        'CV Mean': cv_scores.mean(),\n",
    "        'CV Std': cv_scores.std(),\n",
    "        'Overfit': train_acc - test_acc\n",
    "    })\n",
    "    \n",
    "    print(f\"Done! Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values('CV Mean', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "axes[0].bar(x - width/2, results_df['Train Acc'], width, label='Train', alpha=0.8)\n",
    "axes[0].bar(x + width/2, results_df['Test Acc'], width, label='Test', alpha=0.8)\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Train vs Test Accuracy')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Cross-validation scores\n",
    "axes[1].bar(results_df['Model'], results_df['CV Mean'], alpha=0.7, color='green')\n",
    "axes[1].errorbar(results_df['Model'], results_df['CV Mean'], \n",
    "                yerr=results_df['CV Std'], fmt='none', color='black', capsize=5)\n",
    "axes[1].set_xlabel('Model')\n",
    "axes[1].set_ylabel('CV Accuracy')\n",
    "axes[1].set_title('Cross-Validation Performance (5-fold)')\n",
    "axes[1].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 3 models for hyperparameter tuning\n",
    "top_3_models = results_df.head(3)['Model'].tolist()\n",
    "print(f\"Tuning top 3 models: {top_3_models}\\n\")\n",
    "\n",
    "# Define parameter grids\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7, None],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.3]\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.3]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.3]\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'iterations': [50, 100, 200],\n",
    "        'depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.3]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Tune each of the top models\n",
    "tuned_models = {}\n",
    "\n",
    "for model_name in top_3_models:\n",
    "    if model_name in param_grids:\n",
    "        print(f\"\\nTuning {model_name}...\")\n",
    "        \n",
    "        # Get model and param grid\n",
    "        model = models[model_name]\n",
    "        param_grid = param_grids[model_name]\n",
    "        \n",
    "        # Grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            model, param_grid, cv=5, scoring='accuracy', \n",
    "            n_jobs=-1, verbose=0\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Store best model\n",
    "        tuned_models[model_name] = grid_search.best_estimator_\n",
    "        \n",
    "        print(f\"  Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"  Best CV score: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"  Test accuracy: {grid_search.score(X_test, y_test):.4f}\")\n",
    "    else:\n",
    "        # Use default model if no param grid defined\n",
    "        tuned_models[model_name] = models[model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Ensemble Creation (Voting & Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create voting ensemble\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[(name, model) for name, model in tuned_models.items()],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "voting_acc = voting_clf.score(X_test, y_test)\n",
    "\n",
    "print(\"Voting Ensemble Results:\")\n",
    "print(f\"Test Accuracy: {voting_acc:.4f}\")\n",
    "\n",
    "# Create stacking ensemble\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[(name, model) for name, model in tuned_models.items()],\n",
    "    final_estimator=LogisticRegression(random_state=42),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "stacking_acc = stacking_clf.score(X_test, y_test)\n",
    "\n",
    "print(\"\\nStacking Ensemble Results:\")\n",
    "print(f\"Test Accuracy: {stacking_acc:.4f}\")\n",
    "\n",
    "# Compare with best individual model\n",
    "best_individual_acc = max([model.score(X_test, y_test) \n",
    "                          for model in tuned_models.values()])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENSEMBLE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best Individual Model: {best_individual_acc:.4f}\")\n",
    "print(f\"Voting Ensemble:       {voting_acc:.4f} (+{voting_acc-best_individual_acc:.4f})\")\n",
    "print(f\"Stacking Ensemble:     {stacking_acc:.4f} (+{stacking_acc-best_individual_acc:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model (stacking or voting)\n",
    "if stacking_acc > voting_acc:\n",
    "    final_model = stacking_clf\n",
    "    final_model_name = \"Stacking Ensemble\"\n",
    "else:\n",
    "    final_model = voting_clf\n",
    "    final_model_name = \"Voting Ensemble\"\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL MODEL: {final_model_name}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_final = final_model.predict(X_test)\n",
    "y_pred_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_final, \n",
    "                          target_names=['Did not survive', 'Survived']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=['Did not survive', 'Survived'],\n",
    "           yticklabels=['Did not survive', 'Survived'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'{final_model_name} - Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'{final_model_name} - ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Project Summary and Key Learnings\n",
    "\n",
    "### Project Summary:\n",
    "\n",
    "In this final project, you completed a full machine learning workflow:\n",
    "\n",
    "1. **Exploratory Data Analysis**\n",
    "   - Analyzed missing values\n",
    "   - Visualized feature distributions\n",
    "   - Identified relationships with target variable\n",
    "\n",
    "2. **Feature Engineering**\n",
    "   - Created family_size and is_alone features\n",
    "   - Engineered age_group categories\n",
    "   - Calculated fare_per_person\n",
    "   - Encoded categorical variables\n",
    "\n",
    "3. **Model Building**\n",
    "   - Compared 7+ ensemble methods\n",
    "   - Used cross-validation for robust evaluation\n",
    "   - Identified top performing models\n",
    "\n",
    "4. **Hyperparameter Tuning**\n",
    "   - Grid search on top 3 models\n",
    "   - Optimized key parameters\n",
    "   - Improved model performance\n",
    "\n",
    "5. **Ensemble Creation**\n",
    "   - Built voting ensemble\n",
    "   - Built stacking ensemble\n",
    "   - Selected best final model\n",
    "\n",
    "### Key Learnings:\n",
    "\n",
    "- **Feature engineering significantly impacts performance**\n",
    "- **Different ensemble methods have different strengths**\n",
    "- **Hyperparameter tuning provides incremental improvements**\n",
    "- **Ensemble of ensembles (stacking) often achieves best results**\n",
    "- **Cross-validation prevents overfitting during model selection**\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Try more feature engineering**:\n",
    "   - Extract title from name (Mr., Mrs., etc.)\n",
    "   - Create deck feature from cabin\n",
    "   - Interaction features (e.g., sex × pclass)\n",
    "\n",
    "2. **Advanced ensembling**:\n",
    "   - Multi-level stacking\n",
    "   - Weighted voting based on CV scores\n",
    "   - Include more diverse models\n",
    "\n",
    "3. **Production considerations**:\n",
    "   - Model serialization (pickle/joblib)\n",
    "   - Prediction API\n",
    "   - Monitoring and retraining\n",
    "\n",
    "Congratulations on completing the Ensemble Methods course! You now have the skills to build production-ready ensemble models for real-world problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the final model\n",
    "# Uncomment to save:\n",
    "# with open('titanic_ensemble_model.pkl', 'wb') as f:\n",
    "#     pickle.dump(final_model, f)\n",
    "# print(\"Model saved successfully!\")\n",
    "\n",
    "# To load later:\n",
    "# with open('titanic_ensemble_model.pkl', 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)\n",
    "# predictions = loaded_model.predict(X_test)\n",
    "\n",
    "print(\"Model saving code ready (uncomment to use)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
