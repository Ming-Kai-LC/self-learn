{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 08: Stacking and Blending\n",
    "\n",
    "**Difficulty**: ⭐⭐⭐\n",
    "**Estimated Time**: 55 minutes\n",
    "**Prerequisites**: \n",
    "- Module 00: Introduction to Ensemble Methods\n",
    "- Module 02: Random Forest\n",
    "- Module 05: XGBoost\n",
    "- Module 06: LightGBM\n",
    "- Module 07: CatBoost\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand the concept of stacking (stacked generalization)\n",
    "2. Implement stacking with different base models and meta-learners\n",
    "3. Use cross-validation properly to avoid overfitting in stacking\n",
    "4. Understand the difference between stacking and blending\n",
    "5. Build multi-level stacked ensembles\n",
    "6. Know when stacking helps and when it doesn't\n",
    "7. Apply best practices for creating robust stacked models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Stacking\n",
    "\n",
    "### What is Stacking?\n",
    "\n",
    "**Stacking** (Stacked Generalization) is an ensemble technique that combines multiple models through a **meta-learner**. Instead of using simple averaging or voting, stacking trains a new model to learn how to best combine the predictions of base models.\n",
    "\n",
    "### Architecture:\n",
    "\n",
    "```\n",
    "Training Data\n",
    "     |\n",
    "     +---> Model 1 (e.g., Random Forest)\n",
    "     +---> Model 2 (e.g., XGBoost)         } Base Models (Level 0)\n",
    "     +---> Model 3 (e.g., LightGBM)\n",
    "     |\n",
    "     v\n",
    "Predictions from all models\n",
    "     |\n",
    "     v\n",
    "Meta-Learner (Level 1)  <-- Learns to combine predictions\n",
    "     |\n",
    "     v\n",
    "Final Prediction\n",
    "```\n",
    "\n",
    "### Key Principles:\n",
    "\n",
    "1. **Diversity**: Base models should be diverse (different algorithms, different hyperparameters)\n",
    "2. **Cross-Validation**: Must use CV to generate meta-features to avoid overfitting\n",
    "3. **Meta-Learner**: Usually a simple model (logistic regression, ridge, etc.)\n",
    "4. **Feature Engineering**: Base model predictions become features for meta-learner\n",
    "\n",
    "### Stacking Process:\n",
    "\n",
    "**Training Phase:**\n",
    "1. Split training data into K folds\n",
    "2. For each base model:\n",
    "   - Train on K-1 folds\n",
    "   - Predict on the held-out fold\n",
    "   - Repeat for all folds (cross-validation)\n",
    "3. Collect all out-of-fold predictions as \"meta-features\"\n",
    "4. Train meta-learner on meta-features\n",
    "5. Retrain base models on full training set for test predictions\n",
    "\n",
    "**Prediction Phase:**\n",
    "1. Each base model makes predictions on test data\n",
    "2. Meta-learner combines these predictions\n",
    "3. Output final prediction\n",
    "\n",
    "### Why Stacking Works:\n",
    "\n",
    "- Different models have different strengths and weaknesses\n",
    "- Stacking learns **when to trust which model**\n",
    "- Meta-learner can discover non-linear combinations\n",
    "- Often achieves better performance than any single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.datasets import make_classification, load_breast_cancer, load_diabetes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, RandomForestRegressor,\n",
    "    GradientBoostingClassifier, GradientBoostingRegressor,\n",
    "    StackingClassifier, StackingRegressor\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    mean_squared_error, r2_score, log_loss\n",
    ")\n",
    "\n",
    "# Boosting libraries\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "try:\n",
    "    from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "    CATBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CATBOOST_AVAILABLE = False\n",
    "    print(\"CatBoost not available - will skip CatBoost examples\")\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Stacking Example\n",
    "\n",
    "Let's start with a simple stacking example using scikit-learn's `StackingClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "cancer_data = load_breast_cancer()\n",
    "X = cancer_data.data\n",
    "y = cancer_data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models (diverse algorithms)\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('xgb', XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42, eval_metric='logloss')),\n",
    "    ('lgbm', LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42, verbose=-1)),\n",
    "    ('svm', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "]\n",
    "\n",
    "# Define meta-learner (simple model)\n",
    "meta_learner = LogisticRegression(random_state=42)\n",
    "\n",
    "# Create stacking classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_learner,\n",
    "    cv=5,  # Use 5-fold CV for meta-features\n",
    "    stack_method='auto',  # Use predict_proba if available, else predict\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Stacking Classifier created with:\")\n",
    "print(f\"- {len(base_models)} base models\")\n",
    "print(f\"- Meta-learner: {meta_learner.__class__.__name__}\")\n",
    "print(f\"- CV folds: 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train stacking classifier\n",
    "print(\"Training stacking classifier...\")\n",
    "start_time = time()\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "training_time = time() - start_time\n",
    "\n",
    "# Make predictions\n",
    "y_pred_stack = stacking_clf.predict(X_test)\n",
    "stack_acc = accuracy_score(y_test, y_pred_stack)\n",
    "\n",
    "print(f\"\\nTraining time: {training_time:.2f} seconds\")\n",
    "print(f\"Test Accuracy: {stack_acc:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_stack, target_names=cancer_data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with individual base models\n",
    "print(\"Individual Base Model Performance:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "base_accuracies = {}\n",
    "for name, model in base_models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    base_accuracies[name] = acc\n",
    "    print(f\"{name:10s}: {acc:.4f}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Stacking':10s}: {stack_acc:.4f}\")\n",
    "print(f\"\\nImprovement over best base model: {stack_acc - max(base_accuracies.values()):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "models = list(base_accuracies.keys()) + ['Stacking']\n",
    "accuracies = list(base_accuracies.values()) + [stack_acc]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['lightblue'] * len(base_accuracies) + ['red']\n",
    "bars = plt.bar(models, accuracies, color=colors, alpha=0.7)\n",
    "\n",
    "# Highlight stacking\n",
    "bars[-1].set_edgecolor('darkred')\n",
    "bars[-1].set_linewidth(2)\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylim([min(accuracies) - 0.01, 1.0])\n",
    "plt.axhline(y=max(base_accuracies.values()), color='green', \n",
    "            linestyle='--', label='Best base model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (model, acc) in enumerate(zip(models, accuracies)):\n",
    "    plt.text(i, acc + 0.002, f'{acc:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Manual Stacking Implementation\n",
    "\n",
    "Let's implement stacking manually to understand how it works under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define base models\n",
    "base_learners = [\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42, eval_metric='logloss'),\n",
    "    LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42, verbose=-1)\n",
    "]\n",
    "\n",
    "# Step 2: Generate meta-features using cross-validation\n",
    "n_folds = 5\n",
    "kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize meta-features array\n",
    "meta_features_train = np.zeros((len(X_train), len(base_learners)))\n",
    "meta_features_test = np.zeros((len(X_test), len(base_learners)))\n",
    "\n",
    "print(\"Generating meta-features...\")\n",
    "for i, model in enumerate(base_learners):\n",
    "    print(f\"\\nProcessing {model.__class__.__name__}...\")\n",
    "    \n",
    "    # For test set: average predictions across folds\n",
    "    test_preds = np.zeros(len(X_test))\n",
    "    \n",
    "    # Cross-validation for training meta-features\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_train, y_train)):\n",
    "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        # Train on this fold\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        \n",
    "        # Predict on validation fold (out-of-fold predictions)\n",
    "        meta_features_train[val_idx, i] = model.predict_proba(X_fold_val)[:, 1]\n",
    "        \n",
    "        # Predict on test set and accumulate\n",
    "        test_preds += model.predict_proba(X_test)[:, 1] / n_folds\n",
    "    \n",
    "    # Store test predictions\n",
    "    meta_features_test[:, i] = test_preds\n",
    "    print(f\"  Completed {n_folds} folds\")\n",
    "\n",
    "print(\"\\nMeta-features generated!\")\n",
    "print(f\"Train meta-features shape: {meta_features_train.shape}\")\n",
    "print(f\"Test meta-features shape: {meta_features_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train meta-learner\n",
    "meta_model = LogisticRegression(random_state=42)\n",
    "meta_model.fit(meta_features_train, y_train)\n",
    "\n",
    "# Step 4: Make final predictions\n",
    "y_pred_manual_stack = meta_model.predict(meta_features_test)\n",
    "manual_stack_acc = accuracy_score(y_test, y_pred_manual_stack)\n",
    "\n",
    "print(f\"Manual Stacking Accuracy: {manual_stack_acc:.4f}\")\n",
    "print(f\"Scikit-learn Stacking Accuracy: {stack_acc:.4f}\")\n",
    "print(f\"\\nDifference: {abs(manual_stack_acc - stack_acc):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine meta-learner coefficients\n",
    "print(\"Meta-Learner Coefficients (how much each model is trusted):\")\n",
    "print(\"=\" * 60)\n",
    "for i, model in enumerate(base_learners):\n",
    "    coef = meta_model.coef_[0][i]\n",
    "    print(f\"{model.__class__.__name__:25s}: {coef:8.4f}\")\n",
    "print(f\"{'Intercept':25s}: {meta_model.intercept_[0]:8.4f}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Positive coefficient: Model's high prediction increases final prediction\")\n",
    "print(\"- Negative coefficient: Model's high prediction decreases final prediction\")\n",
    "print(\"- Larger magnitude: Model has more influence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stacking vs Blending\n",
    "\n",
    "### Key Differences:\n",
    "\n",
    "**Stacking:**\n",
    "- Uses cross-validation to generate meta-features\n",
    "- All training data is used for meta-learner training\n",
    "- More robust, less prone to overfitting\n",
    "- More computationally expensive\n",
    "\n",
    "**Blending:**\n",
    "- Splits data into train and holdout sets\n",
    "- Base models train on train set\n",
    "- Predictions on holdout set become meta-features\n",
    "- Simpler, faster\n",
    "- Uses less data for base models\n",
    "\n",
    "Let's implement blending:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blending implementation\n",
    "# Split training data into train and holdout\n",
    "X_blend_train, X_blend_hold, y_blend_train, y_blend_hold = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(\"Blending Data Split:\")\n",
    "print(f\"Train for base models: {X_blend_train.shape}\")\n",
    "print(f\"Holdout for meta-model: {X_blend_hold.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Step 1: Train base models on blend_train\n",
    "base_models_blend = [\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42, eval_metric='logloss'),\n",
    "    LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42, verbose=-1)\n",
    "]\n",
    "\n",
    "blend_meta_train = np.zeros((len(X_blend_hold), len(base_models_blend)))\n",
    "blend_meta_test = np.zeros((len(X_test), len(base_models_blend)))\n",
    "\n",
    "for i, model in enumerate(base_models_blend):\n",
    "    # Train on blend_train\n",
    "    model.fit(X_blend_train, y_blend_train)\n",
    "    \n",
    "    # Predict on holdout set\n",
    "    blend_meta_train[:, i] = model.predict_proba(X_blend_hold)[:, 1]\n",
    "    \n",
    "    # Predict on test set\n",
    "    blend_meta_test[:, i] = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Step 2: Train meta-model on holdout predictions\n",
    "blend_meta_model = LogisticRegression(random_state=42)\n",
    "blend_meta_model.fit(blend_meta_train, y_blend_hold)\n",
    "\n",
    "# Step 3: Predict on test set\n",
    "y_pred_blend = blend_meta_model.predict(blend_meta_test)\n",
    "blend_acc = accuracy_score(y_test, y_pred_blend)\n",
    "\n",
    "print(f\"\\nBlending Accuracy: {blend_acc:.4f}\")\n",
    "print(f\"Stacking Accuracy: {stack_acc:.4f}\")\n",
    "print(f\"Difference: {abs(blend_acc - stack_acc):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-Level Stacking\n",
    "\n",
    "We can stack multiple levels of models for even better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 0: Diverse base models\n",
    "level0_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('xgb', XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')),\n",
    "    ('lgbm', LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('nb', GaussianNB())\n",
    "]\n",
    "\n",
    "# Level 1: Intermediate meta-learners\n",
    "level1_meta = StackingClassifier(\n",
    "    estimators=level0_models,\n",
    "    final_estimator=LogisticRegression(random_state=42),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Level 2: Final ensemble combining Level 0 and Level 1\n",
    "level2_models = [\n",
    "    ('level1_stack', level1_meta),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "final_stack = StackingClassifier(\n",
    "    estimators=level2_models,\n",
    "    final_estimator=Ridge(alpha=1.0),\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "print(\"Multi-Level Stacking Architecture:\")\n",
    "print(f\"Level 0: {len(level0_models)} diverse models\")\n",
    "print(f\"Level 1: Stacking ensemble\")\n",
    "print(f\"Level 2: Final combination\")\n",
    "\n",
    "# Train\n",
    "print(\"\\nTraining multi-level stack (this may take a while)...\")\n",
    "start = time()\n",
    "final_stack.fit(X_train, y_train)\n",
    "multilevel_time = time() - start\n",
    "\n",
    "# Evaluate\n",
    "y_pred_multilevel = final_stack.predict(X_test)\n",
    "multilevel_acc = accuracy_score(y_test, y_pred_multilevel)\n",
    "\n",
    "print(f\"\\nTraining time: {multilevel_time:.2f} seconds\")\n",
    "print(f\"Multi-level Stacking Accuracy: {multilevel_acc:.4f}\")\n",
    "print(f\"Single-level Stacking Accuracy: {stack_acc:.4f}\")\n",
    "print(f\"Improvement: {multilevel_acc - stack_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Multi-level stacking often provides marginal improvements but at significant computational cost. Use it when:\n",
    "- You need every bit of accuracy\n",
    "- You have computational resources\n",
    "- The problem is complex enough to benefit from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Stacking for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load regression dataset\n",
    "diabetes = load_diabetes()\n",
    "X_reg = diabetes.data\n",
    "y_reg = diabetes.target\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Regression dataset: {X_reg.shape}\")\n",
    "print(f\"Train: {X_train_reg.shape}, Test: {X_test_reg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base regressors\n",
    "base_regressors = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    ('xgb', XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)),\n",
    "    ('lgbm', LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42, verbose=-1)),\n",
    "    ('svr', SVR(kernel='rbf'))\n",
    "]\n",
    "\n",
    "# Meta-learner for regression\n",
    "meta_regressor = Ridge(alpha=1.0)\n",
    "\n",
    "# Create stacking regressor\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=base_regressors,\n",
    "    final_estimator=meta_regressor,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Train\n",
    "stacking_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_reg = stacking_reg.predict(X_test_reg)\n",
    "stack_r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "stack_mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(\"Stacking Regressor Performance:\")\n",
    "print(f\"R² Score: {stack_r2:.4f}\")\n",
    "print(f\"MSE: {stack_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with individual models\n",
    "print(\"\\nIndividual Model Performance:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "base_r2_scores = {}\n",
    "for name, model in base_regressors:\n",
    "    model.fit(X_train_reg, y_train_reg)\n",
    "    y_pred = model.predict(X_test_reg)\n",
    "    r2 = r2_score(y_test_reg, y_pred)\n",
    "    mse = mean_squared_error(y_test_reg, y_pred)\n",
    "    base_r2_scores[name] = r2\n",
    "    print(f\"{name:10s}: R² = {r2:.4f}, MSE = {mse:.2f}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Stacking':10s}: R² = {stack_r2:.4f}, MSE = {stack_mse:.2f}\")\n",
    "print(f\"\\nImprovement over best base model: {stack_r2 - max(base_r2_scores.values()):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Best base model\n",
    "best_base_name = max(base_r2_scores, key=base_r2_scores.get)\n",
    "best_base_model = dict(base_regressors)[best_base_name]\n",
    "y_pred_best = best_base_model.predict(X_test_reg)\n",
    "\n",
    "axes[0].scatter(y_test_reg, y_pred_best, alpha=0.5)\n",
    "axes[0].plot([y_test_reg.min(), y_test_reg.max()],\n",
    "             [y_test_reg.min(), y_test_reg.max()],\n",
    "             'r--', linewidth=2)\n",
    "axes[0].set_xlabel('Actual')\n",
    "axes[0].set_ylabel('Predicted')\n",
    "axes[0].set_title(f'Best Base Model ({best_base_name})\\nR² = {base_r2_scores[best_base_name]:.4f}')\n",
    "\n",
    "axes[1].scatter(y_test_reg, y_pred_reg, alpha=0.5, color='green')\n",
    "axes[1].plot([y_test_reg.min(), y_test_reg.max()],\n",
    "             [y_test_reg.min(), y_test_reg.max()],\n",
    "             'r--', linewidth=2)\n",
    "axes[1].set_xlabel('Actual')\n",
    "axes[1].set_ylabel('Predicted')\n",
    "axes[1].set_title(f'Stacking Regressor\\nR² = {stack_r2:.4f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Best Practices and Common Pitfalls\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Use Diverse Base Models**: Different algorithms, different hyperparameters\n",
    "2. **Always Use Cross-Validation**: Prevents overfitting in meta-learner\n",
    "3. **Keep Meta-Learner Simple**: Logistic regression, ridge, or linear models work well\n",
    "4. **Monitor Overfitting**: Check if stacking actually improves test performance\n",
    "5. **Start Simple**: Begin with 2-3 base models, add more if needed\n",
    "6. **Consider Computational Cost**: Stacking is expensive, use when accuracy is critical\n",
    "\n",
    "### Common Pitfalls:\n",
    "\n",
    "1. **Not Using CV**: Training meta-learner on same data as base models → Overfitting\n",
    "2. **Too Complex Meta-Learner**: Neural nets or deep trees as meta-learners often overfit\n",
    "3. **Too Many Similar Base Models**: 10 random forests won't help, diversity matters\n",
    "4. **Ignoring Correlation**: Highly correlated base models provide redundant information\n",
    "5. **Not Checking Improvement**: Sometimes simple averaging works as well as stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Checking if stacking is worth it\n",
    "# Compare stacking with simple averaging\n",
    "\n",
    "# Get probability predictions from each base model\n",
    "base_probs = []\n",
    "for name, model in base_models:\n",
    "    model.fit(X_train, y_train)\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "    base_probs.append(probs)\n",
    "\n",
    "# Simple average\n",
    "avg_probs = np.mean(base_probs, axis=0)\n",
    "y_pred_avg = (avg_probs > 0.5).astype(int)\n",
    "avg_acc = accuracy_score(y_test, y_pred_avg)\n",
    "\n",
    "# Weighted average (weights based on individual performance)\n",
    "weights = np.array([base_accuracies[name] for name, _ in base_models])\n",
    "weights = weights / weights.sum()  # Normalize\n",
    "weighted_avg_probs = np.average(base_probs, axis=0, weights=weights)\n",
    "y_pred_weighted = (weighted_avg_probs > 0.5).astype(int)\n",
    "weighted_acc = accuracy_score(y_test, y_pred_weighted)\n",
    "\n",
    "print(\"Comparison: Averaging vs Stacking\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Simple Average:    {avg_acc:.4f}\")\n",
    "print(f\"Weighted Average:  {weighted_acc:.4f}\")\n",
    "print(f\"Stacking:          {stack_acc:.4f}\")\n",
    "print(\"\\nConclusion:\")\n",
    "if stack_acc > max(avg_acc, weighted_acc) + 0.005:\n",
    "    print(\"Stacking provides meaningful improvement - worth the complexity!\")\n",
    "else:\n",
    "    print(\"Stacking improvement is marginal - simple averaging might be sufficient.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Custom Stacking Ensemble\n",
    "\n",
    "Create a stacking classifier with:\n",
    "- At least 5 diverse base models (include at least one from each family: tree-based, linear, distance-based)\n",
    "- A meta-learner of your choice\n",
    "- 10-fold cross-validation\n",
    "\n",
    "Compare its performance with the best base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Implement Blending from Scratch\n",
    "\n",
    "Implement a complete blending pipeline:\n",
    "1. Split data into train (60%), holdout (20%), and test (20%)\n",
    "2. Train 3 base models on train set\n",
    "3. Generate predictions on holdout set\n",
    "4. Train meta-learner on holdout predictions\n",
    "5. Evaluate on test set\n",
    "\n",
    "Compare with stacking using the same base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Meta-Learner Comparison\n",
    "\n",
    "Using the same set of base models, try different meta-learners:\n",
    "- Logistic Regression\n",
    "- Ridge Regression\n",
    "- Random Forest (with small n_estimators)\n",
    "- Gradient Boosting (with small n_estimators)\n",
    "\n",
    "Which meta-learner works best? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Feature Engineering with Stacking\n",
    "\n",
    "Create a stacking ensemble that uses:\n",
    "- Original features AND base model predictions as input to meta-learner\n",
    "- Set `passthrough=True` in StackingClassifier\n",
    "\n",
    "Does including original features improve performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: When Stacking Fails\n",
    "\n",
    "Create a scenario where stacking doesn't help:\n",
    "1. Use only tree-based models (Random Forest with different n_estimators)\n",
    "2. Create a stacking ensemble\n",
    "3. Compare with simple averaging\n",
    "\n",
    "Explain why stacking doesn't provide much benefit in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "In this notebook, you learned about Stacking and Blending, advanced ensemble techniques:\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Stacking (Stacked Generalization)**:\n",
    "   - Combines models through a meta-learner\n",
    "   - Uses cross-validation to generate meta-features\n",
    "   - Meta-learner learns how to weight base model predictions\n",
    "   - More robust than simple averaging\n",
    "\n",
    "2. **Architecture**:\n",
    "   - **Level 0**: Diverse base models (different algorithms)\n",
    "   - **Level 1**: Meta-learner (simple model)\n",
    "   - Can extend to multiple levels\n",
    "\n",
    "3. **Blending**:\n",
    "   - Simpler alternative to stacking\n",
    "   - Uses holdout set instead of CV\n",
    "   - Faster but uses less training data\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Model Diversity is Crucial**:\n",
    "   - Mix different algorithm types\n",
    "   - Avoid too many similar models\n",
    "   - Uncorrelated errors combine better\n",
    "\n",
    "2. **Always Use Cross-Validation**:\n",
    "   - Essential for preventing overfitting\n",
    "   - 5-10 folds typically work well\n",
    "   - Don't train meta-learner on same data as base models\n",
    "\n",
    "3. **Keep Meta-Learner Simple**:\n",
    "   - Logistic/Linear regression often best\n",
    "   - Complex meta-learners → overfitting\n",
    "   - Meta-learner should combine, not learn new patterns\n",
    "\n",
    "4. **Monitor Performance**:\n",
    "   - Check if stacking actually improves over averaging\n",
    "   - Marginal gains (<0.5%) may not justify complexity\n",
    "   - Use validation set to verify improvements\n",
    "\n",
    "### When to Use Stacking:\n",
    "\n",
    "**Use Stacking when:**\n",
    "✅ You have diverse base models with different strengths\n",
    "✅ Individual models have similar but not identical performance\n",
    "✅ You need maximum accuracy (competitions, critical applications)\n",
    "✅ Computational resources are available\n",
    "✅ You have sufficient training data (>10K samples)\n",
    "\n",
    "**Avoid Stacking when:**\n",
    "❌ Base models are too similar (low diversity)\n",
    "❌ One model significantly outperforms others\n",
    "❌ Training data is very limited (<1K samples)\n",
    "❌ Computational budget is tight\n",
    "❌ Simple averaging works nearly as well\n",
    "❌ Model interpretability is required\n",
    "\n",
    "### Stacking vs Other Ensemble Methods:\n",
    "\n",
    "| Method | Complexity | Diversity | Performance | Speed |\n",
    "|--------|-----------|-----------|-------------|-------|\n",
    "| **Bagging** | Low | Low (same algorithm) | Good | Fast |\n",
    "| **Boosting** | Medium | Low (sequential) | Excellent | Medium |\n",
    "| **Voting** | Low | High (different algorithms) | Good | Fast |\n",
    "| **Stacking** | High | High (different algorithms) | Best | Slow |\n",
    "\n",
    "### Common Applications:\n",
    "\n",
    "1. **Kaggle Competitions**: Most winners use some form of stacking\n",
    "2. **Critical Predictions**: Medical diagnosis, fraud detection\n",
    "3. **Research**: When pushing accuracy boundaries\n",
    "4. **Ensemble of Ensembles**: Combine XGBoost, LightGBM, CatBoost\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In the next module, we'll explore **Voting Classifiers and Regressors**:\n",
    "- Hard vs soft voting\n",
    "- Combining different algorithm types\n",
    "- Weight tuning for voting\n",
    "- When voting helps vs when it doesn't\n",
    "\n",
    "Voting is simpler than stacking but can still provide significant improvements!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "- [Stacked Generalization (Wolpert, 1992)](http://machine-learning.martinsewell.com/ensembles/stacking/Wolpert1992.pdf) - Original paper\n",
    "- [Scikit-learn Stacking Guide](https://scikit-learn.org/stable/modules/ensemble.html#stacking)\n",
    "- [MLxtend Stacking Tutorial](http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/)\n",
    "- [Kaggle Ensembling Guide](https://mlwave.com/kaggle-ensembling-guide/)\n",
    "- [Stacking Made Easy](https://www.kdnuggets.com/2017/02/stacking-models-imropved-predictions.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
