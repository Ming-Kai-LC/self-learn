{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 08: Stacking and Blending\n",
    "\n",
    "**Difficulty**: ‚≠ê‚≠ê‚≠ê Advanced\n",
    "**Estimated Time**: 80 minutes\n",
    "**Prerequisites**: \n",
    "- Module 05: XGBoost\n",
    "- Module 06: LightGBM\n",
    "- Module 07: CatBoost\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand meta-learning and stacked ensembles\n",
    "2. Implement multi-level stacking (2-level, 3-level)\n",
    "3. Prevent overfitting in stacking using proper cross-validation\n",
    "4. Use sklearn's StackingClassifier and StackingRegressor\n",
    "5. Understand blending and its differences from stacking\n",
    "6. Choose diverse base models for optimal ensemble\n",
    "7. Select appropriate meta-model (linear vs non-linear)\n",
    "8. Implement stacking from scratch for complete understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.datasets import load_breast_cancer, make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    roc_auc_score, roc_curve, log_loss\n",
    ")\n",
    "\n",
    "# Base models\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    GradientBoostingClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Gradient boosting libraries\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "    print(\"XGBoost not available\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LGB_AVAILABLE = False\n",
    "    print(\"LightGBM not available\")\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    CB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    CB_AVAILABLE = False\n",
    "    print(\"CatBoost not available\")\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"\\nSetup complete! All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Stacking?\n",
    "\n",
    "### Stacking = Stacked Generalization\n",
    "\n",
    "Stacking is a meta-learning technique that combines multiple models to achieve better performance than any individual model.\n",
    "\n",
    "### Key Idea\n",
    "\n",
    "Instead of using simple averaging or voting:\n",
    "1. Train multiple diverse \"base models\" (Level 0)\n",
    "2. Use their predictions as features\n",
    "3. Train a \"meta-model\" (Level 1) to combine base predictions\n",
    "4. Meta-model learns optimal way to combine base models\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "Training Data\n",
    "     |\n",
    "     v\n",
    "+----+----+----+----+\n",
    "|    |    |    |    |  Level 0: Base Models\n",
    "| RF | XGB| SVM| KNN|\n",
    "+----+----+----+----+\n",
    "  |    |    |    |\n",
    "  v    v    v    v\n",
    "  Predictions (Meta-features)\n",
    "         |\n",
    "         v\n",
    "  +-------------+      Level 1: Meta-Model\n",
    "  | Logistic Reg|\n",
    "  +-------------+\n",
    "         |\n",
    "         v\n",
    "  Final Prediction\n",
    "```\n",
    "\n",
    "### Why Stacking Works\n",
    "\n",
    "1. **Diversity**: Different models make different errors\n",
    "2. **Complementary strengths**: Each model captures different patterns\n",
    "3. **Optimal combination**: Meta-model learns best weighting\n",
    "4. **Non-linear combinations**: Can learn complex interactions\n",
    "\n",
    "### The Critical Challenge: Overfitting\n",
    "\n",
    "**Naive approach (WRONG)**:\n",
    "```python\n",
    "# Train base models on full training data\n",
    "base_predictions = base_model.predict(X_train)  # ‚Üê Leakage!\n",
    "# Train meta-model on same data predictions\n",
    "meta_model.fit(base_predictions, y_train)  # ‚Üê Overfitting!\n",
    "```\n",
    "\n",
    "Problem: Base models already \"saw\" this data, predictions are overly optimistic.\n",
    "\n",
    "**Correct approach: Out-of-fold predictions**:\n",
    "```python\n",
    "# Use cross-validation to get predictions on unseen data\n",
    "for fold in cv_folds:\n",
    "    # Train on other folds, predict on this fold\n",
    "    base_model.fit(X_train_other_folds, y_train_other_folds)\n",
    "    predictions[fold] = base_model.predict(X_train_this_fold)\n",
    "# Now meta-model trains on truly unseen predictions\n",
    "meta_model.fit(predictions, y_train)\n",
    "```\n",
    "\n",
    "### Stacking vs Other Ensembles\n",
    "\n",
    "| Method | Combination | Complexity | Overfitting Risk |\n",
    "|--------|-------------|------------|------------------|\n",
    "| **Voting** | Simple average/vote | Low | Low |\n",
    "| **Weighted Voting** | Weighted average | Low | Moderate |\n",
    "| **Stacking** | Learned combination | High | Higher (needs CV) |\n",
    "| **Boosting** | Sequential | Moderate | Moderate |\n",
    "\n",
    "### When to Use Stacking\n",
    "\n",
    "**Best for**:\n",
    "- Kaggle competitions (extra 0.5-2% accuracy)\n",
    "- High-stakes predictions (medical, finance)\n",
    "- When you have diverse strong models\n",
    "- Sufficient training data\n",
    "\n",
    "**Avoid when**:\n",
    "- Small datasets (<1000 samples)\n",
    "- Need interpretability\n",
    "- Production complexity is concern\n",
    "- Single model already excellent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "cancer_data = load_breast_cancer()\n",
    "X, y = cancer_data.data, cancer_data.target\n",
    "feature_names = cancer_data.feature_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Dataset: {len(X_train)} train, {len(X_test)} test, {X.shape[1]} features\")\n",
    "print(f\"Classes: {np.unique(y)}, Distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simple Stacking with sklearn\n",
    "\n",
    "sklearn provides `StackingClassifier` that handles cross-validation automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define diverse base models (Level 0)\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
    "    ('svm', SVC(probability=True, random_state=RANDOM_STATE)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "]\n",
    "\n",
    "# Define meta-model (Level 1)\n",
    "meta_model = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "# Create stacking classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,  # Use 5-fold CV for out-of-fold predictions\n",
    "    stack_method='predict_proba',  # Use probabilities (better than hard predictions)\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Stacking Classifier created with:\")\n",
    "print(f\"  Base models: {len(base_models)}\")\n",
    "print(f\"  Meta-model: Logistic Regression\")\n",
    "print(f\"  CV folds: 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train stacking classifier\n",
    "print(\"Training stacking classifier...\\n\")\n",
    "start = time.time()\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "stacking_time = time.time() - start\n",
    "\n",
    "# Predict\n",
    "stacking_pred = stacking_clf.predict(X_test)\n",
    "stacking_proba = stacking_clf.predict_proba(X_test)\n",
    "stacking_acc = accuracy_score(y_test, stacking_pred)\n",
    "stacking_auc = roc_auc_score(y_test, stacking_proba[:, 1])\n",
    "\n",
    "print(f\"Training time: {stacking_time:.2f} seconds\")\n",
    "print(f\"Test accuracy: {stacking_acc:.4f}\")\n",
    "print(f\"Test AUC-ROC: {stacking_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with individual base models\n",
    "print(\"\\nComparing Stacking vs Individual Models:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Train and evaluate each base model individually\n",
    "for name, model in base_models:\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        proba = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, proba)\n",
    "    else:\n",
    "        auc = np.nan\n",
    "    \n",
    "    results.append({'Model': name.upper(), 'Accuracy': acc, 'AUC': auc})\n",
    "    print(f\"{name.upper():10s} - Accuracy: {acc:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "# Add stacking results\n",
    "results.append({'Model': 'STACKING', 'Accuracy': stacking_acc, 'AUC': stacking_auc})\n",
    "print(f\"\\n{'STACKING':10s} - Accuracy: {stacking_acc:.4f}, AUC: {stacking_auc:.4f}\")\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "best_base_acc = df_results[df_results['Model'] != 'STACKING']['Accuracy'].max()\n",
    "improvement = (stacking_acc - best_base_acc) * 100\n",
    "\n",
    "print(f\"\\n‚úÖ Stacking improvement: +{improvement:.2f}% over best base model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "colors = ['steelblue'] * (len(results) - 1) + ['#e74c3c']\n",
    "axes[0].bar(range(len(results)), df_results['Accuracy'], color=colors, edgecolor='black')\n",
    "axes[0].set_xticks(range(len(results)))\n",
    "axes[0].set_xticklabels(df_results['Model'], rotation=45, ha='right')\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Model Accuracy Comparison', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].set_ylim([0.9, 1.0])\n",
    "\n",
    "# AUC comparison\n",
    "axes[1].bar(range(len(results)), df_results['AUC'], color=colors, edgecolor='black')\n",
    "axes[1].set_xticks(range(len(results)))\n",
    "axes[1].set_xticklabels(df_results['Model'], rotation=45, ha='right')\n",
    "axes[1].set_ylabel('AUC-ROC', fontsize=12)\n",
    "axes[1].set_title('Model AUC Comparison', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].set_ylim([0.9, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStacking (red bar) combines strengths of all base models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Manual Stacking Implementation\n",
    "\n",
    "Let's implement stacking from scratch to understand exactly how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out_of_fold_predictions(models, X_train, y_train, X_test, n_folds=5):\n",
    "    \"\"\"\n",
    "    Generate out-of-fold predictions for stacking.\n",
    "    \n",
    "    Returns:\n",
    "        train_meta: Out-of-fold predictions on training data (for meta-model training)\n",
    "        test_meta: Average predictions on test data (for meta-model testing)\n",
    "    \"\"\"\n",
    "    n_train = X_train.shape[0]\n",
    "    n_test = X_test.shape[0]\n",
    "    n_models = len(models)\n",
    "    \n",
    "    # Initialize arrays for meta-features\n",
    "    train_meta = np.zeros((n_train, n_models))\n",
    "    test_meta = np.zeros((n_test, n_models))\n",
    "    \n",
    "    # Create stratified folds\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # For each model\n",
    "    for model_idx, (name, model) in enumerate(models):\n",
    "        print(f\"\\nProcessing {name}...\")\n",
    "        test_preds_per_fold = np.zeros((n_test, n_folds))\n",
    "        \n",
    "        # For each fold\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "            # Split data\n",
    "            X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "            \n",
    "            # Train model on this fold's training data\n",
    "            model_clone = type(model)(**model.get_params())\n",
    "            model_clone.fit(X_tr, y_tr)\n",
    "            \n",
    "            # Predict on validation fold (out-of-fold)\n",
    "            if hasattr(model_clone, 'predict_proba'):\n",
    "                val_pred = model_clone.predict_proba(X_val)[:, 1]\n",
    "            else:\n",
    "                val_pred = model_clone.predict(X_val)\n",
    "            \n",
    "            # Store out-of-fold predictions\n",
    "            train_meta[val_idx, model_idx] = val_pred\n",
    "            \n",
    "            # Predict on test data\n",
    "            if hasattr(model_clone, 'predict_proba'):\n",
    "                test_pred = model_clone.predict_proba(X_test)[:, 1]\n",
    "            else:\n",
    "                test_pred = model_clone.predict(X_test)\n",
    "            \n",
    "            test_preds_per_fold[:, fold_idx] = test_pred\n",
    "        \n",
    "        # Average test predictions across folds\n",
    "        test_meta[:, model_idx] = test_preds_per_fold.mean(axis=1)\n",
    "        \n",
    "        print(f\"  Train meta-features shape: {train_meta[:, model_idx].shape}\")\n",
    "        print(f\"  Test meta-features shape: {test_meta[:, model_idx].shape}\")\n",
    "    \n",
    "    return train_meta, test_meta\n",
    "\n",
    "print(\"Manual stacking function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models for manual stacking\n",
    "manual_base_models = [\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
    "    ('SVM', SVC(probability=True, random_state=RANDOM_STATE))\n",
    "]\n",
    "\n",
    "print(\"Generating out-of-fold predictions...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get out-of-fold predictions\n",
    "train_meta_features, test_meta_features = get_out_of_fold_predictions(\n",
    "    manual_base_models, X_train, y_train, X_test, n_folds=5\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Meta-features generated!\")\n",
    "print(f\"Training meta-features: {train_meta_features.shape}\")\n",
    "print(f\"Test meta-features: {test_meta_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize meta-features\n",
    "meta_df = pd.DataFrame(\n",
    "    train_meta_features,\n",
    "    columns=[name for name, _ in manual_base_models]\n",
    ")\n",
    "meta_df['True Label'] = y_train\n",
    "\n",
    "print(\"\\nSample meta-features:\")\n",
    "print(meta_df.head(10))\n",
    "\n",
    "# Correlation between base model predictions\n",
    "corr = meta_df.drop('True Label', axis=1).corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            square=True, linewidths=1, cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Base Model Prediction Correlations', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLower correlation = more diversity = better stacking!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train meta-model\n",
    "print(\"Training meta-model...\")\n",
    "\n",
    "meta_model_manual = LogisticRegression(random_state=RANDOM_STATE)\n",
    "meta_model_manual.fit(train_meta_features, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "manual_stacking_pred = meta_model_manual.predict(test_meta_features)\n",
    "manual_stacking_proba = meta_model_manual.predict_proba(test_meta_features)[:, 1]\n",
    "manual_stacking_acc = accuracy_score(y_test, manual_stacking_pred)\n",
    "manual_stacking_auc = roc_auc_score(y_test, manual_stacking_proba)\n",
    "\n",
    "print(f\"\\nManual Stacking Results:\")\n",
    "print(f\"Test accuracy: {manual_stacking_acc:.4f}\")\n",
    "print(f\"Test AUC-ROC: {manual_stacking_auc:.4f}\")\n",
    "\n",
    "# Show meta-model coefficients\n",
    "print(f\"\\nMeta-model learned weights:\")\n",
    "for (name, _), coef in zip(manual_base_models, meta_model_manual.coef_[0]):\n",
    "    print(f\"  {name:20s}: {coef:+.4f}\")\n",
    "print(f\"  {'Intercept':20s}: {meta_model_manual.intercept_[0]:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Blending vs Stacking\n",
    "\n",
    "### Blending\n",
    "\n",
    "Simpler alternative to stacking:\n",
    "1. Split data: Train (60%), Blend (20%), Test (20%)\n",
    "2. Train base models on Train set\n",
    "3. Predict on Blend set\n",
    "4. Train meta-model on Blend predictions\n",
    "5. Predict on Test set\n",
    "\n",
    "### Differences\n",
    "\n",
    "| Aspect | Stacking | Blending |\n",
    "|--------|----------|----------|\n",
    "| **Data usage** | Cross-validation | Holdout set |\n",
    "| **Training data** | All data used | Some data held out |\n",
    "| **Complexity** | Higher | Lower |\n",
    "| **Overfitting risk** | Lower (CV) | Higher (single split) |\n",
    "| **Computation** | Slower (multiple folds) | Faster |\n",
    "| **Stability** | More stable | Less stable |\n",
    "\n",
    "**Recommendation**: Use stacking unless computational cost is prohibitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement blending\n",
    "print(\"Implementing Blending...\\n\")\n",
    "\n",
    "# Split data: Train (60%), Blend (20%), Test (20%)\n",
    "X_train_blend, X_blend, y_train_blend, y_blend = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=RANDOM_STATE\n",
    ")  # 0.25 of 80% = 20% of total\n",
    "\n",
    "print(f\"Train set: {len(X_train_blend)} samples\")\n",
    "print(f\"Blend set: {len(X_blend)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "# Train base models on train set\n",
    "blend_models = [\n",
    "    RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
    "    GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
    "    SVC(probability=True, random_state=RANDOM_STATE)\n",
    "]\n",
    "\n",
    "blend_meta_train = np.zeros((len(X_blend), len(blend_models)))\n",
    "blend_meta_test = np.zeros((len(X_test), len(blend_models)))\n",
    "\n",
    "for i, model in enumerate(blend_models):\n",
    "    print(f\"\\nTraining model {i+1}/{len(blend_models)}...\")\n",
    "    \n",
    "    # Train on train set\n",
    "    model.fit(X_train_blend, y_train_blend)\n",
    "    \n",
    "    # Predict on blend set (for meta-model training)\n",
    "    blend_meta_train[:, i] = model.predict_proba(X_blend)[:, 1]\n",
    "    \n",
    "    # Predict on test set\n",
    "    blend_meta_test[:, i] = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Train meta-model on blend set\n",
    "meta_model_blend = LogisticRegression(random_state=RANDOM_STATE)\n",
    "meta_model_blend.fit(blend_meta_train, y_blend)\n",
    "\n",
    "# Predict on test set\n",
    "blending_pred = meta_model_blend.predict(blend_meta_test)\n",
    "blending_acc = accuracy_score(y_test, blending_pred)\n",
    "blending_auc = roc_auc_score(y_test, meta_model_blend.predict_proba(blend_meta_test)[:, 1])\n",
    "\n",
    "print(f\"\\n‚úÖ Blending Results:\")\n",
    "print(f\"Test accuracy: {blending_acc:.4f}\")\n",
    "print(f\"Test AUC-ROC: {blending_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Stacking vs Blending\n",
    "comparison = pd.DataFrame([\n",
    "    {'Method': 'Stacking (CV)', 'Accuracy': manual_stacking_acc, 'AUC': manual_stacking_auc},\n",
    "    {'Method': 'Blending', 'Accuracy': blending_acc, 'AUC': blending_auc}\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Stacking vs Blending Comparison\")\n",
    "print(\"=\" * 70)\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\nüí° Stacking typically outperforms blending due to better data usage.\")\n",
    "print(\"   Blending is faster but uses less training data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Level Stacking\n",
    "\n",
    "Stack multiple layers for even better performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-Level Stacking\n",
    "print(\"Building 3-Level Stacking Ensemble...\\n\")\n",
    "\n",
    "# Level 0: Diverse base models\n",
    "level_0 = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE)),\n",
    "    ('svm', SVC(probability=True, random_state=RANDOM_STATE)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=7))\n",
    "]\n",
    "\n",
    "# Level 1: Intermediate models that combine Level 0\n",
    "level_1_model_1 = StackingClassifier(\n",
    "    estimators=level_0[:2],  # RF + GB\n",
    "    final_estimator=LogisticRegression(random_state=RANDOM_STATE),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "level_1_model_2 = StackingClassifier(\n",
    "    estimators=level_0[2:],  # SVM + KNN\n",
    "    final_estimator=LogisticRegression(random_state=RANDOM_STATE),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "level_1 = [\n",
    "    ('stack_1', level_1_model_1),\n",
    "    ('stack_2', level_1_model_2)\n",
    "]\n",
    "\n",
    "# Level 2: Final meta-model\n",
    "level_2 = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "# Create 3-level stacking\n",
    "multilevel_stack = StackingClassifier(\n",
    "    estimators=level_1,\n",
    "    final_estimator=level_2,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "print(\"Training 3-level stacking ensemble...\")\n",
    "start = time.time()\n",
    "multilevel_stack.fit(X_train, y_train)\n",
    "multilevel_time = time.time() - start\n",
    "\n",
    "multilevel_pred = multilevel_stack.predict(X_test)\n",
    "multilevel_acc = accuracy_score(y_test, multilevel_pred)\n",
    "multilevel_auc = roc_auc_score(y_test, multilevel_stack.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"\\nTraining time: {multilevel_time:.2f} seconds\")\n",
    "print(f\"Test accuracy: {multilevel_acc:.4f}\")\n",
    "print(f\"Test AUC-ROC: {multilevel_auc:.4f}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Warning: More levels ‚â† always better!\")\n",
    "print(\"   - Increases complexity and training time\")\n",
    "print(\"   - Risk of overfitting\")\n",
    "print(\"   - Diminishing returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Choosing Meta-Model: Linear vs Non-Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different meta-models\n",
    "meta_models_to_test = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=RANDOM_STATE)),\n",
    "    ('Ridge', Ridge(random_state=RANDOM_STATE)),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=50, max_depth=3, random_state=RANDOM_STATE)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(n_estimators=50, max_depth=2, random_state=RANDOM_STATE))\n",
    "]\n",
    "\n",
    "print(\"Testing different meta-models...\\n\")\n",
    "meta_results = []\n",
    "\n",
    "for meta_name, meta_clf in meta_models_to_test:\n",
    "    # Create stacking classifier with this meta-model\n",
    "    if meta_name == 'Ridge':\n",
    "        # Ridge is a regressor, train directly on meta-features\n",
    "        meta_clf.fit(train_meta_features, y_train)\n",
    "        pred = (meta_clf.predict(test_meta_features) > 0.5).astype(int)\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        auc = np.nan  # Ridge doesn't produce probabilities easily\n",
    "    else:\n",
    "        stack = StackingClassifier(\n",
    "            estimators=base_models,\n",
    "            final_estimator=meta_clf,\n",
    "            cv=5\n",
    "        )\n",
    "        stack.fit(X_train, y_train)\n",
    "        pred = stack.predict(X_test)\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        \n",
    "        if hasattr(stack, 'predict_proba'):\n",
    "            proba = stack.predict_proba(X_test)[:, 1]\n",
    "            auc = roc_auc_score(y_test, proba)\n",
    "        else:\n",
    "            auc = np.nan\n",
    "    \n",
    "    meta_results.append({\n",
    "        'Meta-Model': meta_name,\n",
    "        'Accuracy': acc,\n",
    "        'AUC': auc\n",
    "    })\n",
    "    \n",
    "    print(f\"{meta_name:20s} - Accuracy: {acc:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "df_meta = pd.DataFrame(meta_results)\n",
    "\n",
    "print(\"\\nüí° Insights:\")\n",
    "print(\"   - Linear meta-models (Logistic, Ridge) often work best\")\n",
    "print(\"   - Base models already capture complexity\")\n",
    "print(\"   - Non-linear meta-models can overfit\")\n",
    "print(\"   - Keep meta-model simple!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Passthrough\n",
    "\n",
    "Pass original features to meta-model along with base predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking with feature passthrough\n",
    "stack_passthrough = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "    cv=5,\n",
    "    passthrough=True  # Pass original features to meta-model\n",
    ")\n",
    "\n",
    "print(\"Training stacking with feature passthrough...\")\n",
    "stack_passthrough.fit(X_train, y_train)\n",
    "\n",
    "passthrough_pred = stack_passthrough.predict(X_test)\n",
    "passthrough_acc = accuracy_score(y_test, passthrough_pred)\n",
    "passthrough_auc = roc_auc_score(y_test, stack_passthrough.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"\\nWith passthrough:\")\n",
    "print(f\"  Accuracy: {passthrough_acc:.4f}\")\n",
    "print(f\"  AUC-ROC: {passthrough_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nWithout passthrough:\")\n",
    "print(f\"  Accuracy: {stacking_acc:.4f}\")\n",
    "print(f\"  AUC-ROC: {stacking_auc:.4f}\")\n",
    "\n",
    "print(\"\\nüí° Feature passthrough can help if:\")\n",
    "print(\"   - Base models might miss some patterns\")\n",
    "print(\"   - Original features have direct predictive power\")\n",
    "print(\"   - You have enough data to prevent overfitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Gradient Boosting Ensemble\n",
    "\n",
    "Create stacking ensemble using only gradient boosting libraries:\n",
    "\n",
    "1. Use as base models:\n",
    "   - XGBoost (if available)\n",
    "   - LightGBM (if available)\n",
    "   - CatBoost (if available)\n",
    "   - Sklearn GradientBoostingClassifier\n",
    "2. Tune each base model individually for best performance\n",
    "3. Use different hyperparameters for diversity\n",
    "4. Test different meta-models:\n",
    "   - Logistic Regression\n",
    "   - Linear SVM\n",
    "   - Another gradient boosting model\n",
    "5. Compare:\n",
    "   - Stacking vs best individual model\n",
    "   - Correlation between base predictions\n",
    "   - Improvement from stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Optimal Base Model Selection\n",
    "\n",
    "Determine which combination of base models produces best stacking:\n",
    "\n",
    "1. Create pool of candidate models (8-10 different models)\n",
    "2. For each subset of 3-5 models:\n",
    "   - Create stacking ensemble\n",
    "   - Evaluate with cross-validation\n",
    "   - Measure prediction correlation\n",
    "3. Analyze:\n",
    "   - Which combinations work best?\n",
    "   - Importance of model diversity\n",
    "   - Individual model strength vs diversity trade-off\n",
    "4. Find optimal number of base models\n",
    "5. Test hypothesis: \"More diverse = better stacking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Stacking on Imbalanced Data\n",
    "\n",
    "Test stacking on severely imbalanced classification:\n",
    "\n",
    "1. Create imbalanced dataset (95:5 ratio)\n",
    "2. Compare strategies:\n",
    "   - Stacking with standard models\n",
    "   - Stacking with balanced base models (class_weight)\n",
    "   - Stacking with resampling\n",
    "   - Weighted meta-model\n",
    "3. Evaluate using appropriate metrics:\n",
    "   - Precision-Recall AUC\n",
    "   - F1 score\n",
    "   - Balanced accuracy\n",
    "4. Determine best approach for imbalanced stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Custom Stacking with Feature Engineering\n",
    "\n",
    "Enhance stacking with custom meta-features:\n",
    "\n",
    "1. Generate standard out-of-fold predictions\n",
    "2. Create additional meta-features:\n",
    "   - Prediction variance across models\n",
    "   - Agreement score (how many models agree)\n",
    "   - Prediction confidence (max probability)\n",
    "   - Distance from decision boundary\n",
    "   - Model-specific confidence metrics\n",
    "3. Train meta-model on expanded features\n",
    "4. Compare with standard stacking\n",
    "5. Analyze which meta-features are most useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Stacking = Meta-Learning**:\n",
    "   - Combine multiple models optimally\n",
    "   - Meta-model learns how to weight base predictions\n",
    "   - Captures complementary strengths\n",
    "   - Achieves better performance than any individual model\n",
    "\n",
    "2. **Critical: Prevent Overfitting**:\n",
    "   - **NEVER** train meta-model on same data used for base training\n",
    "   - Use out-of-fold predictions (cross-validation)\n",
    "   - Each sample predicted by models that didn't see it\n",
    "   - Ensures realistic meta-features\n",
    "\n",
    "3. **Stacking vs Blending**:\n",
    "   - **Stacking**: Cross-validation, uses all data, more stable\n",
    "   - **Blending**: Holdout set, simpler, faster, less data efficient\n",
    "   - Prefer stacking for better performance\n",
    "   - Use blending if computation is constrained\n",
    "\n",
    "4. **Base Model Selection**:\n",
    "   - **Diversity is key**: Different algorithm families\n",
    "   - Include linear and non-linear models\n",
    "   - Vary hyperparameters for more diversity\n",
    "   - 3-7 base models typically optimal\n",
    "   - Check correlation - lower is better\n",
    "\n",
    "5. **Meta-Model Selection**:\n",
    "   - **Simple is often best**: Logistic Regression, Ridge\n",
    "   - Base models already capture complexity\n",
    "   - Non-linear meta-models risk overfitting\n",
    "   - Linear models provide interpretability\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Data Requirements**:\n",
    "   - Need sufficient data (1000+ samples minimum)\n",
    "   - More data ‚Üí can handle more complex stacking\n",
    "   - Small datasets ‚Üí risk of overfitting\n",
    "\n",
    "2. **Base Model Strategy**:\n",
    "   - Start with 3-5 diverse models\n",
    "   - Include at least one linear model\n",
    "   - Tune base models individually first\n",
    "   - Ensure models are sufficiently different\n",
    "\n",
    "3. **Cross-Validation**:\n",
    "   - Use 5-10 folds for out-of-fold predictions\n",
    "   - Stratified folds for classification\n",
    "   - More folds = better but slower\n",
    "   - Ensure reproducibility (set random_state)\n",
    "\n",
    "4. **Meta-Model Training**:\n",
    "   - Start simple (Logistic Regression)\n",
    "   - Use probabilities, not hard predictions\n",
    "   - Try feature passthrough if appropriate\n",
    "   - Regularization helps prevent overfitting\n",
    "\n",
    "5. **Multi-Level Stacking**:\n",
    "   - 2 levels usually sufficient\n",
    "   - 3+ levels rarely worth complexity\n",
    "   - Each level increases overfitting risk\n",
    "   - Diminishing returns\n",
    "\n",
    "### Common Mistakes\n",
    "\n",
    "‚ùå **Training meta-model on in-sample predictions**\n",
    "  ‚Üí Use out-of-fold predictions!\n",
    "\n",
    "‚ùå **Using highly correlated base models**\n",
    "  ‚Üí Ensure diversity in model types\n",
    "\n",
    "‚ùå **Over-complex meta-model**\n",
    "  ‚Üí Keep it simple (linear often best)\n",
    "\n",
    "‚ùå **Too many base models**\n",
    "  ‚Üí 3-7 models, quality over quantity\n",
    "\n",
    "‚ùå **Ignoring computational cost**\n",
    "  ‚Üí Stacking is slower than single models\n",
    "\n",
    "‚ùå **Not validating properly**\n",
    "  ‚Üí Always use separate test set\n",
    "\n",
    "### When to Use Stacking\n",
    "\n",
    "**Best for**:\n",
    "- ‚úÖ Kaggle competitions (squeeze last 0.5-2%)\n",
    "- ‚úÖ High-stakes predictions (medical, finance)\n",
    "- ‚úÖ Have diverse strong base models\n",
    "- ‚úÖ Sufficient training data (1000+ samples)\n",
    "- ‚úÖ Computational resources available\n",
    "\n",
    "**Avoid when**:\n",
    "- ‚ùå Small datasets (<500 samples)\n",
    "- ‚ùå Need interpretability\n",
    "- ‚ùå Production complexity is concern\n",
    "- ‚ùå Limited computation\n",
    "- ‚ùå Single model already excellent (>98% accuracy)\n",
    "\n",
    "### Performance Expectations\n",
    "\n",
    "Typical improvements from stacking:\n",
    "- **Accuracy**: +0.5% to +2%\n",
    "- **AUC**: +0.01 to +0.03\n",
    "- **F1 Score**: +1% to +3%\n",
    "\n",
    "Not dramatic, but can be decisive in:\n",
    "- Competitions\n",
    "- Medical diagnosis\n",
    "- Financial predictions\n",
    "- High-value decisions\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "1. **Complexity**: Multiple models to deploy\n",
    "2. **Latency**: Slower predictions (all models + meta)\n",
    "3. **Maintenance**: Update all models, not just one\n",
    "4. **Dependencies**: Multiple libraries potentially\n",
    "5. **Debugging**: Harder to diagnose issues\n",
    "\n",
    "**Tip**: Carefully weigh accuracy gain vs operational complexity!\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 09: Voting Classifiers and Regressors**, we'll explore:\n",
    "- Simpler alternative to stacking\n",
    "- Hard voting vs soft voting\n",
    "- Weighted voting strategies\n",
    "- When voting beats stacking\n",
    "- Optimal weight finding\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- **Paper**: \"Stacked Generalization\" (Wolpert, 1992)\n",
    "- **Paper**: \"Issues in Stacked Generalization\" (Ting & Witten, 1999)\n",
    "- **sklearn**: [Stacking Documentation](https://scikit-learn.org/stable/modules/ensemble.html#stacking)\n",
    "- **Tutorial**: [A Kaggler's Guide to Model Stacking](https://mlwave.com/kaggle-ensembling-guide/)\n",
    "- **Book**: \"Ensemble Methods\" by Zhi-Hua Zhou"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
