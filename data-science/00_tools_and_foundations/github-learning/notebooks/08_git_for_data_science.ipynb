{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Module 08: Git for Data Science\n\n**Difficulty**: \u2b50\u2b50 Intermediate\n\n**Estimated Time**: 75-90 minutes\n\n**Prerequisites**: \n- [Module 00]()\n- [Module 01]()\n- [Module 02]()\n- [Module 03]()\n- [Module 04]()\n- [Module 05]()\n- [Module 06]()\n- [Module 07]()\n\n---\n\n## Learning Objectives\n\nBy the end of this notebook, you will be able to:\n\n1. Version Jupyter notebooks effectively\n2. Handle large datasets with Git LFS\n3. Use nbstripout for clean commits\n4. Implement data versioning strategies\n5. Track experiments systematically\n6. Create reproducible workflows\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Versioning Jupyter Notebooks\n\nJupyter notebooks contain both code and outputs, making version control tricky.\n\n### The Problem\n\nNotebooks include:\n- Code cells\n- Output cells (can be large)\n- Metadata (execution counts, timestamps)\n- Binary data (images, plots)\n\nThis makes diffs messy and merge conflicts common.\n\n### Solution: nbstripout\n\n**Install**:\n```bash\npip install nbstripout\n```\n\n**Setup** (one-time):\n```bash\nnbstripout --install\n```\n\nThis automatically strips outputs before committing!\n\n### Manual Stripping\n\n```bash\n# Strip outputs from specific notebook\nnbstripout notebook.ipynb\n\n# Strip all notebooks\nfind . -name '*.ipynb' -exec nbstripout {} \\;\n```\n\n### .gitattributes for Notebooks\n\nCreate `.gitattributes`:\n```\n*.ipynb filter=nbstripout\n*.ipynb diff=ipynb\n```\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Git LFS for Large Files\n\nGit Large File Storage handles big files efficiently.\n\n### Why Git LFS?\n\nGit struggles with:\n- Large datasets (>100MB)\n- Binary files\n- Files that change frequently\n\n### Installing Git LFS\n\n```bash\n# macOS\nbrew install git-lfs\n\n# Linux\nsudo apt-get install git-lfs\n\n# Initialize\ngit lfs install\n```\n\n### Tracking Large Files\n\n```bash\n# Track specific file types\ngit lfs track \"*.csv\"\ngit lfs track \"*.h5\"\ngit lfs track \"*.pkl\"\n\n# Track specific files\ngit lfs track \"data/large_dataset.csv\"\n\n# Commit .gitattributes\ngit add .gitattributes\ngit commit -m \"Configure Git LFS\"\n```\n\n### Best Practices\n\n- Track files >50MB with LFS\n- Don't track files that change frequently\n- Consider external storage for very large datasets\n- Document data sources in README\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Data Versioning Strategies\n\n### Directory Structure\n\n```\nproject/\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 raw/              # Original data (never modify)\n\u2502   \u251c\u2500\u2500 processed/        # Cleaned data\n\u2502   \u251c\u2500\u2500 interim/          # Intermediate transformations\n\u2502   \u2514\u2500\u2500 external/         # Third-party data\n\u251c\u2500\u2500 notebooks/\n\u2502   \u251c\u2500\u2500 01_exploration.ipynb\n\u2502   \u251c\u2500\u2500 02_preprocessing.ipynb\n\u2502   \u2514\u2500\u2500 03_modeling.ipynb\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 data/             # Data processing scripts\n\u2502   \u2514\u2500\u2500 models/           # Model code\n\u2514\u2500\u2500 .gitignore\n```\n\n### .gitignore for Data Science\n\n```\n# Data (use selective commits)\ndata/raw/*\ndata/processed/*\n!data/raw/.gitkeep\n!data/processed/.gitkeep\n\n# Models\nmodels/*.h5\nmodels/*.pkl\n\n# Jupyter\n.ipynb_checkpoints/\n*_tested.ipynb\n\n# Python\n__pycache__/\n*.py[cod]\n```\n\n### Data Version Control (DVC)\n\nTool specifically for data versioning:\n\n```bash\n# Install\npip install dvc\n\n# Initialize\ndvc init\n\n# Track data\ndvc add data/raw/dataset.csv\ngit add data/raw/dataset.csv.dvc .gitignore\ngit commit -m \"Add dataset\"\n\n# Push data to remote storage\ndvc remote add -d storage s3://mybucket/path\ndvc push\n```\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Experiment Tracking\n\n### Git Branching for Experiments\n\n```bash\n# Create experiment branch\ngit switch -c experiment/xgboost-hyperparameters\n\n# Make changes, train models, evaluate\n# ...\n\n# If successful, merge back\ngit switch main\ngit merge experiment/xgboost-hyperparameters\n\n# If unsuccessful, delete branch\ngit branch -D experiment/xgboost-hyperparameters\n```\n\n### Tags for Model Versions\n\n```bash\n# Tag a model version\ngit tag -a v1.0.0 -m \"Production model v1.0.0 - Accuracy: 94.2%\"\ngit push origin v1.0.0\n\n# List tags\ngit tag -l\n\n# Checkout specific version\ngit checkout v1.0.0\n```\n\n### Experiment Logging\n\nCreate `.experiment_log.md`:\n\n```markdown\n# Experiment Log\n\n## 2024-01-15: XGBoost Hyperparameter Tuning\n\n- **Branch**: experiment/xgboost-hp\n- **Data**: data/processed/train_2024-01.csv\n- **Model**: XGBoost v1.7.0\n- **Parameters**:\n  - max_depth: 6\n  - learning_rate: 0.1\n  - n_estimators: 100\n- **Results**:\n  - Accuracy: 94.2%\n  - F1 Score: 0.91\n- **Status**: SUCCESS - Merged to main\n- **Commit**: abc123\n```\n\n---"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Example: Setting up nbstripout\nimport os\n\n# Create sample notebook for demonstration\npractice_dir = \"../outputs/data_science_git\"\nos.makedirs(practice_dir, exist_ok=True)\n\nprint(f\"Created: {practice_dir}\")\nprint(\"\\nSetup nbstripout:\")\nprint(\"1. pip install nbstripout\")\nprint(\"2. nbstripout --install\")\nprint(\"3. Outputs will be stripped automatically!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Exercises\n\n### Exercise 1\n\nPractice the concepts from this module.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Your code for Exercise 1\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Exercise 2\n\nApply your knowledge to a real scenario.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Your code for Exercise 2\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Exercise 3\n\nChallenge exercise combining multiple concepts.\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Your code for Exercise 3\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Knowledge Check\n\nEnsure you can answer key questions from this module.\n\n### Checklist\n- [ ] Understand core concepts\n- [ ] Completed all exercises\n- [ ] Can apply skills independently\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Summary\n\nIn this module, you learned essential skills for git for data science.\n\n---\n\n## Next Steps\n\nContinue to the next module!\n\n**Excellent work!**"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}