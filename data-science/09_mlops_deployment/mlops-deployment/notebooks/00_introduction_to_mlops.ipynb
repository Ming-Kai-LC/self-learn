{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 00: Introduction to MLOps and the ML Lifecycle\n",
    "\n",
    "**Difficulty**: ⭐⭐ Intermediate\n",
    "**Estimated Time**: 45 minutes\n",
    "**Prerequisites**: Basic understanding of machine learning concepts\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Define MLOps and explain why it's critical for production ML systems\n",
    "2. Describe the complete ML lifecycle from experimentation to production\n",
    "3. Identify key differences between DevOps and MLOps\n",
    "4. Assess MLOps maturity levels and understand the evolution path\n",
    "5. Recognize common challenges in productionizing ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is MLOps?\n",
    "\n",
    "**MLOps (Machine Learning Operations)** is a set of practices that combines Machine Learning, DevOps, and Data Engineering to deploy and maintain ML systems in production reliably and efficiently.\n",
    "\n",
    "### The Challenge\n",
    "According to industry research:\n",
    "- **Only 22% of companies have successfully deployed an ML model to production**\n",
    "- **87% of ML projects never make it to production**\n",
    "- The average time from prototype to production is **8-12 months**\n",
    "\n",
    "### Why MLOps?\n",
    "Building a model in a Jupyter notebook is fundamentally different from running it in production:\n",
    "\n",
    "| Aspect | Research/Development | Production |\n",
    "|--------|---------------------|------------|\n",
    "| Data | Static CSV files | Streaming, changing data |\n",
    "| Performance | Best accuracy on test set | Speed, latency, throughput |\n",
    "| Scale | Small datasets | Millions of predictions/day |\n",
    "| Reliability | Can rerun if fails | Must handle errors gracefully |\n",
    "| Monitoring | Accuracy metrics | Data drift, model drift, uptime |\n",
    "| Updates | When you feel like it | Continuous retraining needed |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Complete ML Lifecycle\n",
    "\n",
    "The ML lifecycle consists of several interconnected phases:\n",
    "\n",
    "```\n",
    "┌─────────────────┐\n",
    "│  1. Problem     │\n",
    "│  Definition     │\n",
    "└────────┬────────┘\n",
    "         │\n",
    "         ↓\n",
    "┌─────────────────┐\n",
    "│  2. Data        │\n",
    "│  Collection     │\n",
    "└────────┬────────┘\n",
    "         │\n",
    "         ↓\n",
    "┌─────────────────┐\n",
    "│  3. Data        │\n",
    "│  Preparation    │\n",
    "└────────┬────────┘\n",
    "         │\n",
    "         ↓\n",
    "┌─────────────────┐\n",
    "│  4. Model       │──────┐\n",
    "│  Training       │      │ Experiment\n",
    "└────────┬────────┘      │ Tracking\n",
    "         │               │\n",
    "         ↓               │\n",
    "┌─────────────────┐      │\n",
    "│  5. Model       │──────┘\n",
    "│  Evaluation     │\n",
    "└────────┬────────┘\n",
    "         │\n",
    "         ↓\n",
    "┌─────────────────┐\n",
    "│  6. Model       │\n",
    "│  Deployment     │\n",
    "└────────┬────────┘\n",
    "         │\n",
    "         ↓\n",
    "┌─────────────────┐\n",
    "│  7. Monitoring  │──┐\n",
    "│  & Maintenance  │  │\n",
    "└─────────────────┘  │\n",
    "         ↑           │\n",
    "         │           │\n",
    "         └───────────┘\n",
    "     (Retrain when needed)\n",
    "```\n",
    "\n",
    "### Phase Breakdown\n",
    "\n",
    "**1. Problem Definition**: What business problem are we solving? What does success look like?\n",
    "\n",
    "**2. Data Collection**: Gathering training data, establishing data pipelines\n",
    "\n",
    "**3. Data Preparation**: Cleaning, feature engineering, train/test splits\n",
    "\n",
    "**4. Model Training**: Experiment with algorithms, hyperparameters, architectures\n",
    "\n",
    "**5. Model Evaluation**: Validate performance on held-out data\n",
    "\n",
    "**6. Model Deployment**: Make model available for predictions\n",
    "\n",
    "**7. Monitoring & Maintenance**: Track performance, detect drift, retrain when necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DevOps vs MLOps\n",
    "\n",
    "While MLOps builds on DevOps principles, ML systems have unique challenges:\n",
    "\n",
    "### Traditional DevOps\n",
    "- **Code** is the primary artifact\n",
    "- Testing is deterministic (same input → same output)\n",
    "- Deployment means deploying new code\n",
    "- Monitoring focuses on system health (CPU, memory, latency)\n",
    "\n",
    "### MLOps: DevOps + More\n",
    "- **Code + Data + Model** are all versioned artifacts\n",
    "- Testing includes data validation and model quality\n",
    "- Deployment means deploying code + model + pipeline\n",
    "- Monitoring includes system health + model performance + data drift\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "| Aspect | DevOps | MLOps |\n",
    "|--------|--------|-------|\n",
    "| **Artifacts** | Code | Code + Data + Model |\n",
    "| **Testing** | Unit, integration tests | + Data validation, model quality |\n",
    "| **Reproducibility** | Git commit | Git + data version + environment |\n",
    "| **Deployment** | Deploy code | Deploy model + inference pipeline |\n",
    "| **Monitoring** | Logs, metrics, traces | + Model metrics, data drift |\n",
    "| **Updates** | When code changes | When code OR data changes |\n",
    "| **Performance** | Deterministic | Can degrade over time (drift) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Three Levels of MLOps Maturity\n",
    "\n",
    "Organizations typically evolve through three maturity levels:\n",
    "\n",
    "### Level 0: Manual Process (No MLOps)\n",
    "- **Training**: Manual, script-driven process\n",
    "- **Deployment**: Manual, infrequent releases\n",
    "- **Monitoring**: Minimal or non-existent\n",
    "- **Typical for**: POCs, academic projects, very small teams\n",
    "- **Pain points**: Slow iteration, hard to reproduce results, fragile systems\n",
    "\n",
    "### Level 1: ML Pipeline Automation\n",
    "- **Training**: Automated pipeline (feature engineering → training → validation)\n",
    "- **Deployment**: Manual deployment but automated testing\n",
    "- **Monitoring**: Basic model performance tracking\n",
    "- **Features**:\n",
    "  - Experiment tracking (MLflow, Weights & Biases)\n",
    "  - Model versioning\n",
    "  - Feature store (optional)\n",
    "  - Continuous training on new data\n",
    "- **Typical for**: Small to medium ML teams, single-model deployments\n",
    "\n",
    "### Level 2: CI/CD Pipeline Automation\n",
    "- **Training**: Fully automated pipeline\n",
    "- **Deployment**: Automated deployment with CI/CD\n",
    "- **Monitoring**: Comprehensive monitoring and alerting\n",
    "- **Features**:\n",
    "  - Automated testing (data validation, model validation)\n",
    "  - Automated deployment (canary, blue-green, A/B testing)\n",
    "  - Feature store with versioning\n",
    "  - Real-time monitoring and drift detection\n",
    "  - Automated retraining triggers\n",
    "- **Typical for**: Large ML teams, multiple models in production, high-stakes applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import required libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizing the MLOps Landscape\n",
    "\n",
    "Let's create visualizations to understand MLOps concepts better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the success rate of ML projects\n",
    "categories = ['Start ML\\nProject', 'Build\\nPrototype', 'Validate\\nModel', 'Deploy to\\nProduction']\n",
    "success_rates = [100, 75, 40, 22]  # Approximate industry statistics\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['#2ecc71', '#f39c12', '#e67e22', '#e74c3c']\n",
    "bars = ax.bar(categories, success_rates, color=colors, alpha=0.8, edgecolor='black')\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for bar, rate in zip(bars, success_rates):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "            f'{rate}%',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Success Rate (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('The ML Project Attrition Funnel\\n(Why We Need MLOps)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_ylim(0, 110)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add insight text\n",
    "ax.text(0.5, 0.95, 'Only 22% of ML projects reach production!',\n",
    "        transform=ax.transAxes, ha='center', va='top',\n",
    "        fontsize=11, style='italic', bbox=dict(boxstyle='round',\n",
    "        facecolor='yellow', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insight: MLOps practices bridge the gap between prototype and production.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate model performance degradation over time (model drift)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate 180 days of model performance\n",
    "days = 180\n",
    "time_points = np.arange(days)\n",
    "\n",
    "# Initial model accuracy with gradual degradation\n",
    "initial_accuracy = 0.92\n",
    "degradation_rate = 0.0008  # Accuracy drops ~0.08% per day\n",
    "noise = np.random.normal(0, 0.01, days)  # Random daily fluctuations\n",
    "\n",
    "# Simulate accuracy over time\n",
    "accuracy_over_time = initial_accuracy - (degradation_rate * time_points) + noise\n",
    "accuracy_over_time = np.clip(accuracy_over_time, 0.7, 1.0)  # Keep realistic bounds\n",
    "\n",
    "# Create visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot accuracy trend\n",
    "ax.plot(time_points, accuracy_over_time, linewidth=2, label='Model Accuracy', color='#3498db')\n",
    "\n",
    "# Add threshold line\n",
    "threshold = 0.85\n",
    "ax.axhline(y=threshold, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Acceptable Threshold ({threshold})', alpha=0.7)\n",
    "\n",
    "# Shade the area below threshold\n",
    "below_threshold = accuracy_over_time < threshold\n",
    "if below_threshold.any():\n",
    "    first_below = np.argmax(below_threshold)\n",
    "    ax.axvspan(first_below, days, alpha=0.2, color='red', \n",
    "               label='Performance Degraded')\n",
    "    ax.axvline(x=first_below, color='orange', linestyle=':', linewidth=2,\n",
    "               label=f'Retraining Needed (Day {first_below})')\n",
    "\n",
    "ax.set_xlabel('Days Since Deployment', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Model Accuracy', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Model Performance Degradation Over Time (Model Drift)\\nWithout MLOps Monitoring', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "ax.set_ylim(0.65, 0.95)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nWithout monitoring, it took {first_below} days to detect performance degradation!\")\n",
    "print(\"MLOps monitoring would alert you immediately when accuracy drops below threshold.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key MLOps Components\n",
    "\n",
    "A complete MLOps system includes:\n",
    "\n",
    "### 1. Experiment Tracking\n",
    "- **Purpose**: Track all experiments, parameters, and results\n",
    "- **Tools**: MLflow, Weights & Biases, Neptune.ai\n",
    "- **What to track**: Hyperparameters, metrics, artifacts, code version\n",
    "\n",
    "### 2. Model Registry\n",
    "- **Purpose**: Central repository for trained models\n",
    "- **Features**: Versioning, staging (dev/staging/production), lineage tracking\n",
    "- **Tools**: MLflow Model Registry, DVC, ModelDB\n",
    "\n",
    "### 3. Feature Store\n",
    "- **Purpose**: Centralized storage for ML features\n",
    "- **Benefits**: Consistency between training and serving, feature reuse\n",
    "- **Tools**: Feast, Tecton, AWS SageMaker Feature Store\n",
    "\n",
    "### 4. Model Serving Infrastructure\n",
    "- **Purpose**: Deploy models for inference\n",
    "- **Patterns**: REST API, batch processing, streaming\n",
    "- **Tools**: FastAPI, TensorFlow Serving, TorchServe, Seldon\n",
    "\n",
    "### 5. Monitoring & Observability\n",
    "- **Purpose**: Track model and system health in production\n",
    "- **Metrics**: Model performance, data drift, system latency\n",
    "- **Tools**: Prometheus, Grafana, Evidently AI, WhyLabs\n",
    "\n",
    "### 6. CI/CD Pipelines\n",
    "- **Purpose**: Automate testing and deployment\n",
    "- **Tests**: Data validation, model validation, integration tests\n",
    "- **Tools**: GitHub Actions, GitLab CI, Jenkins, CircleCI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Common MLOps Challenges\n",
    "\n",
    "### Technical Challenges\n",
    "1. **Reproducibility**: Ensuring experiments can be reproduced exactly\n",
    "2. **Scalability**: Handling large datasets and high prediction volumes\n",
    "3. **Model Versioning**: Tracking models, data, and code together\n",
    "4. **Data Drift**: Detecting when input data distribution changes\n",
    "5. **Model Drift**: Detecting when model performance degrades\n",
    "\n",
    "### Organizational Challenges\n",
    "1. **Skills Gap**: DS/ML engineers may lack ops/engineering skills\n",
    "2. **Collaboration**: Data scientists, ML engineers, DevOps, and business stakeholders need alignment\n",
    "3. **Technical Debt**: Quick prototypes accumulate debt that's hard to refactor\n",
    "4. **Culture**: Moving from \"model accuracy\" to \"business value\" mindset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exercises\n",
    "\n",
    "Test your understanding with these exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Identify MLOps Maturity Level\n",
    "\n",
    "For each scenario, identify the MLOps maturity level (0, 1, or 2):\n",
    "\n",
    "**Scenario A**: A startup runs models in Jupyter notebooks. They retrain manually when performance seems bad. Deployment involves copying the notebook to a server.\n",
    "\n",
    "**Scenario B**: A mid-sized company uses MLflow to track experiments. They have automated training pipelines but deploy models manually after reviewing metrics. Basic monitoring is in place.\n",
    "\n",
    "**Scenario C**: A large tech company has fully automated ML pipelines with CI/CD. Models are automatically tested, validated, and deployed with canary releases. Real-time monitoring triggers automatic retraining.\n",
    "\n",
    "**Your Answers**:\n",
    "- Scenario A: _____ (Level ___)\n",
    "- Scenario B: _____ (Level ___)\n",
    "- Scenario C: _____ (Level ___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 Solution (run to check your answers)\n",
    "print(\"SOLUTION:\")\n",
    "print(\"Scenario A: Level 0 (Manual Process)\")\n",
    "print(\"  - No automation, manual deployment, minimal monitoring\\n\")\n",
    "\n",
    "print(\"Scenario B: Level 1 (ML Pipeline Automation)\")\n",
    "print(\"  - Automated training, experiment tracking, but manual deployment\\n\")\n",
    "\n",
    "print(\"Scenario C: Level 2 (CI/CD Pipeline Automation)\")\n",
    "print(\"  - Fully automated end-to-end, comprehensive monitoring, auto-retraining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: MLOps vs DevOps Comparison\n",
    "\n",
    "Fill in the table comparing DevOps and MLOps practices:\n",
    "\n",
    "| Aspect | DevOps | MLOps |\n",
    "|--------|--------|-------|\n",
    "| Primary artifact | __________ | __________ |\n",
    "| Version control includes | Code | __________ |\n",
    "| Testing includes | Unit tests | __________ |\n",
    "| Performance over time | __________ | __________ |\n",
    "| Deployment triggers | __________ | __________ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 Solution\n",
    "print(\"SOLUTION:\")\n",
    "print(\"\\n| Aspect | DevOps | MLOps |\")\n",
    "print(\"|--------|--------|-------|\")\n",
    "print(\"| Primary artifact | Code | Code + Data + Model |\")\n",
    "print(\"| Version control includes | Code | Code + Data + Model + Environment |\")\n",
    "print(\"| Testing includes | Unit tests | Unit tests + Data validation + Model quality tests |\")\n",
    "print(\"| Performance over time | Stable/deterministic | Can degrade (drift) |\")\n",
    "print(\"| Deployment triggers | Code changes | Code OR Data changes OR Performance degradation |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Identify Missing MLOps Components\n",
    "\n",
    "A company has the following ML infrastructure:\n",
    "- Jupyter notebooks for model development\n",
    "- Git for code versioning\n",
    "- A Flask API to serve predictions\n",
    "- Logging of API requests\n",
    "\n",
    "**Question**: What critical MLOps components are missing? List at least 5 and explain why each is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 Solution\n",
    "print(\"SOLUTION: Missing MLOps Components\\n\")\n",
    "print(\"1. Experiment Tracking\")\n",
    "print(\"   Why: Can't reproduce past experiments or compare different approaches\\n\")\n",
    "\n",
    "print(\"2. Model Registry\")\n",
    "print(\"   Why: No systematic way to version models or track what's in production\\n\")\n",
    "\n",
    "print(\"3. Data Versioning\")\n",
    "print(\"   Why: Can't reproduce models if training data changes\\n\")\n",
    "\n",
    "print(\"4. Automated Testing\")\n",
    "print(\"   Why: No validation that model performs well before deployment\\n\")\n",
    "\n",
    "print(\"5. Model Monitoring\")\n",
    "print(\"   Why: Won't detect if model performance degrades or data drifts\\n\")\n",
    "\n",
    "print(\"6. CI/CD Pipeline\")\n",
    "print(\"   Why: Manual deployment is slow, error-prone, and doesn't scale\\n\")\n",
    "\n",
    "print(\"7. Feature Store (optional but recommended)\")\n",
    "print(\"   Why: Ensures consistency between training and serving features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Design Your MLOps Journey\n",
    "\n",
    "You're a data scientist at a company moving from Level 0 to Level 1 MLOps.\n",
    "\n",
    "**Current State**: \n",
    "- Models trained in notebooks\n",
    "- Manual deployment\n",
    "- No monitoring\n",
    "\n",
    "**Question**: Design a 6-month roadmap to reach Level 1. What would you implement first, second, third? Justify your priorities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4 Solution (Example Roadmap)\n",
    "roadmap = {\n",
    "    \"Month 1-2: Foundation\": [\n",
    "        \"Implement experiment tracking (MLflow)\",\n",
    "        \"Set up model registry\",\n",
    "        \"Establish code versioning best practices\",\n",
    "        \"Why: These are prerequisites for everything else\"\n",
    "    ],\n",
    "    \"Month 3-4: Automation\": [\n",
    "        \"Create automated training pipeline\",\n",
    "        \"Implement data validation\",\n",
    "        \"Set up automated model testing\",\n",
    "        \"Why: Reduce manual work and catch errors early\"\n",
    "    ],\n",
    "    \"Month 5-6: Monitoring & Deployment\": [\n",
    "        \"Deploy basic monitoring dashboard\",\n",
    "        \"Implement model performance tracking\",\n",
    "        \"Create deployment checklists/runbooks\",\n",
    "        \"Why: Ensure models work well in production\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"EXAMPLE SOLUTION: 6-Month MLOps Roadmap\\n\")\n",
    "for phase, tasks in roadmap.items():\n",
    "    print(f\"\\n{phase}\")\n",
    "    print(\"=\" * 50)\n",
    "    for task in tasks:\n",
    "        print(f\"  • {task}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Key Principle: Start with visibility (tracking), then automate, then monitor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **MLOps is critical**: Only 22% of ML projects reach production without it\n",
    "\n",
    "2. **ML lifecycle is circular**: Models need continuous monitoring and retraining\n",
    "\n",
    "3. **MLOps ≠ DevOps**: ML systems require versioning of code, data, AND models\n",
    "\n",
    "4. **Maturity levels**: Organizations evolve from manual (Level 0) → automated pipelines (Level 1) → full CI/CD (Level 2)\n",
    "\n",
    "5. **Core components**: \n",
    "   - Experiment tracking\n",
    "   - Model registry\n",
    "   - Automated pipelines\n",
    "   - Monitoring and alerting\n",
    "   - CI/CD\n",
    "\n",
    "6. **Common challenges**: Reproducibility, drift detection, scaling, and organizational alignment\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In the following modules, we'll implement each MLOps component:\n",
    "- **Module 01**: Experiment tracking with MLflow\n",
    "- **Module 02**: Model versioning and registry\n",
    "- **Module 03**: Model serialization techniques\n",
    "- **Module 04**: Creating ML APIs with FastAPI\n",
    "- And much more...\n",
    "\n",
    "By the end of this learning path, you'll have built a complete production-ready MLOps pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Additional Resources\n",
    "\n",
    "### Books\n",
    "- **\"Designing Machine Learning Systems\"** by Chip Huyen (O'Reilly, 2022)\n",
    "- **\"Machine Learning Engineering\"** by Andriy Burkov (2020)\n",
    "- **\"Building Machine Learning Powered Applications\"** by Emmanuel Ameisen (O'Reilly, 2020)\n",
    "\n",
    "### Courses\n",
    "- **Full Stack Deep Learning** (free): https://fullstackdeeplearning.com/\n",
    "- **Made With ML - MLOps Course** (free): https://madewithml.com/\n",
    "- **AWS MLOps Engineering on AWS** (official AWS training)\n",
    "\n",
    "### Articles & Papers\n",
    "- **\"Hidden Technical Debt in Machine Learning Systems\"** (NeurIPS 2015)\n",
    "- **Google's \"Rules of Machine Learning\"**: https://developers.google.com/machine-learning/guides/rules-of-ml\n",
    "- **\"Machine Learning Operations (MLOps): Overview, Definition, and Architecture\"** (arXiv:2205.02302)\n",
    "\n",
    "### Tools & Platforms\n",
    "- **MLflow**: https://mlflow.org/\n",
    "- **Weights & Biases**: https://wandb.ai/\n",
    "- **DVC (Data Version Control)**: https://dvc.org/\n",
    "- **Evidently AI** (ML monitoring): https://www.evidentlyai.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
