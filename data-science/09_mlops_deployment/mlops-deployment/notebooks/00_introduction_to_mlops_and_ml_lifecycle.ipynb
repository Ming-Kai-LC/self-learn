{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 00: Introduction to MLOps and the ML Lifecycle\n",
    "\n",
    "**Difficulty**: â­â­ Intermediate  \n",
    "**Estimated Time**: 45 minutes  \n",
    "**Prerequisites**: Basic understanding of machine learning model training\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand what MLOps is and why it's critical for production ML\n",
    "2. Identify the key stages of the ML lifecycle\n",
    "3. Recognize the differences between DevOps and MLOps\n",
    "4. Assess MLOps maturity levels and identify gaps in current workflows\n",
    "5. Understand the challenges of taking models from development to production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is MLOps?\n",
    "\n",
    "**MLOps (Machine Learning Operations)** is a set of practices that combines Machine Learning, DevOps, and Data Engineering to deploy and maintain ML systems in production reliably and efficiently.\n",
    "\n",
    "### Why MLOps Matters\n",
    "\n",
    "According to industry research:\n",
    "- **Only 22% of companies** have successfully deployed an ML model to production\n",
    "- **87% of data science projects** never make it to production\n",
    "- The average time to deploy a model is **8-12 months**\n",
    "\n",
    "**Key Challenges Without MLOps:**\n",
    "1. **Reproducibility**: \"It works on my machine\" syndrome\n",
    "2. **Model Decay**: Performance degrades over time due to data drift\n",
    "3. **Scaling**: What works with sample data fails with production scale\n",
    "4. **Monitoring**: No visibility into model performance after deployment\n",
    "5. **Collaboration**: Data scientists and engineers speak different languages\n",
    "6. **Compliance**: Inability to track model lineage and explain decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup: Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "print(f\"Current timestamp: {datetime.now()}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The ML Lifecycle: From Idea to Production\n",
    "\n",
    "The ML lifecycle consists of several stages, each with unique challenges:\n",
    "\n",
    "### Stage 1: Problem Definition & Data Collection\n",
    "- Define business objective and success metrics\n",
    "- Identify data sources and requirements\n",
    "- Assess data quality and availability\n",
    "\n",
    "### Stage 2: Data Preparation & Feature Engineering\n",
    "- Clean and validate data\n",
    "- Create and select features\n",
    "- Split data for training/validation/testing\n",
    "\n",
    "### Stage 3: Model Development\n",
    "- Select algorithms and architectures\n",
    "- Train and tune models\n",
    "- Evaluate performance\n",
    "\n",
    "### Stage 4: Model Validation\n",
    "- Test on holdout data\n",
    "- Validate business metrics\n",
    "- Check for bias and fairness\n",
    "\n",
    "### Stage 5: Deployment\n",
    "- Package model for production\n",
    "- Set up serving infrastructure\n",
    "- Implement API endpoints\n",
    "\n",
    "### Stage 6: Monitoring & Maintenance\n",
    "- Track model performance\n",
    "- Detect data/concept drift\n",
    "- Retrain when necessary\n",
    "\n",
    "Let's visualize the time typically spent in each stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize typical time distribution across ML lifecycle stages\n",
    "stages = ['Problem\\nDefinition', 'Data\\nPreparation', 'Model\\nDevelopment', \n",
    "          'Model\\nValidation', 'Deployment', 'Monitoring']\n",
    "\n",
    "# Typical time allocation (percentage) in traditional ML workflow\n",
    "traditional_time = [10, 40, 30, 10, 5, 5]\n",
    "\n",
    "# Desired time allocation with MLOps practices\n",
    "mlops_time = [15, 25, 20, 15, 15, 10]\n",
    "\n",
    "# Create comparison bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(stages))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, traditional_time, width, label='Traditional ML', \n",
    "               color='steelblue', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, mlops_time, width, label='MLOps Approach', \n",
    "               color='seagreen', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('ML Lifecycle Stage', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Time Allocation (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Time Distribution Across ML Lifecycle Stages', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(stages)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "def add_value_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}%',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "add_value_labels(bars1)\n",
    "add_value_labels(bars2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insight: MLOps shifts focus from pure development to deployment and monitoring.\")\n",
    "print(\"This ensures models remain valuable in production over time.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DevOps vs MLOps: Key Differences\n",
    "\n",
    "While MLOps borrows many practices from DevOps, there are critical differences:\n",
    "\n",
    "| Aspect | DevOps | MLOps |\n",
    "|--------|--------|-------|\n",
    "| **Code** | Application code | Code + Data + Model |\n",
    "| **Testing** | Unit, integration tests | Data validation, model validation |\n",
    "| **Versioning** | Code versions | Code + Data + Model versions |\n",
    "| **Deployment** | Deploy once, stable | Continuous retraining needed |\n",
    "| **Monitoring** | System metrics (CPU, memory) | Model performance, data drift |\n",
    "| **Rollback** | Previous code version | Previous model version |\n",
    "| **Complexity** | Deterministic behavior | Non-deterministic, probabilistic |\n",
    "| **Team** | Engineers | Data Scientists + Engineers + Domain Experts |\n",
    "\n",
    "### The Triple Versioning Challenge\n",
    "\n",
    "In MLOps, you must track three interconnected components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Demonstrate the triple versioning challenge\n",
    "print(\"=\" * 70)\n",
    "print(\"THE TRIPLE VERSIONING CHALLENGE IN MLOPS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Example model versions with their dependencies\n",
    "model_versions = pd.DataFrame([\n",
    "    {\n",
    "        'Model_Version': 'v1.0', \n",
    "        'Code_Version': 'commit-abc123',\n",
    "        'Data_Version': 'dataset-2023-01',\n",
    "        'Accuracy': 0.85,\n",
    "        'Deployed': 'Yes'\n",
    "    },\n",
    "    {\n",
    "        'Model_Version': 'v1.1', \n",
    "        'Code_Version': 'commit-def456',\n",
    "        'Data_Version': 'dataset-2023-01',  # Same data, new code\n",
    "        'Accuracy': 0.87,\n",
    "        'Deployed': 'No'\n",
    "    },\n",
    "    {\n",
    "        'Model_Version': 'v2.0', \n",
    "        'Code_Version': 'commit-def456',  # Same code, new data\n",
    "        'Data_Version': 'dataset-2023-06',\n",
    "        'Accuracy': 0.89,\n",
    "        'Deployed': 'Yes'\n",
    "    },\n",
    "    {\n",
    "        'Model_Version': 'v2.1', \n",
    "        'Code_Version': 'commit-ghi789',  # New code, new data\n",
    "        'Data_Version': 'dataset-2023-09',\n",
    "        'Accuracy': 0.91,\n",
    "        'Deployed': 'Yes'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\nModel Version History:\")\n",
    "print(model_versions.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"WHY THIS MATTERS:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"âœ“ To reproduce v1.0, you need BOTH commit-abc123 AND dataset-2023-01\")\n",
    "print(\"âœ“ Improved accuracy could come from code changes OR new data\")\n",
    "print(\"âœ“ Rolling back requires reverting to the correct code AND data version\")\n",
    "print(\"âœ“ Compliance requires tracking exact lineage of all three components\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MLOps Maturity Model\n",
    "\n",
    "Organizations typically progress through maturity levels:\n",
    "\n",
    "### Level 0: Manual Process\n",
    "- All steps performed manually\n",
    "- No automation or tracking\n",
    "- Models deployed ad-hoc\n",
    "- **Result**: Impossible to scale or maintain\n",
    "\n",
    "### Level 1: ML Pipeline Automation\n",
    "- Automated data preparation and training\n",
    "- Experiment tracking implemented\n",
    "- Deployment still manual\n",
    "- **Result**: Faster iteration, but deployment bottleneck\n",
    "\n",
    "### Level 2: CI/CD Pipeline Automation  \n",
    "- Automated testing and deployment\n",
    "- Model versioning and registry\n",
    "- Basic monitoring in place\n",
    "- **Result**: Reliable deployment, limited adaptability\n",
    "\n",
    "### Level 3: Full MLOps Automation\n",
    "- Continuous training triggered by drift detection\n",
    "- Automated model validation and testing\n",
    "- Comprehensive monitoring and alerting\n",
    "- **Result**: Self-healing ML systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize MLOps maturity characteristics\n",
    "maturity_data = {\n",
    "    'Level': ['Level 0\\nManual', 'Level 1\\nML Pipeline', \n",
    "              'Level 2\\nCI/CD', 'Level 3\\nFull MLOps'],\n",
    "    'Automation': [10, 40, 70, 95],\n",
    "    'Reproducibility': [20, 60, 85, 98],\n",
    "    'Deployment_Speed': [15, 45, 80, 95],\n",
    "    'Monitoring': [5, 30, 70, 95]\n",
    "}\n",
    "\n",
    "df_maturity = pd.DataFrame(maturity_data)\n",
    "\n",
    "# Create radar chart\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Line plot showing progression\n",
    "ax1.plot(df_maturity['Level'], df_maturity['Automation'], \n",
    "         marker='o', linewidth=2, label='Automation', color='blue')\n",
    "ax1.plot(df_maturity['Level'], df_maturity['Reproducibility'], \n",
    "         marker='s', linewidth=2, label='Reproducibility', color='green')\n",
    "ax1.plot(df_maturity['Level'], df_maturity['Deployment_Speed'], \n",
    "         marker='^', linewidth=2, label='Deployment Speed', color='orange')\n",
    "ax1.plot(df_maturity['Level'], df_maturity['Monitoring'], \n",
    "         marker='d', linewidth=2, label='Monitoring', color='red')\n",
    "\n",
    "ax1.set_xlabel('Maturity Level', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Capability Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('MLOps Maturity Progression', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 100)\n",
    "\n",
    "# Bar chart showing time to deploy model\n",
    "deployment_times = [180, 60, 14, 1]  # days\n",
    "colors = ['#d62728', '#ff7f0e', '#2ca02c', '#1f77b4']\n",
    "\n",
    "bars = ax2.bar(df_maturity['Level'], deployment_times, color=colors, alpha=0.7)\n",
    "ax2.set_xlabel('Maturity Level', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Time to Deploy (days)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Average Model Deployment Time by Maturity Level', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, time in zip(bars, deployment_times):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{time} days',\n",
    "             ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Takeaway: Each maturity level dramatically improves deployment speed.\")\n",
    "print(\"Moving from Level 0 to Level 3 reduces deployment time by 99.4%!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Common Production Challenges\n",
    "\n",
    "Understanding what can go wrong helps you prepare better:\n",
    "\n",
    "### Challenge 1: Training-Serving Skew\n",
    "**Problem**: Model trained on clean, preprocessed data but production data is raw  \n",
    "**Solution**: Version preprocessing code and apply same transformations\n",
    "\n",
    "### Challenge 2: Data Drift\n",
    "**Problem**: Input data distribution changes over time  \n",
    "**Solution**: Monitor data distributions and trigger retraining\n",
    "\n",
    "### Challenge 3: Concept Drift\n",
    "**Problem**: Relationship between features and target changes  \n",
    "**Solution**: Monitor model performance metrics continuously\n",
    "\n",
    "### Challenge 4: Resource Constraints\n",
    "**Problem**: Model too large or slow for production requirements  \n",
    "**Solution**: Model optimization, quantization, or distillation\n",
    "\n",
    "### Challenge 5: Model Reproducibility\n",
    "**Problem**: Cannot recreate exact model from 6 months ago  \n",
    "**Solution**: Version control for code, data, and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Simulate data drift scenario\n",
    "print(\"SIMULATION: Data Drift Impact on Model Performance\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Training data distribution (at model creation)\n",
    "training_data = np.random.normal(loc=50, scale=10, size=1000)\n",
    "\n",
    "# Production data over time (distribution gradually shifts)\n",
    "months = np.arange(1, 13)\n",
    "model_accuracy = []\n",
    "\n",
    "initial_accuracy = 0.92\n",
    "for month in months:\n",
    "    # Simulate drift: mean shifts by 2 units per month\n",
    "    drift_amount = month * 2\n",
    "    production_data = np.random.normal(loc=50 + drift_amount, scale=10, size=1000)\n",
    "    \n",
    "    # Calculate distribution difference (simplified)\n",
    "    distribution_diff = abs(production_data.mean() - training_data.mean())\n",
    "    \n",
    "    # Accuracy degrades with drift (simplified model)\n",
    "    accuracy = initial_accuracy * np.exp(-distribution_diff / 100)\n",
    "    model_accuracy.append(accuracy)\n",
    "\n",
    "# Visualize accuracy degradation\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Accuracy over time\n",
    "ax1.plot(months, model_accuracy, marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "ax1.axhline(y=0.85, color='red', linestyle='--', linewidth=2, label='Minimum Acceptable (85%)')\n",
    "ax1.fill_between(months, 0.85, model_accuracy, \n",
    "                  where=[acc >= 0.85 for acc in model_accuracy],\n",
    "                  alpha=0.3, color='green', label='Acceptable Performance')\n",
    "ax1.fill_between(months, 0.85, model_accuracy, \n",
    "                  where=[acc < 0.85 for acc in model_accuracy],\n",
    "                  alpha=0.3, color='red', label='Unacceptable Performance')\n",
    "\n",
    "ax1.set_xlabel('Months Since Deployment', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Model Accuracy', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Model Performance Degradation Due to Data Drift', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0.5, 1.0)\n",
    "\n",
    "# Plot 2: Distribution shift\n",
    "initial_dist = np.random.normal(loc=50, scale=10, size=1000)\n",
    "drifted_dist = np.random.normal(loc=74, scale=10, size=1000)  # After 12 months\n",
    "\n",
    "ax2.hist(initial_dist, bins=30, alpha=0.6, label='Training Data (Month 0)', color='blue')\n",
    "ax2.hist(drifted_dist, bins=30, alpha=0.6, label='Production Data (Month 12)', color='orange')\n",
    "ax2.set_xlabel('Feature Value', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Data Distribution Shift Over Time', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find when retraining is needed\n",
    "retrain_month = next((i+1 for i, acc in enumerate(model_accuracy) if acc < 0.85), None)\n",
    "print(f\"\\nModel falls below acceptable threshold at Month {retrain_month}\")\n",
    "print(f\"Recommendation: Set up monitoring to detect drift by Month {retrain_month - 1}\")\n",
    "print(f\"This gives you time to retrain before performance becomes unacceptable.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exercise: Assess Your MLOps Maturity\n",
    "\n",
    "Complete this assessment to understand your current MLOps maturity level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# MLOps Maturity Self-Assessment Tool\n",
    "print(\"=\" * 70)\n",
    "print(\"MLOPS MATURITY SELF-ASSESSMENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "assessment_questions = [\n",
    "    {\n",
    "        'category': 'Automation',\n",
    "        'question': 'Is your ML pipeline automated?',\n",
    "        'scores': {\n",
    "            'No automation': 0,\n",
    "            'Some automation': 1,\n",
    "            'Mostly automated': 2,\n",
    "            'Fully automated': 3\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'category': 'Versioning',\n",
    "        'question': 'Do you version models, data, and code?',\n",
    "        'scores': {\n",
    "            'None versioned': 0,\n",
    "            'Code only': 1,\n",
    "            'Code and models': 2,\n",
    "            'All three versioned': 3\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'category': 'Testing',\n",
    "        'question': 'Do you have automated testing for ML models?',\n",
    "        'scores': {\n",
    "            'No testing': 0,\n",
    "            'Manual testing': 1,\n",
    "            'Some automated tests': 2,\n",
    "            'Comprehensive automated testing': 3\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'category': 'Monitoring',\n",
    "        'question': 'Do you monitor model performance in production?',\n",
    "        'scores': {\n",
    "            'No monitoring': 0,\n",
    "            'Basic logging': 1,\n",
    "            'Performance metrics tracked': 2,\n",
    "            'Full observability with alerts': 3\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'category': 'Deployment',\n",
    "        'question': 'How do you deploy models?',\n",
    "        'scores': {\n",
    "            'Manual deployment': 0,\n",
    "            'Scripted deployment': 1,\n",
    "            'CI/CD pipeline': 2,\n",
    "            'Continuous deployment with validation': 3\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\nAnswer the following questions to assess your MLOps maturity:\")\n",
    "print(\"(This is a demonstration - in practice, you would provide your answers)\\n\")\n",
    "\n",
    "# Example scores (you would collect these interactively)\n",
    "example_scores = [1, 2, 1, 1, 0]  # Example organization scores\n",
    "\n",
    "total_score = sum(example_scores)\n",
    "max_score = len(assessment_questions) * 3\n",
    "maturity_percentage = (total_score / max_score) * 100\n",
    "\n",
    "# Display results\n",
    "print(f\"Total Score: {total_score}/{max_score}\")\n",
    "print(f\"Maturity Percentage: {maturity_percentage:.1f}%\\n\")\n",
    "\n",
    "# Determine maturity level\n",
    "if maturity_percentage < 25:\n",
    "    level = \"Level 0 (Manual Process)\"\n",
    "    recommendation = \"Start with experiment tracking and basic version control.\"\n",
    "elif maturity_percentage < 50:\n",
    "    level = \"Level 1 (ML Pipeline Automation)\"\n",
    "    recommendation = \"Focus on automating deployment and adding monitoring.\"\n",
    "elif maturity_percentage < 75:\n",
    "    level = \"Level 2 (CI/CD Pipeline)\"\n",
    "    recommendation = \"Implement continuous training and advanced monitoring.\"\n",
    "else:\n",
    "    level = \"Level 3 (Full MLOps)\"\n",
    "    recommendation = \"Optimize and fine-tune existing processes.\"\n",
    "\n",
    "print(f\"Your Maturity Level: {level}\")\n",
    "print(f\"Recommendation: {recommendation}\")\n",
    "\n",
    "# Visualize scores by category\n",
    "categories = [q['category'] for q in assessment_questions]\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.barh(categories, example_scores, color='steelblue', alpha=0.7)\n",
    "ax.set_xlabel('Score (0-3)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Category', fontsize=12, fontweight='bold')\n",
    "ax.set_title('MLOps Maturity by Category', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 3)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, score) in enumerate(zip(bars, example_scores)):\n",
    "    ax.text(score + 0.1, bar.get_y() + bar.get_height()/2,\n",
    "            f'{score}/3',\n",
    "            va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 1: Identify MLOps Challenges\n",
    "\n",
    "Consider a scenario where you've built a fraud detection model that achieved 95% accuracy in development.\n",
    "\n",
    "**Questions:**\n",
    "1. List at least 5 challenges you might face when deploying this model to production\n",
    "2. For each challenge, identify which MLOps practice could address it\n",
    "3. What metrics would you monitor to ensure the model remains effective?\n",
    "\n",
    "**Hint**: Think about data changes, performance requirements, reproducibility, and compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your solution here\n",
    "# Example structure:\n",
    "challenges = {\n",
    "    'Challenge 1': {\n",
    "        'description': '',\n",
    "        'mlops_solution': '',\n",
    "        'metrics_to_monitor': []\n",
    "    },\n",
    "    # Add more challenges...\n",
    "}\n",
    "\n",
    "# TODO: Fill in your analysis"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 2: Design an MLOps Strategy\n",
    "\n",
    "You're joining a company that manually trains and deploys ML models. Design a roadmap to reach Level 2 MLOps maturity.\n",
    "\n",
    "**Requirements:**\n",
    "1. Identify 3-5 key initiatives\n",
    "2. Prioritize them (what to do first, second, etc.)\n",
    "3. Estimate the impact and effort for each\n",
    "4. Identify potential blockers or challenges\n",
    "\n",
    "**Consider**: Quick wins vs. long-term investments, team skills, existing infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your solution here\n",
    "mlops_roadmap = [\n",
    "    {\n",
    "        'initiative': 'Implement Experiment Tracking',\n",
    "        'priority': 1,\n",
    "        'effort': 'Low',  # Low, Medium, High\n",
    "        'impact': 'High',  # Low, Medium, High\n",
    "        'timeline': '2 weeks',\n",
    "        'blockers': ['Need MLflow setup', 'Team training required']\n",
    "    },\n",
    "    # Add more initiatives...\n",
    "]\n",
    "\n",
    "# TODO: Complete your roadmap"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 3: Calculate ROI of MLOps\n",
    "\n",
    "A data science team deploys 1 model per quarter manually (180 days total time). With MLOps automation, they could potentially deploy 1 model every 7 days.\n",
    "\n",
    "**Calculate:**\n",
    "1. How many more models could be deployed per year?\n",
    "2. If each model generates $50,000 in annual value, what's the revenue impact?\n",
    "3. If MLOps implementation costs $200,000, what's the ROI?\n",
    "4. What's the break-even point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your solution here\n",
    "\n",
    "# Current state\n",
    "manual_deployment_days = 180\n",
    "models_per_year_manual = 365 / manual_deployment_days\n",
    "\n",
    "# MLOps state\n",
    "mlops_deployment_days = 7\n",
    "models_per_year_mlops = 365 / mlops_deployment_days\n",
    "\n",
    "# Value calculations\n",
    "value_per_model = 50000\n",
    "mlops_implementation_cost = 200000\n",
    "\n",
    "# TODO: Calculate additional models, revenue impact, ROI, and break-even\n",
    "# Your calculations here...\n",
    "\n",
    "print(\"MLOps ROI Analysis\")\n",
    "print(\"=\" * 50)\n",
    "# Print your results"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### Key Concepts Covered\n",
    "\n",
    "1. **MLOps Definition**: Practices for deploying and maintaining ML systems in production\n",
    "2. **ML Lifecycle**: 6 stages from problem definition to monitoring\n",
    "3. **DevOps vs MLOps**: Triple versioning (code, data, model) is the key difference\n",
    "4. **Maturity Levels**: Progress from manual (Level 0) to fully automated (Level 3)\n",
    "5. **Production Challenges**: Data drift, reproducibility, and training-serving skew\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "- **Only 22% of ML projects** reach production without MLOps practices\n",
    "- **Model performance degrades** over time without monitoring and retraining\n",
    "- **MLOps skills** are the differentiator between academic and industry data scientists\n",
    "- **Business value** comes from deployed models, not notebooks\n",
    "\n",
    "### What's Next\n",
    "\n",
    "In the upcoming notebooks, we'll dive deep into practical MLOps tools and techniques:\n",
    "- **Module 01**: Experiment tracking with MLflow\n",
    "- **Module 02**: Model versioning and registry\n",
    "- **Module 03**: Model serialization techniques\n",
    "- **Module 04**: Creating ML APIs with FastAPI\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- **Books**:\n",
    "  - \"Designing Machine Learning Systems\" by Chip Huyen\n",
    "  - \"Machine Learning Engineering\" by Andriy Burkov\n",
    "- **Courses**:\n",
    "  - Full Stack Deep Learning (free)\n",
    "  - Made With ML MLOps course\n",
    "- **Documentation**:\n",
    "  - MLflow: https://mlflow.org/docs/\n",
    "  - Google MLOps Guide: https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Proceed to **Module 01: Experiment Tracking with MLflow** to learn how to systematically track your ML experiments and ensure reproducibility.\n",
    "\n",
    "**Before moving on, ensure you can:**\n",
    "- âœ… Explain the difference between DevOps and MLOps\n",
    "- âœ… Identify the stages of the ML lifecycle\n",
    "- âœ… Assess your organization's MLOps maturity level\n",
    "- âœ… Recognize common production challenges and their solutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
