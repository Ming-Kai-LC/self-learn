{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 04: ML APIs with FastAPI\n",
    "\n",
    "**Difficulty**: ⭐⭐ Intermediate\n",
    "**Estimated Time**: 70 minutes\n",
    "**Prerequisites**: \n",
    "- [Module 03: Model Serialization](03_model_serialization.ipynb)\n",
    "- Basic understanding of REST APIs\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Create ML prediction APIs using FastAPI\n",
    "2. Define request and response models with Pydantic\n",
    "3. Implement input validation for ML endpoints\n",
    "4. Handle errors gracefully in production APIs\n",
    "5. Test API endpoints programmatically\n",
    "6. Document APIs automatically with OpenAPI/Swagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why FastAPI for ML?\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "You've trained a model. Now what?\n",
    "- **How do web apps use your model?**\n",
    "- **How do mobile apps get predictions?**\n",
    "- **How do you validate inputs?**\n",
    "- **How do you handle errors gracefully?**\n",
    "\n",
    "### The Solution: REST APIs\n",
    "\n",
    "**REST APIs** allow any application to request predictions over HTTP.\n",
    "\n",
    "**Why FastAPI?**\n",
    "1. **Fast**: High performance (based on Starlette and Pydantic)\n",
    "2. **Easy**: Simple syntax, similar to Flask\n",
    "3. **Automatic docs**: Interactive API documentation (Swagger UI)\n",
    "4. **Type hints**: Python type hints for validation\n",
    "5. **Async support**: Handle concurrent requests efficiently\n",
    "\n",
    "### API Workflow\n",
    "\n",
    "```\n",
    "Client (Web/Mobile App)\n",
    "    ↓ HTTP Request\n",
    "FastAPI Server\n",
    "    ↓ Validate input\n",
    "    ↓ Load model\n",
    "    ↓ Make prediction\n",
    "    ↓ HTTP Response\n",
    "Client receives prediction\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import all required libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.datasets import load_iris, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# FastAPI and Pydantic\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List, Optional\n",
    "import uvicorn\n",
    "from fastapi.testclient import TestClient\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(\"FastAPI is ready for ML model serving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training and Saving a Model\n",
    "\n",
    "First, let's train a model to serve via API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset for classification\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Features: {iris.feature_names}\")\n",
    "print(f\"Classes: {iris.target_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(f\"\\n✓ Model trained\")\n",
    "print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save model\n",
    "models_dir = Path(\"api_models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "model_path = models_dir / \"iris_classifier.joblib\"\n",
    "joblib.dump(pipeline, model_path)\n",
    "\n",
    "print(f\"✓ Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating Your First FastAPI App\n",
    "\n",
    "Let's build a simple prediction API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"Iris Classification API\",\n",
    "    description=\"ML API for predicting iris flower species\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Load model at startup\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return {\n",
    "        \"message\": \"Iris Classification API\",\n",
    "        \"status\": \"running\",\n",
    "        \"model_loaded\": model is not None\n",
    "    }\n",
    "\n",
    "print(\"✓ FastAPI app created\")\n",
    "print(\"  Available endpoints: / (health check)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Defining Request/Response Models with Pydantic\n",
    "\n",
    "**Pydantic** provides automatic validation using Python type hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define request model (input to API)\n",
    "class IrisFeatures(BaseModel):\n",
    "    sepal_length: float = Field(..., ge=0, le=10, description=\"Sepal length in cm\")\n",
    "    sepal_width: float = Field(..., ge=0, le=10, description=\"Sepal width in cm\")\n",
    "    petal_length: float = Field(..., ge=0, le=10, description=\"Petal length in cm\")\n",
    "    petal_width: float = Field(..., ge=0, le=10, description=\"Petal width in cm\")\n",
    "    \n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"sepal_length\": 5.1,\n",
    "                \"sepal_width\": 3.5,\n",
    "                \"petal_length\": 1.4,\n",
    "                \"petal_width\": 0.2\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Define response model (output from API)\n",
    "class PredictionResponse(BaseModel):\n",
    "    prediction: str = Field(..., description=\"Predicted iris species\")\n",
    "    confidence: float = Field(..., ge=0, le=1, description=\"Prediction confidence\")\n",
    "    probabilities: dict = Field(..., description=\"Class probabilities\")\n",
    "\n",
    "print(\"✓ Pydantic models defined\")\n",
    "print(\"  Request: IrisFeatures\")\n",
    "print(\"  Response: PredictionResponse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating Prediction Endpoint\n",
    "\n",
    "Now let's add the actual prediction logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/predict\", response_model=PredictionResponse)\n",
    "def predict(features: IrisFeatures):\n",
    "    \"\"\"\n",
    "    Predict iris species from flower measurements.\n",
    "    \n",
    "    Returns the predicted class and confidence scores.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert input to numpy array\n",
    "        input_data = np.array([[\n",
    "            features.sepal_length,\n",
    "            features.sepal_width,\n",
    "            features.petal_length,\n",
    "            features.petal_width\n",
    "        ]])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(input_data)[0]\n",
    "        probabilities = model.predict_proba(input_data)[0]\n",
    "        \n",
    "        # Map prediction to class name\n",
    "        class_names = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "        predicted_class = class_names[prediction]\n",
    "        \n",
    "        # Create probability dictionary\n",
    "        prob_dict = {\n",
    "            class_name: float(prob)\n",
    "            for class_name, prob in zip(class_names, probabilities)\n",
    "        }\n",
    "        \n",
    "        return PredictionResponse(\n",
    "            prediction=predicted_class,\n",
    "            confidence=float(probabilities.max()),\n",
    "            probabilities=prob_dict\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Prediction error: {str(e)}\")\n",
    "\n",
    "print(\"✓ Prediction endpoint created\")\n",
    "print(\"  POST /predict - Make predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing the API\n",
    "\n",
    "FastAPI provides a TestClient for testing without running a server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test client\n",
    "client = TestClient(app)\n",
    "\n",
    "# Test health check endpoint\n",
    "response = client.get(\"/\")\n",
    "print(\"Health Check:\")\n",
    "print(f\"  Status: {response.status_code}\")\n",
    "print(f\"  Response: {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction endpoint with valid input\n",
    "test_input = {\n",
    "    \"sepal_length\": 5.1,\n",
    "    \"sepal_width\": 3.5,\n",
    "    \"petal_length\": 1.4,\n",
    "    \"petal_width\": 0.2\n",
    "}\n",
    "\n",
    "response = client.post(\"/predict\", json=test_input)\n",
    "print(\"\\nPrediction Test:\")\n",
    "print(f\"  Input: {test_input}\")\n",
    "print(f\"  Status: {response.status_code}\")\n",
    "print(f\"  Response: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Input Validation\n",
    "\n",
    "Pydantic automatically validates inputs. Let's test with invalid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with invalid input (negative value)\n",
    "invalid_input = {\n",
    "    \"sepal_length\": -1.0,  # Invalid: negative\n",
    "    \"sepal_width\": 3.5,\n",
    "    \"petal_length\": 1.4,\n",
    "    \"petal_width\": 0.2\n",
    "}\n",
    "\n",
    "response = client.post(\"/predict\", json=invalid_input)\n",
    "print(\"Invalid Input Test (negative value):\")\n",
    "print(f\"  Status: {response.status_code}\")\n",
    "print(f\"  Error: {response.json()['detail']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with missing field\n",
    "incomplete_input = {\n",
    "    \"sepal_length\": 5.1,\n",
    "    \"sepal_width\": 3.5\n",
    "    # Missing petal_length and petal_width\n",
    "}\n",
    "\n",
    "response = client.post(\"/predict\", json=incomplete_input)\n",
    "print(\"\\nIncomplete Input Test:\")\n",
    "print(f\"  Status: {response.status_code}\")\n",
    "print(f\"  Error: {response.json()['detail'][:200]}...\")  # Truncated for display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Predictions\n",
    "\n",
    "Let's add an endpoint for batch predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch request/response models\n",
    "class BatchPredictionRequest(BaseModel):\n",
    "    samples: List[IrisFeatures]\n",
    "\n",
    "class BatchPredictionResponse(BaseModel):\n",
    "    predictions: List[PredictionResponse]\n",
    "    count: int\n",
    "\n",
    "@app.post(\"/predict/batch\", response_model=BatchPredictionResponse)\n",
    "def predict_batch(request: BatchPredictionRequest):\n",
    "    \"\"\"\n",
    "    Make predictions for multiple samples at once.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for sample in request.samples:\n",
    "        # Reuse the single prediction logic\n",
    "        pred = predict(sample)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    return BatchPredictionResponse(\n",
    "        predictions=predictions,\n",
    "        count=len(predictions)\n",
    "    )\n",
    "\n",
    "print(\"✓ Batch prediction endpoint created\")\n",
    "print(\"  POST /predict/batch - Predict multiple samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch prediction\n",
    "batch_input = {\n",
    "    \"samples\": [\n",
    "        {\"sepal_length\": 5.1, \"sepal_width\": 3.5, \"petal_length\": 1.4, \"petal_width\": 0.2},\n",
    "        {\"sepal_length\": 6.2, \"sepal_width\": 2.9, \"petal_length\": 4.3, \"petal_width\": 1.3},\n",
    "        {\"sepal_length\": 7.7, \"sepal_width\": 3.0, \"petal_length\": 6.1, \"petal_width\": 2.3}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = client.post(\"/predict/batch\", json=batch_input)\n",
    "print(\"Batch Prediction Test:\")\n",
    "print(f\"  Input samples: {len(batch_input['samples'])}\")\n",
    "print(f\"  Status: {response.status_code}\")\n",
    "\n",
    "result = response.json()\n",
    "print(f\"\\nPredictions:\")\n",
    "for i, pred in enumerate(result['predictions']):\n",
    "    print(f\"  Sample {i+1}: {pred['prediction']} (confidence: {pred['confidence']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced Validation with Pydantic\n",
    "\n",
    "Add custom validators for domain-specific rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced request model with custom validation\n",
    "class EnhancedIrisFeatures(BaseModel):\n",
    "    sepal_length: float = Field(..., ge=0, le=10)\n",
    "    sepal_width: float = Field(..., ge=0, le=10)\n",
    "    petal_length: float = Field(..., ge=0, le=10)\n",
    "    petal_width: float = Field(..., ge=0, le=10)\n",
    "    \n",
    "    @validator('petal_width')\n",
    "    def petal_width_must_be_less_than_length(cls, v, values):\n",
    "        \"\"\"Validate that petal width is typically less than petal length\"\"\"\n",
    "        if 'petal_length' in values and v > values['petal_length']:\n",
    "            raise ValueError('Petal width should not exceed petal length')\n",
    "        return v\n",
    "    \n",
    "    @validator('sepal_width')\n",
    "    def sepal_width_reasonable(cls, v, values):\n",
    "        \"\"\"Validate sepal width is reasonable compared to length\"\"\"\n",
    "        if 'sepal_length' in values and v > values['sepal_length'] * 1.5:\n",
    "            raise ValueError('Sepal width seems unreasonably large')\n",
    "        return v\n",
    "\n",
    "@app.post(\"/predict/validated\")\n",
    "def predict_validated(features: EnhancedIrisFeatures):\n",
    "    \"\"\"Prediction with enhanced validation\"\"\"\n",
    "    # Convert to standard model for prediction\n",
    "    standard_features = IrisFeatures(**features.dict())\n",
    "    return predict(standard_features)\n",
    "\n",
    "print(\"✓ Enhanced validation endpoint created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with biologically unrealistic data\n",
    "unrealistic_input = {\n",
    "    \"sepal_length\": 5.0,\n",
    "    \"sepal_width\": 3.0,\n",
    "    \"petal_length\": 2.0,\n",
    "    \"petal_width\": 3.0  # Petal width > petal length (unusual)\n",
    "}\n",
    "\n",
    "response = client.post(\"/predict/validated\", json=unrealistic_input)\n",
    "print(\"Validation Test (unrealistic data):\")\n",
    "print(f\"  Status: {response.status_code}\")\n",
    "if response.status_code == 422:\n",
    "    print(f\"  Validation caught the issue!\")\n",
    "    print(f\"  Error: {response.json()['detail'][0]['msg']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Error Handling\n",
    "\n",
    "Proper error handling is crucial for production APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import status\n",
    "\n",
    "@app.post(\"/predict/robust\", response_model=PredictionResponse)\n",
    "def predict_robust(features: IrisFeatures):\n",
    "    \"\"\"\n",
    "    Prediction endpoint with comprehensive error handling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate model is loaded\n",
    "        if model is None:\n",
    "            raise HTTPException(\n",
    "                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n",
    "                detail=\"Model not loaded. Service temporarily unavailable.\"\n",
    "            )\n",
    "        \n",
    "        # Convert to array\n",
    "        input_data = np.array([[\n",
    "            features.sepal_length,\n",
    "            features.sepal_width,\n",
    "            features.petal_length,\n",
    "            features.petal_width\n",
    "        ]])\n",
    "        \n",
    "        # Check for NaN or Inf\n",
    "        if not np.isfinite(input_data).all():\n",
    "            raise HTTPException(\n",
    "                status_code=status.HTTP_400_BAD_REQUEST,\n",
    "                detail=\"Input contains invalid values (NaN or Inf)\"\n",
    "            )\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(input_data)[0]\n",
    "        probabilities = model.predict_proba(input_data)[0]\n",
    "        \n",
    "        class_names = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "        predicted_class = class_names[prediction]\n",
    "        \n",
    "        prob_dict = {\n",
    "            class_name: float(prob)\n",
    "            for class_name, prob in zip(class_names, probabilities)\n",
    "        }\n",
    "        \n",
    "        return PredictionResponse(\n",
    "            prediction=predicted_class,\n",
    "            confidence=float(probabilities.max()),\n",
    "            probabilities=prob_dict\n",
    "        )\n",
    "    \n",
    "    except HTTPException:\n",
    "        raise  # Re-raise HTTP exceptions\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Log the error in production\n",
    "        print(f\"Unexpected error: {str(e)}\")\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n",
    "            detail=\"Internal server error during prediction\"\n",
    "        )\n",
    "\n",
    "print(\"✓ Robust prediction endpoint created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Exercises\n",
    "\n",
    "Practice building ML APIs with FastAPI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Add Model Info Endpoint\n",
    "\n",
    "Create an endpoint that returns model metadata.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create GET endpoint `/model/info`\n",
    "2. Return model type, training accuracy, feature names\n",
    "3. Test the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 Solution\n",
    "\n",
    "class ModelInfo(BaseModel):\n",
    "    model_type: str\n",
    "    training_accuracy: float\n",
    "    features: List[str]\n",
    "    classes: List[str]\n",
    "\n",
    "@app.get(\"/model/info\", response_model=ModelInfo)\n",
    "def get_model_info():\n",
    "    \"\"\"Get information about the loaded model\"\"\"\n",
    "    return ModelInfo(\n",
    "        model_type=\"RandomForestClassifier\",\n",
    "        training_accuracy=accuracy,\n",
    "        features=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
    "        classes=[\"setosa\", \"versicolor\", \"virginica\"]\n",
    "    )\n",
    "\n",
    "# Test\n",
    "response = client.get(\"/model/info\")\n",
    "print(\"✓ Model Info Endpoint:\")\n",
    "print(f\"  Status: {response.status_code}\")\n",
    "print(f\"  Response: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Prediction with Explanation\n",
    "\n",
    "Enhance the prediction endpoint to include feature importance.\n",
    "\n",
    "**Requirements**:\n",
    "1. Get feature importances from the model\n",
    "2. Return top 3 most important features with values\n",
    "3. Test with a sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 Solution\n",
    "\n",
    "class ExplainedPrediction(BaseModel):\n",
    "    prediction: str\n",
    "    confidence: float\n",
    "    top_features: dict\n",
    "\n",
    "@app.post(\"/predict/explain\", response_model=ExplainedPrediction)\n",
    "def predict_with_explanation(features: IrisFeatures):\n",
    "    \"\"\"Prediction with feature importance explanation\"\"\"\n",
    "    # Make prediction\n",
    "    input_data = np.array([[\n",
    "        features.sepal_length, features.sepal_width,\n",
    "        features.petal_length, features.petal_width\n",
    "    ]])\n",
    "    \n",
    "    prediction = model.predict(input_data)[0]\n",
    "    probabilities = model.predict_proba(input_data)[0]\n",
    "    \n",
    "    # Get feature importances\n",
    "    classifier = model.named_steps['classifier']\n",
    "    importances = classifier.feature_importances_\n",
    "    feature_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "    \n",
    "    # Get top 3 features\n",
    "    top_indices = np.argsort(importances)[-3:][::-1]\n",
    "    top_features = {\n",
    "        feature_names[i]: float(importances[i])\n",
    "        for i in top_indices\n",
    "    }\n",
    "    \n",
    "    class_names = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "    \n",
    "    return ExplainedPrediction(\n",
    "        prediction=class_names[prediction],\n",
    "        confidence=float(probabilities.max()),\n",
    "        top_features=top_features\n",
    "    )\n",
    "\n",
    "# Test\n",
    "test_input = {\n",
    "    \"sepal_length\": 6.3,\n",
    "    \"sepal_width\": 2.5,\n",
    "    \"petal_length\": 5.0,\n",
    "    \"petal_width\": 1.9\n",
    "}\n",
    "\n",
    "response = client.post(\"/predict/explain\", json=test_input)\n",
    "print(\"✓ Explained Prediction:\")\n",
    "result = response.json()\n",
    "print(f\"  Prediction: {result['prediction']}\")\n",
    "print(f\"  Confidence: {result['confidence']:.3f}\")\n",
    "print(f\"  Top Features: {result['top_features']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Performance Metrics Endpoint\n",
    "\n",
    "Track API usage statistics.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create a simple counter for predictions made\n",
    "2. Add GET endpoint `/metrics` that returns total predictions\n",
    "3. Increment counter in prediction endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 Solution\n",
    "\n",
    "# Global counter (in production, use proper state management)\n",
    "prediction_counter = {\"total\": 0}\n",
    "\n",
    "class Metrics(BaseModel):\n",
    "    total_predictions: int\n",
    "    model_version: str\n",
    "\n",
    "@app.get(\"/metrics\", response_model=Metrics)\n",
    "def get_metrics():\n",
    "    \"\"\"Get API usage metrics\"\"\"\n",
    "    return Metrics(\n",
    "        total_predictions=prediction_counter[\"total\"],\n",
    "        model_version=\"1.0.0\"\n",
    "    )\n",
    "\n",
    "@app.post(\"/predict/tracked\")\n",
    "def predict_with_tracking(features: IrisFeatures):\n",
    "    \"\"\"Prediction with usage tracking\"\"\"\n",
    "    # Increment counter\n",
    "    prediction_counter[\"total\"] += 1\n",
    "    \n",
    "    # Make prediction\n",
    "    return predict(features)\n",
    "\n",
    "# Test\n",
    "# Make a few predictions\n",
    "for _ in range(3):\n",
    "    client.post(\"/predict/tracked\", json=test_input)\n",
    "\n",
    "# Check metrics\n",
    "response = client.get(\"/metrics\")\n",
    "print(\"✓ API Metrics:\")\n",
    "print(f\"  {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **FastAPI makes ML APIs easy** with automatic validation and documentation\n",
    "\n",
    "2. **Pydantic models** provide type-safe request/response validation\n",
    "\n",
    "3. **Input validation** prevents bad data from reaching your model\n",
    "\n",
    "4. **Error handling** ensures graceful failures in production\n",
    "\n",
    "5. **TestClient** enables testing without running a server\n",
    "\n",
    "6. **Batch endpoints** improve efficiency for multiple predictions\n",
    "\n",
    "### API Best Practices\n",
    "\n",
    "- Always validate inputs with Pydantic\n",
    "- Return structured responses (not just raw predictions)\n",
    "- Include confidence scores with predictions\n",
    "- Handle errors gracefully with proper HTTP status codes\n",
    "- Add health check endpoints\n",
    "- Document your API (FastAPI does this automatically)\n",
    "- Version your APIs (/v1/predict, /v2/predict)\n",
    "- Log predictions for monitoring\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 05**, we'll learn about:\n",
    "- **Containerizing ML applications** with Docker\n",
    "- **Creating Dockerfiles** for ML projects\n",
    "- **Building and running** Docker images\n",
    "- **Docker best practices** for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Additional Resources\n",
    "\n",
    "### Documentation\n",
    "- **FastAPI**: https://fastapi.tiangolo.com/\n",
    "- **Pydantic**: https://pydantic-docs.helpmanual.io/\n",
    "- **Uvicorn**: https://www.uvicorn.org/\n",
    "\n",
    "### Tutorials\n",
    "- **FastAPI Tutorial**: https://fastapi.tiangolo.com/tutorial/\n",
    "- **ML with FastAPI**: https://testdriven.io/blog/fastapi-machine-learning/\n",
    "\n",
    "### Advanced Topics\n",
    "- Async endpoints for better concurrency\n",
    "- Authentication and API keys\n",
    "- Rate limiting\n",
    "- CORS configuration\n",
    "- Deploying FastAPI to cloud platforms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
