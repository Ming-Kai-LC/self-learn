{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 02: Model Versioning and Registry\n",
    "\n",
    "**Difficulty**: â­â­ Intermediate\n",
    "**Estimated Time**: 60 minutes\n",
    "**Prerequisites**: \n",
    "- [Module 01: Experiment Tracking with MLflow](01_experiment_tracking_mlflow.ipynb)\n",
    "- Understanding of ML model lifecycle\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand the need for model versioning and registry\n",
    "2. Set up and configure MLflow Model Registry\n",
    "3. Register models to the MLflow Model Registry\n",
    "4. Transition models between stages (None â†’ Staging â†’ Production â†’ Archived)\n",
    "5. Track model lineage and metadata\n",
    "6. Load and use registered models for predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Model Versioning and Registry?\n",
    "\n",
    "### The Problem Without a Model Registry\n",
    "\n",
    "Imagine your ML team has trained dozens of models:\n",
    "\n",
    "- **Data Scientist**: \"I deployed model_v3_final_FINAL_2.pkl to production last week\"\n",
    "- **MLOps Engineer**: \"Which Python version? Which scikit-learn version? Which training data?\"\n",
    "- **Product Manager**: \"We need to rollback! The model is making bad predictions!\"\n",
    "- **Data Scientist**: \"Uh... let me search my email for the S3 link... ðŸ˜°\"\n",
    "\n",
    "### The Solution: MLflow Model Registry\n",
    "\n",
    "The **MLflow Model Registry** is a centralized model store that provides:\n",
    "\n",
    "1. **Version Control**: Track all versions of a model over time\n",
    "2. **Stage Management**: Move models through dev â†’ staging â†’ production\n",
    "3. **Lineage Tracking**: Know which data and code produced each model\n",
    "4. **Annotations**: Add descriptions, tags, and metadata\n",
    "5. **Model Discovery**: Find the right model quickly\n",
    "6. **Governance**: Control who can promote models to production\n",
    "\n",
    "### Model Stages\n",
    "\n",
    "MLflow defines these standard stages:\n",
    "\n",
    "- **None**: Initial state when model is first registered\n",
    "- **Staging**: Model is being tested in a staging environment\n",
    "- **Production**: Model is live and serving predictions\n",
    "- **Archived**: Model is no longer in use but kept for historical reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import all required libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.datasets import make_classification, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities.model_registry import ModelVersion\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"MLflow version: {mlflow.__version__}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting Up MLflow Model Registry\n",
    "\n",
    "The Model Registry requires a backend database to store model metadata. For this tutorial, we'll use a local SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MLflow with a backend store that supports Model Registry\n",
    "# SQLite is used for simplicity; production systems use PostgreSQL or MySQL\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "\n",
    "# Create MLflow client for interacting with the registry\n",
    "client = MlflowClient()\n",
    "\n",
    "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(\"Model Registry is now available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing Data and Training Models\n",
    "\n",
    "Let's create a dataset and train multiple models to demonstrate versioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic classification dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Registering Your First Model\n",
    "\n",
    "There are two ways to register a model:\n",
    "1. **During training**: Use `mlflow.sklearn.log_model()` with `registered_model_name`\n",
    "2. **After training**: Use `mlflow.register_model()` with a run ID\n",
    "\n",
    "We'll demonstrate both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1: Register model during training\n",
    "\n",
    "mlflow.set_experiment(\"model_registry_demo\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"random_forest_v1\") as run:\n",
    "    \n",
    "    # Train model\n",
    "    params = {\"n_estimators\": 100, \"max_depth\": 10, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    # Log and register model in one step\n",
    "    # This creates a new registered model named \"binary_classifier\"\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"binary_classifier\"  # This registers the model!\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Model registered as 'binary_classifier' version 1\")\n",
    "    print(f\"  Run ID: {run.info.run_id}\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Viewing Registered Models\n",
    "\n",
    "Let's explore what was created in the registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all registered models\n",
    "registered_models = client.search_registered_models()\n",
    "\n",
    "print(f\"Total registered models: {len(registered_models)}\\n\")\n",
    "\n",
    "for rm in registered_models:\n",
    "    print(f\"Model: {rm.name}\")\n",
    "    print(f\"  Description: {rm.description or 'No description'}\")\n",
    "    print(f\"  Latest versions: {len(rm.latest_versions)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed information about a specific model\n",
    "model_name = \"binary_classifier\"\n",
    "model_versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Total versions: {len(model_versions)}\\n\")\n",
    "\n",
    "for mv in model_versions:\n",
    "    print(f\"Version {mv.version}:\")\n",
    "    print(f\"  Stage: {mv.current_stage}\")\n",
    "    print(f\"  Run ID: {mv.run_id}\")\n",
    "    print(f\"  Created: {pd.to_datetime(mv.creation_timestamp, unit='ms')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Adding Model Descriptions and Tags\n",
    "\n",
    "Make your models discoverable by adding rich metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the registered model description\n",
    "client.update_registered_model(\n",
    "    name=\"binary_classifier\",\n",
    "    description=\"Binary classification model for customer churn prediction. \"\n",
    "                \"Uses Random Forest with optimized hyperparameters.\"\n",
    ")\n",
    "\n",
    "# Add tags to the model version\n",
    "client.set_model_version_tag(\n",
    "    name=\"binary_classifier\",\n",
    "    version=\"1\",\n",
    "    key=\"task\",\n",
    "    value=\"classification\"\n",
    ")\n",
    "\n",
    "client.set_model_version_tag(\n",
    "    name=\"binary_classifier\",\n",
    "    version=\"1\",\n",
    "    key=\"framework\",\n",
    "    value=\"scikit-learn\"\n",
    ")\n",
    "\n",
    "client.set_model_version_tag(\n",
    "    name=\"binary_classifier\",\n",
    "    version=\"1\",\n",
    "    key=\"training_data\",\n",
    "    value=\"synthetic_v1\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ Model description and tags updated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Stages: Moving Through the Lifecycle\n",
    "\n",
    "Now let's transition our model through different stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition model to Staging\n",
    "# This indicates the model is ready for testing in a staging environment\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=\"binary_classifier\",\n",
    "    version=1,\n",
    "    stage=\"Staging\",\n",
    "    archive_existing_versions=False  # Keep other staged versions\n",
    ")\n",
    "\n",
    "print(\"âœ“ Model transitioned to Staging\")\n",
    "\n",
    "# Verify the stage change\n",
    "model_version = client.get_model_version(name=\"binary_classifier\", version=\"1\")\n",
    "print(f\"  Current stage: {model_version.current_stage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Registering a New Version\n",
    "\n",
    "Let's train an improved model and register it as version 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an improved model with better hyperparameters\n",
    "\n",
    "with mlflow.start_run(run_name=\"random_forest_v2_improved\") as run:\n",
    "    \n",
    "    # Better hyperparameters based on tuning\n",
    "    params = {\n",
    "        \"n_estimators\": 200,\n",
    "        \"max_depth\": 15,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    # Register as version 2\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"binary_classifier\"  # Same name, new version!\n",
    "    )\n",
    "    \n",
    "    # Add version-specific description\n",
    "    client.update_model_version(\n",
    "        name=\"binary_classifier\",\n",
    "        version=\"2\",\n",
    "        description=\"Improved version with deeper trees and more estimators\"\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Model registered as 'binary_classifier' version 2\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comparing Model Versions\n",
    "\n",
    "Let's compare the performance of different versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all versions and their metrics\n",
    "model_versions = client.search_model_versions(f\"name='binary_classifier'\")\n",
    "\n",
    "version_data = []\n",
    "for mv in model_versions:\n",
    "    # Get the run to access metrics\n",
    "    run = client.get_run(mv.run_id)\n",
    "    \n",
    "    version_data.append({\n",
    "        \"version\": mv.version,\n",
    "        \"stage\": mv.current_stage,\n",
    "        \"accuracy\": run.data.metrics.get(\"accuracy\", 0),\n",
    "        \"created\": pd.to_datetime(mv.creation_timestamp, unit='ms'),\n",
    "        \"run_id\": mv.run_id[:8]  # Shortened for display\n",
    "    })\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(version_data).sort_values(\"version\")\n",
    "print(\"Model Version Comparison:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize accuracy across versions\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(comparison_df['version'], comparison_df['accuracy'], \n",
    "        marker='o', linewidth=2, markersize=10, color='darkblue')\n",
    "ax.set_xlabel('Model Version', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Model Accuracy Across Versions', fontweight='bold', fontsize=14)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_ylim(0.85, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Promoting Model to Production\n",
    "\n",
    "After validating version 2 in staging, let's promote it to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move version 2 to Production\n",
    "# archive_existing_versions=True will archive the current production model\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=\"binary_classifier\",\n",
    "    version=2,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=True  # Archive old production models\n",
    ")\n",
    "\n",
    "print(\"âœ“ Version 2 promoted to Production\")\n",
    "\n",
    "# Check what's now in production\n",
    "prod_models = client.get_latest_versions(\"binary_classifier\", stages=[\"Production\"])\n",
    "for model in prod_models:\n",
    "    print(f\"  Production model: Version {model.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Loading Models from Registry\n",
    "\n",
    "The registry makes it easy to load models by stage or version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Load by stage (recommended for applications)\n",
    "# This always gets the latest production model\n",
    "model_uri = f\"models:/binary_classifier/Production\"\n",
    "production_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "print(\"âœ“ Loaded production model\")\n",
    "print(f\"  URI: {model_uri}\")\n",
    "\n",
    "# Test the loaded model\n",
    "sample_predictions = production_model.predict(X_test[:5])\n",
    "print(f\"\\nSample predictions: {sample_predictions}\")\n",
    "print(f\"Actual values: {y_test[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Load by specific version\n",
    "# Useful for comparing versions or debugging\n",
    "model_uri_v1 = \"models:/binary_classifier/1\"\n",
    "model_v1 = mlflow.sklearn.load_model(model_uri_v1)\n",
    "\n",
    "model_uri_v2 = \"models:/binary_classifier/2\"\n",
    "model_v2 = mlflow.sklearn.load_model(model_uri_v2)\n",
    "\n",
    "# Compare predictions\n",
    "pred_v1 = model_v1.predict(X_test)\n",
    "pred_v2 = model_v2.predict(X_test)\n",
    "\n",
    "acc_v1 = accuracy_score(y_test, pred_v1)\n",
    "acc_v2 = accuracy_score(y_test, pred_v2)\n",
    "\n",
    "print(\"Version Comparison:\")\n",
    "print(f\"  Version 1 accuracy: {acc_v1:.4f}\")\n",
    "print(f\"  Version 2 accuracy: {acc_v2:.4f}\")\n",
    "print(f\"  Improvement: {(acc_v2 - acc_v1)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Lineage and Metadata\n",
    "\n",
    "The registry maintains full lineage: which run created the model, when, and with what parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full lineage for production model\n",
    "prod_model = client.get_latest_versions(\"binary_classifier\", stages=[\"Production\"])[0]\n",
    "run = client.get_run(prod_model.run_id)\n",
    "\n",
    "print(f\"Production Model Lineage:\")\n",
    "print(f\"  Version: {prod_model.version}\")\n",
    "print(f\"  Run ID: {prod_model.run_id}\")\n",
    "print(f\"  Created: {pd.to_datetime(prod_model.creation_timestamp, unit='ms')}\")\n",
    "print(f\"\\nTraining Parameters:\")\n",
    "for key, value in run.data.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nMetrics:\")\n",
    "for key, value in run.data.metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\nTags:\")\n",
    "for key, value in prod_model.tags.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Archiving Old Models\n",
    "\n",
    "Keep your registry clean by archiving models that are no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archive version 1 (it's in Staging and we have a better production model)\n",
    "client.transition_model_version_stage(\n",
    "    name=\"binary_classifier\",\n",
    "    version=1,\n",
    "    stage=\"Archived\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ Version 1 archived\")\n",
    "\n",
    "# View all versions and their stages\n",
    "all_versions = client.search_model_versions(\"name='binary_classifier'\")\n",
    "print(\"\\nAll Model Versions:\")\n",
    "for mv in sorted(all_versions, key=lambda x: x.version):\n",
    "    print(f\"  Version {mv.version}: {mv.current_stage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Exercises\n",
    "\n",
    "Test your understanding of model versioning and registry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Register a Logistic Regression Model\n",
    "\n",
    "Train a LogisticRegression model and register it under the name \"logistic_classifier\".\n",
    "\n",
    "**Requirements**:\n",
    "1. Train a LogisticRegression model on the same dataset\n",
    "2. Log parameters and accuracy\n",
    "3. Register the model as \"logistic_classifier\"\n",
    "4. Add a description and at least 2 tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 Solution\n",
    "\n",
    "with mlflow.start_run(run_name=\"logistic_regression_v1\"):\n",
    "    \n",
    "    # Train model\n",
    "    params = {\"max_iter\": 1000, \"C\": 1.0, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    # Register model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"logistic_classifier\"\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Logistic classifier registered (Accuracy: {accuracy:.4f})\")\n",
    "\n",
    "# Add description and tags\n",
    "client.update_registered_model(\n",
    "    name=\"logistic_classifier\",\n",
    "    description=\"Baseline logistic regression model for binary classification\"\n",
    ")\n",
    "\n",
    "client.set_model_version_tag(\n",
    "    name=\"logistic_classifier\", version=\"1\", key=\"model_type\", value=\"logistic\"\n",
    ")\n",
    "\n",
    "client.set_model_version_tag(\n",
    "    name=\"logistic_classifier\", version=\"1\", key=\"baseline\", value=\"true\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ Description and tags added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Transition Through Stages\n",
    "\n",
    "Practice moving a model through the complete lifecycle.\n",
    "\n",
    "**Requirements**:\n",
    "1. Transition \"logistic_classifier\" version 1 to Staging\n",
    "2. Check its current stage\n",
    "3. Transition it to Production\n",
    "4. Verify the transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 Solution\n",
    "\n",
    "# Move to Staging\n",
    "client.transition_model_version_stage(\n",
    "    name=\"logistic_classifier\",\n",
    "    version=1,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "print(\"âœ“ Transitioned to Staging\")\n",
    "\n",
    "# Check current stage\n",
    "model_version = client.get_model_version(name=\"logistic_classifier\", version=\"1\")\n",
    "print(f\"  Current stage: {model_version.current_stage}\")\n",
    "\n",
    "# Move to Production\n",
    "client.transition_model_version_stage(\n",
    "    name=\"logistic_classifier\",\n",
    "    version=1,\n",
    "    stage=\"Production\"\n",
    ")\n",
    "print(\"âœ“ Transitioned to Production\")\n",
    "\n",
    "# Verify\n",
    "model_version = client.get_model_version(name=\"logistic_classifier\", version=\"1\")\n",
    "print(f\"  Final stage: {model_version.current_stage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Load and Compare Models\n",
    "\n",
    "Load both production models and compare their performance.\n",
    "\n",
    "**Requirements**:\n",
    "1. Load the production version of \"binary_classifier\"\n",
    "2. Load the production version of \"logistic_classifier\"\n",
    "3. Make predictions on the test set\n",
    "4. Print which model has better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 Solution\n",
    "\n",
    "# Load both production models\n",
    "rf_model = mlflow.sklearn.load_model(\"models:/binary_classifier/Production\")\n",
    "lr_model = mlflow.sklearn.load_model(\"models:/logistic_classifier/Production\")\n",
    "\n",
    "# Make predictions\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracies\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "# Compare\n",
    "print(\"Production Model Comparison:\")\n",
    "print(f\"  Random Forest accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"  Logistic Regression accuracy: {lr_accuracy:.4f}\")\n",
    "print()\n",
    "\n",
    "if rf_accuracy > lr_accuracy:\n",
    "    print(f\"âœ“ Random Forest is better by {(rf_accuracy - lr_accuracy)*100:.2f}%\")\n",
    "else:\n",
    "    print(f\"âœ“ Logistic Regression is better by {(lr_accuracy - rf_accuracy)*100:.2f}%\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "models = ['Random Forest', 'Logistic Regression']\n",
    "accuracies = [rf_accuracy, lr_accuracy]\n",
    "colors = ['skyblue', 'lightcoral']\n",
    "\n",
    "ax.bar(models, accuracies, color=colors, edgecolor='black', alpha=0.7)\n",
    "ax.set_ylabel('Accuracy', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Production Models Comparison', fontweight='bold', fontsize=14)\n",
    "ax.set_ylim(0.85, 1.0)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate(accuracies):\n",
    "    ax.text(i, v + 0.005, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **MLflow Model Registry** provides centralized model versioning and lifecycle management\n",
    "\n",
    "2. **Model stages** (None â†’ Staging â†’ Production â†’ Archived) represent the deployment lifecycle\n",
    "\n",
    "3. **Registering models** can be done during training or after using run IDs\n",
    "\n",
    "4. **Rich metadata** (descriptions, tags, lineage) makes models discoverable and traceable\n",
    "\n",
    "5. **Loading models** by stage ensures applications always use the right version\n",
    "\n",
    "6. **Version comparison** helps teams make data-driven promotion decisions\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- Always add descriptions to registered models\n",
    "- Use tags to organize models by team, project, or data source\n",
    "- Test models in Staging before promoting to Production\n",
    "- Archive old models rather than deleting them\n",
    "- Load models by stage in production applications\n",
    "- Document the criteria for promoting models\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 03**, we'll explore:\n",
    "- **Model serialization** formats (pickle, joblib, ONNX)\n",
    "- **Cross-platform compatibility** considerations\n",
    "- **Model size optimization**\n",
    "- **Best practices** for saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Additional Resources\n",
    "\n",
    "### Documentation\n",
    "- **MLflow Model Registry**: https://mlflow.org/docs/latest/model-registry.html\n",
    "- **Model Registry API**: https://mlflow.org/docs/latest/python_api/mlflow.client.html\n",
    "- **Transitioning Models**: https://mlflow.org/docs/latest/model-registry.html#transitioning-an-mlflow-models-stage\n",
    "\n",
    "### Tutorials\n",
    "- **MLflow Registry Tutorial**: https://mlflow.org/docs/latest/registry.html\n",
    "- **Model Registry Workflows**: https://mlflow.org/docs/latest/model-registry.html#model-registry-workflows\n",
    "\n",
    "### Advanced Topics\n",
    "- Setting up model registry with PostgreSQL/MySQL\n",
    "- Implementing approval workflows for production\n",
    "- Integrating registry with CI/CD pipelines\n",
    "- Model governance and access control"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
