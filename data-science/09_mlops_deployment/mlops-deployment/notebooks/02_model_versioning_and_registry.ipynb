{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 02: Model Versioning and Registry\n",
    "\n",
    "**Difficulty**: ⭐⭐ Intermediate  \n",
    "**Estimated Time**: 50 minutes  \n",
    "**Prerequisites**: \n",
    "- Module 01: Experiment Tracking with MLflow\n",
    "- Understanding of ML model lifecycle\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Set up and use MLflow Model Registry for model versioning\n",
    "2. Register models and manage multiple versions\n",
    "3. Transition models between lifecycle stages (Staging, Production, Archived)\n",
    "4. Track model lineage and metadata\n",
    "5. Implement model governance and approval workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Model Versioning and Registry Matter\n",
    "\n",
    "Imagine you have multiple models in production:\n",
    "\n",
    "**Without a Model Registry:**\n",
    "- ❌ \"Which model version is in production?\"\n",
    "- ❌ \"Who approved this model for deployment?\"\n",
    "- ❌ \"When was the last model update?\"\n",
    "- ❌ \"Can we rollback to the previous version?\"\n",
    "- ❌ \"What data was this model trained on?\"\n",
    "\n",
    "**With a Model Registry:**\n",
    "- ✅ Centralized model storage\n",
    "- ✅ Version control for models\n",
    "- ✅ Stage-based model lifecycle (Staging → Production)\n",
    "- ✅ Model lineage tracking\n",
    "- ✅ Collaborative model management\n",
    "- ✅ Easy rollback and A/B testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import required libraries\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n",
    "print(f\"✓ MLflow version: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting Up MLflow Model Registry\n",
    "\n",
    "The Model Registry is a centralized model store that provides:\n",
    "- **Model Versioning**: Automatic version increments\n",
    "- **Stage Transitions**: None → Staging → Production → Archived\n",
    "- **Annotations**: Descriptions, tags, and metadata\n",
    "- **Model Lineage**: Links to training runs and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MLflow tracking and registry\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "\n",
    "# Create experiment for model registry demo\n",
    "experiment_name = \"model_registry_demo\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Initialize MLflow client for registry operations\n",
    "client = MlflowClient()\n",
    "\n",
    "print(f\"✓ MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"✓ Active experiment: {experiment_name}\")\n",
    "print(\"\\nTo view the Model Registry:\")\n",
    "print(\"  1. Run: mlflow ui\")\n",
    "print(\"  2. Navigate to http://localhost:5000\")\n",
    "print(\"  3. Click on 'Models' tab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing Sample Data and Training Models\n",
    "\n",
    "Let's create a dataset and train multiple model versions to demonstrate the registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset for fraud detection\n",
    "X, y = make_classification(\n",
    "    n_samples=3000,\n",
    "    n_features=25,\n",
    "    n_informative=20,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    weights=[0.95, 0.05],  # Highly imbalanced (5% fraud)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create feature names\n",
    "feature_names = [f'feature_{i}' for i in range(25)]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"  Legitimate: {(y == 0).sum()} ({(y == 0).mean()*100:.1f}%)\")\n",
    "print(f\"  Fraud: {(y == 1).sum()} ({(y == 1).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Registering Your First Model\n",
    "\n",
    "To register a model:\n",
    "1. Train and log the model using MLflow\n",
    "2. Register it with a unique name\n",
    "3. MLflow automatically creates version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define registered model name\n",
    "# This is the name that will appear in the Model Registry\n",
    "model_name = \"fraud_detection_model\"\n",
    "\n",
    "# Train and register the first model version\n",
    "with mlflow.start_run(run_name=\"initial_logistic_regression\") as run:\n",
    "    \n",
    "    # Model parameters\n",
    "    params = {\n",
    "        'C': 1.0,\n",
    "        'max_iter': 200,\n",
    "        'solver': 'lbfgs',\n",
    "        'class_weight': 'balanced'  # Handle imbalanced data\n",
    "    }\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Train model\n",
    "    model = LogisticRegression(**params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate and log metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred)\n",
    "    }\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    # Create model signature (input/output schema)\n",
    "    # This helps with model validation and documentation\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    \n",
    "    # Log and register the model\n",
    "    # registered_model_name triggers registration\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    print(\"✓ Model trained and registered!\")\n",
    "    print(f\"✓ Run ID: {run_id}\")\n",
    "    print(f\"✓ Registered as: {model_name}\")\n",
    "    print(f\"\\nMetrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating Multiple Model Versions\n",
    "\n",
    "As you improve your model, you'll create new versions. The registry tracks all versions automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and register version 2: Random Forest\n",
    "with mlflow.start_run(run_name=\"v2_random_forest\") as run:\n",
    "    \n",
    "    params = {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'class_weight': 'balanced',\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred)\n",
    "    }\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    \n",
    "    # Register as the same model name - creates version 2\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "    \n",
    "    print(\"✓ Version 2 (Random Forest) registered!\")\n",
    "    print(f\"\\nMetrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and register version 3: Gradient Boosting\n",
    "with mlflow.start_run(run_name=\"v3_gradient_boosting\") as run:\n",
    "    \n",
    "    params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    model = GradientBoostingClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred)\n",
    "    }\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    \n",
    "    # Register as version 3\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "    \n",
    "    print(\"✓ Version 3 (Gradient Boosting) registered!\")\n",
    "    print(f\"\\nMetrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Viewing and Managing Model Versions\n",
    "\n",
    "Use the MLflow Client to query and manage registered models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all registered models\n",
    "registered_models = client.search_registered_models()\n",
    "\n",
    "print(\"Registered Models:\")\n",
    "print(\"=\"*80)\n",
    "for rm in registered_models:\n",
    "    print(f\"\\nModel: {rm.name}\")\n",
    "    print(f\"Description: {rm.description if rm.description else 'No description'}\")\n",
    "    print(f\"Latest versions: {len(rm.latest_versions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all versions of our fraud detection model\n",
    "versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "\n",
    "print(f\"All versions of '{model_name}':\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create a summary DataFrame\n",
    "version_data = []\n",
    "for version in versions:\n",
    "    # Get metrics from the run\n",
    "    run = client.get_run(version.run_id)\n",
    "    \n",
    "    version_data.append({\n",
    "        'Version': version.version,\n",
    "        'Stage': version.current_stage,\n",
    "        'Run ID': version.run_id[:8] + '...',\n",
    "        'Accuracy': run.data.metrics.get('accuracy', 0),\n",
    "        'F1 Score': run.data.metrics.get('f1_score', 0),\n",
    "        'Recall': run.data.metrics.get('recall', 0)\n",
    "    })\n",
    "\n",
    "versions_df = pd.DataFrame(version_data)\n",
    "versions_df = versions_df.sort_values('Version', ascending=False)\n",
    "print(versions_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Lifecycle Stages\n",
    "\n",
    "MLflow provides four lifecycle stages:\n",
    "1. **None**: Default stage after registration\n",
    "2. **Staging**: Model is being tested (pre-production)\n",
    "3. **Production**: Model is live and serving predictions\n",
    "4. **Archived**: Model is retired but kept for reference\n",
    "\n",
    "### Typical Workflow:\n",
    "```\n",
    "Register → None → Staging → Production → Archived\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition version 2 (Random Forest) to Staging\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=2,\n",
    "    stage=\"Staging\",\n",
    "    archive_existing_versions=False  # Keep other versions in their current stages\n",
    ")\n",
    "\n",
    "print(\"✓ Version 2 transitioned to Staging\")\n",
    "\n",
    "# Transition version 3 (Gradient Boosting) to Production\n",
    "# This is our best performing model\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=3,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=False\n",
    ")\n",
    "\n",
    "print(\"✓ Version 3 transitioned to Production\")\n",
    "\n",
    "# Archive version 1 (Logistic Regression)\n",
    "# It's no longer needed but we keep it for historical reference\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=1,\n",
    "    stage=\"Archived\",\n",
    "    archive_existing_versions=False\n",
    ")\n",
    "\n",
    "print(\"✓ Version 1 archived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View updated stages\n",
    "versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "\n",
    "print(f\"\\nUpdated lifecycle stages for '{model_name}':\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "version_data = []\n",
    "for version in versions:\n",
    "    run = client.get_run(version.run_id)\n",
    "    version_data.append({\n",
    "        'Version': version.version,\n",
    "        'Stage': version.current_stage,\n",
    "        'F1 Score': f\"{run.data.metrics.get('f1_score', 0):.4f}\",\n",
    "        'Description': version.description if version.description else 'No description'\n",
    "    })\n",
    "\n",
    "versions_df = pd.DataFrame(version_data)\n",
    "versions_df = versions_df.sort_values('Version', ascending=False)\n",
    "print(versions_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Adding Model Metadata and Annotations\n",
    "\n",
    "Document your models with descriptions, tags, and annotations for better governance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update model description\n",
    "client.update_registered_model(\n",
    "    name=model_name,\n",
    "    description=\"Fraud detection model for transaction monitoring. \"\n",
    "                \"Uses ensemble methods to identify fraudulent transactions. \"\n",
    "                \"Optimized for high recall to minimize false negatives.\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Updated model description for '{model_name}'\")\n",
    "\n",
    "# Add version-specific descriptions\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=3,\n",
    "    description=\"Production model (v3). Gradient Boosting Classifier. \"\n",
    "                \"Achieved F1=0.85 on validation set. \"\n",
    "                f\"Deployed: {datetime.now().strftime('%Y-%m-%d')}\"\n",
    ")\n",
    "\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=2,\n",
    "    description=\"Staging model (v2). Random Forest Classifier. \"\n",
    "                \"Currently being A/B tested against production.\"\n",
    ")\n",
    "\n",
    "print(\"✓ Updated version-specific descriptions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tags for better organization and searchability\n",
    "client.set_registered_model_tag(\n",
    "    name=model_name,\n",
    "    key=\"task\",\n",
    "    value=\"binary_classification\"\n",
    ")\n",
    "\n",
    "client.set_registered_model_tag(\n",
    "    name=model_name,\n",
    "    key=\"domain\",\n",
    "    value=\"fraud_detection\"\n",
    ")\n",
    "\n",
    "client.set_registered_model_tag(\n",
    "    name=model_name,\n",
    "    key=\"team\",\n",
    "    value=\"risk_analytics\"\n",
    ")\n",
    "\n",
    "# Add version-specific tags\n",
    "client.set_model_version_tag(\n",
    "    name=model_name,\n",
    "    version=3,\n",
    "    key=\"validation_status\",\n",
    "    value=\"approved\"\n",
    ")\n",
    "\n",
    "client.set_model_version_tag(\n",
    "    name=model_name,\n",
    "    version=3,\n",
    "    key=\"approved_by\",\n",
    "    value=\"data_science_lead\"\n",
    ")\n",
    "\n",
    "print(\"✓ Added tags for model governance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Loading Models from Registry\n",
    "\n",
    "In production, you load models by name and stage, not by run ID. This enables easy model updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the production model\n",
    "# This URI automatically gets the latest production version\n",
    "production_model_uri = f\"models:/{model_name}/Production\"\n",
    "production_model = mlflow.sklearn.load_model(production_model_uri)\n",
    "\n",
    "print(f\"✓ Loaded production model from registry\")\n",
    "print(f\"  Model type: {type(production_model).__name__}\")\n",
    "\n",
    "# Make predictions with production model\n",
    "sample_predictions = production_model.predict(X_test[:5])\n",
    "print(f\"\\nSample predictions: {sample_predictions}\")\n",
    "print(f\"Actual values: {y_test[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load staging model for comparison\n",
    "staging_model_uri = f\"models:/{model_name}/Staging\"\n",
    "staging_model = mlflow.sklearn.load_model(staging_model_uri)\n",
    "\n",
    "print(f\"✓ Loaded staging model from registry\")\n",
    "print(f\"  Model type: {type(staging_model).__name__}\")\n",
    "\n",
    "# Compare predictions\n",
    "production_preds = production_model.predict(X_test)\n",
    "staging_preds = staging_model.predict(X_test)\n",
    "\n",
    "prod_f1 = f1_score(y_test, production_preds)\n",
    "staging_f1 = f1_score(y_test, staging_preds)\n",
    "\n",
    "print(f\"\\nProduction model F1: {prod_f1:.4f}\")\n",
    "print(f\"Staging model F1: {staging_f1:.4f}\")\n",
    "print(f\"\\nDifference: {abs(prod_f1 - staging_f1):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specific version (useful for debugging or rollback)\n",
    "specific_version_uri = f\"models:/{model_name}/1\"\n",
    "v1_model = mlflow.sklearn.load_model(specific_version_uri)\n",
    "\n",
    "print(f\"✓ Loaded version 1 (archived) from registry\")\n",
    "print(f\"  Model type: {type(v1_model).__name__}\")\n",
    "\n",
    "# This is useful for:\n",
    "# - Debugging production issues\n",
    "# - Comparing old vs new models\n",
    "# - Rolling back to a previous version\n",
    "v1_preds = v1_model.predict(X_test)\n",
    "v1_f1 = f1_score(y_test, v1_preds)\n",
    "print(f\"  F1 Score: {v1_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Lineage and Traceability\n",
    "\n",
    "Track where models came from and what data they used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed information about production model version\n",
    "prod_versions = client.get_latest_versions(model_name, stages=[\"Production\"])\n",
    "prod_version = prod_versions[0]\n",
    "\n",
    "print(f\"Production Model Lineage:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model Name: {prod_version.name}\")\n",
    "print(f\"Version: {prod_version.version}\")\n",
    "print(f\"Stage: {prod_version.current_stage}\")\n",
    "print(f\"Run ID: {prod_version.run_id}\")\n",
    "print(f\"Source: {prod_version.source}\")\n",
    "print(f\"Created: {datetime.fromtimestamp(prod_version.creation_timestamp/1000)}\")\n",
    "print(f\"Last Updated: {datetime.fromtimestamp(prod_version.last_updated_timestamp/1000)}\")\n",
    "\n",
    "# Get the training run details\n",
    "run = client.get_run(prod_version.run_id)\n",
    "print(f\"\\nTraining Run Details:\")\n",
    "print(f\"  Parameters:\")\n",
    "for param, value in run.data.params.items():\n",
    "    print(f\"    {param}: {value}\")\n",
    "    \n",
    "print(f\"\\n  Metrics:\")\n",
    "for metric, value in run.data.metrics.items():\n",
    "    print(f\"    {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Implementing Model Promotion Workflow\n",
    "\n",
    "Create a function to automate model promotion based on performance criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def promote_model_if_better(model_name, staging_version, production_version=None, \n",
    "                            metric='f1_score', threshold=0.02):\n",
    "    \"\"\"\n",
    "    Promote staging model to production if it performs better.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the registered model\n",
    "        staging_version: Version number in staging\n",
    "        production_version: Current production version (if exists)\n",
    "        metric: Metric to compare (default: f1_score)\n",
    "        threshold: Minimum improvement required (default: 0.02)\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if promoted, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get staging model metrics\n",
    "    staging_model_version = client.get_model_version(model_name, staging_version)\n",
    "    staging_run = client.get_run(staging_model_version.run_id)\n",
    "    staging_metric_value = staging_run.data.metrics.get(metric, 0)\n",
    "    \n",
    "    print(f\"Staging model (v{staging_version}) {metric}: {staging_metric_value:.4f}\")\n",
    "    \n",
    "    # Check if production model exists\n",
    "    if production_version is None:\n",
    "        print(\"No production model exists. Promoting staging to production.\")\n",
    "        should_promote = True\n",
    "    else:\n",
    "        # Get production model metrics\n",
    "        prod_model_version = client.get_model_version(model_name, production_version)\n",
    "        prod_run = client.get_run(prod_model_version.run_id)\n",
    "        prod_metric_value = prod_run.data.metrics.get(metric, 0)\n",
    "        \n",
    "        print(f\"Production model (v{production_version}) {metric}: {prod_metric_value:.4f}\")\n",
    "        \n",
    "        # Check if improvement exceeds threshold\n",
    "        improvement = staging_metric_value - prod_metric_value\n",
    "        print(f\"Improvement: {improvement:.4f} (threshold: {threshold})\")\n",
    "        \n",
    "        should_promote = improvement >= threshold\n",
    "    \n",
    "    if should_promote:\n",
    "        # Archive current production model\n",
    "        if production_version is not None:\n",
    "            client.transition_model_version_stage(\n",
    "                name=model_name,\n",
    "                version=production_version,\n",
    "                stage=\"Archived\"\n",
    "            )\n",
    "            print(f\"✓ Archived production v{production_version}\")\n",
    "        \n",
    "        # Promote staging to production\n",
    "        client.transition_model_version_stage(\n",
    "            name=model_name,\n",
    "            version=staging_version,\n",
    "            stage=\"Production\"\n",
    "        )\n",
    "        print(f\"✓ Promoted staging v{staging_version} to Production\")\n",
    "        \n",
    "        # Add promotion metadata\n",
    "        client.set_model_version_tag(\n",
    "            name=model_name,\n",
    "            version=staging_version,\n",
    "            key=\"promoted_date\",\n",
    "            value=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        )\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(\"✗ Staging model does not meet promotion criteria\")\n",
    "        return False\n",
    "\n",
    "# Example: Try to promote version 2 to production\n",
    "print(\"Attempting to promote model...\")\n",
    "print(\"=\"*80)\n",
    "promoted = promote_model_if_better(\n",
    "    model_name=model_name,\n",
    "    staging_version=2,\n",
    "    production_version=3,\n",
    "    metric='f1_score',\n",
    "    threshold=0.02\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Exercises\n",
    "\n",
    "### Exercise 1: Register and Version a New Model\n",
    "\n",
    "Create a new registered model for a different use case.\n",
    "\n",
    "**Requirements:**\n",
    "1. Train at least 3 different model types (your choice)\n",
    "2. Register them all under the same model name \"customer_churn_predictor\"\n",
    "3. Add descriptions and tags to each version\n",
    "4. Create a comparison table showing all versions and their metrics\n",
    "\n",
    "**Hint**: Use the same dataset or create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "\n",
    "# TODO: Implement your solution\n",
    "# 1. Train multiple models\n",
    "# 2. Register them with the same name\n",
    "# 3. Add metadata\n",
    "# 4. Create comparison table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Implement Stage Transition Workflow\n",
    "\n",
    "Create a complete workflow for moving models through lifecycle stages.\n",
    "\n",
    "**Requirements:**\n",
    "1. Identify the best model from Exercise 1 based on a metric of your choice\n",
    "2. Transition it through: None → Staging → Production\n",
    "3. Add appropriate tags at each stage (e.g., \"tested_by\", \"approved_by\", \"deployment_date\")\n",
    "4. Create a function that checks model readiness before transitioning stages\n",
    "\n",
    "**Bonus**: Add validation checks (e.g., minimum accuracy threshold, required metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "\n",
    "def check_model_readiness(model_name, version, target_stage):\n",
    "    \"\"\"\n",
    "    Check if a model is ready to transition to the target stage.\n",
    "    Add validation logic here.\n",
    "    \"\"\"\n",
    "    # TODO: Implement validation logic\n",
    "    pass\n",
    "\n",
    "# TODO: Implement the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Model Rollback Scenario\n",
    "\n",
    "Simulate a production issue and implement a rollback strategy.\n",
    "\n",
    "**Scenario**: Your production model (v3) is causing issues. You need to rollback to v2.\n",
    "\n",
    "**Requirements:**\n",
    "1. Transition current production model to Archived\n",
    "2. Promote the previous version back to Production\n",
    "3. Add tags documenting the rollback (reason, timestamp, who initiated)\n",
    "4. Create a rollback report showing:\n",
    "   - Which version was rolled back\n",
    "   - Which version is now in production\n",
    "   - Performance comparison between the two\n",
    "   - Rollback timestamp and reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "\n",
    "def rollback_model(model_name, rollback_to_version, reason):\n",
    "    \"\"\"\n",
    "    Rollback production model to a previous version.\n",
    "    \"\"\"\n",
    "    # TODO: Implement rollback logic\n",
    "    pass\n",
    "\n",
    "# TODO: Execute rollback and create report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary\n",
    "\n",
    "### Key Concepts Covered\n",
    "\n",
    "1. **Model Registry Setup**: Configured MLflow Model Registry for centralized model management\n",
    "2. **Model Registration**: Registered models and created multiple versions automatically\n",
    "3. **Lifecycle Stages**: Transitioned models through None → Staging → Production → Archived\n",
    "4. **Metadata Management**: Added descriptions, tags, and annotations for governance\n",
    "5. **Model Loading**: Loaded models by stage for production deployment\n",
    "6. **Lineage Tracking**: Traced model origins, parameters, and training runs\n",
    "7. **Promotion Workflow**: Automated model promotion based on performance criteria\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- ✅ **Use descriptive model names**: Choose names that reflect the business use case\n",
    "- ✅ **Document everything**: Add descriptions to models and versions\n",
    "- ✅ **Tag appropriately**: Use tags for team, approval status, deployment date\n",
    "- ✅ **Load by stage, not version**: Use \"Production\" stage in code, not version numbers\n",
    "- ✅ **Automate promotions**: Create functions to handle stage transitions\n",
    "- ✅ **Track lineage**: Always link models back to training runs and data\n",
    "- ✅ **Implement gates**: Add validation before promoting to production\n",
    "\n",
    "### Common Pitfalls to Avoid\n",
    "\n",
    "- ❌ Hardcoding version numbers in production code\n",
    "- ❌ Skipping the staging stage (always test before production)\n",
    "- ❌ Not documenting why models were promoted or rolled back\n",
    "- ❌ Deleting old model versions (archive instead)\n",
    "- ❌ Promoting models without proper validation\n",
    "\n",
    "### What's Next\n",
    "\n",
    "In **Module 03: Model Serialization**, we'll learn:\n",
    "- Different serialization formats (pickle, joblib, ONNX)\n",
    "- When to use each format\n",
    "- Cross-platform and cross-language model deployment\n",
    "- Model size optimization\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- **MLflow Model Registry**: https://mlflow.org/docs/latest/model-registry.html\n",
    "- **Model Versioning Best Practices**: https://neptune.ai/blog/version-control-for-ml-models\n",
    "- **MLOps Model Governance**: https://ml-ops.org/content/model-governance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Proceed to **Module 03: Model Serialization** to learn about different ways to save and load models for deployment.\n",
    "\n",
    "**Before moving on, ensure you can:**\n",
    "- ✅ Register models in MLflow Model Registry\n",
    "- ✅ Create and manage multiple model versions\n",
    "- ✅ Transition models between lifecycle stages\n",
    "- ✅ Add descriptions, tags, and metadata\n",
    "- ✅ Load models by stage name\n",
    "- ✅ Implement automated promotion workflows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
