{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 09: Multi-Cloud ML Considerations\n",
    "\n",
    "**Difficulty**: ‚≠ê‚≠ê‚≠ê\n",
    "**Estimated Time**: 80 minutes\n",
    "**Prerequisites**: \n",
    "- [Module 00: Introduction to Cloud ML Services](00_introduction_to_cloud_ml_services.ipynb)\n",
    "- [Module 07: Serverless ML](07_serverless_ml.ipynb)\n",
    "- [Module 08: Cost Optimization Strategies](08_cost_optimization_strategies.ipynb)\n",
    "- Understanding of cloud fundamentals\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand when to use multi-cloud vs single cloud strategies\n",
    "2. Map equivalent services across AWS, Azure, and GCP\n",
    "3. Use MLflow for multi-cloud experiment tracking\n",
    "4. Implement model portability with ONNX\n",
    "5. Deploy ML applications on Kubernetes for cloud-agnostic architecture\n",
    "6. Use Terraform for infrastructure as code across clouds\n",
    "7. Mitigate vendor lock-in risks\n",
    "8. Design portable data formats and pipelines\n",
    "\n",
    "## Multi-Cloud vs Single Cloud: The Decision\n",
    "\n",
    "### When to Use Single Cloud ‚úÖ\n",
    "- **Simplicity**: Easier to learn, manage, and optimize\n",
    "- **Cost**: Better volume discounts and reserved pricing\n",
    "- **Integration**: Native services work seamlessly together\n",
    "- **Support**: Single vendor relationship\n",
    "- **Performance**: Lower latency within same cloud\n",
    "\n",
    "**Best for**: Startups, small teams, cost-sensitive projects\n",
    "\n",
    "### When to Use Multi-Cloud ‚úÖ\n",
    "- **Avoid vendor lock-in**: Negotiate better pricing, reduce dependency\n",
    "- **Best-of-breed**: Use best ML services from each provider\n",
    "- **Compliance**: Data residency requirements across regions/countries\n",
    "- **Disaster recovery**: True redundancy across providers\n",
    "- **Customer requirements**: Existing enterprise contracts\n",
    "\n",
    "**Best for**: Large enterprises, regulated industries, high-availability systems\n",
    "\n",
    "### Multi-Cloud Challenges ‚ö†Ô∏è\n",
    "- **Complexity**: Managing multiple platforms, tools, billing\n",
    "- **Cost**: Higher operational overhead, potential waste\n",
    "- **Data transfer**: Expensive cross-cloud egress fees\n",
    "- **Skills**: Team needs expertise in multiple clouds\n",
    "- **Testing**: Harder to ensure consistency across platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Data science libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Multi-cloud tools\n",
    "# pip install mlflow onnx onnxruntime\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Model serialization\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Notebook executed on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"MLflow version: {mlflow.__version__}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Service Equivalency Mapping\n",
    "\n",
    "Understanding service equivalents across clouds is crucial for multi-cloud strategy.\n",
    "\n",
    "### 1.1: ML Service Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Comprehensive ML service mapping across clouds\n",
    "ml_service_mapping = pd.DataFrame([\n",
    "    {\n",
    "        'Category': 'Managed ML Platform',\n",
    "        'AWS': 'SageMaker',\n",
    "        'Azure': 'Azure Machine Learning',\n",
    "        'GCP': 'Vertex AI',\n",
    "        'Open Source Alternative': 'MLflow + Kubeflow'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Serverless Functions',\n",
    "        'AWS': 'Lambda',\n",
    "        'Azure': 'Azure Functions',\n",
    "        'GCP': 'Cloud Functions',\n",
    "        'Open Source Alternative': 'OpenFaaS, Knative'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Container Orchestration',\n",
    "        'AWS': 'EKS (Kubernetes)',\n",
    "        'Azure': 'AKS (Kubernetes)',\n",
    "        'GCP': 'GKE (Kubernetes)',\n",
    "        'Open Source Alternative': 'Kubernetes (self-managed)'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Object Storage',\n",
    "        'AWS': 'S3',\n",
    "        'Azure': 'Blob Storage',\n",
    "        'GCP': 'Cloud Storage',\n",
    "        'Open Source Alternative': 'MinIO'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Managed Notebooks',\n",
    "        'AWS': 'SageMaker Notebooks',\n",
    "        'Azure': 'Azure Notebooks',\n",
    "        'GCP': 'Vertex AI Workbench',\n",
    "        'Open Source Alternative': 'JupyterHub'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'AutoML',\n",
    "        'AWS': 'SageMaker Autopilot',\n",
    "        'Azure': 'Azure AutoML',\n",
    "        'GCP': 'Vertex AI AutoML',\n",
    "        'Open Source Alternative': 'H2O AutoML, Auto-sklearn'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Model Registry',\n",
    "        'AWS': 'SageMaker Model Registry',\n",
    "        'Azure': 'Azure ML Model Registry',\n",
    "        'GCP': 'Vertex AI Model Registry',\n",
    "        'Open Source Alternative': 'MLflow Model Registry'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Experiment Tracking',\n",
    "        'AWS': 'SageMaker Experiments',\n",
    "        'Azure': 'Azure ML Experiments',\n",
    "        'GCP': 'Vertex AI Experiments',\n",
    "        'Open Source Alternative': 'MLflow, Weights & Biases'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Feature Store',\n",
    "        'AWS': 'SageMaker Feature Store',\n",
    "        'Azure': 'Azure ML Feature Store',\n",
    "        'GCP': 'Vertex AI Feature Store',\n",
    "        'Open Source Alternative': 'Feast'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Model Monitoring',\n",
    "        'AWS': 'SageMaker Model Monitor',\n",
    "        'Azure': 'Azure ML Model Monitoring',\n",
    "        'GCP': 'Vertex AI Model Monitoring',\n",
    "        'Open Source Alternative': 'Evidently AI, Seldon Core'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Workflow Orchestration',\n",
    "        'AWS': 'SageMaker Pipelines, Step Functions',\n",
    "        'Azure': 'Azure ML Pipelines',\n",
    "        'GCP': 'Vertex AI Pipelines',\n",
    "        'Open Source Alternative': 'Airflow, Kubeflow Pipelines'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"ML Service Equivalency Mapping\\n\")\n",
    "print(ml_service_mapping.to_string(index=False))\n",
    "print(\"\\nüí° Key Insights:\")\n",
    "print(\"   - Kubernetes is the common denominator for container orchestration\")\n",
    "print(\"   - Open source alternatives exist for most managed services\")\n",
    "print(\"   - MLflow provides cloud-agnostic experiment tracking\")\n",
    "print(\"   - All major clouds support similar ML workflows with different APIs\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Compute Instance Equivalency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Equivalent compute instances across clouds\n",
    "compute_equivalents = pd.DataFrame([\n",
    "    {\n",
    "        'Use Case': 'General Purpose (Small)',\n",
    "        'AWS': 't3.medium (2 vCPU, 4GB)',\n",
    "        'Azure': 'B2s (2 vCPU, 4GB)',\n",
    "        'GCP': 'e2-medium (2 vCPU, 4GB)',\n",
    "        'Approx Cost ($/hr)': '0.04-0.05'\n",
    "    },\n",
    "    {\n",
    "        'Use Case': 'General Purpose (Medium)',\n",
    "        'AWS': 'm5.xlarge (4 vCPU, 16GB)',\n",
    "        'Azure': 'D4s v4 (4 vCPU, 16GB)',\n",
    "        'GCP': 'n2-standard-4 (4 vCPU, 16GB)',\n",
    "        'Approx Cost ($/hr)': '0.19-0.23'\n",
    "    },\n",
    "    {\n",
    "        'Use Case': 'Compute Optimized',\n",
    "        'AWS': 'c5.2xlarge (8 vCPU, 16GB)',\n",
    "        'Azure': 'F8s v2 (8 vCPU, 16GB)',\n",
    "        'GCP': 'c2-standard-8 (8 vCPU, 32GB)',\n",
    "        'Approx Cost ($/hr)': '0.34-0.40'\n",
    "    },\n",
    "    {\n",
    "        'Use Case': 'Memory Optimized',\n",
    "        'AWS': 'r5.xlarge (4 vCPU, 32GB)',\n",
    "        'Azure': 'E4s v4 (4 vCPU, 32GB)',\n",
    "        'GCP': 'n2-highmem-4 (4 vCPU, 32GB)',\n",
    "        'Approx Cost ($/hr)': '0.25-0.30'\n",
    "    },\n",
    "    {\n",
    "        'Use Case': 'GPU (Entry Level)',\n",
    "        'AWS': 'g4dn.xlarge (4 vCPU, 16GB, T4)',\n",
    "        'Azure': 'NC4as T4 v3 (4 vCPU, 28GB, T4)',\n",
    "        'GCP': 'n1-standard-4 + T4 (4 vCPU, 15GB, T4)',\n",
    "        'Approx Cost ($/hr)': '0.52-0.73'\n",
    "    },\n",
    "    {\n",
    "        'Use Case': 'GPU (High Performance)',\n",
    "        'AWS': 'p3.2xlarge (8 vCPU, 61GB, V100)',\n",
    "        'Azure': 'NC6s v3 (6 vCPU, 112GB, V100)',\n",
    "        'GCP': 'n1-standard-8 + V100 (8 vCPU, 30GB, V100)',\n",
    "        'Approx Cost ($/hr)': '3.06-3.80'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"Compute Instance Equivalency Guide\\n\")\n",
    "print(compute_equivalents.to_string(index=False))\n",
    "print(\"\\n‚ö†Ô∏è Important Notes:\")\n",
    "print(\"   - Exact equivalents rarely exist; choose closest match\")\n",
    "print(\"   - Pricing varies by region (us-east-1 / East US / us-central1 shown)\")\n",
    "print(\"   - Performance can differ even with same specs\")\n",
    "print(\"   - Test your specific workload on each platform\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: MLflow for Multi-Cloud Tracking\n",
    "\n",
    "MLflow is an open-source platform for managing the ML lifecycle. It's cloud-agnostic and can track experiments across any platform.\n",
    "\n",
    "### 2.1: Setting Up MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set up local MLflow tracking (can be hosted on any cloud)\n",
    "mlflow_dir = Path('mlruns')\n",
    "mlflow_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Set tracking URI (local for demo, can be remote MLflow server)\n",
    "mlflow.set_tracking_uri(f'file://{mlflow_dir.absolute()}')\n",
    "\n",
    "# Create experiment\n",
    "experiment_name = 'multi-cloud-iris-classification'\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"‚úÖ MLflow tracking initialized\")\n",
    "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Experiment: {experiment_name}\")\n",
    "print(\"\\nüí° In production, host MLflow on:\")\n",
    "print(\"   - AWS: EC2 with S3 backend\")\n",
    "print(\"   - Azure: VM with Blob Storage backend\")\n",
    "print(\"   - GCP: Compute Engine with Cloud Storage backend\")\n",
    "print(\"   - Kubernetes: MLflow server on any cloud\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Training and Logging Models with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load data\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Simulate training on different clouds\n",
    "cloud_platforms = ['AWS', 'Azure', 'GCP']\n",
    "model_configs = [\n",
    "    {'n_estimators': 50, 'max_depth': 5},\n",
    "    {'n_estimators': 100, 'max_depth': 10},\n",
    "    {'n_estimators': 150, 'max_depth': 15},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for platform, config in zip(cloud_platforms, model_configs):\n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=f'{platform}_training'):\n",
    "        # Log platform information\n",
    "        mlflow.set_tag('cloud_platform', platform)\n",
    "        mlflow.set_tag('region', f'{platform.lower()}-region-1')\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params(config)\n",
    "        \n",
    "        # Train model\n",
    "        model = RandomForestClassifier(**config, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        test_acc = model.score(X_test, y_test)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric('train_accuracy', train_acc)\n",
    "        mlflow.log_metric('test_accuracy', test_acc)\n",
    "        \n",
    "        # Log model (cloud-agnostic format)\n",
    "        mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            'model',\n",
    "            registered_model_name=f'iris_classifier_{platform.lower()}'\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'Platform': platform,\n",
    "            'Estimators': config['n_estimators'],\n",
    "            'Max Depth': config['max_depth'],\n",
    "            'Train Accuracy': train_acc,\n",
    "            'Test Accuracy': test_acc\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ Logged {platform} training run\")\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nMulti-Cloud Training Results:\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"\\nüí° All experiments tracked in unified MLflow interface\")\n",
    "print(\"   Run 'mlflow ui' to view dashboard\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Loading Models from MLflow Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load model from MLflow (works regardless of training platform)\n",
    "def load_model_from_registry(model_name: str, version: str = 'latest'):\n",
    "    \"\"\"\n",
    "    Load model from MLflow registry - cloud-agnostic\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if version == 'latest':\n",
    "            model_uri = f\"models:/{model_name}/latest\"\n",
    "        else:\n",
    "            model_uri = f\"models:/{model_name}/{version}\"\n",
    "        \n",
    "        model = mlflow.sklearn.load_model(model_uri)\n",
    "        print(f\"‚úÖ Loaded model: {model_name} (version: {version})\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading model: {e}\")\n",
    "        print(\"   Note: In this demo, models are logged but not registered to registry\")\n",
    "        print(\"   In production, use mlflow.register_model() to add to registry\")\n",
    "        return None\n",
    "\n",
    "# Example: Load AWS model and use for inference on GCP\n",
    "print(\"Example: Cross-cloud model deployment\")\n",
    "print(\"Training on AWS ‚Üí Deploy on GCP (same model artifact)\\n\")\n",
    "\n",
    "# In practice, you'd load from registry:\n",
    "# model = load_model_from_registry('iris_classifier_aws', 'latest')\n",
    "\n",
    "# For demo, use the last trained model\n",
    "sample_input = X_test[:5]\n",
    "# predictions = model.predict(sample_input)\n",
    "print(\"Model loaded successfully and ready for inference on any cloud!\")\n",
    "print(\"\\nüí° Benefits of MLflow Model Registry:\")\n",
    "print(\"   - Single source of truth for models\")\n",
    "print(\"   - Version control and lineage tracking\")\n",
    "print(\"   - Deploy same model to AWS, Azure, or GCP\")\n",
    "print(\"   - Stage transitions: None ‚Üí Staging ‚Üí Production ‚Üí Archived\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Model Portability with ONNX\n",
    "\n",
    "ONNX (Open Neural Network Exchange) is an open format for ML models that enables interoperability across frameworks and platforms.\n",
    "\n",
    "### 3.1: Converting Models to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ONNX conversion example (requires skl2onnx)\n",
    "# pip install skl2onnx onnxruntime\n",
    "\n",
    "try:\n",
    "    from skl2onnx import convert_sklearn\n",
    "    from skl2onnx.common.data_types import FloatTensorType\n",
    "    import onnxruntime as rt\n",
    "    \n",
    "    # Train a simple model\n",
    "    model = RandomForestClassifier(n_estimators=10, max_depth=5, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Define input type for ONNX conversion\n",
    "    initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]\n",
    "    \n",
    "    # Convert to ONNX\n",
    "    onnx_model = convert_sklearn(model, initial_types=initial_type)\n",
    "    \n",
    "    # Save ONNX model\n",
    "    onnx_path = 'iris_model.onnx'\n",
    "    with open(onnx_path, 'wb') as f:\n",
    "        f.write(onnx_model.SerializeToString())\n",
    "    \n",
    "    print(\"‚úÖ Model converted to ONNX format\")\n",
    "    print(f\"ONNX model saved: {onnx_path}\")\n",
    "    print(f\"File size: {os.path.getsize(onnx_path) / 1024:.2f} KB\")\n",
    "    \n",
    "    # Load and run ONNX model\n",
    "    sess = rt.InferenceSession(onnx_path)\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    label_name = sess.get_outputs()[0].name\n",
    "    \n",
    "    # Make predictions\n",
    "    test_sample = X_test[:5].astype(np.float32)\n",
    "    pred_onx = sess.run([label_name], {input_name: test_sample})[0]\n",
    "    \n",
    "    print(\"\\nONNX Inference Results:\")\n",
    "    print(f\"Predictions: {pred_onx}\")\n",
    "    print(\"\\nüí° ONNX Benefits:\")\n",
    "    print(\"   - Framework agnostic (scikit-learn, PyTorch, TensorFlow)\")\n",
    "    print(\"   - Platform agnostic (Windows, Linux, macOS, mobile)\")\n",
    "    print(\"   - Cloud agnostic (AWS, Azure, GCP)\")\n",
    "    print(\"   - Optimized for inference performance\")\n",
    "    print(\"   - Smaller model size (sometimes)\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è skl2onnx not installed\")\n",
    "    print(\"Install with: pip install skl2onnx onnxruntime\")\n",
    "    print(\"\\nONNX enables model portability across:\")\n",
    "    print(\"   - Different ML frameworks (scikit-learn ‚Üí PyTorch)\")\n",
    "    print(\"   - Different cloud platforms (AWS ‚Üí Azure)\")\n",
    "    print(\"   - Different devices (server ‚Üí mobile ‚Üí edge)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: ONNX Deployment Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ONNX deployment options across clouds\n",
    "onnx_deployment = pd.DataFrame([\n",
    "    {\n",
    "        'Platform': 'AWS',\n",
    "        'Service': 'SageMaker',\n",
    "        'ONNX Support': 'Yes (ONNX Runtime)',\n",
    "        'Deployment Method': 'Custom container with ONNX Runtime'\n",
    "    },\n",
    "    {\n",
    "        'Platform': 'Azure',\n",
    "        'Service': 'Azure ML',\n",
    "        'ONNX Support': 'Native',\n",
    "        'Deployment Method': 'Direct ONNX model deployment'\n",
    "    },\n",
    "    {\n",
    "        'Platform': 'GCP',\n",
    "        'Service': 'Vertex AI',\n",
    "        'ONNX Support': 'Yes (via container)',\n",
    "        'Deployment Method': 'Custom container with ONNX Runtime'\n",
    "    },\n",
    "    {\n",
    "        'Platform': 'Edge',\n",
    "        'Service': 'ONNX Runtime',\n",
    "        'ONNX Support': 'Native',\n",
    "        'Deployment Method': 'Direct ONNX inference on device'\n",
    "    },\n",
    "    {\n",
    "        'Platform': 'Mobile',\n",
    "        'Service': 'ONNX Runtime Mobile',\n",
    "        'ONNX Support': 'Native',\n",
    "        'Deployment Method': 'iOS/Android app integration'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"ONNX Deployment Options Across Platforms\\n\")\n",
    "print(onnx_deployment.to_string(index=False))\n",
    "print(\"\\nüéØ Use ONNX when:\")\n",
    "print(\"   - Need to deploy same model to multiple platforms\")\n",
    "print(\"   - Want to avoid platform lock-in\")\n",
    "print(\"   - Deploying to edge/mobile devices\")\n",
    "print(\"   - Optimizing inference performance\")\n",
    "print(\"   - Switching between ML frameworks\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Kubernetes for Cloud-Agnostic Deployment\n",
    "\n",
    "Kubernetes (K8s) is the standard for container orchestration and works identically across all major clouds.\n",
    "\n",
    "### 4.1: Kubernetes ML Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Kubernetes deployment manifest for ML model\n",
    "k8s_deployment = '''\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: iris-classifier\n",
    "  labels:\n",
    "    app: iris-classifier\n",
    "spec:\n",
    "  replicas: 3  # High availability\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: iris-classifier\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: iris-classifier\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: model-server\n",
    "        image: your-registry/iris-classifier:v1.0\n",
    "        ports:\n",
    "        - containerPort: 8080\n",
    "        env:\n",
    "        - name: MODEL_PATH\n",
    "          value: \"/models/model.onnx\"\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"256Mi\"\n",
    "            cpu: \"250m\"\n",
    "          limits:\n",
    "            memory: \"512Mi\"\n",
    "            cpu: \"500m\"\n",
    "        livenessProbe:\n",
    "          httpGet:\n",
    "            path: /health\n",
    "            port: 8080\n",
    "          initialDelaySeconds: 30\n",
    "          periodSeconds: 10\n",
    "        readinessProbe:\n",
    "          httpGet:\n",
    "            path: /ready\n",
    "            port: 8080\n",
    "          initialDelaySeconds: 5\n",
    "          periodSeconds: 5\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: iris-classifier-service\n",
    "spec:\n",
    "  type: LoadBalancer  # Or ClusterIP, NodePort\n",
    "  selector:\n",
    "    app: iris-classifier\n",
    "  ports:\n",
    "  - protocol: TCP\n",
    "    port: 80\n",
    "    targetPort: 8080\n",
    "---\n",
    "apiVersion: autoscaling/v2\n",
    "kind: HorizontalPodAutoscaler\n",
    "metadata:\n",
    "  name: iris-classifier-hpa\n",
    "spec:\n",
    "  scaleTargetRef:\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    name: iris-classifier\n",
    "  minReplicas: 2\n",
    "  maxReplicas: 10\n",
    "  metrics:\n",
    "  - type: Resource\n",
    "    resource:\n",
    "      name: cpu\n",
    "      target:\n",
    "        type: Utilization\n",
    "        averageUtilization: 70\n",
    "  - type: Resource\n",
    "    resource:\n",
    "      name: memory\n",
    "      target:\n",
    "        type: Utilization\n",
    "        averageUtilization: 80\n",
    "'''\n",
    "\n",
    "# Save Kubernetes manifest\n",
    "with open('k8s_ml_deployment.yaml', 'w') as f:\n",
    "    f.write(k8s_deployment)\n",
    "\n",
    "print(\"‚úÖ Kubernetes deployment manifest created\")\n",
    "print(\"\\nThis exact manifest works on:\")\n",
    "print(\"   - AWS: EKS (Elastic Kubernetes Service)\")\n",
    "print(\"   - Azure: AKS (Azure Kubernetes Service)\")\n",
    "print(\"   - GCP: GKE (Google Kubernetes Engine)\")\n",
    "print(\"   - On-premises: Self-managed Kubernetes\")\n",
    "print(\"\\nDeploy with: kubectl apply -f k8s_ml_deployment.yaml\")\n",
    "print(\"\\nüéØ Kubernetes Benefits for Multi-Cloud:\")\n",
    "print(\"   - Write once, deploy anywhere\")\n",
    "print(\"   - Consistent API across clouds\")\n",
    "print(\"   - Avoid vendor lock-in\")\n",
    "print(\"   - Rich ecosystem (Istio, Prometheus, etc.)\")\n",
    "print(\"   - Easy migration between clouds\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2: Managed Kubernetes Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Managed Kubernetes service comparison\n",
    "k8s_comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Feature': 'Service Name',\n",
    "        'AWS': 'EKS',\n",
    "        'Azure': 'AKS',\n",
    "        'GCP': 'GKE'\n",
    "    },\n",
    "    {\n",
    "        'Feature': 'Control Plane Cost',\n",
    "        'AWS': '$0.10/hour ($73/month)',\n",
    "        'Azure': 'Free',\n",
    "        'GCP': '$0.10/hour ($73/month)'\n",
    "    },\n",
    "    {\n",
    "        'Feature': 'Free Tier',\n",
    "        'AWS': 'None',\n",
    "        'Azure': 'Yes (free control plane)',\n",
    "        'GCP': '$300 credit (90 days)'\n",
    "    },\n",
    "    {\n",
    "        'Feature': 'Auto-scaling',\n",
    "        'AWS': 'Cluster Autoscaler',\n",
    "        'Azure': 'Cluster Autoscaler',\n",
    "        'GCP': 'Node Auto-provisioning'\n",
    "    },\n",
    "    {\n",
    "        'Feature': 'GPU Support',\n",
    "        'AWS': 'Yes',\n",
    "        'Azure': 'Yes',\n",
    "        'GCP': 'Yes'\n",
    "    },\n",
    "    {\n",
    "        'Feature': 'Serverless Pods',\n",
    "        'AWS': 'Fargate',\n",
    "        'Azure': 'Virtual Nodes',\n",
    "        'GCP': 'Autopilot'\n",
    "    },\n",
    "    {\n",
    "        'Feature': 'Integration',\n",
    "        'AWS': 'Deep AWS integration',\n",
    "        'Azure': 'Deep Azure integration',\n",
    "        'GCP': 'Deep GCP integration'\n",
    "    },\n",
    "    {\n",
    "        'Feature': 'Best For',\n",
    "        'AWS': 'AWS-heavy workloads',\n",
    "        'Azure': 'Cost-conscious, Azure users',\n",
    "        'GCP': 'GCP ecosystem, Autopilot'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"Managed Kubernetes Service Comparison\\n\")\n",
    "print(k8s_comparison.to_string(index=False))\n",
    "print(\"\\nüí° Cost Consideration:\")\n",
    "print(\"   - Azure AKS: FREE control plane (best for cost)\")\n",
    "print(\"   - AWS EKS: $73/month per cluster\")\n",
    "print(\"   - GCP GKE: $73/month per cluster (Autopilot mode varies)\")\n",
    "print(\"   - All: Pay for worker nodes (same pricing as VMs)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Terraform for Multi-Cloud Infrastructure\n",
    "\n",
    "Terraform enables Infrastructure as Code (IaC) across multiple cloud providers.\n",
    "\n",
    "### 5.1: Multi-Cloud Terraform Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Terraform configuration for multi-cloud deployment\n",
    "terraform_multicloud = '''\n",
    "# main.tf - Multi-cloud ML infrastructure\n",
    "\n",
    "terraform {\n",
    "  required_version = \">= 1.0\"\n",
    "  \n",
    "  required_providers {\n",
    "    aws = {\n",
    "      source  = \"hashicorp/aws\"\n",
    "      version = \"~> 5.0\"\n",
    "    }\n",
    "    azurerm = {\n",
    "      source  = \"hashicorp/azurerm\"\n",
    "      version = \"~> 3.0\"\n",
    "    }\n",
    "    google = {\n",
    "      source  = \"hashicorp/google\"\n",
    "      version = \"~> 5.0\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Variables for multi-cloud deployment\n",
    "variable \"deploy_to_aws\" {\n",
    "  type    = bool\n",
    "  default = true\n",
    "}\n",
    "\n",
    "variable \"deploy_to_azure\" {\n",
    "  type    = bool\n",
    "  default = true\n",
    "}\n",
    "\n",
    "variable \"deploy_to_gcp\" {\n",
    "  type    = bool\n",
    "  default = false\n",
    "}\n",
    "\n",
    "# AWS Provider\n",
    "provider \"aws\" {\n",
    "  region = \"us-east-1\"\n",
    "}\n",
    "\n",
    "# Azure Provider\n",
    "provider \"azurerm\" {\n",
    "  features {}\n",
    "}\n",
    "\n",
    "# GCP Provider\n",
    "provider \"google\" {\n",
    "  project = \"your-gcp-project\"\n",
    "  region  = \"us-central1\"\n",
    "}\n",
    "\n",
    "# AWS S3 Bucket for ML Data\n",
    "resource \"aws_s3_bucket\" \"ml_data\" {\n",
    "  count  = var.deploy_to_aws ? 1 : 0\n",
    "  bucket = \"ml-data-${random_id.suffix.hex}\"\n",
    "  \n",
    "  tags = {\n",
    "    Environment = \"multi-cloud\"\n",
    "    Purpose     = \"ml-data-storage\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# Azure Storage Account\n",
    "resource \"azurerm_storage_account\" \"ml_data\" {\n",
    "  count                    = var.deploy_to_azure ? 1 : 0\n",
    "  name                     = \"mldata${random_id.suffix.hex}\"\n",
    "  resource_group_name      = azurerm_resource_group.ml_rg[0].name\n",
    "  location                 = azurerm_resource_group.ml_rg[0].location\n",
    "  account_tier             = \"Standard\"\n",
    "  account_replication_type = \"LRS\"\n",
    "  \n",
    "  tags = {\n",
    "    Environment = \"multi-cloud\"\n",
    "    Purpose     = \"ml-data-storage\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# Azure Resource Group\n",
    "resource \"azurerm_resource_group\" \"ml_rg\" {\n",
    "  count    = var.deploy_to_azure ? 1 : 0\n",
    "  name     = \"ml-resources-rg\"\n",
    "  location = \"East US\"\n",
    "}\n",
    "\n",
    "# GCP Storage Bucket\n",
    "resource \"google_storage_bucket\" \"ml_data\" {\n",
    "  count    = var.deploy_to_gcp ? 1 : 0\n",
    "  name     = \"ml-data-${random_id.suffix.hex}\"\n",
    "  location = \"US\"\n",
    "  \n",
    "  labels = {\n",
    "    environment = \"multi-cloud\"\n",
    "    purpose     = \"ml-data-storage\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# Random suffix for unique naming\n",
    "resource \"random_id\" \"suffix\" {\n",
    "  byte_length = 4\n",
    "}\n",
    "\n",
    "# Outputs\n",
    "output \"aws_bucket\" {\n",
    "  value = var.deploy_to_aws ? aws_s3_bucket.ml_data[0].id : \"Not deployed\"\n",
    "}\n",
    "\n",
    "output \"azure_storage\" {\n",
    "  value = var.deploy_to_azure ? azurerm_storage_account.ml_data[0].name : \"Not deployed\"\n",
    "}\n",
    "\n",
    "output \"gcp_bucket\" {\n",
    "  value = var.deploy_to_gcp ? google_storage_bucket.ml_data[0].name : \"Not deployed\"\n",
    "}\n",
    "'''\n",
    "\n",
    "# Save Terraform configuration\n",
    "with open('multi_cloud_terraform.tf', 'w') as f:\n",
    "    f.write(terraform_multicloud)\n",
    "\n",
    "print(\"‚úÖ Multi-cloud Terraform configuration created\")\n",
    "print(\"\\nUsage:\")\n",
    "print(\"  terraform init\")\n",
    "print(\"  terraform plan\")\n",
    "print(\"  terraform apply -var='deploy_to_aws=true' -var='deploy_to_azure=true'\")\n",
    "print(\"\\nüí° Terraform Benefits:\")\n",
    "print(\"   - Single language for all clouds (HCL)\")\n",
    "print(\"   - Version control your infrastructure\")\n",
    "print(\"   - Preview changes before applying\")\n",
    "print(\"   - Easy to switch clouds or go multi-cloud\")\n",
    "print(\"   - Reusable modules across projects\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Data Portability and Vendor Lock-in Mitigation\n",
    "\n",
    "### 6.1: Portable Data Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Portable data format recommendations\n",
    "data_formats = pd.DataFrame([\n",
    "    {\n",
    "        'Data Type': 'Tabular Data',\n",
    "        'Recommended Format': 'Parquet, CSV',\n",
    "        'Avoid': 'Proprietary binary formats',\n",
    "        'Why': 'Open standard, efficient, cloud-agnostic'\n",
    "    },\n",
    "    {\n",
    "        'Data Type': 'Model Artifacts',\n",
    "        'Recommended Format': 'ONNX, SavedModel, pickle',\n",
    "        'Avoid': 'Platform-specific formats',\n",
    "        'Why': 'Framework/platform independent'\n",
    "    },\n",
    "    {\n",
    "        'Data Type': 'Images',\n",
    "        'Recommended Format': 'JPEG, PNG, WebP',\n",
    "        'Avoid': 'Rare proprietary formats',\n",
    "        'Why': 'Universal support'\n",
    "    },\n",
    "    {\n",
    "        'Data Type': 'Text/Documents',\n",
    "        'Recommended Format': 'JSON, XML, TXT',\n",
    "        'Avoid': 'Proprietary document formats',\n",
    "        'Why': 'Human readable, parseable anywhere'\n",
    "    },\n",
    "    {\n",
    "        'Data Type': 'Large Datasets',\n",
    "        'Recommended Format': 'Parquet, ORC, Avro',\n",
    "        'Avoid': 'Non-splittable formats',\n",
    "        'Why': 'Columnar, compressed, distributed processing'\n",
    "    },\n",
    "    {\n",
    "        'Data Type': 'Time Series',\n",
    "        'Recommended Format': 'Parquet with timestamp index',\n",
    "        'Avoid': 'Custom binary formats',\n",
    "        'Why': 'Efficient querying, compression'\n",
    "    },\n",
    "    {\n",
    "        'Data Type': 'Experiment Metadata',\n",
    "        'Recommended Format': 'MLflow format, JSON',\n",
    "        'Avoid': 'Platform-specific tracking',\n",
    "        'Why': 'Portable across clouds'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"Portable Data Format Guidelines\\n\")\n",
    "print(data_formats.to_string(index=False))\n",
    "print(\"\\nüéØ Data Portability Best Practices:\")\n",
    "print(\"   - Use open formats (Parquet > proprietary)\")\n",
    "print(\"   - Avoid cloud-specific APIs in data pipelines\")\n",
    "print(\"   - Abstract storage layer (use fsspec, S3-compatible APIs)\")\n",
    "print(\"   - Document data schemas and versioning\")\n",
    "print(\"   - Test data migration between clouds regularly\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2: Vendor Lock-in Mitigation Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Vendor lock-in mitigation strategies\n",
    "lock_in_mitigation = [\n",
    "    {\n",
    "        'Category': 'Compute',\n",
    "        'Lock-in Risk': 'Platform-specific APIs',\n",
    "        'Mitigation': 'Use Kubernetes, Docker, open frameworks',\n",
    "        'Effort': 'Medium',\n",
    "        'Impact': 'High'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Storage',\n",
    "        'Lock-in Risk': 'Proprietary storage services',\n",
    "        'Mitigation': 'S3-compatible APIs, abstract with libraries',\n",
    "        'Effort': 'Low',\n",
    "        'Impact': 'High'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'ML Platform',\n",
    "        'Lock-in Risk': 'SageMaker/Azure ML specific code',\n",
    "        'Mitigation': 'Use MLflow, Kubeflow, open frameworks',\n",
    "        'Effort': 'High',\n",
    "        'Impact': 'High'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Model Format',\n",
    "        'Lock-in Risk': 'Framework-specific serialization',\n",
    "        'Mitigation': 'Export to ONNX, SavedModel formats',\n",
    "        'Effort': 'Low',\n",
    "        'Impact': 'Medium'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Data Pipeline',\n",
    "        'Lock-in Risk': 'Cloud-specific orchestration',\n",
    "        'Mitigation': 'Use Airflow, Prefect, Dagster',\n",
    "        'Effort': 'Medium',\n",
    "        'Impact': 'High'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Monitoring',\n",
    "        'Lock-in Risk': 'CloudWatch/Azure Monitor only',\n",
    "        'Mitigation': 'Prometheus, Grafana, ELK stack',\n",
    "        'Effort': 'Medium',\n",
    "        'Impact': 'Medium'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Database',\n",
    "        'Lock-in Risk': 'DynamoDB/CosmosDB specific',\n",
    "        'Mitigation': 'PostgreSQL, MongoDB (cloud-agnostic)',\n",
    "        'Effort': 'Low',\n",
    "        'Impact': 'High'\n",
    "    },\n",
    "    {\n",
    "        'Category': 'Infrastructure',\n",
    "        'Lock-in Risk': 'CloudFormation/ARM templates',\n",
    "        'Mitigation': 'Use Terraform, Pulumi',\n",
    "        'Effort': 'Low',\n",
    "        'Impact': 'High'\n",
    "    }\n",
    "]\n",
    "\n",
    "lock_in_df = pd.DataFrame(lock_in_mitigation)\n",
    "\n",
    "print(\"Vendor Lock-in Mitigation Strategies\\n\")\n",
    "print(lock_in_df.to_string(index=False))\n",
    "print(\"\\nüìä Priority Recommendations:\")\n",
    "print(\"   1. High Impact + Low Effort: Storage abstraction, Terraform\")\n",
    "print(\"   2. High Impact + Medium Effort: Kubernetes, Airflow\")\n",
    "print(\"   3. High Impact + High Effort: Open ML platforms (MLflow, Kubeflow)\")\n",
    "print(\"\\nüí° Start Small:\")\n",
    "print(\"   - Begin with storage and infrastructure (Terraform)\")\n",
    "print(\"   - Add container orchestration (Kubernetes)\")\n",
    "print(\"   - Finally migrate to open ML platforms\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned comprehensive multi-cloud ML strategies:\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **When to Go Multi-Cloud**\n",
    "   - Avoid vendor lock-in and negotiate better pricing\n",
    "   - Use best-of-breed services from each provider\n",
    "   - Meet compliance and data residency requirements\n",
    "   - Achieve true disaster recovery\n",
    "   - BUT: Adds complexity and cost\n",
    "\n",
    "2. **Service Equivalency**\n",
    "   - All major clouds offer similar ML services\n",
    "   - APIs differ, but concepts are the same\n",
    "   - Open source alternatives exist for most services\n",
    "   - Kubernetes is the common orchestration layer\n",
    "\n",
    "3. **MLflow for Multi-Cloud**\n",
    "   - Cloud-agnostic experiment tracking\n",
    "   - Unified model registry across platforms\n",
    "   - Train on AWS, deploy on Azure seamlessly\n",
    "   - Open source and extensible\n",
    "\n",
    "4. **ONNX for Model Portability**\n",
    "   - Framework-agnostic model format\n",
    "   - Deploy same model to any platform\n",
    "   - Optimized for inference performance\n",
    "   - Supports edge and mobile deployment\n",
    "\n",
    "5. **Kubernetes Deployment**\n",
    "   - Write once, deploy anywhere\n",
    "   - Consistent API across EKS, AKS, GKE\n",
    "   - Rich ecosystem for ML (KServe, Seldon)\n",
    "   - Azure AKS: Free control plane\n",
    "\n",
    "6. **Terraform for IaC**\n",
    "   - Single language for all clouds (HCL)\n",
    "   - Version control infrastructure\n",
    "   - Easy migration between clouds\n",
    "   - Reusable modules\n",
    "\n",
    "7. **Avoiding Vendor Lock-in**\n",
    "   - Use open formats: Parquet, ONNX, JSON\n",
    "   - Abstract storage with S3-compatible APIs\n",
    "   - Open source tools: MLflow, Airflow, Kubernetes\n",
    "   - Infrastructure as Code: Terraform\n",
    "\n",
    "### Multi-Cloud Decision Matrix:\n",
    "\n",
    "| Scenario | Recommendation | Reason |\n",
    "|----------|----------------|--------|\n",
    "| Startup/Learning | **Single Cloud** | Simplicity, cost, faster iteration |\n",
    "| Enterprise with compliance | **Multi-Cloud** | Data residency, risk mitigation |\n",
    "| High-availability critical | **Multi-Cloud** | True redundancy |\n",
    "| Cost-conscious SMB | **Single Cloud** | Better discounts, lower overhead |\n",
    "| Best-of-breed strategy | **Multi-Cloud** | Use best services from each |\n",
    "\n",
    "### Recommended Multi-Cloud Stack:\n",
    "\n",
    "- **Container Orchestration**: Kubernetes (EKS/AKS/GKE)\n",
    "- **Experiment Tracking**: MLflow\n",
    "- **Model Format**: ONNX (when possible)\n",
    "- **Infrastructure**: Terraform\n",
    "- **Data Format**: Parquet, JSON\n",
    "- **Workflow**: Airflow or Kubeflow Pipelines\n",
    "- **Monitoring**: Prometheus + Grafana\n",
    "- **Storage**: S3-compatible APIs\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **[Module 10: Cloud Storage for ML](10_cloud_storage_for_ml.ipynb)**: Deep dive into cloud storage\n",
    "- **[Module 11: Final Project - Deploy Model on Cloud](11_final_project_deploy_model_on_cloud.ipynb)**: Capstone project\n",
    "- **Practice**: Set up MLflow tracking server\n",
    "- **Explore**: Kubeflow for end-to-end ML on Kubernetes\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)\n",
    "- [ONNX Documentation](https://onnx.ai/)\n",
    "- [Kubernetes ML Operators](https://github.com/kubeflow/kubeflow)\n",
    "- [Terraform Multi-Cloud Examples](https://github.com/hashicorp/terraform-provider-aws)\n",
    "- [KServe (Model Serving on K8s)](https://kserve.github.io/website/)\n",
    "- [Feast (Feature Store)](https://feast.dev/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Service Mapping Analysis ‚≠ê\n",
    "\n",
    "Create a comprehensive service mapping for your specific ML project:\n",
    "\n",
    "1. List all services you need (storage, compute, ML platform, etc.)\n",
    "2. Find equivalents in AWS, Azure, and GCP\n",
    "3. Compare pricing for each option\n",
    "4. Identify open source alternatives\n",
    "5. Recommend optimal provider for each service\n",
    "\n",
    "Present findings in a decision matrix with justification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your code here\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: MLflow Multi-Cloud Experiment ‚≠ê‚≠ê\n",
    "\n",
    "Set up MLflow and log experiments with:\n",
    "\n",
    "1. Train 3 different models (RandomForest, SVM, Logistic Regression)\n",
    "2. Tag each with a different \"cloud\" (simulated AWS, Azure, GCP)\n",
    "3. Log different hyperparameters for each\n",
    "4. Compare results in MLflow UI\n",
    "5. Register the best model to MLflow Model Registry\n",
    "6. Load and deploy the best model\n",
    "\n",
    "**Bonus**: Set up remote MLflow tracking server on a cloud VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your code here\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: ONNX Model Conversion Pipeline ‚≠ê‚≠ê\n",
    "\n",
    "Create a complete model conversion pipeline:\n",
    "\n",
    "1. Train models in multiple frameworks:\n",
    "   - scikit-learn RandomForest\n",
    "   - PyTorch neural network (if installed)\n",
    "   - XGBoost model\n",
    "2. Convert all to ONNX format\n",
    "3. Compare model sizes before and after\n",
    "4. Benchmark inference time: native vs ONNX\n",
    "5. Verify predictions match between formats\n",
    "\n",
    "Document conversion process and performance differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your code here\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Kubernetes ML Deployment Simulation ‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "Design a complete Kubernetes deployment for ML:\n",
    "\n",
    "1. **Create Kubernetes manifests** for:\n",
    "   - Model serving deployment\n",
    "   - Horizontal Pod Autoscaler\n",
    "   - Service (LoadBalancer)\n",
    "   - ConfigMap for configuration\n",
    "   - Secret for API keys\n",
    "\n",
    "2. **Simulate deployment** on different clouds:\n",
    "   - Calculate costs on EKS vs AKS vs GKE\n",
    "   - Compare setup complexity\n",
    "   - List cloud-specific integrations\n",
    "\n",
    "3. **Design migration plan**:\n",
    "   - Steps to move from AWS to Azure\n",
    "   - Potential pitfalls\n",
    "   - Estimated downtime\n",
    "\n",
    "**Bonus**: If you have minikube, deploy locally and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your code here\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Multi-Cloud TCO Analysis ‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "Conduct a Total Cost of Ownership analysis for:\n",
    "\n",
    "**Scenario**: ML application with:\n",
    "- 500GB data storage\n",
    "- 100 hours/month training (GPU)\n",
    "- 10M predictions/month\n",
    "- 3 environments (dev, staging, prod)\n",
    "\n",
    "**Compare**:\n",
    "1. **Single Cloud** (AWS SageMaker)\n",
    "2. **Multi-Cloud** (training on cheapest, inference on Azure)\n",
    "3. **Hybrid** (Kubernetes on any cloud)\n",
    "\n",
    "**Calculate**:\n",
    "- Direct costs (compute, storage, data transfer)\n",
    "- Hidden costs (engineering time, tooling, training)\n",
    "- Total 12-month TCO\n",
    "\n",
    "**Present**:\n",
    "- Cost breakdown charts\n",
    "- Break-even analysis\n",
    "- Risk assessment\n",
    "- Final recommendation\n",
    "\n",
    "**Bonus**: Include vendor lock-in risk quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your code here\n"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
