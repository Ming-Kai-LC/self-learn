{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 01: AWS SageMaker Basics\n",
    "\n",
    "**Difficulty**: â­â­ Intermediate\n",
    "\n",
    "**Estimated Time**: 60 minutes\n",
    "\n",
    "**Prerequisites**: \n",
    "- Module 00: Introduction to Cloud ML Services\n",
    "- AWS account (free tier)\n",
    "- Basic Python and ML knowledge\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Set up AWS credentials and configure the SageMaker SDK\n",
    "2. Understand SageMaker architecture and key components\n",
    "3. Use SageMaker Studio and notebook instances\n",
    "4. Train a simple ML model using SageMaker's built-in algorithms\n",
    "5. Manage training jobs and monitor costs\n",
    "6. Work with S3 for data storage and model artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. AWS SageMaker Overview\n",
    "\n",
    "### What is Amazon SageMaker?\n",
    "\n",
    "Amazon SageMaker is a comprehensive ML platform that covers the entire ML workflow:\n",
    "\n",
    "**Key Components**:\n",
    "1. **SageMaker Studio**: Integrated development environment (IDE) for ML\n",
    "2. **Notebook Instances**: Managed Jupyter notebooks\n",
    "3. **Training**: Distributed training with auto-scaling\n",
    "4. **Deployment**: Hosting for real-time and batch inference\n",
    "5. **Pipelines**: Workflow automation and MLOps\n",
    "6. **Model Registry**: Centralized model catalog\n",
    "\n",
    "### SageMaker Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                  SageMaker Studio/IDE                   â”‚\n",
    "â”‚  (Development Environment - Notebooks, Experiments)     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                          |\n",
    "                          v\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     Amazon S3                           â”‚\n",
    "â”‚  (Data Storage - Training Data, Model Artifacts)        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                          |\n",
    "                          v\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                  Training Jobs                          â”‚\n",
    "â”‚  (Managed Compute - ml.m5.xlarge, ml.p3.2xlarge, etc.)  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                          |\n",
    "                          v\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                  Model Registry                         â”‚\n",
    "â”‚         (Versioned Model Artifacts)                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                          |\n",
    "                          v\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           Endpoints (Real-time Inference)               â”‚\n",
    "â”‚        or Batch Transform (Batch Inference)             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Configuration\n",
    "\n",
    "### 2.1 Install Required Libraries\n",
    "\n",
    "âš ï¸ **Note**: This notebook demonstrates SageMaker usage. Some cells are for reference only and won't execute without valid AWS credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install SageMaker SDK\n",
    "# Uncomment to install (already in requirements.txt)\n",
    "# !pip install sagemaker boto3 --upgrade\n",
    "\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Import required libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Display library versions\n",
    "print(f\"\\nSageMaker SDK version: {sagemaker.__version__}\")\n",
    "print(f\"Boto3 version: {boto3.__version__}\")\n",
    "\n",
    "# Configure plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 AWS Credentials Configuration\n",
    "\n",
    "**Before using SageMaker, you need AWS credentials**:\n",
    "\n",
    "1. **Create AWS Account**: Sign up at [aws.amazon.com](https://aws.amazon.com)\n",
    "2. **Create IAM User**: \n",
    "   - Go to IAM Console\n",
    "   - Create user with programmatic access\n",
    "   - Attach policy: `AmazonSageMakerFullAccess`\n",
    "   - Save Access Key ID and Secret Access Key\n",
    "\n",
    "3. **Configure Credentials** (choose one method):\n",
    "\n",
    "**Method 1: AWS CLI (Recommended)**\n",
    "```bash\n",
    "# Install AWS CLI\n",
    "pip install awscli\n",
    "\n",
    "# Configure credentials\n",
    "aws configure\n",
    "# Enter:\n",
    "#   - AWS Access Key ID\n",
    "#   - AWS Secret Access Key\n",
    "#   - Default region (e.g., ap-southeast-1 for Singapore)\n",
    "#   - Default output format (json)\n",
    "```\n",
    "\n",
    "**Method 2: Environment Variables**\n",
    "```python\n",
    "import os\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'your-access-key-id'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'your-secret-access-key'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'ap-southeast-1'\n",
    "```\n",
    "\n",
    "**Method 3: Credentials File**\n",
    "```bash\n",
    "# Create ~/.aws/credentials file:\n",
    "[default]\n",
    "aws_access_key_id = YOUR_ACCESS_KEY\n",
    "aws_secret_access_key = YOUR_SECRET_KEY\n",
    "region = ap-southeast-1\n",
    "```\n",
    "\n",
    "âš ï¸ **Security Warning**: NEVER commit credentials to Git! Use `.env` files or AWS Secrets Manager for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Simulated SageMaker session setup (for demonstration)\n",
    "# In real usage, this would connect to AWS\n",
    "\n",
    "class MockSageMakerSession:\n",
    "    \"\"\"\n",
    "    Mock SageMaker session for demonstration without AWS credentials.\n",
    "    Replace with real session when you have AWS access.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.region = 'ap-southeast-1'  # Singapore region\n",
    "        self.account_id = '123456789012'  # Mock account ID\n",
    "        \n",
    "    def default_bucket(self):\n",
    "        return f\"sagemaker-{self.region}-{self.account_id}\"\n",
    "    \n",
    "    def get_role(self):\n",
    "        return f\"arn:aws:iam::{self.account_id}:role/SageMakerExecutionRole\"\n",
    "\n",
    "# For demonstration purposes\n",
    "DEMO_MODE = True  # Set to False when using real AWS credentials\n",
    "\n",
    "if DEMO_MODE:\n",
    "    # Mock session for learning\n",
    "    print(\"ğŸ“ Running in DEMO MODE (no AWS credentials required)\")\n",
    "    print(\"   Set DEMO_MODE = False when you have AWS credentials\\n\")\n",
    "    \n",
    "    mock_session = MockSageMakerSession()\n",
    "    region = mock_session.region\n",
    "    bucket = mock_session.default_bucket()\n",
    "    role = mock_session.get_role()\n",
    "else:\n",
    "    # Real SageMaker session\n",
    "    print(\"ğŸ”‘ Connecting to AWS SageMaker...\\n\")\n",
    "    \n",
    "    # Create SageMaker session\n",
    "    sess = sagemaker.Session()\n",
    "    \n",
    "    # Get execution role\n",
    "    # This role allows SageMaker to access other AWS services on your behalf\n",
    "    role = sagemaker.get_execution_role()\n",
    "    \n",
    "    # Get default S3 bucket (created automatically by SageMaker)\n",
    "    bucket = sess.default_bucket()\n",
    "    \n",
    "    # Get region\n",
    "    region = sess.boto_region_name\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"S3 Bucket: {bucket}\")\n",
    "print(f\"Execution Role: {role}\")\n",
    "print(f\"\\nâœ… SageMaker session configured successfully!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Working with S3 for Data Storage\n",
    "\n",
    "### Understanding S3 in SageMaker\n",
    "\n",
    "Amazon S3 (Simple Storage Service) is AWS's object storage service. SageMaker uses S3 for:\n",
    "- **Input Data**: Training and validation datasets\n",
    "- **Output Data**: Model artifacts, predictions\n",
    "- **Model Storage**: Trained model files\n",
    "\n",
    "**S3 URI Format**: `s3://bucket-name/prefix/key`\n",
    "\n",
    "**Free Tier**: \n",
    "- 5 GB of S3 Standard storage\n",
    "- 20,000 GET requests\n",
    "- 2,000 PUT requests\n",
    "- Valid for 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create sample training data\n",
    "# Using Iris dataset for classification example\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from io import StringIO\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "iris_data = pd.DataFrame(\n",
    "    data=np.c_[iris['data'], iris['target']],\n",
    "    columns=iris['feature_names'] + ['target']\n",
    ")\n",
    "\n",
    "print(\"Iris Dataset Sample:\")\n",
    "print(iris_data.head())\n",
    "print(f\"\\nShape: {iris_data.shape}\")\n",
    "print(f\"Classes: {iris.target_names}\")\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = train_test_split(\n",
    "    iris_data, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=iris_data['target']\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {len(train_data)} samples\")\n",
    "print(f\"Test set: {len(test_data)} samples\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare data for SageMaker (CSV format without header, target as first column)\n",
    "# This is the format expected by many SageMaker built-in algorithms\n",
    "\n",
    "def prepare_sagemaker_data(df, target_column='target'):\n",
    "    \"\"\"\n",
    "    Prepare DataFrame for SageMaker format.\n",
    "    \n",
    "    SageMaker expects:\n",
    "    - No header row\n",
    "    - Target variable as first column\n",
    "    - CSV format\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame\n",
    "    target_column : str\n",
    "        Name of target column\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Reformatted DataFrame\n",
    "    \"\"\"\n",
    "    # Move target column to first position\n",
    "    cols = [target_column] + [col for col in df.columns if col != target_column]\n",
    "    return df[cols]\n",
    "\n",
    "# Prepare data\n",
    "train_formatted = prepare_sagemaker_data(train_data)\n",
    "test_formatted = prepare_sagemaker_data(test_data)\n",
    "\n",
    "# Save locally first\n",
    "train_file = 'iris_train.csv'\n",
    "test_file = 'iris_test.csv'\n",
    "\n",
    "train_formatted.to_csv(train_file, index=False, header=False)\n",
    "test_formatted.to_csv(test_file, index=False, header=False)\n",
    "\n",
    "print(f\"âœ… Data saved locally:\")\n",
    "print(f\"   - {train_file}\")\n",
    "print(f\"   - {test_file}\")\n",
    "print(f\"\\nSample of formatted training data (first 3 rows):\")\n",
    "print(train_formatted.head(3).to_string(index=False))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Upload data to S3 (simulated in demo mode)\n",
    "\n",
    "if DEMO_MODE:\n",
    "    # Simulate S3 upload\n",
    "    train_s3_uri = f\"s3://{bucket}/iris/train/iris_train.csv\"\n",
    "    test_s3_uri = f\"s3://{bucket}/iris/test/iris_test.csv\"\n",
    "    \n",
    "    print(\"ğŸ“¦ [SIMULATED] Uploading data to S3...\")\n",
    "    print(f\"   Training data would be at: {train_s3_uri}\")\n",
    "    print(f\"   Test data would be at: {test_s3_uri}\")\n",
    "    print(\"\\nğŸ’¡ In real usage, data is uploaded to S3 for SageMaker access\")\n",
    "else:\n",
    "    # Real S3 upload\n",
    "    prefix = 'iris'\n",
    "    \n",
    "    # Upload training data\n",
    "    train_s3_uri = sess.upload_data(\n",
    "        path=train_file,\n",
    "        bucket=bucket,\n",
    "        key_prefix=f'{prefix}/train'\n",
    "    )\n",
    "    \n",
    "    # Upload test data\n",
    "    test_s3_uri = sess.upload_data(\n",
    "        path=test_file,\n",
    "        bucket=bucket,\n",
    "        key_prefix=f'{prefix}/test'\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Data uploaded to S3:\")\n",
    "    print(f\"   Training: {train_s3_uri}\")\n",
    "    print(f\"   Test: {test_s3_uri}\")\n",
    "\n",
    "# Store URIs for later use\n",
    "data_locations = {\n",
    "    'train': train_s3_uri,\n",
    "    'test': test_s3_uri\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ“ S3 Data Locations saved\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SageMaker Built-in Algorithms\n",
    "\n",
    "### What are Built-in Algorithms?\n",
    "\n",
    "SageMaker provides optimized, pre-built algorithms that you can use without writing training code:\n",
    "\n",
    "**Classification/Regression**:\n",
    "- **XGBoost**: Gradient boosting (most popular)\n",
    "- **Linear Learner**: Linear models with SGD\n",
    "- **K-NN**: K-nearest neighbors\n",
    "\n",
    "**Computer Vision**:\n",
    "- **Image Classification**: CNN-based classification\n",
    "- **Object Detection**: Detect objects in images\n",
    "- **Semantic Segmentation**: Pixel-level classification\n",
    "\n",
    "**NLP**:\n",
    "- **BlazingText**: Text classification and word embeddings\n",
    "- **Seq2Seq**: Sequence-to-sequence (translation, summarization)\n",
    "\n",
    "**Other**:\n",
    "- **Factorization Machines**: Recommendation systems\n",
    "- **K-Means**: Clustering\n",
    "- **PCA**: Dimensionality reduction\n",
    "\n",
    "**Advantages**:\n",
    "- No training code needed\n",
    "- Optimized for distributed training\n",
    "- Automatic hyperparameter tuning available\n",
    "- Well-documented and tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training with SageMaker XGBoost\n",
    "\n",
    "Let's train a model using SageMaker's XGBoost algorithm:\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Container Image**: Pre-built Docker image with algorithm\n",
    "2. **Estimator**: Configuration for training job\n",
    "3. **Training Job**: Managed compute that trains your model\n",
    "4. **Hyperparameters**: Algorithm-specific parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get XGBoost container image URI\n",
    "# SageMaker maintains optimized algorithm containers in ECR\n",
    "\n",
    "if DEMO_MODE:\n",
    "    # Simulated container URI\n",
    "    container = f\"683313688378.dkr.ecr.{region}.amazonaws.com/sagemaker-xgboost:1.7-1\"\n",
    "    print(\"ğŸ“¦ [SIMULATED] XGBoost Container URI:\")\n",
    "    print(f\"   {container}\")\n",
    "else:\n",
    "    # Get real container URI\n",
    "    from sagemaker import image_uris\n",
    "    \n",
    "    container = image_uris.retrieve(\n",
    "        framework='xgboost',\n",
    "        region=region,\n",
    "        version='1.7-1'  # XGBoost version\n",
    "    )\n",
    "    print(f\"âœ… XGBoost Container: {container}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ This container has XGBoost pre-installed and optimized for SageMaker\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configure the XGBoost estimator\n",
    "# This defines how the training job will run\n",
    "\n",
    "if DEMO_MODE:\n",
    "    # Show configuration without creating actual estimator\n",
    "    estimator_config = {\n",
    "        'image_uri': container,\n",
    "        'role': role,\n",
    "        'instance_count': 1,\n",
    "        'instance_type': 'ml.m5.xlarge',  # Free tier eligible\n",
    "        'volume_size': 5,  # GB\n",
    "        'max_run': 3600,  # Max training time in seconds\n",
    "        'output_path': f's3://{bucket}/iris/output',\n",
    "        'sagemaker_session': 'mock_session'\n",
    "    }\n",
    "    \n",
    "    print(\"âš™ï¸  [SIMULATED] XGBoost Estimator Configuration:\")\n",
    "    print(json.dumps(estimator_config, indent=2))\n",
    "    \n",
    "    # Simulated hyperparameters\n",
    "    hyperparameters = {\n",
    "        'objective': 'multi:softmax',  # Multi-class classification\n",
    "        'num_class': 3,  # 3 iris species\n",
    "        'num_round': 100,  # Number of boosting rounds\n",
    "        'max_depth': 5,\n",
    "        'eta': 0.2,  # Learning rate\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8\n",
    "    }\n",
    "    \n",
    "    print(\"\\nğŸ“Š Hyperparameters:\")\n",
    "    print(json.dumps(hyperparameters, indent=2))\n",
    "    \n",
    "else:\n",
    "    # Real estimator creation\n",
    "    from sagemaker.estimator import Estimator\n",
    "    \n",
    "    xgb_estimator = Estimator(\n",
    "        image_uri=container,\n",
    "        role=role,\n",
    "        instance_count=1,\n",
    "        instance_type='ml.m5.xlarge',  # Free tier eligible (first 2 months)\n",
    "        volume_size=5,  # EBS volume size in GB\n",
    "        max_run=3600,  # Maximum training time (1 hour)\n",
    "        output_path=f's3://{bucket}/iris/output',\n",
    "        sagemaker_session=sess\n",
    "    )\n",
    "    \n",
    "    # Set hyperparameters\n",
    "    xgb_estimator.set_hyperparameters(\n",
    "        objective='multi:softmax',\n",
    "        num_class=3,\n",
    "        num_round=100,\n",
    "        max_depth=5,\n",
    "        eta=0.2,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… XGBoost Estimator created and configured\")\n",
    "\n",
    "print(\"\\nğŸ’° COST ESTIMATE:\")\n",
    "print(\"   Instance: ml.m5.xlarge at ~$0.23/hour\")\n",
    "print(\"   Expected training time: <5 minutes\")\n",
    "print(\"   Estimated cost: ~$0.02 per training job\")\n",
    "print(\"\\nâš ï¸  Remember to check current pricing in your region!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Launch training job\n",
    "\n",
    "if DEMO_MODE:\n",
    "    print(\"ğŸ¯ [SIMULATED] Training Job Launch\")\n",
    "    print(\"\\nIn real usage, this would:\")\n",
    "    print(\"  1. Spin up ml.m5.xlarge instance\")\n",
    "    print(\"  2. Download training data from S3\")\n",
    "    print(\"  3. Train XGBoost model\")\n",
    "    print(\"  4. Save model artifacts to S3\")\n",
    "    print(\"  5. Terminate instance\")\n",
    "    print(\"\\nExpected output:\")\n",
    "    print(\"  - Training job name: xgboost-iris-2025-11-19-12-34-56\")\n",
    "    print(\"  - Status: InProgress â†’ Completed\")\n",
    "    print(\"  - Training time: ~3-5 minutes\")\n",
    "    print(\"  - Model location: s3://{bucket}/iris/output/...\")\n",
    "    \n",
    "    # Simulate training metrics\n",
    "    simulated_metrics = pd.DataFrame({\n",
    "        'iteration': range(0, 101, 10),\n",
    "        'train_mlogloss': [1.0986, 0.7234, 0.5123, 0.3891, 0.3012, \n",
    "                           0.2456, 0.2098, 0.1834, 0.1645, 0.1512, 0.1423]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nğŸ“Š Simulated Training Metrics:\")\n",
    "    print(simulated_metrics.to_string(index=False))\n",
    "    \n",
    "else:\n",
    "    # Real training job\n",
    "    print(\"ğŸš€ Launching SageMaker training job...\\n\")\n",
    "    \n",
    "    # Start training\n",
    "    xgb_estimator.fit({\n",
    "        'train': train_s3_uri,\n",
    "        'validation': test_s3_uri\n",
    "    })\n",
    "    \n",
    "    print(\"\\nâœ… Training job completed!\")\n",
    "    print(f\"Model artifacts saved to: {xgb_estimator.model_data}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Training Job Tips:\")\n",
    "print(\"   â€¢ Monitor in SageMaker Console â†’ Training Jobs\")\n",
    "print(\"   â€¢ Check CloudWatch for detailed logs\")\n",
    "print(\"   â€¢ Training job automatically terminates when done\")\n",
    "print(\"   â€¢ Model artifacts are saved to S3 automatically\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cost Management and Monitoring\n",
    "\n",
    "### Understanding SageMaker Costs\n",
    "\n",
    "**Cost Components**:\n",
    "1. **Notebook Instances**: Charged per hour (can be stopped)\n",
    "2. **Training Jobs**: Charged per second (minimum 1 minute)\n",
    "3. **Endpoints**: Charged per hour (24/7 if not deleted)\n",
    "4. **Storage**: S3 charges for data and model storage\n",
    "\n",
    "**Cost Optimization Tips**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cost estimation helper functions\n",
    "\n",
    "def estimate_training_cost(instance_type, training_time_minutes, region='us-east-1'):\n",
    "    \"\"\"\n",
    "    Estimate SageMaker training job cost.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    instance_type : str\n",
    "        EC2 instance type (e.g., 'ml.m5.xlarge')\n",
    "    training_time_minutes : float\n",
    "        Expected training time in minutes\n",
    "    region : str\n",
    "        AWS region\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Cost breakdown\n",
    "    \"\"\"\n",
    "    # Approximate hourly rates (as of 2025, US East)\n",
    "    # Always check current pricing!\n",
    "    hourly_rates = {\n",
    "        'ml.t3.medium': 0.05,   # Free tier eligible\n",
    "        'ml.m5.large': 0.115,\n",
    "        'ml.m5.xlarge': 0.23,\n",
    "        'ml.m5.2xlarge': 0.46,\n",
    "        'ml.p3.2xlarge': 3.825,  # GPU\n",
    "        'ml.p3.8xlarge': 14.688, # 4x GPU\n",
    "    }\n",
    "    \n",
    "    if instance_type not in hourly_rates:\n",
    "        return {'error': f'Unknown instance type: {instance_type}'}\n",
    "    \n",
    "    hourly_rate = hourly_rates[instance_type]\n",
    "    training_hours = training_time_minutes / 60\n",
    "    training_cost = hourly_rate * training_hours\n",
    "    \n",
    "    # Add storage cost (minimal for small jobs)\n",
    "    storage_cost = 0.01  # Approximate\n",
    "    \n",
    "    total_cost = training_cost + storage_cost\n",
    "    \n",
    "    return {\n",
    "        'instance_type': instance_type,\n",
    "        'hourly_rate': hourly_rate,\n",
    "        'training_time_minutes': training_time_minutes,\n",
    "        'training_cost': round(training_cost, 4),\n",
    "        'storage_cost': round(storage_cost, 4),\n",
    "        'total_cost': round(total_cost, 4)\n",
    "    }\n",
    "\n",
    "# Example cost estimates\n",
    "scenarios = [\n",
    "    ('ml.m5.xlarge', 5),    # Small model, quick training\n",
    "    ('ml.m5.xlarge', 60),   # Medium model\n",
    "    ('ml.p3.2xlarge', 30),  # GPU training\n",
    "]\n",
    "\n",
    "print(\"ğŸ’° TRAINING COST ESTIMATES (USD)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "cost_results = []\n",
    "for instance, minutes in scenarios:\n",
    "    cost = estimate_training_cost(instance, minutes)\n",
    "    cost_results.append(cost)\n",
    "    print(f\"\\nScenario: {instance} for {minutes} minutes\")\n",
    "    print(f\"  Hourly Rate: ${cost['hourly_rate']}\")\n",
    "    print(f\"  Training Cost: ${cost['training_cost']}\")\n",
    "    print(f\"  Total Cost: ${cost['total_cost']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nâš ï¸  IMPORTANT COST TIPS:\")\n",
    "print(\"   1. Use Managed Spot Training for 70% cost savings\")\n",
    "print(\"   2. Stop notebook instances when not in use\")\n",
    "print(\"   3. Delete endpoints after testing\")\n",
    "print(\"   4. Use AWS Cost Explorer for tracking\")\n",
    "print(\"   5. Set up billing alerts immediately!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize cost comparison\n",
    "\n",
    "instance_types = ['ml.t3.medium', 'ml.m5.xlarge', 'ml.m5.2xlarge', 'ml.p3.2xlarge']\n",
    "hourly_costs = [0.05, 0.23, 0.46, 3.825]\n",
    "\n",
    "# Calculate costs for 1 hour of training\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Cost comparison\n",
    "colors = ['green', 'blue', 'orange', 'red']\n",
    "bars = ax1.bar(range(len(instance_types)), hourly_costs, color=colors, alpha=0.7)\n",
    "ax1.set_xticks(range(len(instance_types)))\n",
    "ax1.set_xticklabels(instance_types, rotation=45, ha='right')\n",
    "ax1.set_ylabel('Cost per Hour (USD)', fontsize=11)\n",
    "ax1.set_title('SageMaker Training Instance Costs', fontsize=12, fontweight='bold')\n",
    "ax1.set_yscale('log')  # Log scale due to wide range\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add cost labels\n",
    "for i, (bar, cost) in enumerate(zip(bars, hourly_costs)):\n",
    "    ax1.text(i, cost, f'${cost}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Monthly cost if running 24/7 (what NOT to do!)\n",
    "monthly_costs = [cost * 24 * 30 for cost in hourly_costs]\n",
    "bars2 = ax2.bar(range(len(instance_types)), monthly_costs, color=colors, alpha=0.7)\n",
    "ax2.set_xticks(range(len(instance_types)))\n",
    "ax2.set_xticklabels(instance_types, rotation=45, ha='right')\n",
    "ax2.set_ylabel('Monthly Cost if 24/7 (USD)', fontsize=11)\n",
    "ax2.set_title('âš ï¸ Cost if Endpoint Runs 24/7 (DON\\'T DO THIS!)', \n",
    "              fontsize=12, fontweight='bold', color='red')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add cost labels\n",
    "for i, (bar, cost) in enumerate(zip(bars2, monthly_costs)):\n",
    "    ax2.text(i, cost, f'${cost:.0f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ KEY INSIGHT:\")\n",
    "print(\"   A ml.p3.2xlarge endpoint running 24/7 costs $2,754/month!\")\n",
    "print(\"   Always delete endpoints when not in use.\")\n",
    "print(\"   Use on-demand endpoints or batch transform for production.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best Practices for SageMaker\n",
    "\n",
    "### Development Workflow\n",
    "\n",
    "**1. Local Development First**:\n",
    "```python\n",
    "# Develop and test locally\n",
    "# â†’ Use SageMaker local mode for testing\n",
    "# â†’ Move to cloud when ready\n",
    "```\n",
    "\n",
    "**2. Use Managed Spot Training**:\n",
    "- Save up to 70% on training costs\n",
    "- Good for interruptible workloads\n",
    "- Enable with `use_spot_instances=True`\n",
    "\n",
    "**3. Version Everything**:\n",
    "- Track experiments with SageMaker Experiments\n",
    "- Version datasets in S3\n",
    "- Use Model Registry for model versioning\n",
    "\n",
    "**4. Monitor Costs**:\n",
    "- Set up AWS Budgets alerts\n",
    "- Tag all resources\n",
    "- Review Cost Explorer weekly\n",
    "\n",
    "**5. Security**:\n",
    "- Use IAM roles (never hard-code credentials)\n",
    "- Enable encryption for S3 and EBS\n",
    "- Use VPC for network isolation\n",
    "- Enable CloudTrail for auditing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Data Preparation\n",
    "\n",
    "Prepare the California Housing dataset for SageMaker training:\n",
    "1. Load the dataset\n",
    "2. Split into train/test\n",
    "3. Format for SageMaker (target first, no header)\n",
    "4. Save as CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your solution here\n",
    "# Hint: Use sklearn.datasets.fetch_california_housing()\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Cost Calculation\n",
    "\n",
    "You need to train 100 models for hyperparameter tuning. Each training job takes 10 minutes on ml.m5.xlarge.\n",
    "\n",
    "Calculate:\n",
    "1. Total training time\n",
    "2. Cost with regular instances\n",
    "3. Cost with Managed Spot Training (70% discount)\n",
    "4. Total savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your solution here\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Configuration Comparison\n",
    "\n",
    "Compare two training configurations:\n",
    "- **Config A**: ml.m5.2xlarge for 30 minutes\n",
    "- **Config B**: ml.p3.2xlarge for 10 minutes (GPU speeds up training)\n",
    "\n",
    "Which is more cost-effective? What other factors should you consider besides cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your solution here\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: S3 Path Construction\n",
    "\n",
    "Write a function that constructs proper S3 paths for a SageMaker project with the following structure:\n",
    "```\n",
    "s3://my-bucket/\n",
    "  â””â”€â”€ projects/\n",
    "      â””â”€â”€ project-name/\n",
    "          â”œâ”€â”€ data/\n",
    "          â”‚   â”œâ”€â”€ train/\n",
    "          â”‚   â””â”€â”€ test/\n",
    "          â”œâ”€â”€ models/\n",
    "          â””â”€â”€ outputs/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your solution here\n",
    "def create_s3_paths(bucket, project_name):\n",
    "    \"\"\"\n",
    "    Create S3 path structure for a SageMaker project.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    bucket : str\n",
    "        S3 bucket name\n",
    "    project_name : str\n",
    "        Project name\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary of S3 paths\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test your function\n",
    "# paths = create_s3_paths('my-ml-bucket', 'customer-churn')\n",
    "# print(paths)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **SageMaker Architecture**:\n",
    "   - Studio/Notebooks for development\n",
    "   - S3 for data and model storage\n",
    "   - Training jobs on managed compute\n",
    "   - Endpoints for inference\n",
    "\n",
    "2. **Built-in Algorithms**:\n",
    "   - XGBoost, Linear Learner, K-NN for tabular data\n",
    "   - Image Classification, Object Detection for vision\n",
    "   - BlazingText for NLP\n",
    "   - No training code required!\n",
    "\n",
    "3. **Data Management**:\n",
    "   - Use S3 for all data storage\n",
    "   - Format data correctly (target first, no header)\n",
    "   - Organize with clear prefixes\n",
    "\n",
    "4. **Cost Management**:\n",
    "   - Training: Billed per second\n",
    "   - Endpoints: Billed per hour (delete when not needed!)\n",
    "   - Use Managed Spot Training for savings\n",
    "   - Monitor with Cost Explorer\n",
    "\n",
    "5. **Best Practices**:\n",
    "   - Develop locally, train in cloud\n",
    "   - Version everything (data, code, models)\n",
    "   - Set up billing alerts\n",
    "   - Use IAM roles for security\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 02: AWS SageMaker Deployment**, you'll learn:\n",
    "- Deploy models to real-time endpoints\n",
    "- Use Batch Transform for large-scale inference\n",
    "- Implement A/B testing\n",
    "- Monitor production models\n",
    "- Auto-scaling and cost optimization\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [SageMaker Developer Guide](https://docs.aws.amazon.com/sagemaker/)\n",
    "- [SageMaker Examples](https://github.com/aws/amazon-sagemaker-examples)\n",
    "- [AWS Machine Learning Blog](https://aws.amazon.com/blogs/machine-learning/)\n",
    "- [SageMaker Pricing](https://aws.amazon.com/sagemaker/pricing/)\n",
    "- [AWS Free Tier](https://aws.amazon.com/free/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Next Steps**: \n",
    "1. Set up your AWS account if you haven't already\n",
    "2. Configure AWS credentials\n",
    "3. Try running a simple training job\n",
    "4. Proceed to Module 02 for deployment\n",
    "\n",
    "**Remember**: Always check your AWS billing dashboard and set up alerts before running any jobs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
