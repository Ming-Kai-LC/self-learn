{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 03: Azure ML Studio Introduction\n",
    "\n",
    "**Difficulty**: â­â­\n",
    "**Estimated Time**: 55 minutes\n",
    "**Prerequisites**: \n",
    "- [Module 01: AWS SageMaker Basics](01_aws_sagemaker_basics.ipynb)\n",
    "- Basic understanding of machine learning workflows\n",
    "- Familiarity with Python and scikit-learn\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand Azure ML workspace architecture and components\n",
    "2. Configure and manage compute instances and clusters\n",
    "3. Use Azure ML Designer for visual ML pipeline creation\n",
    "4. Train models using Azure ML SDK (v2)\n",
    "5. Manage datasets and datastores effectively\n",
    "6. Apply Azure AutoML for automated model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Introduction\n",
    "\n",
    "### Azure ML Studio Overview\n",
    "\n",
    "Azure ML Studio is Microsoft's cloud platform for the complete ML lifecycle.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           Azure ML Workspace Architecture                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
    "â”‚  â”‚         Azure ML Workspace                      â”‚   â”‚\n",
    "â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚\n",
    "â”‚  â”‚                                                 â”‚   â”‚\n",
    "â”‚  â”‚  Compute Resources    Datastores   Models      â”‚   â”‚\n",
    "â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚\n",
    "â”‚  â”‚  â”‚ Instances    â”‚    â”‚ Blob    â”‚  â”‚Registryâ”‚  â”‚   â”‚\n",
    "â”‚  â”‚  â”‚ Clusters     â”‚    â”‚ ADLS    â”‚  â”‚Versionsâ”‚  â”‚   â”‚\n",
    "â”‚  â”‚  â”‚ Inference    â”‚    â”‚ SQL DB  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚\n",
    "â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚\n",
    "â”‚  â”‚                                                 â”‚   â”‚\n",
    "â”‚  â”‚  Experiments      Pipelines      Endpoints     â”‚   â”‚\n",
    "â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚\n",
    "â”‚  â”‚  â”‚ Runs     â”‚    â”‚ Designer â”‚   â”‚ Online  â”‚  â”‚   â”‚\n",
    "â”‚  â”‚  â”‚ Metrics  â”‚    â”‚ SDK      â”‚   â”‚ Batch   â”‚  â”‚   â”‚\n",
    "â”‚  â”‚  â”‚ Logs     â”‚    â”‚ AutoML   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚\n",
    "â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚   â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Integrated with:                                       â”‚\n",
    "â”‚  - Azure DevOps (CI/CD)                                 â”‚\n",
    "â”‚  - GitHub Actions                                       â”‚\n",
    "â”‚  - MLflow                                               â”‚\n",
    "â”‚  - Power BI                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Cost Note**: Azure offers a free tier with limited compute hours. Always stop compute instances when not in use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock Azure ML SDK for demonstration\n",
    "# In production, use: from azure.ai.ml import MLClient\n",
    "\n",
    "class MockAzureMLWorkspace:\n",
    "    \"\"\"Simulates Azure ML Workspace for educational purposes\"\"\"\n",
    "    \n",
    "    def __init__(self, name, subscription_id, resource_group):\n",
    "        self.name = name\n",
    "        self.subscription_id = subscription_id\n",
    "        self.resource_group = resource_group\n",
    "        self.compute_targets = {}\n",
    "        self.datastores = {}\n",
    "        self.experiments = {}\n",
    "    \n",
    "    def get_details(self):\n",
    "        \"\"\"Get workspace configuration details\"\"\"\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'subscription_id': self.subscription_id,\n",
    "            'resource_group': self.resource_group,\n",
    "            'location': 'eastus',\n",
    "            'workspace_id': f'ws-{np.random.randint(1000, 9999)}'\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Azure ML Workspace Setup\n",
    "\n",
    "The workspace is the top-level resource for Azure ML. It contains all your ML assets.\n",
    "\n",
    "### Workspace Components\n",
    "\n",
    "```\n",
    "Workspace\n",
    "â”œâ”€â”€ Compute\n",
    "â”‚   â”œâ”€â”€ Compute Instances (development)\n",
    "â”‚   â”œâ”€â”€ Compute Clusters (training)\n",
    "â”‚   â”œâ”€â”€ Inference Clusters (deployment)\n",
    "â”‚   â””â”€â”€ Attached Compute (external)\n",
    "â”œâ”€â”€ Data\n",
    "â”‚   â”œâ”€â”€ Datastores (connections)\n",
    "â”‚   â””â”€â”€ Datasets (versioned data)\n",
    "â”œâ”€â”€ Assets\n",
    "â”‚   â”œâ”€â”€ Models (registered models)\n",
    "â”‚   â”œâ”€â”€ Environments (dependencies)\n",
    "â”‚   â””â”€â”€ Components (reusable code)\n",
    "â””â”€â”€ Jobs\n",
    "    â”œâ”€â”€ Experiments (training runs)\n",
    "    â”œâ”€â”€ Pipelines (workflows)\n",
    "    â””â”€â”€ Endpoints (deployments)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate workspace creation\n",
    "\n",
    "def create_workspace_config():\n",
    "    \"\"\"Define Azure ML workspace configuration\"\"\"\n",
    "    config = {\n",
    "        'workspace_name': 'my-ml-workspace',\n",
    "        'subscription_id': 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx',\n",
    "        'resource_group': 'ml-resources',\n",
    "        'location': 'eastus',\n",
    "        'storage_account': 'mlstorageaccount',\n",
    "        'key_vault': 'mlkeyvault',\n",
    "        'app_insights': 'mlappinsights',\n",
    "        'container_registry': 'mlcontainerregistry'\n",
    "    }\n",
    "    return config\n",
    "\n",
    "ws_config = create_workspace_config()\n",
    "print(\"Azure ML Workspace Configuration:\")\n",
    "print(json.dumps(ws_config, indent=2))\n",
    "\n",
    "# Create mock workspace\n",
    "workspace = MockAzureMLWorkspace(\n",
    "    name=ws_config['workspace_name'],\n",
    "    subscription_id=ws_config['subscription_id'],\n",
    "    resource_group=ws_config['resource_group']\n",
    ")\n",
    "\n",
    "print(\"\\nWorkspace created successfully!\")\n",
    "print(f\"Workspace ID: {workspace.get_details()['workspace_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection string for workspace\n",
    "\n",
    "def generate_workspace_config_json(workspace_details):\n",
    "    \"\"\"\n",
    "    Generate config.json for workspace connection\n",
    "    This file allows SDK to connect to your workspace\n",
    "    \"\"\"\n",
    "    config_json = {\n",
    "        \"subscription_id\": workspace_details['subscription_id'],\n",
    "        \"resource_group\": workspace_details['resource_group'],\n",
    "        \"workspace_name\": workspace_details['name']\n",
    "    }\n",
    "    \n",
    "    print(\"Save this as config.json in your project directory:\")\n",
    "    print(json.dumps(config_json, indent=2))\n",
    "    print(\"\\nThen connect with: MLClient.from_config()\")\n",
    "    return config_json\n",
    "\n",
    "config_json = generate_workspace_config_json(workspace.get_details())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute Resources\n",
    "\n",
    "Azure ML provides several compute options for different scenarios.\n",
    "\n",
    "### Compute Types Comparison\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚              Azure ML Compute Types                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  1. Compute Instance                                    â”‚\n",
    "â”‚     Use: Development, notebooks, debugging              â”‚\n",
    "â”‚     Features: Jupyter, VS Code, RStudio                 â”‚\n",
    "â”‚     Scaling: Single VM, can stop/start                  â”‚\n",
    "â”‚     Cost: ~$0.15-$5/hour (varies by size)               â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  2. Compute Cluster                                     â”‚\n",
    "â”‚     Use: Training jobs, batch inference                 â”‚\n",
    "â”‚     Features: Auto-scaling (0 to N nodes)               â”‚\n",
    "â”‚     Scaling: Multi-node, scales to zero                 â”‚\n",
    "â”‚     Cost: Pay only when running jobs                    â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  3. Inference Cluster (AKS)                             â”‚\n",
    "â”‚     Use: Production deployments                         â”‚\n",
    "â”‚     Features: High availability, auto-scaling           â”‚\n",
    "â”‚     Scaling: Kubernetes-based                           â”‚\n",
    "â”‚     Cost: ~$0.10/hour + node costs                      â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  4. Attached Compute                                    â”‚\n",
    "â”‚     Use: Existing VMs, Databricks, Synapse              â”‚\n",
    "â”‚     Features: Use external compute                      â”‚\n",
    "â”‚     Scaling: Managed externally                         â”‚\n",
    "â”‚     Cost: Based on attached resource                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute instance configuration\n",
    "\n",
    "def create_compute_instance_config():\n",
    "    \"\"\"Configure compute instance for development\"\"\"\n",
    "    config = {\n",
    "        'name': 'dev-instance-01',\n",
    "        'vm_size': 'STANDARD_DS3_V2',  # 4 cores, 14GB RAM\n",
    "        'ssh_public_access_enabled': False,\n",
    "        'idle_time_before_shutdown_minutes': 30,  # Auto-shutdown\n",
    "        'applications': [\n",
    "            'jupyter',\n",
    "            'jupyterlab',\n",
    "            'rstudio',\n",
    "            'vscode'\n",
    "        ]\n",
    "    }\n",
    "    return config\n",
    "\n",
    "instance_config = create_compute_instance_config()\n",
    "print(\"Compute Instance Configuration:\")\n",
    "print(json.dumps(instance_config, indent=2))\n",
    "print(\"\\nğŸ’¡ Tip: Set idle shutdown to save costs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cluster configuration\n",
    "\n",
    "def create_compute_cluster_config():\n",
    "    \"\"\"Configure auto-scaling compute cluster for training\"\"\"\n",
    "    config = {\n",
    "        'name': 'training-cluster',\n",
    "        'vm_size': 'STANDARD_DS3_V2',\n",
    "        'min_instances': 0,  # Scales to zero when idle\n",
    "        'max_instances': 4,  # Maximum concurrent nodes\n",
    "        'idle_seconds_before_scaledown': 300,  # 5 minutes\n",
    "        'tier': 'dedicated',  # or 'low_priority' for cost savings\n",
    "        'location': 'eastus'\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸ’° Cost Optimization:\")\n",
    "    print(\"- Min instances = 0: No cost when idle\")\n",
    "    print(\"- Low priority VMs: Up to 80% cost savings\")\n",
    "    print(\"- Auto-scaledown: Minimizes billable hours\\n\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "cluster_config = create_compute_cluster_config()\n",
    "print(\"Compute Cluster Configuration:\")\n",
    "print(json.dumps(cluster_config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate compute cluster scaling\n",
    "\n",
    "class ComputeClusterSimulator:\n",
    "    \"\"\"Simulates Azure ML compute cluster auto-scaling\"\"\"\n",
    "    \n",
    "    def __init__(self, min_nodes=0, max_nodes=4):\n",
    "        self.min_nodes = min_nodes\n",
    "        self.max_nodes = max_nodes\n",
    "        self.current_nodes = min_nodes\n",
    "        self.jobs_queue = []\n",
    "    \n",
    "    def submit_job(self, job_name):\n",
    "        \"\"\"Submit training job to cluster\"\"\"\n",
    "        self.jobs_queue.append(job_name)\n",
    "        self._scale_up()\n",
    "        print(f\"Job '{job_name}' submitted. Nodes: {self.current_nodes}\")\n",
    "    \n",
    "    def _scale_up(self):\n",
    "        \"\"\"Scale up cluster based on queue length\"\"\"\n",
    "        needed_nodes = min(len(self.jobs_queue), self.max_nodes)\n",
    "        if needed_nodes > self.current_nodes:\n",
    "            self.current_nodes = needed_nodes\n",
    "            print(f\"â¬†ï¸  Scaling up to {self.current_nodes} nodes\")\n",
    "    \n",
    "    def complete_job(self):\n",
    "        \"\"\"Complete a job and potentially scale down\"\"\"\n",
    "        if self.jobs_queue:\n",
    "            completed = self.jobs_queue.pop(0)\n",
    "            print(f\"âœ“ Job '{completed}' completed\")\n",
    "            if not self.jobs_queue:\n",
    "                self._scale_down()\n",
    "    \n",
    "    def _scale_down(self):\n",
    "        \"\"\"Scale down to minimum when idle\"\"\"\n",
    "        self.current_nodes = self.min_nodes\n",
    "        print(f\"â¬‡ï¸  Scaling down to {self.current_nodes} nodes (idle)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cluster scaling\n",
    "cluster = ComputeClusterSimulator(min_nodes=0, max_nodes=4)\n",
    "\n",
    "# Submit multiple jobs\n",
    "print(\"Submitting jobs:\\n\")\n",
    "cluster.submit_job('train-model-v1')\n",
    "cluster.submit_job('train-model-v2')\n",
    "cluster.submit_job('hyperparameter-tuning')\n",
    "\n",
    "print(\"\\nCompleting jobs:\\n\")\n",
    "cluster.complete_job()\n",
    "cluster.complete_job()\n",
    "cluster.complete_job()\n",
    "\n",
    "print(f\"\\nFinal state: {cluster.current_nodes} nodes (saves cost when at 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Azure ML Designer (Visual ML)\n",
    "\n",
    "Designer provides a drag-and-drop interface for building ML pipelines without code.\n",
    "\n",
    "### Designer Pipeline Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚         Azure ML Designer Pipeline                       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚\n",
    "â”‚  â”‚  Data    â”‚                                           â”‚\n",
    "â”‚  â”‚  Import  â”‚                                           â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                           â”‚\n",
    "â”‚       â”‚                                                 â”‚\n",
    "â”‚       â–¼                                                 â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚\n",
    "â”‚  â”‚ Clean        â”‚â”€â”€â”€â”€â–¶â”‚ Normalize    â”‚                 â”‚\n",
    "â”‚  â”‚ Missing Data â”‚     â”‚ Data         â”‚                 â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚\n",
    "â”‚                              â”‚                          â”‚\n",
    "â”‚                              â–¼                          â”‚\n",
    "â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚\n",
    "â”‚                       â”‚ Split Data   â”‚                 â”‚\n",
    "â”‚                       â”‚ (70/30)      â”‚                 â”‚\n",
    "â”‚                       â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â”‚\n",
    "â”‚                          â”‚      â”‚                      â”‚\n",
    "â”‚                  Train   â”‚      â”‚   Test               â”‚\n",
    "â”‚                          â–¼      â–¼                      â”‚\n",
    "â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                      â”‚\n",
    "â”‚                    â”‚ Train   â”‚  â”‚                      â”‚\n",
    "â”‚                    â”‚ Model   â”‚  â”‚                      â”‚\n",
    "â”‚                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚                      â”‚\n",
    "â”‚                         â”‚       â”‚                      â”‚\n",
    "â”‚                         â–¼       â–¼                      â”‚\n",
    "â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚\n",
    "â”‚                       â”‚ Score     â”‚                    â”‚\n",
    "â”‚                       â”‚ Model     â”‚                    â”‚\n",
    "â”‚                       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                    â”‚\n",
    "â”‚                             â”‚                          â”‚\n",
    "â”‚                             â–¼                          â”‚\n",
    "â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚\n",
    "â”‚                       â”‚ Evaluate  â”‚                    â”‚\n",
    "â”‚                       â”‚ Model     â”‚                    â”‚\n",
    "â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Designer Benefits**:\n",
    "- No code required\n",
    "- Visual pipeline creation\n",
    "- Reusable components\n",
    "- Built-in algorithms\n",
    "- Easy experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Designer pipeline components\n",
    "\n",
    "class DesignerPipeline:\n",
    "    \"\"\"Simulates Azure ML Designer pipeline execution\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.components = []\n",
    "        self.data = None\n",
    "    \n",
    "    def add_component(self, component_type, params):\n",
    "        \"\"\"Add component to pipeline\"\"\"\n",
    "        component = {\n",
    "            'type': component_type,\n",
    "            'params': params,\n",
    "            'order': len(self.components)\n",
    "        }\n",
    "        self.components.append(component)\n",
    "        print(f\"Added: {component_type}\")\n",
    "    \n",
    "    def run_pipeline(self, input_data):\n",
    "        \"\"\"Execute pipeline on data\"\"\"\n",
    "        print(f\"\\nRunning pipeline: {self.name}\")\n",
    "        print(f\"Components: {len(self.components)}\\n\")\n",
    "        \n",
    "        self.data = input_data\n",
    "        for comp in self.components:\n",
    "            print(f\"Executing: {comp['type']}...\")\n",
    "        \n",
    "        print(\"\\nâœ“ Pipeline completed successfully!\")\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Designer pipeline\n",
    "pipeline = DesignerPipeline('credit-risk-model')\n",
    "\n",
    "# Add components in order\n",
    "pipeline.add_component('Import Data', {'source': 'Azure Blob Storage'})\n",
    "pipeline.add_component('Clean Missing Data', {'method': 'mean'})\n",
    "pipeline.add_component('Normalize Data', {'method': 'MinMax'})\n",
    "pipeline.add_component('Split Data', {'ratio': 0.7})\n",
    "pipeline.add_component('Train Model', {'algorithm': 'Logistic Regression'})\n",
    "pipeline.add_component('Score Model', {})\n",
    "pipeline.add_component('Evaluate Model', {'metrics': ['AUC', 'Accuracy']})\n",
    "\n",
    "# Run pipeline\n",
    "sample_data = pd.DataFrame(np.random.randn(100, 5))\n",
    "result = pipeline.run_pipeline(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training with Azure ML SDK (v2)\n",
    "\n",
    "The Azure ML SDK provides programmatic access to all workspace features.\n",
    "\n",
    "### SDK Training Workflow\n",
    "\n",
    "```\n",
    "1. Define Environment (dependencies)\n",
    "2. Create Training Script\n",
    "3. Configure Compute Target\n",
    "4. Submit Training Job\n",
    "5. Monitor Progress\n",
    "6. Register Model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training environment\n",
    "\n",
    "def create_training_environment():\n",
    "    \"\"\"Define conda environment for training job\"\"\"\n",
    "    env_config = {\n",
    "        'name': 'sklearn-env',\n",
    "        'version': '1',\n",
    "        'conda_specification': {\n",
    "            'name': 'sklearn-env',\n",
    "            'channels': ['conda-forge'],\n",
    "            'dependencies': [\n",
    "                'python=3.9',\n",
    "                'pip',\n",
    "                {\n",
    "                    'pip': [\n",
    "                        'scikit-learn==1.3.0',\n",
    "                        'pandas==2.0.0',\n",
    "                        'azureml-mlflow',\n",
    "                        'numpy'\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        'docker_image': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04'\n",
    "    }\n",
    "    return env_config\n",
    "\n",
    "env = create_training_environment()\n",
    "print(\"Training Environment:\")\n",
    "print(json.dumps(env, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training job configuration\n",
    "\n",
    "def create_training_job_config():\n",
    "    \"\"\"Configure training job with compute and parameters\"\"\"\n",
    "    job_config = {\n",
    "        'code': './src',  # Training script directory\n",
    "        'command': 'python train.py --epochs 10 --lr 0.001',\n",
    "        'environment': 'sklearn-env:1',\n",
    "        'compute': 'training-cluster',\n",
    "        'experiment_name': 'classification-experiment',\n",
    "        'display_name': 'sklearn-training-run-001',\n",
    "        'inputs': {\n",
    "            'training_data': {\n",
    "                'type': 'uri_folder',\n",
    "                'path': 'azureml://datastores/workspaceblobstore/paths/data/'\n",
    "            }\n",
    "        },\n",
    "        'outputs': {\n",
    "            'model_output': {\n",
    "                'type': 'uri_folder',\n",
    "                'path': 'azureml://datastores/workspaceblobstore/paths/models/'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return job_config\n",
    "\n",
    "job_config = create_training_job_config()\n",
    "print(\"Training Job Configuration:\")\n",
    "print(json.dumps(job_config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate training job execution\n",
    "\n",
    "class TrainingJobSimulator:\n",
    "    \"\"\"Simulates Azure ML training job execution\"\"\"\n",
    "    \n",
    "    def __init__(self, job_name):\n",
    "        self.job_name = job_name\n",
    "        self.status = 'NotStarted'\n",
    "        self.metrics = {}\n",
    "    \n",
    "    def submit(self):\n",
    "        \"\"\"Submit training job to compute cluster\"\"\"\n",
    "        self.status = 'Running'\n",
    "        print(f\"Job '{self.job_name}' submitted\")\n",
    "        print(f\"Status: {self.status}\")\n",
    "        print(\"Monitor at: https://ml.azure.com/runs/{job_id}\\n\")\n",
    "    \n",
    "    def log_metrics(self, epoch, metrics):\n",
    "        \"\"\"Log training metrics (simulated)\"\"\"\n",
    "        self.metrics[epoch] = metrics\n",
    "        print(f\"Epoch {epoch}: {metrics}\")\n",
    "    \n",
    "    def complete(self):\n",
    "        \"\"\"Mark job as completed\"\"\"\n",
    "        self.status = 'Completed'\n",
    "        print(f\"\\nJob '{self.job_name}' completed successfully!\")\n",
    "        print(f\"Final metrics: {self.metrics[max(self.metrics.keys())]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulated training job\n",
    "job = TrainingJobSimulator('sklearn-classification-001')\n",
    "job.submit()\n",
    "\n",
    "# Simulate training epochs\n",
    "for epoch in range(1, 6):\n",
    "    metrics = {\n",
    "        'loss': 1.0 / (epoch + 1) + np.random.rand() * 0.1,\n",
    "        'accuracy': 0.6 + (epoch * 0.05) + np.random.rand() * 0.02\n",
    "    }\n",
    "    job.log_metrics(epoch, metrics)\n",
    "\n",
    "job.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dataset and Datastore Management\n",
    "\n",
    "Datastores connect to storage services, while Datasets provide versioned data abstractions.\n",
    "\n",
    "### Data Management Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚         Azure ML Data Management                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Datastores (Connections)                               â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚\n",
    "â”‚  â”‚ Azure Blob Storage                      â”‚           â”‚\n",
    "â”‚  â”‚ Azure Data Lake Storage Gen2            â”‚           â”‚\n",
    "â”‚  â”‚ Azure SQL Database                      â”‚           â”‚\n",
    "â”‚  â”‚ Azure PostgreSQL                        â”‚           â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚\n",
    "â”‚                     â”‚                                   â”‚\n",
    "â”‚                     â–¼                                   â”‚\n",
    "â”‚  Datasets (Versioned Data)                              â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚\n",
    "â”‚  â”‚ FileDataset (files/folders)             â”‚           â”‚\n",
    "â”‚  â”‚ - Images, text, any file format         â”‚           â”‚\n",
    "â”‚  â”‚                                         â”‚           â”‚\n",
    "â”‚  â”‚ TabularDataset (structured)             â”‚           â”‚\n",
    "â”‚  â”‚ - CSV, Parquet, JSON                    â”‚           â”‚\n",
    "â”‚  â”‚ - SQL query results                     â”‚           â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚\n",
    "â”‚                     â”‚                                   â”‚\n",
    "â”‚                     â–¼                                   â”‚\n",
    "â”‚  Data Versioning & Lineage                              â”‚\n",
    "â”‚  - Track data changes                                   â”‚\n",
    "â”‚  - Reproduce experiments                                â”‚\n",
    "â”‚  - Monitor data drift                                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datastore configuration\n",
    "\n",
    "def create_datastore_config():\n",
    "    \"\"\"Configure connection to Azure Blob Storage\"\"\"\n",
    "    datastore_config = {\n",
    "        'name': 'ml_datastore',\n",
    "        'type': 'AzureBlobStorage',\n",
    "        'account_name': 'mlstorageaccount',\n",
    "        'container_name': 'mldata',\n",
    "        'credentials': {\n",
    "            'type': 'account_key',  # or SAS token, service principal\n",
    "            'account_key': '[STORED_IN_KEY_VAULT]'\n",
    "        },\n",
    "        'protocol': 'https'\n",
    "    }\n",
    "    \n",
    "    print(\"Security Best Practice:\")\n",
    "    print(\"- Store credentials in Azure Key Vault\")\n",
    "    print(\"- Use managed identity when possible\")\n",
    "    print(\"- Rotate keys regularly\\n\")\n",
    "    \n",
    "    return datastore_config\n",
    "\n",
    "datastore = create_datastore_config()\n",
    "print(\"Datastore Configuration:\")\n",
    "print(json.dumps(datastore, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from datastore\n",
    "\n",
    "def create_tabular_dataset():\n",
    "    \"\"\"Create versioned tabular dataset from CSV files\"\"\"\n",
    "    dataset_config = {\n",
    "        'name': 'customer_churn_data',\n",
    "        'version': 1,\n",
    "        'description': 'Customer churn prediction dataset',\n",
    "        'type': 'TabularDataset',\n",
    "        'path': [\n",
    "            'azureml://datastores/ml_datastore/paths/data/churn/*.csv'\n",
    "        ],\n",
    "        'tags': {\n",
    "            'department': 'marketing',\n",
    "            'project': 'churn-prediction',\n",
    "            'data_quality': 'validated'\n",
    "        },\n",
    "        'schema': {\n",
    "            'customer_id': 'string',\n",
    "            'age': 'integer',\n",
    "            'tenure': 'integer',\n",
    "            'monthly_charges': 'float',\n",
    "            'churn': 'boolean'\n",
    "        }\n",
    "    }\n",
    "    return dataset_config\n",
    "\n",
    "dataset = create_tabular_dataset()\n",
    "print(\"Dataset Configuration:\")\n",
    "print(json.dumps(dataset, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Azure AutoML\n",
    "\n",
    "AutoML automatically tries multiple algorithms and hyperparameters to find the best model.\n",
    "\n",
    "### AutoML Process\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚            Azure AutoML Workflow                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Input: Dataset + Task Type + Constraints               â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚\n",
    "â”‚  â”‚ Task: Classification/Regression/...     â”‚           â”‚\n",
    "â”‚  â”‚ Time limit: 1 hour                      â”‚           â”‚\n",
    "â”‚  â”‚ Metric: AUC / RMSE / ...                â”‚           â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚\n",
    "â”‚                     â”‚                                   â”‚\n",
    "â”‚                     â–¼                                   â”‚\n",
    "â”‚  AutoML Engine                                          â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚\n",
    "â”‚  â”‚ 1. Data Preprocessing                   â”‚           â”‚\n",
    "â”‚  â”‚    - Feature engineering                â”‚           â”‚\n",
    "â”‚  â”‚    - Scaling, encoding                  â”‚           â”‚\n",
    "â”‚  â”‚                                         â”‚           â”‚\n",
    "â”‚  â”‚ 2. Algorithm Selection                  â”‚           â”‚\n",
    "â”‚  â”‚    - Try multiple algorithms            â”‚           â”‚\n",
    "â”‚  â”‚    - Ensemble methods                   â”‚           â”‚\n",
    "â”‚  â”‚                                         â”‚           â”‚\n",
    "â”‚  â”‚ 3. Hyperparameter Tuning                â”‚           â”‚\n",
    "â”‚  â”‚    - Bayesian optimization              â”‚           â”‚\n",
    "â”‚  â”‚    - Random search                      â”‚           â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚\n",
    "â”‚                     â”‚                                   â”‚\n",
    "â”‚                     â–¼                                   â”‚\n",
    "â”‚  Output: Best Model + Explanation                       â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚\n",
    "â”‚  â”‚ - Model artifacts                       â”‚           â”‚\n",
    "â”‚  â”‚ - Feature importance                    â”‚           â”‚\n",
    "â”‚  â”‚ - Performance metrics                   â”‚           â”‚\n",
    "â”‚  â”‚ - Deployment-ready                      â”‚           â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML configuration\n",
    "\n",
    "def create_automl_config():\n",
    "    \"\"\"Configure AutoML experiment for classification\"\"\"\n",
    "    automl_config = {\n",
    "        'task': 'classification',\n",
    "        'primary_metric': 'AUC_weighted',\n",
    "        'training_data': 'customer_churn_data:1',\n",
    "        'target_column_name': 'churn',\n",
    "        'compute_target': 'training-cluster',\n",
    "        'limits': {\n",
    "            'timeout_minutes': 60,\n",
    "            'trial_timeout_minutes': 10,\n",
    "            'max_trials': 20,\n",
    "            'max_concurrent_trials': 4,\n",
    "            'enable_early_termination': True\n",
    "        },\n",
    "        'featurization': {\n",
    "            'mode': 'auto',  # Automatic feature engineering\n",
    "            'blocked_transformers': [],  # Optionally block transformers\n",
    "        },\n",
    "        'validation': {\n",
    "            'n_cross_validations': 5\n",
    "        },\n",
    "        'training': {\n",
    "            'enable_onnx_compatible_models': True,  # For deployment\n",
    "            'enable_voting_ensemble': True,\n",
    "            'enable_stack_ensemble': True\n",
    "        }\n",
    "    }\n",
    "    return automl_config\n",
    "\n",
    "automl = create_automl_config()\n",
    "print(\"AutoML Configuration:\")\n",
    "print(json.dumps(automl, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate AutoML experiment\n",
    "\n",
    "class AutoMLSimulator:\n",
    "    \"\"\"Simulates Azure AutoML experiment execution\"\"\"\n",
    "    \n",
    "    def __init__(self, max_trials=10):\n",
    "        self.max_trials = max_trials\n",
    "        self.trials = []\n",
    "        self.algorithms = [\n",
    "            'LogisticRegression',\n",
    "            'RandomForest',\n",
    "            'XGBoost',\n",
    "            'LightGBM',\n",
    "            'VotingEnsemble'\n",
    "        ]\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Run AutoML experiment with multiple trials\"\"\"\n",
    "        print(\"Starting AutoML experiment...\\n\")\n",
    "        \n",
    "        for i in range(self.max_trials):\n",
    "            algorithm = np.random.choice(self.algorithms)\n",
    "            auc = 0.65 + np.random.rand() * 0.3  # Simulated AUC\n",
    "            \n",
    "            trial = {\n",
    "                'trial': i + 1,\n",
    "                'algorithm': algorithm,\n",
    "                'auc': auc,\n",
    "                'duration': np.random.randint(30, 300)  # seconds\n",
    "            }\n",
    "            self.trials.append(trial)\n",
    "            \n",
    "            print(f\"Trial {i+1}/{self.max_trials}: {algorithm} - AUC: {auc:.4f}\")\n",
    "        \n",
    "        # Find best model\n",
    "        best_trial = max(self.trials, key=lambda x: x['auc'])\n",
    "        print(f\"\\nâœ“ Best model: {best_trial['algorithm']}\")\n",
    "        print(f\"  AUC: {best_trial['auc']:.4f}\")\n",
    "        \n",
    "        return best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run AutoML simulation\n",
    "automl_experiment = AutoMLSimulator(max_trials=10)\n",
    "best_model = automl_experiment.run()\n",
    "\n",
    "print(\"\\nAutoML Benefits:\")\n",
    "print(\"- Tries multiple algorithms automatically\")\n",
    "print(\"- Handles feature engineering\")\n",
    "print(\"- Provides model explanations\")\n",
    "print(\"- Faster than manual tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Compute Cost Optimization\n",
    "\n",
    "You have three training workloads:\n",
    "1. Daily model retraining (30 min/day)\n",
    "2. Hyperparameter tuning (4 hours/week)\n",
    "3. Ad-hoc experiments (variable)\n",
    "\n",
    "Design a compute strategy using instances and clusters. Calculate monthly costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "def design_compute_strategy():\n",
    "    \"\"\"\n",
    "    Design optimal compute strategy for different workloads\n",
    "    \n",
    "    Consider:\n",
    "    - Compute instance vs cluster\n",
    "    - VM sizes\n",
    "    - Auto-shutdown/scale-down\n",
    "    - Low-priority VMs\n",
    "    \n",
    "    Returns:\n",
    "        dict with strategy and cost estimate\n",
    "    \"\"\"\n",
    "    # TODO: Implement strategy\n",
    "    pass\n",
    "\n",
    "# Test your strategy\n",
    "# strategy = design_compute_strategy()\n",
    "# print(json.dumps(strategy, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Pipeline Design\n",
    "\n",
    "Design a Designer pipeline for a regression task:\n",
    "- Input: House prices CSV\n",
    "- Steps: Clean data, engineer features, train model, evaluate\n",
    "- Output: Trained model and metrics\n",
    "\n",
    "List all components in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "def design_regression_pipeline():\n",
    "    \"\"\"\n",
    "    Design complete Designer pipeline for house price prediction\n",
    "    \n",
    "    Include:\n",
    "    - Data import and cleaning\n",
    "    - Feature engineering\n",
    "    - Model training\n",
    "    - Evaluation\n",
    "    \n",
    "    Returns:\n",
    "        list of pipeline components\n",
    "    \"\"\"\n",
    "    # TODO: Design pipeline\n",
    "    pass\n",
    "\n",
    "# Test your pipeline\n",
    "# pipeline = design_regression_pipeline()\n",
    "# for i, component in enumerate(pipeline, 1):\n",
    "#     print(f\"{i}. {component}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Dataset Versioning Strategy\n",
    "\n",
    "You need to version datasets that:\n",
    "- Update weekly with new data\n",
    "- May have schema changes\n",
    "- Need to be reproducible for compliance\n",
    "\n",
    "Design a versioning and tagging strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "def design_versioning_strategy():\n",
    "    \"\"\"\n",
    "    Design dataset versioning strategy\n",
    "    \n",
    "    Consider:\n",
    "    - Version numbering scheme\n",
    "    - Tags for metadata\n",
    "    - Schema validation\n",
    "    - Retention policy\n",
    "    \n",
    "    Returns:\n",
    "        dict with versioning guidelines\n",
    "    \"\"\"\n",
    "    # TODO: Design strategy\n",
    "    pass\n",
    "\n",
    "# Test your strategy\n",
    "# strategy = design_versioning_strategy()\n",
    "# print(json.dumps(strategy, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **Workspace Architecture**: Understanding Azure ML workspace components\n",
    "2. **Compute Management**: Instances vs clusters, auto-scaling strategies\n",
    "3. **Designer**: Visual ML pipeline creation without code\n",
    "4. **SDK Training**: Programmatic job submission and monitoring\n",
    "5. **Data Management**: Datastores and versioned datasets\n",
    "6. **AutoML**: Automated model selection and tuning\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Use compute instances for development, clusters for training\n",
    "- Enable auto-shutdown and scale-to-zero to save costs\n",
    "- Designer is great for no-code ML workflows\n",
    "- SDK provides full programmatic control\n",
    "- Version datasets for reproducibility\n",
    "- AutoML accelerates model development\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "- [Module 04: Azure ML Pipelines and Deployment](04_azure_ml_pipelines_and_deployment.ipynb)\n",
    "- Explore MLflow integration\n",
    "- Practice with real Azure ML workspace (free tier)\n",
    "- Build reusable pipeline components\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Azure ML Documentation](https://docs.microsoft.com/azure/machine-learning/)\n",
    "- [Azure ML SDK v2](https://docs.microsoft.com/python/api/overview/azure/ml/)\n",
    "- [Designer Component Reference](https://docs.microsoft.com/azure/machine-learning/component-reference/)\n",
    "- [AutoML Guide](https://docs.microsoft.com/azure/machine-learning/concept-automated-ml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
