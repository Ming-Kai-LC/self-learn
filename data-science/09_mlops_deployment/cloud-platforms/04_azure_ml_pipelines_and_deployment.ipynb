{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 04: Azure ML Pipelines and Deployment\n",
    "\n",
    "**Difficulty**: â­â­â­\n",
    "**Estimated Time**: 60 minutes\n",
    "**Prerequisites**: \n",
    "- [Module 03: Azure ML Studio Introduction](03_azure_ml_studio_introduction.ipynb)\n",
    "- Understanding of ML pipelines and CI/CD concepts\n",
    "- Basic knowledge of REST APIs\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Create and orchestrate Azure ML Pipelines with components\n",
    "2. Schedule pipelines with triggers and automate workflows\n",
    "3. Deploy models to online (real-time) endpoints\n",
    "4. Use batch endpoints for large-scale inference\n",
    "5. Integrate MLflow for experiment tracking and model management\n",
    "6. Implement model registration and versioning strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Introduction\n",
    "\n",
    "### Azure ML Pipelines Overview\n",
    "\n",
    "Pipelines enable building reproducible, automated ML workflows.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚         Azure ML Pipeline Architecture                   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Pipeline = Sequence of Components                      â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚ Component 1 â”‚â”€â”€â”€â–¶â”‚ Component 2 â”‚â”€â”€â”€â–¶â”‚Component â”‚  â”‚\n",
    "â”‚  â”‚ Data Prep   â”‚    â”‚  Training   â”‚    â”‚ Evaluate â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Each Component:                                        â”‚\n",
    "â”‚  â”œâ”€ Has inputs and outputs                             â”‚\n",
    "â”‚  â”œâ”€ Runs in its own environment                        â”‚\n",
    "â”‚  â”œâ”€ Is reusable across pipelines                       â”‚\n",
    "â”‚  â””â”€ Can run in parallel                                â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Pipeline Execution:                                    â”‚\n",
    "â”‚  â”œâ”€ Triggered manually or scheduled                    â”‚\n",
    "â”‚  â”œâ”€ Runs on compute clusters                           â”‚\n",
    "â”‚  â”œâ”€ Tracked and versioned                              â”‚\n",
    "â”‚  â””â”€ Outputs logged to workspace                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock Azure ML components for demonstration\n",
    "# In production, use: from azure.ai.ml import command, Input, Output\n",
    "\n",
    "class MockPipelineComponent:\n",
    "    \"\"\"Simulates Azure ML pipeline component\"\"\"\n",
    "    \n",
    "    def __init__(self, name, inputs, outputs, command):\n",
    "        self.name = name\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.command = command\n",
    "        self.status = 'NotStarted'\n",
    "    \n",
    "    def execute(self):\n",
    "        \"\"\"Simulate component execution\"\"\"\n",
    "        self.status = 'Running'\n",
    "        print(f\"Executing: {self.name}\")\n",
    "        print(f\"Command: {self.command}\")\n",
    "        self.status = 'Completed'\n",
    "        return {'status': self.status}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Pipeline Components\n",
    "\n",
    "Components are reusable building blocks for pipelines.\n",
    "\n",
    "### Component Structure\n",
    "\n",
    "```yaml\n",
    "name: data_preparation\n",
    "display_name: Data Preparation\n",
    "version: 1\n",
    "type: command\n",
    "inputs:\n",
    "  raw_data:\n",
    "    type: uri_folder\n",
    "outputs:\n",
    "  clean_data:\n",
    "    type: uri_folder\n",
    "code: ./src\n",
    "environment: azureml:sklearn-env:1\n",
    "command: >-\n",
    "  python prep_data.py \n",
    "  --input ${{inputs.raw_data}} \n",
    "  --output ${{outputs.clean_data}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline components\n",
    "\n",
    "def create_data_prep_component():\n",
    "    \"\"\"Component for data preparation\"\"\"\n",
    "    component_spec = {\n",
    "        'name': 'data_preparation',\n",
    "        'display_name': 'Data Preparation',\n",
    "        'version': '1',\n",
    "        'type': 'command',\n",
    "        'inputs': {\n",
    "            'raw_data': {'type': 'uri_folder'},\n",
    "            'test_split_ratio': {'type': 'number', 'default': 0.2}\n",
    "        },\n",
    "        'outputs': {\n",
    "            'train_data': {'type': 'uri_folder'},\n",
    "            'test_data': {'type': 'uri_folder'}\n",
    "        },\n",
    "        'code': './components/prep',\n",
    "        'environment': 'azureml:sklearn-env:1',\n",
    "        'command': 'python prep.py --input ${{inputs.raw_data}} --train ${{outputs.train_data}} --test ${{outputs.test_data}} --ratio ${{inputs.test_split_ratio}}'\n",
    "    }\n",
    "    return component_spec\n",
    "\n",
    "def create_training_component():\n",
    "    \"\"\"Component for model training\"\"\"\n",
    "    component_spec = {\n",
    "        'name': 'train_model',\n",
    "        'display_name': 'Model Training',\n",
    "        'version': '1',\n",
    "        'type': 'command',\n",
    "        'inputs': {\n",
    "            'training_data': {'type': 'uri_folder'},\n",
    "            'learning_rate': {'type': 'number', 'default': 0.01},\n",
    "            'n_estimators': {'type': 'integer', 'default': 100}\n",
    "        },\n",
    "        'outputs': {\n",
    "            'model_output': {'type': 'uri_folder'}\n",
    "        },\n",
    "        'code': './components/train',\n",
    "        'environment': 'azureml:sklearn-env:1',\n",
    "        'command': 'python train.py --data ${{inputs.training_data}} --lr ${{inputs.learning_rate}} --estimators ${{inputs.n_estimators}} --output ${{outputs.model_output}}'\n",
    "    }\n",
    "    return component_spec\n",
    "\n",
    "prep_comp = create_data_prep_component()\n",
    "train_comp = create_training_component()\n",
    "\n",
    "print(\"Data Preparation Component:\")\n",
    "print(json.dumps(prep_comp, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline from components\n",
    "\n",
    "def create_training_pipeline():\n",
    "    \"\"\"\n",
    "    Assemble components into complete training pipeline\n",
    "    Data Prep â†’ Training â†’ Evaluation â†’ Registration\n",
    "    \"\"\"\n",
    "    pipeline_spec = {\n",
    "        'name': 'classification_training_pipeline',\n",
    "        'display_name': 'End-to-End Classification Pipeline',\n",
    "        'description': 'Pipeline for training and evaluating classification model',\n",
    "        'settings': {\n",
    "            'default_compute': 'training-cluster',\n",
    "            'default_datastore': 'workspaceblobstore'\n",
    "        },\n",
    "        'inputs': {\n",
    "            'pipeline_input_data': {\n",
    "                'type': 'uri_folder',\n",
    "                'path': 'azureml://datastores/workspaceblobstore/paths/data/'\n",
    "            },\n",
    "            'test_split_ratio': {'type': 'number', 'default': 0.2},\n",
    "            'learning_rate': {'type': 'number', 'default': 0.01}\n",
    "        },\n",
    "        'jobs': {\n",
    "            'prep_step': {\n",
    "                'component': 'data_preparation:1',\n",
    "                'inputs': {\n",
    "                    'raw_data': '${{parent.inputs.pipeline_input_data}}',\n",
    "                    'test_split_ratio': '${{parent.inputs.test_split_ratio}}'\n",
    "                }\n",
    "            },\n",
    "            'train_step': {\n",
    "                'component': 'train_model:1',\n",
    "                'inputs': {\n",
    "                    'training_data': '${{parent.jobs.prep_step.outputs.train_data}}',\n",
    "                    'learning_rate': '${{parent.inputs.learning_rate}}'\n",
    "                }\n",
    "            },\n",
    "            'evaluate_step': {\n",
    "                'component': 'evaluate_model:1',\n",
    "                'inputs': {\n",
    "                    'model': '${{parent.jobs.train_step.outputs.model_output}}',\n",
    "                    'test_data': '${{parent.jobs.prep_step.outputs.test_data}}'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return pipeline_spec\n",
    "\n",
    "pipeline = create_training_pipeline()\n",
    "print(\"Pipeline Configuration:\")\n",
    "print(json.dumps(pipeline, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline Scheduling and Triggers\n",
    "\n",
    "Automate pipeline execution with schedules and event-based triggers.\n",
    "\n",
    "### Scheduling Options\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚          Pipeline Triggers & Schedules                   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  1. Time-based Schedule                                 â”‚\n",
    "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚\n",
    "â”‚     â”‚ Cron: 0 2 * * *  (Daily 2am)    â”‚               â”‚\n",
    "â”‚     â”‚ Frequency: Hourly/Daily/Weekly   â”‚               â”‚\n",
    "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  2. Data Change Trigger                                 â”‚\n",
    "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚\n",
    "â”‚     â”‚ New file in Blob Storage         â”‚               â”‚\n",
    "â”‚     â”‚ Dataset version updated          â”‚               â”‚\n",
    "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  3. Manual Trigger                                      â”‚\n",
    "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚\n",
    "â”‚     â”‚ Azure Portal                     â”‚               â”‚\n",
    "â”‚     â”‚ SDK/CLI                          â”‚               â”‚\n",
    "â”‚     â”‚ REST API                         â”‚               â”‚\n",
    "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  4. CI/CD Integration                                   â”‚\n",
    "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚\n",
    "â”‚     â”‚ GitHub Actions                   â”‚               â”‚\n",
    "â”‚     â”‚ Azure DevOps Pipelines           â”‚               â”‚\n",
    "â”‚     â”‚ Jenkins                          â”‚               â”‚\n",
    "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based schedule\n",
    "\n",
    "def create_pipeline_schedule():\n",
    "    \"\"\"Configure recurring pipeline schedule\"\"\"\n",
    "    schedule_config = {\n",
    "        'name': 'daily_retraining_schedule',\n",
    "        'pipeline_id': 'classification_training_pipeline:1',\n",
    "        'recurrence': {\n",
    "            'frequency': 'Day',  # Hour, Day, Week, Month\n",
    "            'interval': 1,  # Every N days\n",
    "            'schedule': {\n",
    "                'hours': [2],  # Run at 2 AM\n",
    "                'minutes': [0]\n",
    "            },\n",
    "            'time_zone': 'UTC'\n",
    "        },\n",
    "        'enabled': True,\n",
    "        'description': 'Retrain model daily with fresh data'\n",
    "    }\n",
    "    \n",
    "    # Alternative: Cron expression\n",
    "    cron_config = {\n",
    "        'name': 'weekly_retraining_cron',\n",
    "        'pipeline_id': 'classification_training_pipeline:1',\n",
    "        'cron_expression': '0 2 * * 0',  # Every Sunday at 2 AM\n",
    "        'time_zone': 'UTC',\n",
    "        'enabled': True\n",
    "    }\n",
    "    \n",
    "    return schedule_config, cron_config\n",
    "\n",
    "recurrence, cron = create_pipeline_schedule()\n",
    "print(\"Recurrence Schedule:\")\n",
    "print(json.dumps(recurrence, indent=2))\n",
    "print(\"\\nCron Schedule:\")\n",
    "print(json.dumps(cron, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate scheduled pipeline execution\n",
    "\n",
    "class PipelineScheduler:\n",
    "    \"\"\"Simulates Azure ML pipeline scheduling\"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline_name, schedule_config):\n",
    "        self.pipeline_name = pipeline_name\n",
    "        self.schedule = schedule_config\n",
    "        self.run_history = []\n",
    "    \n",
    "    def calculate_next_run(self, current_time):\n",
    "        \"\"\"Calculate next scheduled run time\"\"\"\n",
    "        interval = self.schedule['recurrence']['interval']\n",
    "        frequency = self.schedule['recurrence']['frequency']\n",
    "        \n",
    "        if frequency == 'Day':\n",
    "            next_run = current_time + timedelta(days=interval)\n",
    "        elif frequency == 'Hour':\n",
    "            next_run = current_time + timedelta(hours=interval)\n",
    "        else:\n",
    "            next_run = current_time + timedelta(weeks=interval)\n",
    "        \n",
    "        return next_run\n",
    "    \n",
    "    def trigger_run(self, run_time):\n",
    "        \"\"\"Trigger pipeline execution\"\"\"\n",
    "        run_id = f\"run_{len(self.run_history) + 1}\"\n",
    "        run_info = {\n",
    "            'run_id': run_id,\n",
    "            'pipeline': self.pipeline_name,\n",
    "            'triggered_at': run_time,\n",
    "            'trigger_type': 'scheduled',\n",
    "            'status': 'Running'\n",
    "        }\n",
    "        self.run_history.append(run_info)\n",
    "        print(f\"âœ“ Triggered {run_id} at {run_time}\")\n",
    "        return run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pipeline scheduling\n",
    "scheduler = PipelineScheduler(\n",
    "    pipeline_name='classification_training_pipeline',\n",
    "    schedule_config=recurrence\n",
    ")\n",
    "\n",
    "# Simulate scheduled runs\n",
    "current_time = datetime.now()\n",
    "print(\"Simulating scheduled pipeline runs:\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    next_run_time = scheduler.calculate_next_run(current_time)\n",
    "    scheduler.trigger_run(next_run_time)\n",
    "    current_time = next_run_time\n",
    "\n",
    "print(f\"\\nTotal runs: {len(scheduler.run_history)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Online Endpoint Deployment\n",
    "\n",
    "Deploy models for real-time predictions via REST API.\n",
    "\n",
    "### Online Endpoint Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           Azure ML Online Endpoint                       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Client App                                             â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚\n",
    "â”‚  â”‚ POST     â”‚                                           â”‚\n",
    "â”‚  â”‚ /score   â”‚                                           â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                           â”‚\n",
    "â”‚       â”‚ HTTPS + Auth                                    â”‚\n",
    "â”‚       â–¼                                                 â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚\n",
    "â”‚  â”‚  Managed Online Endpoint            â”‚               â”‚\n",
    "â”‚  â”‚  - Auto-scaling                     â”‚               â”‚\n",
    "â”‚  â”‚  - Load balancing                   â”‚               â”‚\n",
    "â”‚  â”‚  - Monitoring                       â”‚               â”‚\n",
    "â”‚  â”‚  - Managed identity                 â”‚               â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚\n",
    "â”‚               â”‚                                         â”‚\n",
    "â”‚               â–¼                                         â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚\n",
    "â”‚  â”‚ Deployment v1    â”‚  â”‚ Deployment v2    â”‚           â”‚\n",
    "â”‚  â”‚ (90% traffic)    â”‚  â”‚ (10% traffic)    â”‚           â”‚\n",
    "â”‚  â”‚                  â”‚  â”‚                  â”‚           â”‚\n",
    "â”‚  â”‚ Model: v1.0      â”‚  â”‚ Model: v2.0      â”‚           â”‚\n",
    "â”‚  â”‚ Instances: 2     â”‚  â”‚ Instances: 1     â”‚           â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create online endpoint configuration\n",
    "\n",
    "def create_online_endpoint():\n",
    "    \"\"\"Configure managed online endpoint\"\"\"\n",
    "    endpoint_config = {\n",
    "        'name': 'classification-endpoint',\n",
    "        'description': 'Real-time classification endpoint',\n",
    "        'auth_mode': 'key',  # or 'aml_token'\n",
    "        'properties': {\n",
    "            'enforce_https': True,\n",
    "            'public_network_access': 'enabled'  # or 'disabled' for private\n",
    "        },\n",
    "        'tags': {\n",
    "            'model': 'classifier',\n",
    "            'version': '1.0',\n",
    "            'environment': 'production'\n",
    "        }\n",
    "    }\n",
    "    return endpoint_config\n",
    "\n",
    "def create_deployment():\n",
    "    \"\"\"Configure deployment within endpoint\"\"\"\n",
    "    deployment_config = {\n",
    "        'name': 'blue-deployment',\n",
    "        'endpoint_name': 'classification-endpoint',\n",
    "        'model': 'azureml:classifier-model:1',\n",
    "        'environment': 'azureml:sklearn-env:1',\n",
    "        'code_configuration': {\n",
    "            'code': './scoring',\n",
    "            'scoring_script': 'score.py'\n",
    "        },\n",
    "        'instance_type': 'Standard_DS3_v2',\n",
    "        'instance_count': 2,\n",
    "        'app_insights_enabled': True,\n",
    "        'scale_settings': {\n",
    "            'type': 'target_utilization',\n",
    "            'min_instances': 1,\n",
    "            'max_instances': 5,\n",
    "            'target_utilization_percentage': 70\n",
    "        },\n",
    "        'liveness_probe': {\n",
    "            'initial_delay': 10,\n",
    "            'period': 10,\n",
    "            'timeout': 2,\n",
    "            'success_threshold': 1,\n",
    "            'failure_threshold': 3\n",
    "        }\n",
    "    }\n",
    "    return deployment_config\n",
    "\n",
    "endpoint = create_online_endpoint()\n",
    "deployment = create_deployment()\n",
    "\n",
    "print(\"Online Endpoint:\")\n",
    "print(json.dumps(endpoint, indent=2))\n",
    "print(\"\\nDeployment Configuration:\")\n",
    "print(json.dumps(deployment, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate online endpoint invocation\n",
    "\n",
    "class OnlineEndpoint:\n",
    "    \"\"\"Simulates Azure ML online endpoint\"\"\"\n",
    "    \n",
    "    def __init__(self, endpoint_uri, auth_key):\n",
    "        self.endpoint_uri = endpoint_uri\n",
    "        self.auth_key = auth_key\n",
    "        self.request_count = 0\n",
    "        self.latencies = []\n",
    "    \n",
    "    def invoke(self, data):\n",
    "        \"\"\"\n",
    "        Invoke endpoint for real-time prediction\n",
    "        \n",
    "        Args:\n",
    "            data: Input features for prediction\n",
    "        \n",
    "        Returns:\n",
    "            Prediction result with metadata\n",
    "        \"\"\"\n",
    "        # Simulate API call\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Simulate prediction\n",
    "        prediction = np.random.choice([0, 1], p=[0.6, 0.4])\n",
    "        probability = np.random.rand()\n",
    "        \n",
    "        latency = (time.time() - start_time) * 1000\n",
    "        self.latencies.append(latency)\n",
    "        self.request_count += 1\n",
    "        \n",
    "        response = {\n",
    "            'prediction': int(prediction),\n",
    "            'probability': float(probability),\n",
    "            'model_version': '1.0',\n",
    "            'latency_ms': latency\n",
    "        }\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get endpoint statistics\"\"\"\n",
    "        return {\n",
    "            'total_requests': self.request_count,\n",
    "            'avg_latency_ms': np.mean(self.latencies) if self.latencies else 0,\n",
    "            'p95_latency_ms': np.percentile(self.latencies, 95) if self.latencies else 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test online endpoint\n",
    "endpoint = OnlineEndpoint(\n",
    "    endpoint_uri='https://classification-endpoint.eastus.inference.ml.azure.com/score',\n",
    "    auth_key='[REDACTED]'\n",
    ")\n",
    "\n",
    "# Make sample predictions\n",
    "print(\"Making predictions via online endpoint:\\n\")\n",
    "for i in range(5):\n",
    "    test_data = np.random.randn(10).tolist()\n",
    "    result = endpoint.invoke(test_data)\n",
    "    print(f\"Request {i+1}: Prediction={result['prediction']}, \"\n",
    "          f\"Probability={result['probability']:.3f}, \"\n",
    "          f\"Latency={result['latency_ms']:.2f}ms\")\n",
    "\n",
    "# Display statistics\n",
    "stats = endpoint.get_stats()\n",
    "print(\"\\nEndpoint Statistics:\")\n",
    "print(json.dumps(stats, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Endpoints\n",
    "\n",
    "Process large datasets efficiently with batch inference.\n",
    "\n",
    "### Batch Endpoint Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚            Batch Endpoint Workflow                       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  1. Upload Data                                         â”‚\n",
    "â”‚     Blob Storage: data/input/batch_001.csv              â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  2. Invoke Batch Endpoint                               â”‚\n",
    "â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚\n",
    "â”‚     â”‚ Batch Job                       â”‚                â”‚\n",
    "â”‚     â”‚ - Reads from Blob               â”‚                â”‚\n",
    "â”‚     â”‚ - Processes in chunks           â”‚                â”‚\n",
    "â”‚     â”‚ - Parallel processing           â”‚                â”‚\n",
    "â”‚     â”‚ - Auto-scales compute           â”‚                â”‚\n",
    "â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  3. Write Results                                       â”‚\n",
    "â”‚     Blob Storage: data/output/predictions.csv           â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Benefits:                                              â”‚\n",
    "â”‚  - Process millions of records                          â”‚\n",
    "â”‚  - Cost-effective (compute released after job)          â”‚\n",
    "â”‚  - Automatic retry on failure                           â”‚\n",
    "â”‚  - Parallel processing                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch endpoint configuration\n",
    "\n",
    "def create_batch_endpoint():\n",
    "    \"\"\"Configure batch endpoint for large-scale inference\"\"\"\n",
    "    endpoint_config = {\n",
    "        'name': 'batch-scoring-endpoint',\n",
    "        'description': 'Batch inference for large datasets',\n",
    "        'defaults': {\n",
    "            'deployment_name': 'production-batch'\n",
    "        }\n",
    "    }\n",
    "    return endpoint_config\n",
    "\n",
    "def create_batch_deployment():\n",
    "    \"\"\"Configure batch deployment\"\"\"\n",
    "    deployment_config = {\n",
    "        'name': 'production-batch',\n",
    "        'endpoint_name': 'batch-scoring-endpoint',\n",
    "        'model': 'azureml:classifier-model:1',\n",
    "        'environment': 'azureml:sklearn-env:1',\n",
    "        'code_configuration': {\n",
    "            'code': './batch-scoring',\n",
    "            'scoring_script': 'batch_score.py'\n",
    "        },\n",
    "        'compute': 'training-cluster',\n",
    "        'resources': {\n",
    "            'instance_count': 4  # Parallel processing\n",
    "        },\n",
    "        'max_concurrency_per_instance': 4,\n",
    "        'mini_batch_size': 10,  # Process 10 files per batch\n",
    "        'output_action': 'append_row',\n",
    "        'output_file_name': 'predictions.csv',\n",
    "        'retry_settings': {\n",
    "            'max_retries': 3,\n",
    "            'timeout': 300\n",
    "        },\n",
    "        'error_threshold': 10,  # Fail job if >10 files fail\n",
    "        'logging_level': 'info'\n",
    "    }\n",
    "    return deployment_config\n",
    "\n",
    "batch_endpoint = create_batch_endpoint()\n",
    "batch_deployment = create_batch_deployment()\n",
    "\n",
    "print(\"Batch Endpoint:\")\n",
    "print(json.dumps(batch_endpoint, indent=2))\n",
    "print(\"\\nBatch Deployment:\")\n",
    "print(json.dumps(batch_deployment, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate batch inference job\n",
    "\n",
    "class BatchInferenceJob:\n",
    "    \"\"\"Simulates Azure ML batch inference\"\"\"\n",
    "    \n",
    "    def __init__(self, num_files, instances=4):\n",
    "        self.num_files = num_files\n",
    "        self.instances = instances\n",
    "        self.processed = 0\n",
    "        self.failed = 0\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Execute batch inference job\"\"\"\n",
    "        print(f\"Starting batch job: {self.num_files} files\")\n",
    "        print(f\"Compute instances: {self.instances}\\n\")\n",
    "        \n",
    "        files_per_instance = self.num_files // self.instances\n",
    "        \n",
    "        for i in range(self.instances):\n",
    "            start_idx = i * files_per_instance\n",
    "            end_idx = start_idx + files_per_instance\n",
    "            print(f\"Instance {i+1}: Processing files {start_idx}-{end_idx}\")\n",
    "            \n",
    "            # Simulate some failures\n",
    "            failures = np.random.randint(0, 2)\n",
    "            self.processed += files_per_instance - failures\n",
    "            self.failed += failures\n",
    "        \n",
    "        success_rate = (self.processed / self.num_files) * 100\n",
    "        print(f\"\\nâœ“ Job completed\")\n",
    "        print(f\"Processed: {self.processed}/{self.num_files} ({success_rate:.1f}%)\")\n",
    "        print(f\"Failed: {self.failed}\")\n",
    "        \n",
    "        return {\n",
    "            'status': 'Completed',\n",
    "            'processed': self.processed,\n",
    "            'failed': self.failed\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch inference simulation\n",
    "batch_job = BatchInferenceJob(num_files=1000, instances=4)\n",
    "result = batch_job.run()\n",
    "\n",
    "print(\"\\nðŸ’° Cost Comparison:\")\n",
    "print(\"Batch endpoint: Pay only during job execution\")\n",
    "print(\"Online endpoint: Continuous billing even when idle\")\n",
    "print(\"\\nUse batch for: Large datasets, scheduled scoring, no real-time needs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MLflow Integration\n",
    "\n",
    "MLflow provides experiment tracking, model management, and deployment.\n",
    "\n",
    "### MLflow in Azure ML\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚              MLflow Integration                          â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  Training Script                                        â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚\n",
    "â”‚  â”‚ import mlflow                       â”‚               â”‚\n",
    "â”‚  â”‚                                     â”‚               â”‚\n",
    "â”‚  â”‚ mlflow.autolog()                    â”‚               â”‚\n",
    "â”‚  â”‚                                     â”‚               â”‚\n",
    "â”‚  â”‚ with mlflow.start_run():            â”‚               â”‚\n",
    "â”‚  â”‚   mlflow.log_param(\"lr\", 0.01)      â”‚               â”‚\n",
    "â”‚  â”‚   mlflow.log_metric(\"auc\", 0.95)    â”‚               â”‚\n",
    "â”‚  â”‚   mlflow.sklearn.log_model(model)   â”‚               â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚\n",
    "â”‚               â”‚                                         â”‚\n",
    "â”‚               â–¼                                         â”‚\n",
    "â”‚  Azure ML Workspace                                     â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚\n",
    "â”‚  â”‚ Experiments                         â”‚               â”‚\n",
    "â”‚  â”‚ - Parameters logged                 â”‚               â”‚\n",
    "â”‚  â”‚ - Metrics tracked                   â”‚               â”‚\n",
    "â”‚  â”‚ - Artifacts stored                  â”‚               â”‚\n",
    "â”‚  â”‚ - Models registered                 â”‚               â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate MLflow tracking\n",
    "\n",
    "class MLflowTracker:\n",
    "    \"\"\"Simulates MLflow experiment tracking\"\"\"\n",
    "    \n",
    "    def __init__(self, experiment_name):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.runs = []\n",
    "        self.current_run = None\n",
    "    \n",
    "    def start_run(self, run_name=None):\n",
    "        \"\"\"Start new MLflow run\"\"\"\n",
    "        run_id = f\"run_{len(self.runs) + 1}\"\n",
    "        self.current_run = {\n",
    "            'run_id': run_id,\n",
    "            'run_name': run_name or run_id,\n",
    "            'experiment': self.experiment_name,\n",
    "            'params': {},\n",
    "            'metrics': {},\n",
    "            'artifacts': [],\n",
    "            'start_time': datetime.now()\n",
    "        }\n",
    "        print(f\"Started MLflow run: {run_id}\")\n",
    "    \n",
    "    def log_param(self, key, value):\n",
    "        \"\"\"Log parameter\"\"\"\n",
    "        if self.current_run:\n",
    "            self.current_run['params'][key] = value\n",
    "            print(f\"  Param: {key}={value}\")\n",
    "    \n",
    "    def log_metric(self, key, value, step=None):\n",
    "        \"\"\"Log metric\"\"\"\n",
    "        if self.current_run:\n",
    "            if key not in self.current_run['metrics']:\n",
    "                self.current_run['metrics'][key] = []\n",
    "            self.current_run['metrics'][key].append({\n",
    "                'value': value,\n",
    "                'step': step\n",
    "            })\n",
    "            print(f\"  Metric: {key}={value}\")\n",
    "    \n",
    "    def log_artifact(self, artifact_path):\n",
    "        \"\"\"Log artifact (model, plot, etc.)\"\"\"\n",
    "        if self.current_run:\n",
    "            self.current_run['artifacts'].append(artifact_path)\n",
    "            print(f\"  Artifact: {artifact_path}\")\n",
    "    \n",
    "    def end_run(self):\n",
    "        \"\"\"End current run\"\"\"\n",
    "        if self.current_run:\n",
    "            self.current_run['end_time'] = datetime.now()\n",
    "            self.runs.append(self.current_run)\n",
    "            print(f\"Ended run: {self.current_run['run_id']}\\n\")\n",
    "            self.current_run = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate training with MLflow tracking\n",
    "mlflow = MLflowTracker('classification-experiment')\n",
    "\n",
    "# Run experiment with different parameters\n",
    "for lr in [0.001, 0.01, 0.1]:\n",
    "    mlflow.start_run(run_name=f'lr_{lr}')\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param('learning_rate', lr)\n",
    "    mlflow.log_param('n_estimators', 100)\n",
    "    mlflow.log_param('max_depth', 10)\n",
    "    \n",
    "    # Simulate training and log metrics\n",
    "    for epoch in range(3):\n",
    "        # Simulated metrics\n",
    "        train_loss = 1.0 / (epoch + 1) * (1 / lr)\n",
    "        val_auc = 0.7 + (epoch * 0.05) + (lr * 0.1)\n",
    "        \n",
    "        mlflow.log_metric('train_loss', train_loss, step=epoch)\n",
    "        mlflow.log_metric('val_auc', val_auc, step=epoch)\n",
    "    \n",
    "    # Log model artifact\n",
    "    mlflow.log_artifact('models/classifier.pkl')\n",
    "    \n",
    "    mlflow.end_run()\n",
    "\n",
    "print(f\"Total runs logged: {len(mlflow.runs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Registration and Versioning\n",
    "\n",
    "Register models for deployment and track versions.\n",
    "\n",
    "### Model Registry Workflow\n",
    "\n",
    "```\n",
    "Training â†’ Evaluation â†’ Registration â†’ Staging â†’ Production\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model registration\n",
    "\n",
    "def register_model(model_info):\n",
    "    \"\"\"Register model in Azure ML workspace\"\"\"\n",
    "    registration = {\n",
    "        'name': model_info['name'],\n",
    "        'version': model_info.get('version', 'auto'),  # Auto-increment\n",
    "        'path': model_info['path'],\n",
    "        'type': 'mlflow_model',  # or 'custom_model'\n",
    "        'description': model_info.get('description', ''),\n",
    "        'tags': {\n",
    "            'framework': model_info.get('framework', 'sklearn'),\n",
    "            'task': model_info.get('task', 'classification'),\n",
    "            'algorithm': model_info.get('algorithm', ''),\n",
    "            'training_date': datetime.now().isoformat()\n",
    "        },\n",
    "        'properties': {\n",
    "            'auc': model_info.get('auc', 0),\n",
    "            'accuracy': model_info.get('accuracy', 0),\n",
    "            'dataset_version': model_info.get('dataset_version', 1)\n",
    "        },\n",
    "        'stage': 'Staging'  # or 'Production', 'Archived'\n",
    "    }\n",
    "    return registration\n",
    "\n",
    "# Register a model\n",
    "model_registration = register_model({\n",
    "    'name': 'churn-classifier',\n",
    "    'path': 'runs/run_1/model',\n",
    "    'description': 'Customer churn prediction model',\n",
    "    'framework': 'sklearn',\n",
    "    'algorithm': 'RandomForest',\n",
    "    'auc': 0.94,\n",
    "    'accuracy': 0.89,\n",
    "    'dataset_version': 2\n",
    "})\n",
    "\n",
    "print(\"Model Registration:\")\n",
    "print(json.dumps(model_registration, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate model registry\n",
    "\n",
    "class ModelRegistry:\n",
    "    \"\"\"Simulates Azure ML model registry\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "    \n",
    "    def register(self, model_name, model_info):\n",
    "        \"\"\"Register new model or version\"\"\"\n",
    "        if model_name not in self.models:\n",
    "            self.models[model_name] = []\n",
    "        \n",
    "        version = len(self.models[model_name]) + 1\n",
    "        model_info['version'] = version\n",
    "        model_info['registered_at'] = datetime.now()\n",
    "        \n",
    "        self.models[model_name].append(model_info)\n",
    "        print(f\"âœ“ Registered {model_name} version {version}\")\n",
    "        return version\n",
    "    \n",
    "    def get_latest(self, model_name, stage=None):\n",
    "        \"\"\"Get latest version of model\"\"\"\n",
    "        if model_name not in self.models:\n",
    "            return None\n",
    "        \n",
    "        versions = self.models[model_name]\n",
    "        if stage:\n",
    "            versions = [v for v in versions if v.get('stage') == stage]\n",
    "        \n",
    "        return versions[-1] if versions else None\n",
    "    \n",
    "    def promote_to_production(self, model_name, version):\n",
    "        \"\"\"Promote model version to production\"\"\"\n",
    "        if model_name in self.models:\n",
    "            for model in self.models[model_name]:\n",
    "                if model['version'] == version:\n",
    "                    model['stage'] = 'Production'\n",
    "                    print(f\"âœ“ Promoted {model_name} v{version} to Production\")\n",
    "                    return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model registry\n",
    "registry = ModelRegistry()\n",
    "\n",
    "# Register multiple versions\n",
    "v1 = registry.register('churn-classifier', {\n",
    "    'auc': 0.89,\n",
    "    'stage': 'Staging'\n",
    "})\n",
    "\n",
    "v2 = registry.register('churn-classifier', {\n",
    "    'auc': 0.94,\n",
    "    'stage': 'Staging'\n",
    "})\n",
    "\n",
    "v3 = registry.register('churn-classifier', {\n",
    "    'auc': 0.96,\n",
    "    'stage': 'Staging'\n",
    "})\n",
    "\n",
    "# Promote best version to production\n",
    "registry.promote_to_production('churn-classifier', v3)\n",
    "\n",
    "# Get production model\n",
    "prod_model = registry.get_latest('churn-classifier', stage='Production')\n",
    "print(f\"\\nProduction model: v{prod_model['version']}, AUC={prod_model['auc']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Pipeline Design\n",
    "\n",
    "Design a complete ML pipeline for fraud detection:\n",
    "1. Data validation (check schema, quality)\n",
    "2. Feature engineering (aggregate transactions)\n",
    "3. Model training (with hyperparameter tuning)\n",
    "4. Model evaluation (multiple metrics)\n",
    "5. Conditional registration (only if AUC > 0.90)\n",
    "\n",
    "Define all components and their connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "def design_fraud_detection_pipeline():\n",
    "    \"\"\"\n",
    "    Design end-to-end fraud detection pipeline\n",
    "    \n",
    "    Include:\n",
    "    - Component definitions\n",
    "    - Input/output connections\n",
    "    - Conditional logic\n",
    "    - Parallel execution where possible\n",
    "    \n",
    "    Returns:\n",
    "        dict with complete pipeline specification\n",
    "    \"\"\"\n",
    "    # TODO: Design pipeline\n",
    "    pass\n",
    "\n",
    "# Test your pipeline\n",
    "# pipeline = design_fraud_detection_pipeline()\n",
    "# print(json.dumps(pipeline, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Deployment Strategy\n",
    "\n",
    "You need to deploy a model with these requirements:\n",
    "- 10,000 predictions/day (mostly during business hours)\n",
    "- Must support A/B testing new versions\n",
    "- Latency < 200ms at p95\n",
    "- Budget: $500/month\n",
    "\n",
    "Choose between online endpoint, batch endpoint, or hybrid. Justify your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "def design_deployment_strategy(requirements):\n",
    "    \"\"\"\n",
    "    Design deployment strategy based on requirements\n",
    "    \n",
    "    Consider:\n",
    "    - Traffic patterns\n",
    "    - Latency requirements\n",
    "    - Cost constraints\n",
    "    - A/B testing needs\n",
    "    \n",
    "    Returns:\n",
    "        dict with deployment strategy and cost estimate\n",
    "    \"\"\"\n",
    "    # TODO: Design strategy\n",
    "    pass\n",
    "\n",
    "# Test your strategy\n",
    "# requirements = {\n",
    "#     'daily_predictions': 10000,\n",
    "#     'latency_p95_ms': 200,\n",
    "#     'budget_monthly': 500,\n",
    "#     'ab_testing': True\n",
    "# }\n",
    "# strategy = design_deployment_strategy(requirements)\n",
    "# print(json.dumps(strategy, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Model Governance\n",
    "\n",
    "Design a model versioning and promotion strategy:\n",
    "- Automatic registration from pipeline\n",
    "- Staging environment for testing\n",
    "- Approval workflow for production\n",
    "- Rollback capability\n",
    "- Compliance tracking\n",
    "\n",
    "Define the complete workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "def design_model_governance():\n",
    "    \"\"\"\n",
    "    Design model governance workflow\n",
    "    \n",
    "    Include:\n",
    "    - Registration criteria\n",
    "    - Promotion gates (metrics, approvals)\n",
    "    - Rollback procedure\n",
    "    - Audit trail\n",
    "    \n",
    "    Returns:\n",
    "        dict with governance workflow\n",
    "    \"\"\"\n",
    "    # TODO: Design governance\n",
    "    pass\n",
    "\n",
    "# Test your workflow\n",
    "# governance = design_model_governance()\n",
    "# print(json.dumps(governance, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **Pipeline Components**: Building reusable, modular ML workflows\n",
    "2. **Pipeline Scheduling**: Automating workflows with triggers\n",
    "3. **Online Endpoints**: Real-time model serving with auto-scaling\n",
    "4. **Batch Endpoints**: Cost-effective large-scale inference\n",
    "5. **MLflow Integration**: Experiment tracking and model management\n",
    "6. **Model Registry**: Versioning and lifecycle management\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Use pipelines for reproducible, automated workflows\n",
    "- Schedule pipelines for regular retraining\n",
    "- Choose online vs batch based on latency and cost requirements\n",
    "- Track experiments with MLflow for better visibility\n",
    "- Version models and use staging for safe deployments\n",
    "- Implement approval workflows for production models\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "- [Module 05: Google Cloud AI Platform Basics](05_google_cloud_ai_platform_basics.ipynb)\n",
    "- Explore Azure DevOps integration for CI/CD\n",
    "- Practice building custom pipeline components\n",
    "- Implement monitoring and alerting for endpoints\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Azure ML Pipelines](https://docs.microsoft.com/azure/machine-learning/concept-ml-pipelines)\n",
    "- [Online Endpoints](https://docs.microsoft.com/azure/machine-learning/concept-endpoints)\n",
    "- [Batch Endpoints](https://docs.microsoft.com/azure/machine-learning/batch-inference/)\n",
    "- [MLflow on Azure ML](https://docs.microsoft.com/azure/machine-learning/how-to-use-mlflow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
