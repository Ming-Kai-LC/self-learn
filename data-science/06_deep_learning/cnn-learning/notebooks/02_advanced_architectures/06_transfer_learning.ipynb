{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 06: Transfer Learning\n",
    "\n",
    "**Leverage Pre-Trained Models for Your Own Projects**\n",
    "\n",
    "Don't train from scratch! Use models trained on millions of images.\n",
    "\n",
    "## What You'll Learn\n",
    "- What is transfer learning?\n",
    "- Feature extraction vs fine-tuning\n",
    "- Using PyTorch's pre-trained models\n",
    "- Adapting models to your dataset\n",
    "- Practical project: Custom image classifier\n",
    "\n",
    "## Time: 60 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: What is Transfer Learning?\n",
    "\n",
    "### The Idea\n",
    "\n",
    "**Transfer Learning:** Use knowledge learned from one task to solve a different but related task.\n",
    "\n",
    "### Why Transfer Learning?\n",
    "\n",
    "1. **Saves Time**: No need to train for days/weeks\n",
    "2. **Less Data Needed**: Pre-trained models already know image features\n",
    "3. **Better Performance**: Models trained on millions of images\n",
    "4. **Practical**: Most real-world applications use transfer learning\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```\n",
    "Pre-trained Model (trained on ImageNet - 1.2M images, 1000 classes)\n",
    "    ↓\n",
    "[Keep early layers] → They recognize general features (edges, textures, shapes)\n",
    "    ↓\n",
    "[Replace final layers] → Train on YOUR specific task\n",
    "    ↓\n",
    "Your Custom Classifier!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Two Approaches\n",
    "\n",
    "### Approach 1: Feature Extraction\n",
    "\n",
    "- **Freeze** all pre-trained layers\n",
    "- **Train** only the new final layer\n",
    "- **Fast**, requires little data\n",
    "- Use when: Dataset is small and similar to ImageNet\n",
    "\n",
    "### Approach 2: Fine-Tuning\n",
    "\n",
    "- **Freeze** early layers\n",
    "- **Unfreeze** some later layers\n",
    "- **Train** final layers + unfrozen layers\n",
    "- **Slower**, needs more data\n",
    "- Use when: Larger dataset or different from ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet18\n",
    "model = models.resnet18(pretrained=True)\n",
    "print(\"Loaded pre-trained ResNet18!\")\n",
    "print(f\"\\nOriginal output layer: {model.fc}\")\n",
    "print(f\"Designed for {model.fc.out_features} classes (ImageNet)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Feature Extraction Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1: Feature Extraction\n",
    "model_fe = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all parameters\n",
    "for param in model_fe.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for YOUR task (e.g., 10 classes)\n",
    "num_features = model_fe.fc.in_features\n",
    "model_fe.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "model_fe = model_fe.to(device)\n",
    "\n",
    "print(\"Feature Extraction Model:\")\n",
    "print(f\"Frozen layers: {sum(1 for p in model_fe.parameters() if not p.requires_grad)}\")\n",
    "print(f\"Trainable layers: {sum(1 for p in model_fe.parameters() if p.requires_grad)}\")\n",
    "print(f\"\\nNew output layer: {model_fe.fc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Fine-Tuning Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 2: Fine-Tuning\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze early layers only\n",
    "for name, param in model_ft.named_parameters():\n",
    "    if \"layer4\" not in name and \"fc\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Replace final layer\n",
    "num_features = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "print(\"Fine-Tuning Model:\")\n",
    "trainable = sum(p.numel() for p in model_ft.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model_ft.parameters())\n",
    "print(f\"Trainable parameters: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Training with Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms for pre-trained models\n",
    "# Important: Use ImageNet normalization!\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),  # ResNet expects 224×224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]  # ImageNet mean\n",
    "        ),  # ImageNet std\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Data transforms ready!\")\n",
    "print(\"\\nKey points:\")\n",
    "print(\"- Resize to 224×224 (ResNet input size)\")\n",
    "print(\"- Use ImageNet normalization\")\n",
    "print(\"- Apply same transforms during inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Available Pre-Trained Models\n",
    "\n",
    "### Classification Models\n",
    "- **ResNet** (18, 34, 50, 101, 152): Great all-purpose\n",
    "- **VGG** (11, 13, 16, 19): Simple, accurate\n",
    "- **MobileNet**: Lightweight, fast\n",
    "- **EfficientNet**: State-of-the-art accuracy\n",
    "- **DenseNet**: Dense connections\n",
    "\n",
    "### How to Choose?\n",
    "\n",
    "- **Need speed?** → MobileNet\n",
    "- **Need accuracy?** → EfficientNet or ResNet-50+\n",
    "- **Limited resources?** → ResNet-18 or MobileNet\n",
    "- **Just starting?** → ResNet-18 (good balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load different models\n",
    "print(\"Available pre-trained models:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Small and fast\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "print(f\"MobileNetV2: {sum(p.numel() for p in mobilenet.parameters()):,} parameters\")\n",
    "\n",
    "# Balanced\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "print(f\"ResNet-18: {sum(p.numel() for p in resnet18.parameters()):,} parameters\")\n",
    "\n",
    "# More accurate\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "print(f\"ResNet-50: {sum(p.numel() for p in resnet50.parameters()):,} parameters\")\n",
    "\n",
    "print(\"\\nAll trained on ImageNet (1.2M images, 1000 classes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What You Learned:\n",
    "\n",
    "1. **Transfer Learning Concept**\n",
    "   - Reuse knowledge from large datasets\n",
    "   - Saves time and improves performance\n",
    "\n",
    "2. **Two Approaches**\n",
    "   - Feature extraction: Freeze all, train final layer\n",
    "   - Fine-tuning: Unfreeze some layers, train more\n",
    "\n",
    "3. **Practical Implementation**\n",
    "   - Load pre-trained models from torchvision\n",
    "   - Replace final layer for your task\n",
    "   - Use ImageNet normalization\n",
    "\n",
    "4. **Model Selection**\n",
    "   - Different models for different needs\n",
    "   - ResNet-18 is a great starting point\n",
    "\n",
    "### Next: Module 07 - Image Classification Project\n",
    "Build a complete end-to-end classifier using transfer learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
