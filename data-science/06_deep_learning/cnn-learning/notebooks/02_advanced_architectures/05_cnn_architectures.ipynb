{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 05: Famous CNN Architectures\n",
    "\n",
    "Learn from the architectures that revolutionized computer vision.\n",
    "\n",
    "## Architectures Covered\n",
    "- LeNet-5 (1998) - The pioneer\n",
    "- AlexNet (2012) - The ImageNet winner\n",
    "- VGG (2014) - Simplicity and depth\n",
    "- ResNet (2015) - Solving vanishing gradients\n",
    "- Modern architectures overview\n",
    "\n",
    "## Time: 45 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: LeNet-5 (1998)\n",
    "\n",
    "**First successful CNN**, designed by Yann LeCun for handwritten digit recognition.\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Input (32×32) → Conv(6) → Pool → Conv(16) → Pool → FC(120) → FC(84) → FC(10)\n",
    "```\n",
    "\n",
    "**Key Insights:**\n",
    "- Convolution preserves spatial information\n",
    "- Pooling reduces dimensions\n",
    "- Hierarchical feature learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "lenet = LeNet5()\n",
    "print(\"LeNet-5: The CNN that started it all!\")\n",
    "print(lenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: AlexNet (2012)\n",
    "\n",
    "**Won ImageNet 2012**, sparked the deep learning revolution!\n",
    "\n",
    "**Innovations:**\n",
    "- Used ReLU (faster than sigmoid/tanh)\n",
    "- Dropout for regularization\n",
    "- Data augmentation\n",
    "- GPU acceleration\n",
    "- Much deeper (8 layers)\n",
    "\n",
    "**Impact:** Showed deep learning works for complex real-world problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained AlexNet\n",
    "alexnet = models.alexnet(pretrained=False)\n",
    "print(\"AlexNet architecture:\")\n",
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: VGG (2014)\n",
    "\n",
    "**Philosophy:** Deeper networks with small (3×3) filters work better!\n",
    "\n",
    "**Key Ideas:**\n",
    "- Only 3×3 convolutions\n",
    "- Many layers (16-19 layers)\n",
    "- Simple, uniform architecture\n",
    "\n",
    "**VGG-16:** 13 conv layers + 3 FC layers = 16 layers\n",
    "\n",
    "**Drawback:** Very large number of parameters (138M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16\n",
    "vgg = models.vgg16(pretrained=False)\n",
    "print(\"VGG-16: Deep and simple\")\n",
    "total_params = sum(p.numel() for p in vgg.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: ResNet (2015)\n",
    "\n",
    "**Revolutionary idea:** Skip connections!\n",
    "\n",
    "**Problem Solved:** Vanishing gradients in very deep networks\n",
    "\n",
    "**Skip Connections:** Allow gradients to flow directly through network\n",
    "\n",
    "```\n",
    "x → [Conv → Conv] → Add → Output\n",
    " \\________________↗ (skip connection)\n",
    "```\n",
    "\n",
    "**Impact:** Enabled networks with 100+ layers (ResNet-152)\n",
    "\n",
    "**Variants:** ResNet-18, ResNet-34, ResNet-50, ResNet-101, ResNet-152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet-18\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "print(\"ResNet-18: Revolutionary skip connections!\")\n",
    "print(resnet)\n",
    "\n",
    "\n",
    "# Basic residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # Save input\n",
    "\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        out += identity  # Skip connection!\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "print(\"\\nResidual blocks enable training very deep networks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Modern Architectures\n",
    "\n",
    "### EfficientNet (2019)\n",
    "- Balances depth, width, and resolution\n",
    "- State-of-the-art accuracy with fewer parameters\n",
    "\n",
    "### Vision Transformers (2020)\n",
    "- Apply transformer architecture (from NLP) to vision\n",
    "- Competitive with CNNs\n",
    "\n",
    "### MobileNet\n",
    "- Designed for mobile devices\n",
    "- Depthwise separable convolutions\n",
    "- Fast and lightweight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Evolution of CNNs:\n",
    "1. **LeNet (1998)**: Proved CNNs work\n",
    "2. **AlexNet (2012)**: Showed depth + GPUs = power\n",
    "3. **VGG (2014)**: Simple is good, depth matters\n",
    "4. **ResNet (2015)**: Skip connections enable very deep networks\n",
    "5. **Modern**: Focus on efficiency and performance\n",
    "\n",
    "### Key Takeaway:\n",
    "You don't need to design from scratch - use proven architectures!\n",
    "\n",
    "### Next: Module 06 - Transfer Learning\n",
    "Learn to use these pre-trained models for your own problems!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
