{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 00: Setup & Introduction to CNNs\n",
    "\n",
    "**Welcome to the CNN Learning Journey!**\n",
    "\n",
    "In this introductory module, you'll:\n",
    "- Set up your PyTorch environment\n",
    "- Verify your installation\n",
    "- Learn what CNNs are and why they're important\n",
    "- Load and visualize your first images\n",
    "- Get an overview of the learning path ahead\n",
    "\n",
    "## Prerequisites\n",
    "- Python 3.8 or higher installed\n",
    "- Basic Python knowledge (variables, functions, loops)\n",
    "- Curiosity and enthusiasm!\n",
    "\n",
    "## Time Required\n",
    "30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Environment Setup and Verification\n",
    "\n",
    "Let's make sure you have everything installed correctly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Libraries\n",
    "\n",
    "First, let's try importing PyTorch and other essential libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch and related libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Print versions to verify installation\n",
    "print(\"Library Versions:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"TorchVision version: {torchvision.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nAll libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Check GPU Availability\n",
    "\n",
    "**Why check for GPU?**\n",
    "- **GPU (Graphics Processing Unit)**: Dramatically speeds up deep learning training\n",
    "- **CPU (Central Processing Unit)**: Works fine for learning, just slower\n",
    "\n",
    "Don't worry if you don't have a GPU - you can complete the entire course on CPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA (NVIDIA GPU support) is available\n",
    "print(\"Device Information:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"\\nYou'll be using: GPU\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"\\nYou'll be using: CPU\")\n",
    "    print(\"Note: Training will be slower but perfectly fine for learning!\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Store the device for later use\n",
    "print(f\"\\nDevice set to: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Test PyTorch Operations\n",
    "\n",
    "Let's make sure PyTorch can create and manipulate tensors (the fundamental data structure in PyTorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple tensor\n",
    "print(\"Testing PyTorch tensor operations...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a 3x3 tensor with random values\n",
    "test_tensor = torch.randn(3, 3)\n",
    "print(\"Created a 3x3 tensor with random values:\")\n",
    "print(test_tensor)\n",
    "\n",
    "# Move it to the device (GPU or CPU)\n",
    "test_tensor = test_tensor.to(device)\n",
    "print(f\"\\nMoved tensor to {device}\")\n",
    "\n",
    "# Perform a simple operation\n",
    "result = test_tensor * 2\n",
    "print(\"\\nMultiplied by 2:\")\n",
    "print(result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PyTorch is working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: What Are Convolutional Neural Networks?\n",
    "\n",
    "### What is a CNN?\n",
    "\n",
    "**Convolutional Neural Network (CNN)** is a type of deep learning model specifically designed for processing grid-like data, especially images.\n",
    "\n",
    "### Think of it like this:\n",
    "\n",
    "Imagine you're teaching a child to recognize a cat:\n",
    "1. **First**, they notice simple features: edges, curves, colors\n",
    "2. **Then**, they recognize cat parts: ears, whiskers, paws\n",
    "3. **Finally**, they put it together: \"That's a cat!\"\n",
    "\n",
    "CNNs work exactly the same way!\n",
    "\n",
    "### Why are CNNs Special for Images?\n",
    "\n",
    "**Traditional neural networks** treat all pixels equally and lose spatial relationships.\n",
    "\n",
    "**CNNs** understand that:\n",
    "- Nearby pixels are related (an eye is made of many connected pixels)\n",
    "- The same feature can appear anywhere (a cat's ear can be on the left or right)\n",
    "- We need to recognize patterns at different scales (small details and big structures)\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "CNNs power amazing technologies:\n",
    "- **Face Recognition**: Unlocking your phone\n",
    "- **Medical Diagnosis**: Detecting diseases in X-rays and MRIs\n",
    "- **Self-Driving Cars**: Recognizing pedestrians, signs, and other vehicles\n",
    "- **Photo Apps**: Automatic filters, background removal\n",
    "- **Agriculture**: Detecting crop diseases\n",
    "- **Security**: Surveillance and anomaly detection\n",
    "- **E-commerce**: Visual search (\"find similar items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Loading and Visualizing Images\n",
    "\n",
    "Let's get hands-on! We'll load and display images using PyTorch and matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Image Data\n",
    "\n",
    "**What is a digital image?**\n",
    "- A grid of pixels (picture elements)\n",
    "- Each pixel has color values\n",
    "\n",
    "**Grayscale image**:\n",
    "- One value per pixel (0 = black, 255 = white)\n",
    "- Shape: (Height, Width)\n",
    "\n",
    "**Color (RGB) image**:\n",
    "- Three values per pixel (Red, Green, Blue)\n",
    "- Shape: (Height, Width, 3) or (3, Height, Width) in PyTorch\n",
    "- Each color channel: 0-255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple synthetic image to understand image structure\n",
    "\n",
    "# Create a 5x5 grayscale image (small so we can see the numbers)\n",
    "simple_image = np.array(\n",
    "    [\n",
    "        [0, 0, 255, 0, 0],\n",
    "        [0, 255, 255, 255, 0],\n",
    "        [255, 255, 255, 255, 255],\n",
    "        [0, 255, 255, 255, 0],\n",
    "        [0, 0, 255, 0, 0],\n",
    "    ],\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "print(\"Simple 5x5 Image (as numbers):\")\n",
    "print(simple_image)\n",
    "print(f\"\\nShape: {simple_image.shape}\")\n",
    "print(f\"Data type: {simple_image.dtype}\")\n",
    "\n",
    "# Visualize it\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(simple_image, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"5x5 Grayscale Image\\n(0=black, 255=white)\", fontsize=14, fontweight=\"bold\")\n",
    "plt.colorbar(label=\"Pixel Value\")\n",
    "\n",
    "# Add grid to see individual pixels\n",
    "for i in range(6):\n",
    "    plt.axhline(i - 0.5, color=\"red\", linewidth=0.5)\n",
    "    plt.axvline(i - 0.5, color=\"red\", linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSee? Each number becomes a pixel!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Color Image\n",
    "\n",
    "Now let's create a small RGB (color) image to understand the 3-channel structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small 3x3 RGB image\n",
    "# Shape: (Height, Width, Channels) = (3, 3, 3)\n",
    "\n",
    "rgb_image = np.zeros((3, 3, 3), dtype=np.uint8)\n",
    "\n",
    "# Top row: Red, Green, Blue\n",
    "rgb_image[0, 0] = [255, 0, 0]  # Red\n",
    "rgb_image[0, 1] = [0, 255, 0]  # Green\n",
    "rgb_image[0, 2] = [0, 0, 255]  # Blue\n",
    "\n",
    "# Middle row: Cyan, Magenta, Yellow\n",
    "rgb_image[1, 0] = [0, 255, 255]  # Cyan\n",
    "rgb_image[1, 1] = [255, 0, 255]  # Magenta\n",
    "rgb_image[1, 2] = [255, 255, 0]  # Yellow\n",
    "\n",
    "# Bottom row: White, Gray, Black\n",
    "rgb_image[2, 0] = [255, 255, 255]  # White\n",
    "rgb_image[2, 1] = [128, 128, 128]  # Gray\n",
    "rgb_image[2, 2] = [0, 0, 0]  # Black\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "# Full color image\n",
    "axes[0].imshow(rgb_image, interpolation=\"nearest\")\n",
    "axes[0].set_title(\"RGB Image\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Red channel\n",
    "axes[1].imshow(rgb_image[:, :, 0], cmap=\"Reds\", vmin=0, vmax=255, interpolation=\"nearest\")\n",
    "axes[1].set_title(\"Red Channel\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "# Green channel\n",
    "axes[2].imshow(rgb_image[:, :, 1], cmap=\"Greens\", vmin=0, vmax=255, interpolation=\"nearest\")\n",
    "axes[2].set_title(\"Green Channel\", fontsize=12, fontweight=\"bold\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "# Blue channel\n",
    "axes[3].imshow(rgb_image[:, :, 2], cmap=\"Blues\", vmin=0, vmax=255, interpolation=\"nearest\")\n",
    "axes[3].set_title(\"Blue Channel\", fontsize=12, fontweight=\"bold\")\n",
    "axes[3].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image shape: {rgb_image.shape}\")\n",
    "print(\n",
    "    f\"Interpretation: (Height={rgb_image.shape[0]}, Width={rgb_image.shape[1]}, Channels={rgb_image.shape[2]})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Images to PyTorch Tensors\n",
    "\n",
    "PyTorch works with **tensors**, not NumPy arrays. Let's learn to convert between them.\n",
    "\n",
    "**Important**: PyTorch uses channel-first format `(C, H, W)` while most image libraries use `(H, W, C)`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy image to PyTorch tensor\n",
    "\n",
    "print(\"Original NumPy array shape (H, W, C):\", rgb_image.shape)\n",
    "\n",
    "# Method 1: Using torch.from_numpy and permute\n",
    "tensor_image = torch.from_numpy(rgb_image)\n",
    "print(\"After torch.from_numpy:\", tensor_image.shape)\n",
    "\n",
    "# Permute to (C, H, W) format\n",
    "tensor_image = tensor_image.permute(2, 0, 1)\n",
    "print(\"After permute to (C, H, W):\", tensor_image.shape)\n",
    "\n",
    "# Normalize to [0, 1] range (neural networks prefer this)\n",
    "tensor_image_normalized = tensor_image.float() / 255.0\n",
    "print(\"After normalization:\", tensor_image_normalized.shape)\n",
    "print(\n",
    "    \"Value range: [{:.2f}, {:.2f}]\".format(\n",
    "        tensor_image_normalized.min().item(), tensor_image_normalized.max().item()\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nNote: CNNs typically expect:\")\n",
    "print(\"  - Format: (Batch, Channels, Height, Width)\")\n",
    "print(\"  - Values: [0, 1] or normalized with mean/std\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Download Datasets\n",
    "\n",
    "We'll use real datasets throughout this course. Let's download them now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll download MNIST as our first dataset\n",
    "# MNIST: 70,000 handwritten digits (0-9)\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "# Define data directory\n",
    "data_dir = \"../data/datasets\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "print(\"Downloading MNIST dataset...\")\n",
    "print(\"This might take a few minutes on first run.\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Download MNIST training set\n",
    "mnist_train = datasets.MNIST(\n",
    "    root=data_dir, train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "print(f\"\\nMNIST training set downloaded!\")\n",
    "print(f\"Number of training images: {len(mnist_train)}\")\n",
    "print(f\"Image shape: {mnist_train[0][0].shape}\")\n",
    "print(f\"Number of classes: {len(mnist_train.classes)}\")\n",
    "print(f\"Classes: {mnist_train.classes}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize MNIST Samples\n",
    "\n",
    "Let's see what the MNIST digits look like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a grid of MNIST images\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "fig.suptitle(\"Sample MNIST Digits\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    # Get image and label\n",
    "    image, label = mnist_train[idx]\n",
    "\n",
    "    # Convert tensor to numpy for visualization\n",
    "    # image shape: (1, 28, 28) -> squeeze to (28, 28)\n",
    "    img_np = image.squeeze().numpy()\n",
    "\n",
    "    # Display\n",
    "    ax.imshow(img_np, cmap=\"gray\")\n",
    "    ax.set_title(f\"Label: {label}\", fontsize=12)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"These are the images we'll teach our CNN to recognize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Your Learning Journey\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "Here's the complete learning path you'll follow:\n",
    "\n",
    "#### **Module 01: Neural Network Fundamentals** (45 min)\n",
    "Learn the basics of neural networks before diving into CNNs.\n",
    "\n",
    "#### **Module 02: Introduction to CNNs** (45 min)\n",
    "Understand convolution, filters, and why CNNs work for images.\n",
    "\n",
    "#### **Module 03: Building Your First CNN** (60 min)\n",
    "Hands-on: Build a CNN to recognize MNIST digits!\n",
    "\n",
    "#### **Module 04: Training & Optimization** (45 min)\n",
    "Learn how to train CNNs effectively.\n",
    "\n",
    "#### **Module 05: CNN Architectures** (45 min)\n",
    "Explore famous architectures like LeNet, AlexNet, VGG, ResNet.\n",
    "\n",
    "#### **Module 06: Transfer Learning** (60 min)\n",
    "Use pre-trained models to solve your own problems!\n",
    "\n",
    "#### **Module 07: Image Classification Project** (60 min)\n",
    "Build a complete image classifier from scratch.\n",
    "\n",
    "#### **Module 08: Introduction to Object Detection** (45 min)\n",
    "Detect and localize multiple objects in images.\n",
    "\n",
    "#### **Module 09: Introduction to Image Segmentation** (45 min)\n",
    "Classify every pixel in an image.\n",
    "\n",
    "#### **Module 10: Final Projects & Next Steps** (30 min)\n",
    "Ideas for building your portfolio and continuing your learning.\n",
    "\n",
    "### Tips for Success\n",
    "\n",
    "1. **Run every code cell** - Don't just read, execute!\n",
    "2. **Experiment** - Change parameters and see what happens\n",
    "3. **Take breaks** - Deep learning is complex, let concepts sink in\n",
    "4. **Ask questions** - Use forums, communities, or GitHub Issues\n",
    "5. **Build projects** - Apply what you learn to your own problems\n",
    "\n",
    "### Getting Help\n",
    "\n",
    "- **PyTorch Documentation**: [pytorch.org/docs](https://pytorch.org/docs)\n",
    "- **PyTorch Forums**: [discuss.pytorch.org](https://discuss.pytorch.org)\n",
    "- **This Project's Issues**: For questions specific to this course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Congratulations on completing Module 00!\n",
    "\n",
    "### What You Learned:\n",
    "- Set up and verified your PyTorch environment\n",
    "- Checked for GPU availability\n",
    "- Understood what CNNs are and why they're important\n",
    "- Learned how images are represented digitally\n",
    "- Converted images to PyTorch tensors\n",
    "- Downloaded the MNIST dataset\n",
    "- Visualized sample images\n",
    "\n",
    "### Key Takeaways:\n",
    "- CNNs are specialized for image processing\n",
    "- Images are grids of pixels with numeric values\n",
    "- PyTorch uses tensors in (C, H, W) format\n",
    "- We normalize images to [0, 1] for neural networks\n",
    "\n",
    "### Next Steps:\n",
    "Proceed to **Module 01: Neural Network Fundamentals** to learn how neural networks learn!\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to continue? Let's build your first neural network!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice Exercises (Optional)\n",
    "\n",
    "Try these to reinforce your learning:\n",
    "\n",
    "1. **Create your own image**: Make a 10x10 NumPy array with a simple pattern (like a cross or a letter)\n",
    "2. **Convert to tensor**: Convert your image to a PyTorch tensor and normalize it\n",
    "3. **Visualize MNIST**: Display 20 random MNIST images with their labels\n",
    "4. **Explore colors**: Create a small RGB image and visualize each channel separately\n",
    "5. **Batch of images**: Stack multiple MNIST images into a batch tensor with shape (Batch, Channels, Height, Width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise space - Try the exercises here!\n",
    "\n",
    "# Example: Create your own 10x10 pattern\n",
    "# your_image = np.zeros((10, 10), dtype=np.uint8)\n",
    "# ... fill in your pattern ...\n",
    "# plt.imshow(your_image, cmap='gray')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
