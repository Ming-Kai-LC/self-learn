# Deep Learning

Neural networks, transformers, and modern deep learning.

## Overview

According to the DataScience_SelfLearnPath.md: **"Learn PyTorch firstâ€”it dominates research (85% of papers), offers more intuitive Python-like programming, and provides easier debugging."** Deep learning mentions doubled to **20% of job postings**, with NLP jumping from 5% to **19% between 2023-2024**.

GenAI and LLMs are transforming the field, with **45% of IT budgets now allocated to GenAI**.

## Projects in This Domain

1. **deep-learning-fundamentals** (60-80 hours) ðŸš§ *Placeholder*
   - Neural network foundations
   - PyTorch and TensorFlow
   - Training and optimization
   - Transfer learning
   - Model debugging and interpretation

2. **cnn-learning** (~20 hours)
   - Convolutional Neural Networks
   - Image classification
   - Computer vision applications
   - ResNet, VGG architectures

3. **nlp-transformers** (60-80 hours) ðŸš§ *Placeholder*
   - Transformer architecture
   - BERT, GPT, T5 models
   - Hugging Face ecosystem
   - Fine-tuning with PEFT, LoRA, QLoRA
   - LLM applications

## Learning Path

**Recommended order:**
1. deep-learning-fundamentals (neural network basics)
2. Either cnn-learning OR nlp-transformers (based on interest)
3. Advanced specialization in chosen area

**Time investment:** 6-10 months (Advanced phase)

## Prerequisites

- **machine-learning-fundamentals** (ML basics)
- **mathematics-for-data-science** (calculus, linear algebra)
- **data-science-fundamentals** (NumPy proficiency)

## What You'll Achieve

After completing these projects, you will:
- Build neural networks from scratch in PyTorch
- Understand backpropagation and optimization
- Apply CNNs for computer vision
- Use transformers for NLP tasks
- Fine-tune large language models
- Deploy deep learning models
- Choose between PyTorch and TensorFlow

## Key Technologies

**Frameworks**: PyTorch (primary), TensorFlow/Keras (secondary)
**Architectures**: MLP, CNN, RNN, LSTM, Transformers
**Models**: BERT, GPT, T5, LLAMA, Phi2, ResNet, YOLO
**Techniques**: Transfer learning, fine-tuning, PEFT, LoRA, QLoRA

## Next Steps

Proceed to:
- **07_computer_vision** - Advanced CV applications
- **11_portfolio_projects** - Build impressive DL projects
- **09_mlops_deployment** - Deploy DL models at scale

## Roadmap Alignment

**DataScience_SelfLearnPath.md**: Intermediate to Advanced (Months 7-15)
- **Months 7-9**: Deep learning fundamentals (fast.ai or Ng's DL Specialization)
- **Months 13-15**: NLP/Transformers specialization
- PyTorch dominates research, TensorFlow common in enterprise
- GenAI/LLMs are 2025's hottest skills

## Industry Trends (2025)

- **Deep learning mentions**: Doubled to 20% of postings
- **NLP demand**: Jumped from 5% to 19%
- **New roles**: GenAI Engineer, LLM Engineer, AI Product Analyst
- **Key skills**: Hugging Face, PEFT, LoRA, prompt engineering
- **Market**: 45% of IT budgets allocated to GenAI

## Learning Resources

- **fast.ai**: Practical Deep Learning for Coders (FREE, top-down approach)
- **Coursera**: Andrew Ng's Deep Learning Specialization ($49/month)
- **Hugging Face**: NLP Course (FREE, updated for LLMs 2025)
- **Books**: "Deep Learning with PyTorch", "Hands-On ML" by GÃ©ron

---

**Status**: ðŸš§ deep-learning-fundamentals and nlp-transformers are placeholders
âœ… cnn-learning is complete
