{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12: Model Interpretation and Visualization\n",
    "\n",
    "**Difficulty**: ⭐⭐⭐ (Advanced)\n",
    "\n",
    "**Estimated Time**: 60-75 minutes\n",
    "\n",
    "**Prerequisites**: \n",
    "- [Module 05: Feed-Forward Neural Networks with Keras](05_feedforward_neural_networks_keras.ipynb)\n",
    "- [Module 10: Transfer Learning Concepts](10_transfer_learning_concepts.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand what different layers in a neural network learn\n",
    "2. Visualize layer activations to see how networks process inputs\n",
    "3. Generate feature visualizations to understand learned representations\n",
    "4. Create saliency maps to identify important input regions\n",
    "5. Interpret model predictions and assess confidence\n",
    "6. Apply basic interpretability techniques for explainable AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Model Interpretation Matters\n",
    "\n",
    "Neural networks are often called \"black boxes\" - they make predictions, but we don't know why.\n",
    "\n",
    "**Why we need interpretability**:\n",
    "- **Trust**: Understand if model reasons are valid\n",
    "- **Debugging**: Find what model learned wrong\n",
    "- **Compliance**: Legal requirements in healthcare, finance\n",
    "- **Improvement**: Identify areas for model enhancement\n",
    "- **Fairness**: Detect biases and discriminatory patterns\n",
    "\n",
    "**Levels of Interpretation**:\n",
    "1. **Global**: What has the model learned overall?\n",
    "2. **Local**: Why did the model make this specific prediction?\n",
    "3. **Layer-wise**: What does each layer represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.datasets import mnist, cifar10\n",
    "\n",
    "# Image processing\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Plotting configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data and Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load MNIST for clear visualization\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize and reshape\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a CNN for MNIST\n",
    "def create_mnist_cnn():\n",
    "    \"\"\"Create CNN with multiple conv layers for visualization.\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # First conv block\n",
    "        layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1'),\n",
    "        layers.MaxPooling2D((2, 2), name='pool1'),\n",
    "        \n",
    "        # Second conv block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2'),\n",
    "        layers.MaxPooling2D((2, 2), name='pool2'),\n",
    "        \n",
    "        # Third conv block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv3'),\n",
    "        \n",
    "        # Classification head\n",
    "        layers.Flatten(name='flatten'),\n",
    "        layers.Dense(128, activation='relu', name='dense1'),\n",
    "        layers.Dropout(0.5, name='dropout'),\n",
    "        layers.Dense(10, activation='softmax', name='output')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and train model\n",
    "model = create_mnist_cnn()\n",
    "print(\"Model Architecture:\")\n",
    "model.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train the model\n",
    "print(\"\\nTraining model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nTest accuracy: {test_acc:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing Layer Activations\n",
    "\n",
    "**Layer activations** show how the network transforms input through successive layers.\n",
    "\n",
    "**What we'll see**:\n",
    "- **Early layers**: Detect simple features (edges, corners)\n",
    "- **Middle layers**: Combine features into patterns\n",
    "- **Late layers**: Abstract, high-level representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def visualize_activations(model, image, layer_names=None):\n",
    "    \"\"\"\n",
    "    Visualize activations from specified layers.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        image: Input image (single sample)\n",
    "        layer_names: List of layer names to visualize (default: all conv layers)\n",
    "    \"\"\"\n",
    "    # Get all convolutional layers if not specified\n",
    "    if layer_names is None:\n",
    "        layer_names = [layer.name for layer in model.layers \n",
    "                      if isinstance(layer, layers.Conv2D)]\n",
    "    \n",
    "    # Create models to extract layer outputs\n",
    "    layer_outputs = [model.get_layer(name).output for name in layer_names]\n",
    "    activation_model = keras.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    \n",
    "    # Get activations\n",
    "    activations = activation_model.predict(image[np.newaxis, ...], verbose=0)\n",
    "    \n",
    "    # Visualize\n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        n_features = layer_activation.shape[-1]  # Number of filters\n",
    "        size = layer_activation.shape[1]  # Feature map size\n",
    "        \n",
    "        # Display up to 16 filters per layer\n",
    "        n_cols = 8\n",
    "        n_rows = min(2, (n_features + n_cols - 1) // n_cols)\n",
    "        n_display = min(16, n_features)\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 1.5, n_rows * 1.5))\n",
    "        fig.suptitle(f'Layer: {layer_name} ({n_features} filters, {size}x{size})', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        \n",
    "        axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
    "        \n",
    "        for i in range(n_cols * n_rows):\n",
    "            if i < n_display:\n",
    "                # Display feature map\n",
    "                axes[i].imshow(layer_activation[0, :, :, i], cmap='viridis')\n",
    "                axes[i].set_title(f'Filter {i}', fontsize=9)\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Select a test image\n",
    "test_image = X_test[0]\n",
    "test_label = y_test[0]\n",
    "\n",
    "# Display the input image\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(test_image.squeeze(), cmap='gray')\n",
    "plt.title(f'Input Image (Label: {test_label})', fontsize=12, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Visualize activations\n",
    "print(\"Visualizing layer activations...\\n\")\n",
    "visualize_activations(model, test_image)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filter Visualization\n",
    "\n",
    "**Filter Visualization** shows what patterns each filter is designed to detect.\n",
    "\n",
    "We'll visualize the actual learned weights of convolutional filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def visualize_conv_filters(model, layer_name, max_filters=16):\n",
    "    \"\"\"\n",
    "    Visualize convolutional filter weights.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        layer_name: Name of convolutional layer\n",
    "        max_filters: Maximum number of filters to display\n",
    "    \"\"\"\n",
    "    # Get layer weights\n",
    "    layer = model.get_layer(layer_name)\n",
    "    filters = layer.get_weights()[0]  # Shape: (height, width, input_channels, output_channels)\n",
    "    \n",
    "    n_filters = min(max_filters, filters.shape[-1])\n",
    "    n_cols = 8\n",
    "    n_rows = (n_filters + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "    fig.suptitle(f'Filters from {layer_name}', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
    "    \n",
    "    for i in range(n_cols * n_rows):\n",
    "        if i < n_filters:\n",
    "            # Get filter (average across input channels if multiple)\n",
    "            filt = filters[:, :, :, i]\n",
    "            if filt.shape[-1] > 1:\n",
    "                filt = filt.mean(axis=-1)\n",
    "            else:\n",
    "                filt = filt.squeeze()\n",
    "            \n",
    "            # Normalize for visualization\n",
    "            filt = (filt - filt.min()) / (filt.max() - filt.min() + 1e-8)\n",
    "            \n",
    "            axes[i].imshow(filt, cmap='gray')\n",
    "            axes[i].set_title(f'{i}', fontsize=8)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize filters from first convolutional layer\n",
    "print(\"First layer filters (detecting basic patterns like edges):\")\n",
    "visualize_conv_filters(model, 'conv1', max_filters=16)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saliency Maps (Gradient-based Visualization)\n",
    "\n",
    "**Saliency Maps** highlight which input pixels are most important for a prediction.\n",
    "\n",
    "**Method**: Compute gradient of output with respect to input:\n",
    "$$\\text{Saliency}(x) = \\left|\\frac{\\partial y_c}{\\partial x}\\right|$$\n",
    "\n",
    "where $y_c$ is the score for class $c$.\n",
    "\n",
    "**Interpretation**: Pixels with large gradients have strong influence on the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def generate_saliency_map(model, image, class_idx):\n",
    "    \"\"\"\n",
    "    Generate saliency map showing important regions for prediction.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        image: Input image\n",
    "        class_idx: Target class index\n",
    "    \n",
    "    Returns:\n",
    "        Saliency map (same size as input)\n",
    "    \"\"\"\n",
    "    # Convert to tensor\n",
    "    image_tensor = tf.Variable(image[np.newaxis, ...])\n",
    "    \n",
    "    # Compute gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(image_tensor)\n",
    "        target_class = predictions[:, class_idx]\n",
    "    \n",
    "    # Get gradient with respect to input\n",
    "    gradients = tape.gradient(target_class, image_tensor)\n",
    "    \n",
    "    # Take absolute value and reduce to 2D (if multiple channels)\n",
    "    saliency = tf.abs(gradients).numpy().squeeze()\n",
    "    if len(saliency.shape) == 3:\n",
    "        saliency = saliency.max(axis=-1)\n",
    "    \n",
    "    return saliency\n",
    "\n",
    "def visualize_saliency(model, image, true_label):\n",
    "    \"\"\"\n",
    "    Visualize saliency map for an image.\n",
    "    \"\"\"\n",
    "    # Get model prediction\n",
    "    prediction = model.predict(image[np.newaxis, ...], verbose=0)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    confidence = prediction[0][predicted_class]\n",
    "    \n",
    "    # Generate saliency map\n",
    "    saliency = generate_saliency_map(model, image, predicted_class)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(image.squeeze(), cmap='gray')\n",
    "    axes[0].set_title(f'Input Image\\nTrue: {true_label}, Pred: {predicted_class}', \n",
    "                     fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Saliency map\n",
    "    axes[1].imshow(saliency, cmap='hot')\n",
    "    axes[1].set_title('Saliency Map\\n(Brighter = More Important)', fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    axes[2].imshow(image.squeeze(), cmap='gray', alpha=0.6)\n",
    "    axes[2].imshow(saliency, cmap='hot', alpha=0.4)\n",
    "    axes[2].set_title(f'Overlay\\nConfidence: {confidence:.2%}', fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate saliency maps for several test images\n",
    "print(\"Saliency Maps - What does the model focus on?\\n\")\n",
    "for i in range(3):\n",
    "    visualize_saliency(model, X_test[i], y_test[i])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Class Activation Maps (CAM)\n",
    "\n",
    "**Class Activation Maps** show which regions of the image are most relevant for a specific class.\n",
    "\n",
    "**How it works**:\n",
    "1. Take the last convolutional layer's output\n",
    "2. Weight each feature map by its importance to the predicted class\n",
    "3. Sum weighted feature maps to create heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def generate_class_activation_map(model, image, last_conv_layer_name, pred_index=None):\n",
    "    \"\"\"\n",
    "    Generate class activation map (CAM) for an image.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        image: Input image\n",
    "        last_conv_layer_name: Name of last convolutional layer\n",
    "        pred_index: Class index (if None, use predicted class)\n",
    "    \n",
    "    Returns:\n",
    "        CAM heatmap\n",
    "    \"\"\"\n",
    "    # Create model that outputs both predictions and last conv layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    \n",
    "    grad_model = keras.Model(\n",
    "        inputs=model.input,\n",
    "        outputs=[last_conv_layer.output, model.output]\n",
    "    )\n",
    "    \n",
    "    # Get gradients and predictions\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(image[np.newaxis, ...])\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "    \n",
    "    # Gradient of class score with respect to feature maps\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    \n",
    "    # Global average pooling of gradients\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    # Weight feature maps by gradients\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    \n",
    "    # Normalize heatmap\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    \n",
    "    return heatmap.numpy()\n",
    "\n",
    "def visualize_cam(model, image, true_label, last_conv_layer_name='conv3'):\n",
    "    \"\"\"\n",
    "    Visualize Class Activation Map.\n",
    "    \"\"\"\n",
    "    # Get prediction\n",
    "    prediction = model.predict(image[np.newaxis, ...], verbose=0)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    confidence = prediction[0][predicted_class]\n",
    "    \n",
    "    # Generate CAM\n",
    "    heatmap = generate_class_activation_map(model, image, last_conv_layer_name)\n",
    "    \n",
    "    # Resize heatmap to match input image size\n",
    "    img_size = image.shape[0]\n",
    "    heatmap_resized = zoom(heatmap, img_size / heatmap.shape[0])\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    # Original\n",
    "    axes[0].imshow(image.squeeze(), cmap='gray')\n",
    "    axes[0].set_title(f'Input Image\\nTrue: {true_label}, Pred: {predicted_class}',\n",
    "                     fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # CAM heatmap\n",
    "    axes[1].imshow(heatmap_resized, cmap='jet')\n",
    "    axes[1].set_title('Class Activation Map\\n(Red = Most Important)', fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    axes[2].imshow(image.squeeze(), cmap='gray', alpha=0.6)\n",
    "    axes[2].imshow(heatmap_resized, cmap='jet', alpha=0.4)\n",
    "    axes[2].set_title(f'Overlay\\nConfidence: {confidence:.2%}', fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize CAMs\n",
    "print(\"Class Activation Maps - Where does the model look?\\n\")\n",
    "for i in range(3):\n",
    "    visualize_cam(model, X_test[i], y_test[i])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prediction Confidence and Uncertainty\n",
    "\n",
    "Understanding model confidence is crucial for:\n",
    "- Knowing when to trust predictions\n",
    "- Identifying ambiguous cases\n",
    "- Detecting out-of-distribution samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_prediction_confidence(model, X_samples, y_true, n_samples=10):\n",
    "    \"\"\"\n",
    "    Analyze and visualize prediction confidence.\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    predictions = model.predict(X_samples[:n_samples], verbose=0)\n",
    "    \n",
    "    # Plot each prediction\n",
    "    fig, axes = plt.subplots(n_samples, 2, figsize=(10, n_samples * 1.5))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Display image\n",
    "        axes[i, 0].imshow(X_samples[i].squeeze(), cmap='gray')\n",
    "        axes[i, 0].set_title(f'True Label: {y_true[i]}', fontsize=10)\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Display confidence distribution\n",
    "        pred_probs = predictions[i]\n",
    "        predicted_class = np.argmax(pred_probs)\n",
    "        confidence = pred_probs[predicted_class]\n",
    "        \n",
    "        colors = ['green' if j == predicted_class else 'lightblue' for j in range(10)]\n",
    "        axes[i, 1].bar(range(10), pred_probs, color=colors, alpha=0.7)\n",
    "        axes[i, 1].set_ylim([0, 1])\n",
    "        axes[i, 1].set_xlabel('Class', fontsize=9)\n",
    "        axes[i, 1].set_ylabel('Probability', fontsize=9)\n",
    "        \n",
    "        # Title shows prediction and confidence\n",
    "        correct = predicted_class == y_true[i]\n",
    "        status = \"✓\" if correct else \"✗\"\n",
    "        axes[i, 1].set_title(f'{status} Pred: {predicted_class} (Conf: {confidence:.2%})',\n",
    "                            fontsize=10,\n",
    "                            color='green' if correct else 'red')\n",
    "        axes[i, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle('Prediction Confidence Analysis', fontsize=14, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analyze predictions\n",
    "analyze_prediction_confidence(model, X_test, y_test, n_samples=5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Identify high and low confidence predictions\n",
    "def find_confidence_extremes(model, X_test, y_test, n_show=3):\n",
    "    \"\"\"\n",
    "    Find and display highest and lowest confidence predictions.\n",
    "    \"\"\"\n",
    "    # Get all predictions\n",
    "    predictions = model.predict(X_test[:1000], verbose=0)\n",
    "    \n",
    "    # Calculate confidence (max probability)\n",
    "    confidences = np.max(predictions, axis=1)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Check correctness\n",
    "    correct = predicted_classes == y_test[:1000]\n",
    "    \n",
    "    # Find high confidence correct and incorrect\n",
    "    high_conf_correct = np.where(correct & (confidences > 0.99))[0]\n",
    "    high_conf_incorrect = np.where(~correct & (confidences > 0.90))[0]\n",
    "    low_conf_correct = np.where(correct & (confidences < 0.80))[0]\n",
    "    \n",
    "    print(f\"High confidence correct: {len(high_conf_correct)} samples\")\n",
    "    print(f\"High confidence incorrect: {len(high_conf_incorrect)} samples (model is confidently wrong!)\")\n",
    "    print(f\"Low confidence correct: {len(low_conf_correct)} samples (model unsure but right)\")\n",
    "    \n",
    "    # Visualize examples\n",
    "    fig, axes = plt.subplots(3, n_show, figsize=(n_show * 3, 9))\n",
    "    \n",
    "    categories = [\n",
    "        ('High Confidence Correct', high_conf_correct),\n",
    "        ('High Confidence WRONG', high_conf_incorrect),\n",
    "        ('Low Confidence Correct', low_conf_correct)\n",
    "    ]\n",
    "    \n",
    "    for row, (title, indices) in enumerate(categories):\n",
    "        for col in range(n_show):\n",
    "            if col < len(indices):\n",
    "                idx = indices[col]\n",
    "                axes[row, col].imshow(X_test[idx].squeeze(), cmap='gray')\n",
    "                axes[row, col].set_title(\n",
    "                    f'True: {y_test[idx]}\\n'\n",
    "                    f'Pred: {predicted_classes[idx]}\\n'\n",
    "                    f'Conf: {confidences[idx]:.2%}',\n",
    "                    fontsize=9\n",
    "                )\n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        axes[row, 0].set_ylabel(title, fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "find_confidence_extremes(model, X_test, y_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Space Visualization (t-SNE)\n",
    "\n",
    "**t-SNE** (t-Distributed Stochastic Neighbor Embedding) visualizes high-dimensional learned features in 2D.\n",
    "\n",
    "This shows how well the model separates different classes in its internal representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize_feature_space(model, X_samples, y_samples, layer_name='dense1', n_samples=1000):\n",
    "    \"\"\"\n",
    "    Visualize learned feature representations using t-SNE.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_samples: Input samples\n",
    "        y_samples: Labels\n",
    "        layer_name: Layer to extract features from\n",
    "        n_samples: Number of samples to visualize\n",
    "    \"\"\"\n",
    "    # Extract features from specified layer\n",
    "    feature_model = keras.Model(\n",
    "        inputs=model.input,\n",
    "        outputs=model.get_layer(layer_name).output\n",
    "    )\n",
    "    \n",
    "    print(f\"Extracting features from layer '{layer_name}'...\")\n",
    "    features = feature_model.predict(X_samples[:n_samples], verbose=0)\n",
    "    \n",
    "    # Apply t-SNE\n",
    "    print(\"Applying t-SNE (this may take a minute)...\")\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "    features_2d = tsne.fit_transform(features)\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter = plt.scatter(\n",
    "        features_2d[:, 0], \n",
    "        features_2d[:, 1],\n",
    "        c=y_samples[:n_samples],\n",
    "        cmap='tab10',\n",
    "        alpha=0.6,\n",
    "        s=20\n",
    "    )\n",
    "    plt.colorbar(scatter, label='Class')\n",
    "    plt.title(f'Feature Space Visualization (t-SNE)\\nLayer: {layer_name}',\n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('t-SNE Component 1', fontsize=12)\n",
    "    plt.ylabel('t-SNE Component 2', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"- Well-separated clusters = Model learned distinct class representations\")\n",
    "    print(\"- Overlapping clusters = Model struggles to distinguish these classes\")\n",
    "    print(\"- Outliers = Potentially mislabeled or difficult samples\")\n",
    "\n",
    "# Visualize feature space\n",
    "visualize_feature_space(model, X_test, y_test, layer_name='dense1', n_samples=1000)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exercise 1: Activation Maximization\n",
    "\n",
    "**Task**: Generate images that maximally activate specific neurons or classes.\n",
    "\n",
    "**Concept**: Start with random noise and use gradient ascent to modify the image to maximize a neuron's activation.\n",
    "\n",
    "**Requirements**:\n",
    "1. Implement gradient ascent to maximize class scores\n",
    "2. Generate images for at least 3 different classes\n",
    "3. Apply regularization (total variation, L2 norm) for better visualizations\n",
    "4. Display the generated \"ideal\" images for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# YOUR CODE HERE\n",
    "# Hint: Use tf.GradientTape to compute gradients w.r.t. input\n",
    "# Update input image to maximize class score\n",
    "# Apply regularization to get interpretable images\n",
    "\n",
    "pass  # Replace with your implementation"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Exercise 2: Adversarial Examples\n",
    "\n",
    "**Task**: Create adversarial examples - images that look normal to humans but fool the network.\n",
    "\n",
    "**Concept**: Add small perturbations to images to change predictions.\n",
    "\n",
    "**Requirements**:\n",
    "1. Implement Fast Gradient Sign Method (FGSM)\n",
    "2. Generate adversarial examples with different perturbation strengths (epsilon)\n",
    "3. Visualize original vs adversarial images and their predictions\n",
    "4. Analyze how perturbation strength affects attack success\n",
    "5. Discuss implications for model robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# YOUR CODE HERE\n",
    "# Hint: FGSM formula: x_adv = x + epsilon * sign(gradient)\n",
    "# Test with epsilon values: 0.01, 0.05, 0.1, 0.2\n",
    "\n",
    "pass  # Replace with your implementation"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Exercise 3: Layer-wise Relevance Propagation (LRP)\n",
    "\n",
    "**Task**: Implement a simplified version of Layer-wise Relevance Propagation.\n",
    "\n",
    "**Concept**: Backpropagate relevance scores from output to input to identify which features contributed to the prediction.\n",
    "\n",
    "**Requirements**:\n",
    "1. Implement relevance propagation for at least the final dense layers\n",
    "2. Visualize relevance scores as heatmaps\n",
    "3. Compare LRP with saliency maps\n",
    "4. Analyze which method provides more interpretable results\n",
    "5. Test on both correct and incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# YOUR CODE HERE\n",
    "# Hint: LRP propagates relevance backward through layers\n",
    "# R_i = sum_j (w_ij * a_i / sum_k w_kj * a_k) * R_j\n",
    "\n",
    "pass  # Replace with your implementation"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary\n",
    "\n",
    "### Key Concepts Covered:\n",
    "\n",
    "1. **Layer Activations**\n",
    "   - Visualize how networks transform inputs through layers\n",
    "   - Early layers detect simple features, late layers detect complex patterns\n",
    "   - Helps understand what representations the model learns\n",
    "\n",
    "2. **Filter Visualization**\n",
    "   - Shows what patterns convolutional filters detect\n",
    "   - First layer filters often resemble edge/blob detectors\n",
    "   - Deeper layers learn more abstract patterns\n",
    "\n",
    "3. **Saliency Maps**\n",
    "   - Gradient-based method to find important input regions\n",
    "   - Formula: $|\\partial y_c / \\partial x|$\n",
    "   - Quick and simple but can be noisy\n",
    "\n",
    "4. **Class Activation Maps (CAM)**\n",
    "   - Show which regions activated for specific classes\n",
    "   - More localized than saliency maps\n",
    "   - Useful for understanding spatial attention\n",
    "\n",
    "5. **Prediction Confidence**\n",
    "   - Softmax outputs indicate model uncertainty\n",
    "   - High confidence doesn't always mean correct!\n",
    "   - Important for knowing when to trust predictions\n",
    "\n",
    "6. **Feature Space Visualization**\n",
    "   - t-SNE shows how model organizes classes internally\n",
    "   - Well-separated clusters indicate good learning\n",
    "   - Reveals which classes model confuses\n",
    "\n",
    "### Interpretation Techniques Summary:\n",
    "\n",
    "| Technique | Purpose | Pros | Cons |\n",
    "|-----------|---------|------|------|\n",
    "| **Activations** | See layer outputs | Direct view of processing | Hard to interpret deep layers |\n",
    "| **Saliency Maps** | Important input pixels | Fast, simple | Noisy, not always interpretable |\n",
    "| **CAM** | Class-specific attention | Localized, intuitive | Requires specific architecture |\n",
    "| **t-SNE** | Class separation | Global view | Slow, parameters matter |\n",
    "| **LIME/SHAP** | Local explanations | Model-agnostic | Computationally expensive |\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- Use multiple interpretation methods (they complement each other)\n",
    "- Always validate interpretations with domain knowledge\n",
    "- Be skeptical of overconfident predictions\n",
    "- Test model on edge cases and adversarial examples\n",
    "- Document model limitations and failure modes\n",
    "\n",
    "### Ethical Considerations:\n",
    "\n",
    "- **Fairness**: Check if model focuses on biased features\n",
    "- **Transparency**: Explain model decisions to stakeholders\n",
    "- **Safety**: Understand failure modes before deployment\n",
    "- **Privacy**: Ensure visualizations don't reveal sensitive data\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "- [Module 13: PyTorch Introduction](13_pytorch_introduction.ipynb)\n",
    "- Advanced interpretability: LIME, SHAP, Integrated Gradients\n",
    "- Attention mechanisms and Transformers\n",
    "\n",
    "### Additional Resources:\n",
    "\n",
    "1. \"Visualizing and Understanding Convolutional Networks\" (Zeiler & Fergus, 2014)\n",
    "2. \"Deep Inside Convolutional Networks\" (Simonyan et al., 2013)\n",
    "3. LIME paper: \"Why Should I Trust You?\" (Ribeiro et al., 2016)\n",
    "4. Distill.pub: https://distill.pub/ (excellent interactive visualizations)\n",
    "5. TensorFlow Lucid: https://github.com/tensorflow/lucid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
