{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 14: Final Project - Complete Deep Learning Pipeline\n",
    "\n",
    "**Difficulty**: â­â­â­ (Advanced)\n",
    "\n",
    "**Estimated Time**: 90-120 minutes\n",
    "\n",
    "**Prerequisites**: \n",
    "- All previous modules (00-13)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Design and implement a complete end-to-end deep learning pipeline\n",
    "2. Integrate data preprocessing, model training, evaluation, and deployment preparation\n",
    "3. Apply best practices from all previous modules\n",
    "4. Create a production-ready deep learning solution\n",
    "5. Document and present your work professionally\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**Goal**: Build a complete image classification system for Fashion-MNIST with production-quality code.\n",
    "\n",
    "**Pipeline Components**:\n",
    "1. Data loading and preprocessing\n",
    "2. Exploratory data analysis\n",
    "3. Model architecture design\n",
    "4. Training with best practices\n",
    "5. Hyperparameter tuning\n",
    "6. Model evaluation and interpretation\n",
    "7. Error analysis\n",
    "8. Model deployment preparation\n",
    "\n",
    "**Success Criteria**:\n",
    "- Test accuracy > 90%\n",
    "- Well-documented code\n",
    "- Comprehensive evaluation\n",
    "- Deployment-ready model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    ")\n",
    "\n",
    "# Evaluation and visualization\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, \n",
    "    roc_curve, auc, precision_recall_curve\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Display versions\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "\n",
    "# Create directories for outputs\n",
    "OUTPUT_DIR = Path('outputs')\n",
    "MODELS_DIR = OUTPUT_DIR / 'models'\n",
    "PLOTS_DIR = OUTPUT_DIR / 'plots'\n",
    "LOGS_DIR = OUTPUT_DIR / 'logs'\n",
    "\n",
    "for directory in [OUTPUT_DIR, MODELS_DIR, PLOTS_DIR, LOGS_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\nProject directories created successfully.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load Fashion-MNIST dataset\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Class names\n",
    "class_names = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(f\"Training samples: {len(X_train_full)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Image shape: {X_train_full[0].shape}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocessing function\n",
    "def preprocess_data(X, y, validation_split=0.1):\n",
    "    \"\"\"\n",
    "    Preprocess image data with best practices.\n",
    "    \n",
    "    Args:\n",
    "        X: Images array\n",
    "        y: Labels array\n",
    "        validation_split: Fraction for validation set\n",
    "    \n",
    "    Returns:\n",
    "        Preprocessed train, validation data\n",
    "    \"\"\"\n",
    "    # Normalize to [0, 1]\n",
    "    X = X.astype('float32') / 255.0\n",
    "    \n",
    "    # Reshape for CNN (add channel dimension)\n",
    "    X = X.reshape(-1, 28, 28, 1)\n",
    "    \n",
    "    # Split into train and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, \n",
    "        test_size=validation_split,\n",
    "        random_state=RANDOM_SEED,\n",
    "        stratify=y  # Maintain class distribution\n",
    "    )\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "# Preprocess training data\n",
    "X_train, X_val, y_train, y_val = preprocess_data(X_train_full, y_train_full)\n",
    "\n",
    "# Preprocess test data\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(\"\\nData preprocessed:\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nValue range: [{X_train.min()}, {X_train.max()}]\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize sample images\n",
    "def plot_sample_images(X, y, class_names, n_samples=10):\n",
    "    \"\"\"Plot sample images from each class.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        axes[i].imshow(X[i].squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'{class_names[y[i]]}', fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Images from Dataset', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'sample_images.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_sample_images(X_train, y_train, class_names)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Class distribution analysis\n",
    "def analyze_class_distribution(y_train, y_val, y_test, class_names):\n",
    "    \"\"\"Analyze and visualize class distribution.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    datasets = [\n",
    "        ('Training', y_train),\n",
    "        ('Validation', y_val),\n",
    "        ('Test', y_test)\n",
    "    ]\n",
    "    \n",
    "    for ax, (name, y) in zip(axes, datasets):\n",
    "        counts = np.bincount(y)\n",
    "        ax.bar(range(len(counts)), counts, alpha=0.7)\n",
    "        ax.set_xlabel('Class', fontsize=11)\n",
    "        ax.set_ylabel('Count', fontsize=11)\n",
    "        ax.set_title(f'{name} Set Distribution', fontsize=12, fontweight='bold')\n",
    "        ax.set_xticks(range(len(class_names)))\n",
    "        ax.set_xticklabels(class_names, rotation=45, ha='right', fontsize=9)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Check balance\n",
    "    train_counts = np.bincount(y_train)\n",
    "    balance_ratio = train_counts.max() / train_counts.min()\n",
    "    print(f\"\\nClass balance ratio: {balance_ratio:.2f}\")\n",
    "    if balance_ratio < 1.5:\n",
    "        print(\"âœ“ Dataset is well-balanced\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Dataset has class imbalance - consider using class weights\")\n",
    "\n",
    "analyze_class_distribution(y_train, y_val, y_test, class_names)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_cnn_model(input_shape=(28, 28, 1), num_classes=10):\n",
    "    \"\"\"\n",
    "    Create CNN model with best practices:\n",
    "    - Batch normalization for stable training\n",
    "    - Dropout for regularization\n",
    "    - Global average pooling to reduce parameters\n",
    "    - Proper initialization\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # Input layer\n",
    "        layers.InputLayer(input_shape=input_shape),\n",
    "        \n",
    "        # First conv block\n",
    "        layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second conv block\n",
    "        layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third conv block\n",
    "        layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Classification head\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(128, activation='relu', kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ], name='FashionMNIST_CNN')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_cnn_model()\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "model.summary()\n",
    "\n",
    "# Calculate model size\n",
    "total_params = model.count_params()\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Estimated model size: {total_params * 4 / 1024 / 1024:.2f} MB (float32)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Configuration and Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compile model with best practices\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]\n",
    ")\n",
    "\n",
    "# Setup callbacks\n",
    "callbacks = [\n",
    "    # Early stopping to prevent overfitting\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Save best model\n",
    "    ModelCheckpoint(\n",
    "        filepath=str(MODELS_DIR / 'best_model.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate on plateau\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # TensorBoard logging\n",
    "    TensorBoard(\n",
    "        log_dir=str(LOGS_DIR / datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Training configuration completed.\")\n",
    "print(\"Callbacks configured:\")\n",
    "print(\"  âœ“ Early stopping (patience=10)\")\n",
    "print(\"  âœ“ Model checkpoint (save best)\")\n",
    "print(\"  âœ“ Learning rate reduction\")\n",
    "print(\"  âœ“ TensorBoard logging\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train model\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot comprehensive training history.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history.history['loss'], label='Training', linewidth=2)\n",
    "    axes[0, 0].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch', fontsize=11)\n",
    "    axes[0, 0].set_ylabel('Loss', fontsize=11)\n",
    "    axes[0, 0].set_title('Model Loss', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].legend(fontsize=10)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(history.history['accuracy'], label='Training', linewidth=2)\n",
    "    axes[0, 1].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Epoch', fontsize=11)\n",
    "    axes[0, 1].set_ylabel('Accuracy', fontsize=11)\n",
    "    axes[0, 1].set_title('Model Accuracy', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].legend(fontsize=10)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate (if available)\n",
    "    if 'lr' in history.history:\n",
    "        axes[1, 0].plot(history.history['lr'], linewidth=2, color='orange')\n",
    "        axes[1, 0].set_xlabel('Epoch', fontsize=11)\n",
    "        axes[1, 0].set_ylabel('Learning Rate', fontsize=11)\n",
    "        axes[1, 0].set_title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
    "        axes[1, 0].set_yscale('log')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Overfitting analysis\n",
    "    train_loss = np.array(history.history['loss'])\n",
    "    val_loss = np.array(history.history['val_loss'])\n",
    "    gap = val_loss - train_loss\n",
    "    \n",
    "    axes[1, 1].plot(gap, linewidth=2, color='red')\n",
    "    axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[1, 1].fill_between(range(len(gap)), gap, 0, where=(gap > 0), \n",
    "                            alpha=0.3, color='red', label='Overfitting')\n",
    "    axes[1, 1].set_xlabel('Epoch', fontsize=11)\n",
    "    axes[1, 1].set_ylabel('Val Loss - Train Loss', fontsize=11)\n",
    "    axes[1, 1].set_title('Overfitting Gap', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].legend(fontsize=10)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# Print final metrics\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "best_val_acc = max(history.history['val_accuracy'])\n",
    "\n",
    "print(f\"\\nFinal Training Accuracy: {final_train_acc:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\\n\")\n",
    "test_results = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(f\"\\nTest Loss: {test_results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {test_results[1]:.4f}\")\n",
    "print(f\"Test Top-3 Accuracy: {test_results[2]:.4f}\")\n",
    "\n",
    "# Check success criteria\n",
    "if test_results[1] >= 0.90:\n",
    "    print(\"\\nâœ“ SUCCESS: Achieved >90% test accuracy!\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Test accuracy is {test_results[1]:.2%}, target is 90%\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate predictions\n",
    "y_pred_proba = model.predict(X_test, verbose=0)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    \"\"\"Plot confusion matrix with percentages.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Percentage (%)'})\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.title('Confusion Matrix (Percentages)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, class_names)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Per-class performance report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "# Identify best and worst performing classes\n",
    "report_dict = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)\n",
    "class_f1_scores = {name: report_dict[name]['f1-score'] for name in class_names}\n",
    "\n",
    "best_class = max(class_f1_scores, key=class_f1_scores.get)\n",
    "worst_class = min(class_f1_scores, key=class_f1_scores.get)\n",
    "\n",
    "print(f\"\\nBest performing class: {best_class} (F1: {class_f1_scores[best_class]:.4f})\")\n",
    "print(f\"Worst performing class: {worst_class} (F1: {class_f1_scores[worst_class]:.4f})\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Find misclassified samples\n",
    "def analyze_errors(X_test, y_test, y_pred, y_pred_proba, class_names):\n",
    "    \"\"\"Analyze and visualize misclassified samples.\"\"\"\n",
    "    # Find errors\n",
    "    errors = y_test != y_pred\n",
    "    error_indices = np.where(errors)[0]\n",
    "    \n",
    "    print(f\"Total errors: {len(error_indices)} / {len(y_test)} ({len(error_indices)/len(y_test)*100:.2f}%)\")\n",
    "    \n",
    "    # Sort by prediction confidence (high confidence errors are most interesting)\n",
    "    confidences = np.max(y_pred_proba, axis=1)\n",
    "    error_confidences = confidences[errors]\n",
    "    sorted_indices = error_indices[np.argsort(error_confidences)[::-1]]\n",
    "    \n",
    "    # Visualize top confident mistakes\n",
    "    fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, idx in enumerate(sorted_indices[:15]):\n",
    "        axes[i].imshow(X_test[idx].squeeze(), cmap='gray')\n",
    "        true_label = class_names[y_test[idx]]\n",
    "        pred_label = class_names[y_pred[idx]]\n",
    "        confidence = confidences[idx]\n",
    "        \n",
    "        axes[i].set_title(\n",
    "            f'True: {true_label}\\n'\n",
    "            f'Pred: {pred_label}\\n'\n",
    "            f'Conf: {confidence:.2%}',\n",
    "            fontsize=9,\n",
    "            color='red'\n",
    "        )\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Top 15 Confident Mistakes', fontsize=14, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'error_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "analyze_errors(X_test, y_test, y_pred, y_pred_proba, class_names)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze prediction confidence distribution\n",
    "def analyze_confidence_distribution(y_test, y_pred, y_pred_proba):\n",
    "    \"\"\"Analyze prediction confidence for correct and incorrect predictions.\"\"\"\n",
    "    confidences = np.max(y_pred_proba, axis=1)\n",
    "    correct = y_test == y_pred\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Confidence distribution\n",
    "    axes[0].hist(confidences[correct], bins=50, alpha=0.7, label='Correct', color='green')\n",
    "    axes[0].hist(confidences[~correct], bins=50, alpha=0.7, label='Incorrect', color='red')\n",
    "    axes[0].set_xlabel('Prediction Confidence', fontsize=11)\n",
    "    axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[0].set_title('Confidence Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[0].legend(fontsize=10)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy vs confidence\n",
    "    bins = np.linspace(0, 1, 11)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    bin_accuracies = []\n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "        mask = (confidences >= bins[i]) & (confidences < bins[i+1])\n",
    "        if mask.sum() > 0:\n",
    "            bin_accuracies.append(correct[mask].mean())\n",
    "        else:\n",
    "            bin_accuracies.append(0)\n",
    "    \n",
    "    axes[1].plot(bin_centers, bin_accuracies, 'o-', linewidth=2, markersize=8)\n",
    "    axes[1].plot([0, 1], [0, 1], '--', color='gray', label='Perfect Calibration')\n",
    "    axes[1].set_xlabel('Prediction Confidence', fontsize=11)\n",
    "    axes[1].set_ylabel('Actual Accuracy', fontsize=11)\n",
    "    axes[1].set_title('Model Calibration', fontsize=12, fontweight='bold')\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_xlim([0, 1])\n",
    "    axes[1].set_ylim([0, 1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'confidence_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nAverage confidence (correct): {confidences[correct].mean():.4f}\")\n",
    "    print(f\"Average confidence (incorrect): {confidences[~correct].mean():.4f}\")\n",
    "\n",
    "analyze_confidence_distribution(y_test, y_pred, y_pred_proba)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Deployment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save final model\n",
    "final_model_path = MODELS_DIR / 'fashion_mnist_final.h5'\n",
    "model.save(final_model_path)\n",
    "print(f\"Final model saved to: {final_model_path}\")\n",
    "\n",
    "# Save model configuration\n",
    "config = {\n",
    "    'model_name': 'FashionMNIST_CNN',\n",
    "    'version': '1.0',\n",
    "    'created_at': datetime.now().isoformat(),\n",
    "    'input_shape': [28, 28, 1],\n",
    "    'num_classes': 10,\n",
    "    'class_names': class_names,\n",
    "    'preprocessing': {\n",
    "        'normalization': 'divide by 255',\n",
    "        'input_range': [0, 1]\n",
    "    },\n",
    "    'performance': {\n",
    "        'test_accuracy': float(test_results[1]),\n",
    "        'test_loss': float(test_results[0]),\n",
    "        'test_top3_accuracy': float(test_results[2])\n",
    "    },\n",
    "    'training': {\n",
    "        'epochs_trained': len(history.history['loss']),\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'optimizer': 'Adam',\n",
    "        'initial_lr': 0.001\n",
    "    }\n",
    "}\n",
    "\n",
    "config_path = MODELS_DIR / 'model_config.json'\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"Model configuration saved to: {config_path}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create inference function\n",
    "def create_inference_function(model, class_names):\n",
    "    \"\"\"\n",
    "    Create a production-ready inference function.\n",
    "    \"\"\"\n",
    "    def predict_image(image):\n",
    "        \"\"\"\n",
    "        Predict class for a single image.\n",
    "        \n",
    "        Args:\n",
    "            image: numpy array of shape (28, 28) or (28, 28, 1), values in [0, 255] or [0, 1]\n",
    "        \n",
    "        Returns:\n",
    "            dict with prediction results\n",
    "        \"\"\"\n",
    "        # Ensure correct shape\n",
    "        if image.shape == (28, 28):\n",
    "            image = image.reshape(28, 28, 1)\n",
    "        \n",
    "        # Normalize if needed\n",
    "        if image.max() > 1.0:\n",
    "            image = image.astype('float32') / 255.0\n",
    "        \n",
    "        # Add batch dimension\n",
    "        image_batch = np.expand_dims(image, axis=0)\n",
    "        \n",
    "        # Predict\n",
    "        predictions = model.predict(image_batch, verbose=0)[0]\n",
    "        \n",
    "        # Get top 3 predictions\n",
    "        top_3_indices = np.argsort(predictions)[-3:][::-1]\n",
    "        \n",
    "        result = {\n",
    "            'predicted_class': class_names[np.argmax(predictions)],\n",
    "            'confidence': float(predictions.max()),\n",
    "            'top_3': [\n",
    "                {\n",
    "                    'class': class_names[idx],\n",
    "                    'probability': float(predictions[idx])\n",
    "                }\n",
    "                for idx in top_3_indices\n",
    "            ],\n",
    "            'all_probabilities': {class_names[i]: float(predictions[i]) for i in range(len(class_names))}\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    return predict_image\n",
    "\n",
    "# Create inference function\n",
    "predict_image = create_inference_function(model, class_names)\n",
    "\n",
    "# Test inference function\n",
    "test_image = X_test[0]\n",
    "result = predict_image(test_image)\n",
    "\n",
    "print(\"Inference function test:\")\n",
    "print(json.dumps(result, indent=2))\n",
    "print(f\"\\nActual label: {class_names[y_test[0]]}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Project Summary and Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate project summary\n",
    "summary = f\"\"\"\n",
    "{'='*70}\n",
    "FASHION-MNIST CLASSIFICATION PROJECT SUMMARY\n",
    "{'='*70}\n",
    "\n",
    "Project Overview:\n",
    "  - Task: Multi-class image classification\n",
    "  - Dataset: Fashion-MNIST (10 clothing categories)\n",
    "  - Model: Custom CNN with batch normalization and dropout\n",
    "  - Framework: TensorFlow/Keras\n",
    "\n",
    "Dataset Statistics:\n",
    "  - Training samples: {len(X_train):,}\n",
    "  - Validation samples: {len(X_val):,}\n",
    "  - Test samples: {len(X_test):,}\n",
    "  - Image size: 28x28 grayscale\n",
    "  - Number of classes: {len(class_names)}\n",
    "\n",
    "Model Architecture:\n",
    "  - Total parameters: {model.count_params():,}\n",
    "  - Convolutional blocks: 3\n",
    "  - Dense layers: 1\n",
    "  - Regularization: Dropout + L2 + Batch Normalization\n",
    "\n",
    "Training Configuration:\n",
    "  - Optimizer: Adam (initial LR: 0.001)\n",
    "  - Batch size: {BATCH_SIZE}\n",
    "  - Epochs trained: {len(history.history['loss'])}\n",
    "  - Early stopping: Yes (patience=10)\n",
    "  - LR scheduling: ReduceLROnPlateau\n",
    "\n",
    "Performance Metrics:\n",
    "  - Test Accuracy: {test_results[1]:.4f} ({test_results[1]*100:.2f}%)\n",
    "  - Test Loss: {test_results[0]:.4f}\n",
    "  - Top-3 Accuracy: {test_results[2]:.4f} ({test_results[2]*100:.2f}%)\n",
    "  - Best class: {best_class} (F1: {class_f1_scores[best_class]:.4f})\n",
    "  - Worst class: {worst_class} (F1: {class_f1_scores[worst_class]:.4f})\n",
    "\n",
    "Success Criteria:\n",
    "  {'âœ“ ACHIEVED' if test_results[1] >= 0.90 else 'âœ— NOT MET'}: Test accuracy > 90%\n",
    "  âœ“ ACHIEVED: Well-documented code\n",
    "  âœ“ ACHIEVED: Comprehensive evaluation\n",
    "  âœ“ ACHIEVED: Deployment-ready model\n",
    "\n",
    "Files Generated:\n",
    "  - Model: {final_model_path}\n",
    "  - Config: {config_path}\n",
    "  - Plots: {len(list(PLOTS_DIR.glob('*.png')))} visualization files\n",
    "\n",
    "Best Practices Applied:\n",
    "  âœ“ Proper train/val/test split\n",
    "  âœ“ Data normalization\n",
    "  âœ“ Batch normalization for stability\n",
    "  âœ“ Dropout for regularization\n",
    "  âœ“ Early stopping to prevent overfitting\n",
    "  âœ“ Learning rate scheduling\n",
    "  âœ“ Model checkpointing\n",
    "  âœ“ Comprehensive evaluation\n",
    "  âœ“ Error analysis\n",
    "  âœ“ Production-ready inference function\n",
    "\n",
    "Next Steps:\n",
    "  1. Deploy model to production environment\n",
    "  2. Monitor model performance in production\n",
    "  3. Collect user feedback\n",
    "  4. Retrain with new data periodically\n",
    "  5. A/B test model improvements\n",
    "\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save summary to file\n",
    "summary_path = OUTPUT_DIR / 'project_summary.txt'\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(f\"\\nProject summary saved to: {summary_path}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Congratulations!\n",
    "\n",
    "You have successfully completed the Deep Learning Fundamentals series!\n",
    "\n",
    "### What You've Learned:\n",
    "\n",
    "Throughout this 15-module series (00-14), you've mastered:\n",
    "\n",
    "**Foundations (Modules 00-03)**:\n",
    "- Neural network fundamentals\n",
    "- Perceptrons and activation functions\n",
    "- Backpropagation and gradient descent\n",
    "- Building networks from scratch with NumPy\n",
    "\n",
    "**Frameworks (Modules 04-05)**:\n",
    "- TensorFlow and Keras\n",
    "- Feed-forward neural networks\n",
    "\n",
    "**Optimization (Modules 06-08)**:\n",
    "- Optimizers (SGD, Adam, RMSprop)\n",
    "- Regularization techniques\n",
    "- Loss functions and metrics\n",
    "\n",
    "**Advanced Topics (Modules 09-13)**:\n",
    "- Hyperparameter tuning\n",
    "- Transfer learning\n",
    "- Debugging neural networks\n",
    "- Model interpretation and visualization\n",
    "- PyTorch introduction\n",
    "\n",
    "**Integration (Module 14)**:\n",
    "- End-to-end deep learning pipeline\n",
    "- Production best practices\n",
    "- Model deployment preparation\n",
    "\n",
    "### Your Skills Now:\n",
    "\n",
    "âœ“ Design and implement neural networks from scratch\n",
    "âœ“ Use TensorFlow/Keras and PyTorch effectively\n",
    "âœ“ Optimize models with proper hyperparameters\n",
    "âœ“ Debug and fix training problems\n",
    "âœ“ Interpret and explain model decisions\n",
    "âœ“ Build production-ready ML systems\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "Continue your deep learning journey with:\n",
    "\n",
    "1. **Specialized Architectures**:\n",
    "   - Convolutional Neural Networks (CNNs) for computer vision\n",
    "   - Recurrent Neural Networks (RNNs/LSTMs) for sequences\n",
    "   - Transformers for NLP and beyond\n",
    "   - Generative models (GANs, VAEs, Diffusion models)\n",
    "\n",
    "2. **Advanced Topics**:\n",
    "   - Neural Architecture Search (NAS)\n",
    "   - Meta-learning and few-shot learning\n",
    "   - Continual learning\n",
    "   - Model compression and optimization\n",
    "\n",
    "3. **Production ML**:\n",
    "   - MLOps and deployment pipelines\n",
    "   - Model monitoring and maintenance\n",
    "   - A/B testing and experimentation\n",
    "   - Distributed training\n",
    "\n",
    "4. **Domain Applications**:\n",
    "   - Computer Vision (object detection, segmentation)\n",
    "   - Natural Language Processing (LLMs, transformers)\n",
    "   - Reinforcement Learning\n",
    "   - Time series forecasting\n",
    "\n",
    "### Resources for Further Learning:\n",
    "\n",
    "**Books**:\n",
    "- \"Deep Learning\" by Goodfellow, Bengio, Courville\n",
    "- \"Hands-On Machine Learning\" by AurÃ©lien GÃ©ron\n",
    "- \"Deep Learning with Python\" by FranÃ§ois Chollet\n",
    "\n",
    "**Courses**:\n",
    "- Fast.ai Practical Deep Learning\n",
    "- Stanford CS231n (Computer Vision)\n",
    "- Stanford CS224n (NLP)\n",
    "- DeepLearning.AI specializations\n",
    "\n",
    "**Communities**:\n",
    "- Papers With Code\n",
    "- Hugging Face\n",
    "- Kaggle\n",
    "- Reddit r/MachineLearning\n",
    "\n",
    "### Final Thoughts:\n",
    "\n",
    "Deep learning is a rapidly evolving field. The fundamentals you've learned here will remain relevant, but always keep learning and experimenting. \n",
    "\n",
    "**Most importantly**: Build projects, participate in competitions, and contribute to open source. Practical experience is the best teacher!\n",
    "\n",
    "**Good luck on your deep learning journey! ðŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
