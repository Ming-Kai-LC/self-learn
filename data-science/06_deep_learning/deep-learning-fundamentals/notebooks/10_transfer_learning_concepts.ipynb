{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 10: Transfer Learning Concepts\n",
    "\n",
    "**Difficulty**: ⭐⭐ (Intermediate)\n",
    "\n",
    "**Estimated Time**: 45-60 minutes\n",
    "\n",
    "**Prerequisites**: \n",
    "- [Module 05: Feed-Forward Neural Networks with Keras](05_feedforward_neural_networks_keras.ipynb)\n",
    "- [Module 07: Regularization Techniques](07_regularization_techniques.ipynb)\n",
    "- [Module 09: Hyperparameter Tuning](09_hyperparameter_tuning.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand what transfer learning is and why it works\n",
    "2. Differentiate between feature extraction and fine-tuning approaches\n",
    "3. Use pre-trained models from Keras Applications\n",
    "4. Freeze and unfreeze layers for controlled training\n",
    "5. Apply transfer learning to small datasets effectively\n",
    "6. Decide when transfer learning is appropriate for your problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Transfer Learning?\n",
    "\n",
    "**Transfer Learning** is the practice of using knowledge gained from solving one problem and applying it to a different but related problem.\n",
    "\n",
    "### The Core Idea\n",
    "\n",
    "Instead of training a neural network from scratch, we:\n",
    "1. Take a model pre-trained on a large dataset (e.g., ImageNet with 1.2M images)\n",
    "2. Adapt it to our specific task (which might have only 1,000 images)\n",
    "3. Leverage the learned features (edges, textures, patterns) from the pre-trained model\n",
    "\n",
    "### Why Transfer Learning Works\n",
    "\n",
    "Neural networks learn hierarchical features:\n",
    "- **Early layers**: Generic features (edges, colors, textures)\n",
    "- **Middle layers**: Pattern combinations (shapes, object parts)\n",
    "- **Late layers**: Task-specific features (entire objects, classes)\n",
    "\n",
    "The generic features learned on ImageNet are useful for many vision tasks!\n",
    "\n",
    "### Benefits of Transfer Learning\n",
    "\n",
    "1. **Requires less data**: Works well with small datasets\n",
    "2. **Trains faster**: Pre-trained features reduce training time\n",
    "3. **Better performance**: Often achieves higher accuracy than training from scratch\n",
    "4. **Reduces computational cost**: No need for massive compute resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import (\n",
    "    VGG16, ResNet50, MobileNetV2,\n",
    "    vgg16, resnet50, mobilenet_v2\n",
    ")\n",
    "\n",
    "# Dataset\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Plotting configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Data\n",
    "\n",
    "We'll use CIFAR-10, but simulate a small dataset scenario by using only a subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load CIFAR-10 dataset\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Class names for CIFAR-10\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Simulate small dataset: use only 1000 training samples\n",
    "# This demonstrates transfer learning's power on limited data\n",
    "n_samples = 1000\n",
    "indices = np.random.choice(len(X_train_full), n_samples, replace=False)\n",
    "X_train_small = X_train_full[indices]\n",
    "y_train_small = y_train_full[indices]\n",
    "\n",
    "# Create validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_small, y_train_small, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_train_small\n",
    ")\n",
    "\n",
    "# Normalize to [0, 1] range\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_val = X_val.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Flatten labels\n",
    "y_train = y_train.flatten()\n",
    "y_val = y_val.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Image shape: {X_train[0].shape}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize some training examples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    axes[i].imshow(X_train[i])\n",
    "    axes[i].set_title(class_names[y_train[i]], fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Training Images', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline: Training from Scratch\n",
    "\n",
    "First, let's train a model from scratch to establish a baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_baseline_model():\n",
    "    \"\"\"\n",
    "    Create a simple CNN trained from scratch.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.InputLayer(input_shape=(32, 32, 3)),\n",
    "        \n",
    "        # First conv block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Second conv block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Third conv block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and display baseline model\n",
    "baseline_model = create_baseline_model()\n",
    "print(\"Baseline Model Architecture:\")\n",
    "baseline_model.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train baseline model\n",
    "print(\"Training baseline model from scratch...\")\n",
    "baseline_history = baseline_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "baseline_test_loss, baseline_test_acc = baseline_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nBaseline Test Accuracy: {baseline_test_acc:.4f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Understanding Pre-trained Models\n",
    "\n",
    "Keras provides several pre-trained models through `keras.applications`:\n",
    "\n",
    "### Popular Pre-trained Models:\n",
    "\n",
    "1. **VGG16/VGG19**: Simple architecture, large model size\n",
    "2. **ResNet50/ResNet101**: Skip connections, deeper networks\n",
    "3. **MobileNetV2**: Lightweight, efficient for mobile/edge devices\n",
    "4. **InceptionV3**: Multi-scale feature extraction\n",
    "5. **EfficientNet**: State-of-the-art accuracy with efficiency\n",
    "\n",
    "All are trained on **ImageNet** (1.2M images, 1000 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load pre-trained VGG16 model\n",
    "# include_top=False removes the final classification layer\n",
    "# weights='imagenet' loads ImageNet pre-trained weights\n",
    "base_model = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(32, 32, 3)\n",
    ")\n",
    "\n",
    "print(\"Pre-trained VGG16 Base Model:\")\n",
    "print(f\"Number of layers: {len(base_model.layers)}\")\n",
    "print(f\"Total parameters: {base_model.count_params():,}\")\n",
    "print(f\"Output shape: {base_model.output_shape}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transfer Learning Approach 1: Feature Extraction\n",
    "\n",
    "**Feature Extraction** means:\n",
    "1. Freeze all pre-trained layers (don't update their weights)\n",
    "2. Add new trainable layers on top\n",
    "3. Train only the new layers\n",
    "\n",
    "**When to use**: \n",
    "- Small dataset (< 10,000 samples)\n",
    "- Similar to ImageNet images\n",
    "- Limited computational resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_feature_extraction_model(base_model):\n",
    "    \"\"\"\n",
    "    Create transfer learning model using feature extraction.\n",
    "    Base model layers are frozen.\n",
    "    \"\"\"\n",
    "    # Freeze all layers in base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom classification head\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),  # Convert feature maps to single vector\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create feature extraction model\n",
    "feature_extraction_model = create_feature_extraction_model(base_model)\n",
    "\n",
    "# Check trainable parameters\n",
    "print(\"Feature Extraction Model:\")\n",
    "print(f\"Total parameters: {feature_extraction_model.count_params():,}\")\n",
    "print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in feature_extraction_model.trainable_weights]):,}\")\n",
    "print(f\"Non-trainable parameters: {sum([tf.size(w).numpy() for w in feature_extraction_model.non_trainable_weights]):,}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train feature extraction model\n",
    "print(\"Training feature extraction model...\")\n",
    "feature_history = feature_extraction_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "feature_test_loss, feature_test_acc = feature_extraction_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nFeature Extraction Test Accuracy: {feature_test_acc:.4f}\")\n",
    "print(f\"Improvement over baseline: {(feature_test_acc - baseline_test_acc) * 100:+.2f}%\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Transfer Learning Approach 2: Fine-Tuning\n",
    "\n",
    "**Fine-Tuning** means:\n",
    "1. Start with pre-trained weights\n",
    "2. Freeze early layers (generic features)\n",
    "3. Unfreeze later layers (task-specific features)\n",
    "4. Train with a small learning rate\n",
    "\n",
    "**When to use**:\n",
    "- Medium dataset (10,000 - 100,000 samples)\n",
    "- Want to maximize performance\n",
    "- Have sufficient computational resources\n",
    "\n",
    "**Best Practice**: Fine-tune in two stages:\n",
    "1. Train top layers with base frozen\n",
    "2. Unfreeze some base layers and train with low LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a fresh base model for fine-tuning\n",
    "base_model_finetune = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(32, 32, 3)\n",
    ")\n",
    "\n",
    "# Initially freeze all layers\n",
    "base_model_finetune.trainable = False\n",
    "\n",
    "# Build model with custom head\n",
    "finetune_model = keras.Sequential([\n",
    "    base_model_finetune,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "finetune_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Stage 1: Train top layers only\n",
    "print(\"Stage 1: Training custom layers...\")\n",
    "finetune_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"Stage 1 complete.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Stage 2: Unfreeze last few layers and fine-tune\n",
    "print(\"\\nStage 2: Fine-tuning last layers...\")\n",
    "\n",
    "# Unfreeze the base model\n",
    "base_model_finetune.trainable = True\n",
    "\n",
    "# Freeze all layers except the last 4\n",
    "for layer in base_model_finetune.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Check which layers are trainable\n",
    "print(\"Trainable layers:\")\n",
    "for i, layer in enumerate(base_model_finetune.layers):\n",
    "    if layer.trainable:\n",
    "        print(f\"  Layer {i}: {layer.name}\")\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "# Lower LR is critical for fine-tuning to avoid destroying pre-trained weights\n",
    "finetune_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),  # Much smaller LR!\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fine-tune\n",
    "finetune_history = finetune_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "finetune_test_loss, finetune_test_acc = finetune_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nFine-tuned Test Accuracy: {finetune_test_acc:.4f}\")\n",
    "print(f\"Improvement over baseline: {(finetune_test_acc - baseline_test_acc) * 100:+.2f}%\")\n",
    "print(f\"Improvement over feature extraction: {(finetune_test_acc - feature_test_acc) * 100:+.2f}%\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparing All Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create comparison visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot training accuracy\n",
    "axes[0].plot(baseline_history.history['accuracy'], label='Baseline', linewidth=2)\n",
    "axes[0].plot(feature_history.history['accuracy'], label='Feature Extraction', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=11)\n",
    "axes[0].set_ylabel('Training Accuracy', fontsize=11)\n",
    "axes[0].set_title('Training Accuracy Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot validation accuracy\n",
    "axes[1].plot(baseline_history.history['val_accuracy'], label='Baseline', linewidth=2)\n",
    "axes[1].plot(feature_history.history['val_accuracy'], label='Feature Extraction', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=11)\n",
    "axes[1].set_ylabel('Validation Accuracy', fontsize=11)\n",
    "axes[1].set_title('Validation Accuracy Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test accuracy comparison\n",
    "models = ['Baseline\\n(From Scratch)', 'Feature\\nExtraction', 'Fine-Tuning']\n",
    "accuracies = [baseline_test_acc, feature_test_acc, finetune_test_acc]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(models, accuracies, color=['#e74c3c', '#3498db', '#2ecc71'], alpha=0.8)\n",
    "plt.ylabel('Test Accuracy', fontsize=12)\n",
    "plt.title('Transfer Learning Methods Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{acc:.4f}',\n",
    "             ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Baseline (from scratch):  {baseline_test_acc:.4f}\")\n",
    "print(f\"Feature Extraction:       {feature_test_acc:.4f} ({(feature_test_acc - baseline_test_acc) * 100:+.2f}%)\")\n",
    "print(f\"Fine-Tuning:              {finetune_test_acc:.4f} ({(finetune_test_acc - baseline_test_acc) * 100:+.2f}%)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Using Different Pre-trained Models\n",
    "\n",
    "Let's compare different pre-trained architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_transfer_model(base_model_name='VGG16'):\n",
    "    \"\"\"\n",
    "    Create transfer learning model with specified base.\n",
    "    \n",
    "    Args:\n",
    "        base_model_name: Name of pre-trained model to use\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    # Select base model\n",
    "    if base_model_name == 'VGG16':\n",
    "        base = VGG16(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
    "    elif base_model_name == 'ResNet50':\n",
    "        base = ResNet50(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
    "    elif base_model_name == 'MobileNetV2':\n",
    "        base = MobileNetV2(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown base model: {base_model_name}\")\n",
    "    \n",
    "    # Freeze base\n",
    "    base.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    model = keras.Sequential([\n",
    "        base,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Compare different architectures\n",
    "architectures = ['VGG16', 'ResNet50', 'MobileNetV2']\n",
    "architecture_results = {}\n",
    "\n",
    "for arch in architectures:\n",
    "    print(f\"\\nTesting {arch}...\")\n",
    "    \n",
    "    model = create_transfer_model(arch)\n",
    "    \n",
    "    # Train briefly\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    architecture_results[arch] = {\n",
    "        'test_accuracy': test_acc,\n",
    "        'parameters': model.count_params()\n",
    "    }\n",
    "    \n",
    "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  Parameters: {model.count_params():,}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize architecture comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "arch_names = list(architecture_results.keys())\n",
    "accuracies = [architecture_results[arch]['test_accuracy'] for arch in arch_names]\n",
    "\n",
    "axes[0].bar(arch_names, accuracies, color=['#3498db', '#e74c3c', '#2ecc71'], alpha=0.8)\n",
    "axes[0].set_ylabel('Test Accuracy', fontsize=11)\n",
    "axes[0].set_title('Accuracy by Architecture', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for i, (name, acc) in enumerate(zip(arch_names, accuracies)):\n",
    "    axes[0].text(i, acc, f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Parameter count comparison\n",
    "params = [architecture_results[arch]['parameters'] / 1e6 for arch in arch_names]  # In millions\n",
    "\n",
    "axes[1].bar(arch_names, params, color=['#3498db', '#e74c3c', '#2ecc71'], alpha=0.8)\n",
    "axes[1].set_ylabel('Parameters (Millions)', fontsize=11)\n",
    "axes[1].set_title('Model Size by Architecture', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for i, (name, param) in enumerate(zip(arch_names, params)):\n",
    "    axes[1].text(i, param, f'{param:.1f}M', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. When to Use Transfer Learning: Decision Guide\n",
    "\n",
    "### ✅ Use Transfer Learning When:\n",
    "\n",
    "1. **Limited Training Data**\n",
    "   - You have < 10,000 labeled examples\n",
    "   - Collecting more data is expensive or time-consuming\n",
    "\n",
    "2. **Similar Domain**\n",
    "   - Your images are natural images (like ImageNet)\n",
    "   - Tasks like object recognition, scene classification\n",
    "\n",
    "3. **Resource Constraints**\n",
    "   - Limited computational budget\n",
    "   - Need faster training times\n",
    "\n",
    "4. **Quick Prototyping**\n",
    "   - Want to establish baseline quickly\n",
    "   - Exploring feasibility of deep learning approach\n",
    "\n",
    "### ❌ Consider Training from Scratch When:\n",
    "\n",
    "1. **Very Different Domain**\n",
    "   - Medical images (X-rays, MRI)\n",
    "   - Satellite imagery\n",
    "   - Specialized scientific images\n",
    "\n",
    "2. **Massive Dataset Available**\n",
    "   - You have > 1M labeled examples\n",
    "   - Enough data to learn from scratch\n",
    "\n",
    "3. **Completely Different Task**\n",
    "   - Image generation (GANs)\n",
    "   - Super-resolution\n",
    "   - Novel architectures needed\n",
    "\n",
    "### Feature Extraction vs Fine-Tuning Decision:\n",
    "\n",
    "| Criterion | Feature Extraction | Fine-Tuning |\n",
    "|-----------|-------------------|-------------|\n",
    "| **Dataset Size** | < 10,000 | > 10,000 |\n",
    "| **Similarity to ImageNet** | Very similar | Somewhat similar |\n",
    "| **Computational Budget** | Low | Medium-High |\n",
    "| **Training Time** | Fast | Slower |\n",
    "| **Peak Accuracy** | Good | Best |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Exercise 1: Transfer Learning with Your Own Data\n",
    "\n",
    "**Task**: Apply transfer learning to a binary classification problem.\n",
    "\n",
    "**Requirements**:\n",
    "1. Select 2 classes from CIFAR-10 (e.g., cats vs dogs)\n",
    "2. Create a small dataset (200 samples per class)\n",
    "3. Build both feature extraction and fine-tuning models\n",
    "4. Compare performance with baseline model\n",
    "5. Visualize training curves and final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# YOUR CODE HERE\n",
    "# Hint: Filter CIFAR-10 to keep only 2 classes\n",
    "# Use np.isin() to filter labels\n",
    "\n",
    "pass  # Replace with your implementation"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Exercise 2: Layer Freezing Strategy\n",
    "\n",
    "**Task**: Experiment with different layer freezing strategies.\n",
    "\n",
    "**Requirements**:\n",
    "1. Load a pre-trained model (VGG16 or ResNet50)\n",
    "2. Try freezing different numbers of layers:\n",
    "   - All layers frozen (feature extraction)\n",
    "   - Last 25% unfrozen\n",
    "   - Last 50% unfrozen\n",
    "   - All layers unfrozen\n",
    "3. Train each variant for the same number of epochs\n",
    "4. Compare accuracy vs training time\n",
    "5. Determine the optimal freezing strategy for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# YOUR CODE HERE\n",
    "# Hint: Use a loop to iterate over different freeze percentages\n",
    "# Track both accuracy and training time\n",
    "\n",
    "pass  # Replace with your implementation"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Exercise 3: Pre-trained Model Comparison\n",
    "\n",
    "**Task**: Compare at least 3 different pre-trained models systematically.\n",
    "\n",
    "**Requirements**:\n",
    "1. Select 3 models from keras.applications (e.g., VGG16, ResNet50, MobileNetV2, InceptionV3)\n",
    "2. For each model:\n",
    "   - Record number of parameters\n",
    "   - Measure training time per epoch\n",
    "   - Record best validation accuracy\n",
    "   - Measure inference time (prediction speed)\n",
    "3. Create a comprehensive comparison table\n",
    "4. Visualize the trade-offs between accuracy, size, and speed\n",
    "5. Make a recommendation based on different scenarios (accuracy vs speed vs size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# YOUR CODE HERE\n",
    "# Hint: Use time.time() to measure training and inference time\n",
    "# Create scatter plots showing trade-offs\n",
    "\n",
    "pass  # Replace with your implementation"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary\n",
    "\n",
    "### Key Concepts Covered:\n",
    "\n",
    "1. **Transfer Learning Fundamentals**\n",
    "   - Using pre-trained models for new tasks\n",
    "   - Why it works: hierarchical feature learning\n",
    "   - Benefits: less data, faster training, better performance\n",
    "\n",
    "2. **Feature Extraction**\n",
    "   - Freeze pre-trained layers completely\n",
    "   - Train only custom classification head\n",
    "   - Best for small datasets and quick prototyping\n",
    "\n",
    "3. **Fine-Tuning**\n",
    "   - Unfreeze later layers and train with low learning rate\n",
    "   - Two-stage process for best results\n",
    "   - Achieves highest accuracy but requires more data\n",
    "\n",
    "4. **Pre-trained Model Zoo**\n",
    "   - VGG: Simple, large\n",
    "   - ResNet: Deep with skip connections\n",
    "   - MobileNet: Lightweight and efficient\n",
    "   - Choose based on accuracy vs speed vs size trade-offs\n",
    "\n",
    "5. **Decision Framework**\n",
    "   - When to use transfer learning\n",
    "   - Feature extraction vs fine-tuning choice\n",
    "   - Model architecture selection\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- Always start with feature extraction as baseline\n",
    "- Use very low learning rates for fine-tuning (1e-5 to 1e-4)\n",
    "- Freeze early layers, unfreeze later layers\n",
    "- Monitor validation metrics to prevent overfitting\n",
    "- Consider model size for deployment constraints\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "- [Module 11: Debugging Neural Networks](11_debugging_neural_networks.ipynb)\n",
    "- Advanced: Domain adaptation, multi-task learning\n",
    "- Specialized models: Object detection (YOLO), Segmentation (U-Net)\n",
    "\n",
    "### Additional Resources:\n",
    "\n",
    "1. Keras Applications documentation: https://keras.io/api/applications/\n",
    "2. \"How transferable are features in deep neural networks?\" (Yosinski et al., 2014)\n",
    "3. ImageNet website: http://www.image-net.org/\n",
    "4. Transfer Learning Guide: https://www.tensorflow.org/tutorials/images/transfer_learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
