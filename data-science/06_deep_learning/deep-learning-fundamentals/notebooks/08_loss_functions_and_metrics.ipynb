{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 08: Loss Functions and Metrics\n",
    "\n",
    "**Difficulty**: ⭐⭐ (Intermediate)\n",
    "\n",
    "**Estimated Time**: 45-60 minutes\n",
    "\n",
    "**Prerequisites**: \n",
    "- [Module 05: Feed-Forward Neural Networks with Keras](05_feedforward_neural_networks_keras.ipynb)\n",
    "- [Module 04: Introduction to TensorFlow and Keras](04_introduction_to_tensorflow_keras.ipynb)\n",
    "- [Module 02: Backpropagation and Gradient Descent](02_backpropagation_and_gradient_descent.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Understand and apply regression loss functions (MSE, MAE, Huber)\n",
    "2. Understand and apply classification loss functions (Binary/Categorical Cross-Entropy, Focal Loss)\n",
    "3. Implement custom loss functions for specific problems\n",
    "4. Choose appropriate evaluation metrics for different tasks\n",
    "5. Handle class imbalance in classification problems\n",
    "6. Distinguish between multi-class and multi-label classification\n",
    "7. Create custom metrics for monitoring training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, losses, metrics\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Sklearn for metrics and data generation\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_curve, auc,\n",
    "    precision_recall_curve, f1_score, mean_squared_error, mean_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regression Loss Functions\n",
    "\n",
    "### 2.1 Mean Squared Error (MSE) - L2 Loss\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "**Properties**:\n",
    "- **Sensitive to outliers**: Squares the errors, heavily penalizes large errors\n",
    "- **Differentiable everywhere**: Smooth gradients\n",
    "- **Units**: Squared units of target variable\n",
    "\n",
    "**When to use**:\n",
    "- Default choice for regression\n",
    "- When you want to heavily penalize large errors\n",
    "- When outliers should be minimized\n",
    "\n",
    "### 2.2 Mean Absolute Error (MAE) - L1 Loss\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "**Properties**:\n",
    "- **Robust to outliers**: Linear penalty\n",
    "- **Same units** as target variable\n",
    "- **Not differentiable** at zero (but subgradient works)\n",
    "\n",
    "**When to use**:\n",
    "- When outliers are present in data\n",
    "- When you want interpretable error in original units\n",
    "- When all errors should be weighted equally\n",
    "\n",
    "### 2.3 Huber Loss\n",
    "\n",
    "**Formula** (combines MSE and MAE):\n",
    "$$\n",
    "L_\\delta(y, \\hat{y}) = \\begin{cases}\n",
    "\\frac{1}{2}(y - \\hat{y})^2 & \\text{if } |y - \\hat{y}| \\leq \\delta \\\\\n",
    "\\delta \\cdot (|y - \\hat{y}| - \\frac{1}{2}\\delta) & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Properties**:\n",
    "- **Best of both worlds**: MSE for small errors, MAE for large errors\n",
    "- **Robust to outliers** while maintaining MSE's smoothness\n",
    "- **Hyperparameter $\\delta$**: Threshold between quadratic and linear\n",
    "\n",
    "**When to use**:\n",
    "- When you have some outliers but want smooth gradients\n",
    "- Default choice for robust regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize regression loss functions\n",
    "def visualize_regression_losses():\n",
    "    \"\"\"\n",
    "    Visualize how different regression losses penalize errors.\n",
    "    \"\"\"\n",
    "    # Generate error range\n",
    "    errors = np.linspace(-5, 5, 200)\n",
    "    \n",
    "    # Compute losses\n",
    "    mse_loss = errors ** 2\n",
    "    mae_loss = np.abs(errors)\n",
    "    \n",
    "    # Huber loss with delta=1\n",
    "    delta = 1.0\n",
    "    huber_loss = np.where(\n",
    "        np.abs(errors) <= delta,\n",
    "        0.5 * errors ** 2,\n",
    "        delta * (np.abs(errors) - 0.5 * delta)\n",
    "    )\n",
    "    \n",
    "    # Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Loss functions\n",
    "    ax1.plot(errors, mse_loss, linewidth=3, label='MSE (L2)', color='red')\n",
    "    ax1.plot(errors, mae_loss, linewidth=3, label='MAE (L1)', color='blue')\n",
    "    ax1.plot(errors, huber_loss, linewidth=3, label='Huber (δ=1)', color='green')\n",
    "    ax1.axvline(x=0, color='black', linestyle='--', alpha=0.3)\n",
    "    ax1.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    ax1.set_xlabel('Error (y - ŷ)', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.set_title('Regression Loss Functions', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 10)\n",
    "    \n",
    "    # Zoom in on small errors\n",
    "    ax2.plot(errors, mse_loss, linewidth=3, label='MSE (L2)', color='red')\n",
    "    ax2.plot(errors, mae_loss, linewidth=3, label='MAE (L1)', color='blue')\n",
    "    ax2.plot(errors, huber_loss, linewidth=3, label='Huber (δ=1)', color='green')\n",
    "    ax2.axvline(x=0, color='black', linestyle='--', alpha=0.3)\n",
    "    ax2.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    ax2.set_xlabel('Error (y - ŷ)', fontsize=12)\n",
    "    ax2.set_ylabel('Loss', fontsize=12)\n",
    "    ax2.set_title('Zoomed: Small Errors Region', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim(-2, 2)\n",
    "    ax2.set_ylim(0, 3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Observations:\")\n",
    "    print(\"- MSE: Grows quadratically, heavily penalizes outliers\")\n",
    "    print(\"- MAE: Grows linearly, robust to outliers\")\n",
    "    print(\"- Huber: Quadratic near zero (smooth), linear for large errors (robust)\")\n",
    "\n",
    "visualize_regression_losses()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Demonstrate on synthetic regression data\n",
    "print(\"Generating synthetic regression data with outliers...\\n\")\n",
    "\n",
    "# Generate clean data\n",
    "X, y = make_regression(n_samples=1000, n_features=10, noise=10, random_state=42)\n",
    "\n",
    "# Add outliers (10% of data)\n",
    "n_outliers = 100\n",
    "outlier_indices = np.random.choice(len(y), n_outliers, replace=False)\n",
    "y[outlier_indices] += np.random.randn(n_outliers) * 100  # Large noise\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Outliers added: {n_outliers}\")\n",
    "print(f\"Target mean: {y_train.mean():.2f}\")\n",
    "print(f\"Target std: {y_train.std():.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train models with different loss functions\n",
    "def create_regression_model():\n",
    "    \"\"\"Create simple regression model.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(10,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)  # Single output for regression\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train with different losses\n",
    "loss_functions = {\n",
    "    'MSE': losses.MeanSquaredError(),\n",
    "    'MAE': losses.MeanAbsoluteError(),\n",
    "    'Huber': losses.Huber(delta=1.0)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, loss_fn in loss_functions.items():\n",
    "    print(f\"\\nTraining with {name} loss...\")\n",
    "    \n",
    "    model = create_regression_model()\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['mae'])\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    test_mse = mean_squared_error(y_test, y_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'history': history,\n",
    "        'predictions': y_pred,\n",
    "        'test_mse': test_mse,\n",
    "        'test_mae': test_mae\n",
    "    }\n",
    "    \n",
    "    print(f\"  Test MSE: {test_mse:.2f}\")\n",
    "    print(f\"  Test MAE: {test_mae:.2f}\")\n",
    "\n",
    "print(\"\\nAll models trained!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare regression loss functions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Training curves\n",
    "for name, result in results.items():\n",
    "    ax1.plot(result['history'].history['loss'], linewidth=2, label=name)\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Training Loss', fontsize=12)\n",
    "ax1.set_title('Training Loss Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Test metrics comparison\n",
    "metrics_names = ['Test MSE', 'Test MAE']\n",
    "x = np.arange(len(loss_functions))\n",
    "width = 0.35\n",
    "\n",
    "mse_values = [results[name]['test_mse'] for name in loss_functions.keys()]\n",
    "mae_values = [results[name]['test_mae'] for name in loss_functions.keys()]\n",
    "\n",
    "ax2.bar(x - width/2, mse_values, width, label='MSE', alpha=0.8)\n",
    "ax2.bar(x + width/2, mae_values, width, label='MAE', alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Loss Function Used', fontsize=12)\n",
    "ax2.set_ylabel('Error Value', fontsize=12)\n",
    "ax2.set_title('Test Set Performance', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(loss_functions.keys())\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConclusion:\")\n",
    "print(\"Huber loss often performs best with outliers - robust yet smooth!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification Loss Functions\n",
    "\n",
    "### 3.1 Binary Cross-Entropy (Log Loss)\n",
    "\n",
    "**For binary classification** (2 classes: 0 or 1)\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{BCE} = -\\frac{1}{n} \\sum_{i=1}^n \\left[ y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i) \\right]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y_i \\in \\{0, 1\\}$ is the true label\n",
    "- $\\hat{y}_i \\in (0, 1)$ is the predicted probability\n",
    "\n",
    "**When to use**:\n",
    "- Binary classification tasks\n",
    "- Output layer: Single neuron with sigmoid activation\n",
    "\n",
    "### 3.2 Categorical Cross-Entropy\n",
    "\n",
    "**For multi-class classification** (K > 2 classes, mutually exclusive)\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{CCE} = -\\frac{1}{n} \\sum_{i=1}^n \\sum_{k=1}^K y_{i,k} \\log(\\hat{y}_{i,k})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y_{i,k}$ is 1 if sample $i$ belongs to class $k$, else 0 (one-hot encoded)\n",
    "- $\\hat{y}_{i,k}$ is the predicted probability for class $k$\n",
    "\n",
    "**Variants**:\n",
    "- **`categorical_crossentropy`**: Expects one-hot encoded labels\n",
    "- **`sparse_categorical_crossentropy`**: Expects integer labels (more convenient)\n",
    "\n",
    "**When to use**:\n",
    "- Multi-class classification (single label per sample)\n",
    "- Output layer: K neurons with softmax activation\n",
    "\n",
    "### 3.3 Focal Loss\n",
    "\n",
    "**For imbalanced classification**\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{FL}(p_t) = -\\alpha_t (1 - p_t)^\\gamma \\log(p_t)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $p_t$ is the model's estimated probability for the true class\n",
    "- $\\gamma$ is the focusing parameter (typically 2)\n",
    "- $\\alpha_t$ is the class weight\n",
    "\n",
    "**Key idea**: Down-weight easy examples, focus on hard examples\n",
    "\n",
    "**When to use**:\n",
    "- Severe class imbalance\n",
    "- Object detection\n",
    "- When easy examples dominate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize cross-entropy loss\n",
    "def visualize_cross_entropy():\n",
    "    \"\"\"\n",
    "    Visualize how cross-entropy penalizes predictions.\n",
    "    \"\"\"\n",
    "    # Predicted probabilities\n",
    "    probs = np.linspace(0.001, 0.999, 200)\n",
    "    \n",
    "    # Loss when true label is 1\n",
    "    loss_positive = -np.log(probs)\n",
    "    \n",
    "    # Loss when true label is 0\n",
    "    loss_negative = -np.log(1 - probs)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Binary cross-entropy\n",
    "    ax1.plot(probs, loss_positive, linewidth=3, label='True Class = 1', color='blue')\n",
    "    ax1.plot(probs, loss_negative, linewidth=3, label='True Class = 0', color='red')\n",
    "    ax1.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    ax1.set_xlabel('Predicted Probability', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.set_title('Binary Cross-Entropy Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 8)\n",
    "    \n",
    "    # Focal loss comparison (for true class = 1)\n",
    "    focal_gamma_0 = loss_positive  # Focal loss with γ=0 is just CE\n",
    "    focal_gamma_1 = -(1 - probs) * np.log(probs)\n",
    "    focal_gamma_2 = -((1 - probs) ** 2) * np.log(probs)\n",
    "    \n",
    "    ax2.plot(probs, focal_gamma_0, linewidth=3, label='γ=0 (Standard CE)', linestyle='--')\n",
    "    ax2.plot(probs, focal_gamma_1, linewidth=3, label='γ=1')\n",
    "    ax2.plot(probs, focal_gamma_2, linewidth=3, label='γ=2 (Focal Loss)')\n",
    "    ax2.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    ax2.set_xlabel('Predicted Probability (for True Class)', fontsize=12)\n",
    "    ax2.set_ylabel('Loss', fontsize=12)\n",
    "    ax2.set_title('Focal Loss: Down-weighting Easy Examples', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 4)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Observations:\")\n",
    "    print(\"- Cross-Entropy: Heavily penalizes confident wrong predictions\")\n",
    "    print(\"- Focal Loss: Reduces loss for well-classified examples (high prob)\")\n",
    "    print(\"- Higher γ: More focus on hard examples\")\n",
    "\n",
    "visualize_cross_entropy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load Fashion-MNIST for multi-class classification\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Preprocess\n",
    "X_train_full = X_train_full.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "X_train_full_flat = X_train_full.reshape(-1, 784)\n",
    "X_test_flat = X_test.reshape(-1, 784)\n",
    "\n",
    "# Split validation\n",
    "X_train = X_train_full_flat[:50000]\n",
    "X_valid = X_train_full_flat[50000:]\n",
    "y_train = y_train_full[:50000]\n",
    "y_valid = y_train_full[50000:]\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_valid.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_train))}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create binary classification task: T-shirts (0) vs Everything Else\n",
    "y_train_binary = (y_train == 0).astype(int)\n",
    "y_valid_binary = (y_valid == 0).astype(int)\n",
    "y_test_binary = (y_test == 0).astype(int)\n",
    "\n",
    "print(\"Binary Classification Setup:\")\n",
    "print(f\"  Class 0 (T-shirts): {np.sum(y_train_binary == 0)} samples\")\n",
    "print(f\"  Class 1 (Others): {np.sum(y_train_binary == 1)} samples\")\n",
    "print(f\"  Imbalance ratio: {np.sum(y_train_binary == 0) / np.sum(y_train_binary == 1):.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model for binary classification\n",
    "def create_binary_classifier():\n",
    "    \"\"\"Binary classification model.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(784,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  # Single output with sigmoid\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train binary classifier\n",
    "print(\"Training binary classifier...\\n\")\n",
    "model_binary = create_binary_classifier()\n",
    "model_binary.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',  # Binary cross-entropy\n",
    "    metrics=['accuracy', metrics.Precision(), metrics.Recall()]\n",
    ")\n",
    "\n",
    "history_binary = model_binary.fit(\n",
    "    X_train, y_train_binary,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_valid, y_valid_binary),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nBinary classifier trained!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model for multi-class classification\n",
    "def create_multiclass_classifier():\n",
    "    \"\"\"Multi-class classification model.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(784,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')  # 10 classes with softmax\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train multi-class classifier\n",
    "print(\"Training multi-class classifier...\\n\")\n",
    "model_multiclass = create_multiclass_classifier()\n",
    "model_multiclass.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',  # Sparse categorical CE\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_multiclass = model_multiclass.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nMulti-class classifier trained!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation Metrics\n",
    "\n",
    "### 4.1 Classification Metrics\n",
    "\n",
    "#### Confusion Matrix:\n",
    "```\n",
    "                Predicted\n",
    "              Negative  Positive\n",
    "Actual Negative   TN       FP\n",
    "       Positive   FN       TP\n",
    "```\n",
    "\n",
    "#### Derived Metrics:\n",
    "\n",
    "**Accuracy**: Overall correctness\n",
    "$$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "**Precision**: Of predicted positives, how many are correct?\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "**Recall (Sensitivity)**: Of actual positives, how many did we find?\n",
    "$$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "**F1 Score**: Harmonic mean of precision and recall\n",
    "$$\\text{F1} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "\n",
    "**ROC-AUC**: Area under ROC curve (TPR vs FPR)\n",
    "- 1.0 = Perfect classifier\n",
    "- 0.5 = Random guess\n",
    "\n",
    "### When to Use Which Metric:\n",
    "\n",
    "| Scenario | Best Metric |\n",
    "|----------|-------------|\n",
    "| **Balanced classes** | Accuracy |\n",
    "| **Imbalanced classes** | F1, ROC-AUC, Precision-Recall AUC |\n",
    "| **False positives costly** | Precision |\n",
    "| **False negatives costly** | Recall |\n",
    "| **Need single metric** | F1 Score |\n",
    "| **Probability calibration matters** | ROC-AUC |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate binary classifier\n",
    "y_pred_proba = model_binary.predict(X_test_flat, verbose=0)\n",
    "y_pred_binary = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "            xticklabels=['T-shirt', 'Other'],\n",
    "            yticklabels=['T-shirt', 'Other'])\n",
    "ax1.set_xlabel('Predicted', fontsize=12)\n",
    "ax1.set_ylabel('Actual', fontsize=12)\n",
    "ax1.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "ax2.plot(fpr, tpr, linewidth=3, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "ax2.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Guess')\n",
    "ax2.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax2.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax2.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test_binary, y_pred_binary, \n",
    "                           target_names=['T-shirt', 'Other']))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate multi-class classifier\n",
    "y_pred_multiclass = model_multiclass.predict(X_test_flat, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred_multiclass, axis=1)\n",
    "\n",
    "# Multi-class confusion matrix\n",
    "cm_multi = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "class_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.title('Multi-Class Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per-class metrics\n",
    "print(\"\\nMulti-Class Classification Report:\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_test, y_pred_classes, target_names=class_names))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handling Class Imbalance\n",
    "\n",
    "### Problem:\n",
    "When one class significantly outnumbers others, model may:\n",
    "- Ignore minority class\n",
    "- Achieve high accuracy by always predicting majority class\n",
    "- Have poor performance on minority class\n",
    "\n",
    "### Solutions:\n",
    "\n",
    "#### 1. Class Weights\n",
    "Penalize misclassification of minority class more heavily:\n",
    "$$w_k = \\frac{n_{\\text{samples}}}{n_{\\text{classes}} \\times n_{\\text{samples in class k}}}$$\n",
    "\n",
    "#### 2. Oversampling Minority Class\n",
    "Duplicate minority class samples\n",
    "\n",
    "#### 3. Undersampling Majority Class\n",
    "Remove majority class samples\n",
    "\n",
    "#### 4. Focal Loss\n",
    "Down-weight well-classified examples\n",
    "\n",
    "#### 5. Different Metrics\n",
    "Use F1, ROC-AUC instead of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create severely imbalanced dataset\n",
    "# Keep only 10% of \"Other\" class samples\n",
    "print(\"Creating imbalanced dataset...\\n\")\n",
    "\n",
    "# Indices for each class\n",
    "tshirt_indices = np.where(y_train_binary == 0)[0]\n",
    "other_indices = np.where(y_train_binary == 1)[0]\n",
    "\n",
    "# Keep all T-shirts, only 10% of others\n",
    "n_others_keep = len(other_indices) // 10\n",
    "other_indices_sampled = np.random.choice(other_indices, n_others_keep, replace=False)\n",
    "\n",
    "# Combine\n",
    "imbalanced_indices = np.concatenate([tshirt_indices, other_indices_sampled])\n",
    "np.random.shuffle(imbalanced_indices)\n",
    "\n",
    "X_train_imb = X_train[imbalanced_indices]\n",
    "y_train_imb = y_train_binary[imbalanced_indices]\n",
    "\n",
    "print(f\"Original dataset:\")\n",
    "print(f\"  T-shirts: {len(tshirt_indices)}\")\n",
    "print(f\"  Others: {len(other_indices)}\")\n",
    "print(f\"  Ratio: {len(tshirt_indices) / len(other_indices):.2f}\")\n",
    "\n",
    "print(f\"\\nImbalanced dataset:\")\n",
    "print(f\"  T-shirts: {np.sum(y_train_imb == 0)}\")\n",
    "print(f\"  Others: {np.sum(y_train_imb == 1)}\")\n",
    "print(f\"  Ratio: {np.sum(y_train_imb == 0) / np.sum(y_train_imb == 1):.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train without class weights (baseline)\n",
    "print(\"\\nTraining WITHOUT class weights...\")\n",
    "model_no_weights = create_binary_classifier()\n",
    "model_no_weights.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', metrics.Precision(), metrics.Recall()]\n",
    ")\n",
    "\n",
    "history_no_weights = model_no_weights.fit(\n",
    "    X_train_imb, y_train_imb,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_valid, y_valid_binary),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_no_weights = (model_no_weights.predict(X_test_flat, verbose=0) > 0.5).astype(int)\n",
    "print(\"\\nResults WITHOUT class weights:\")\n",
    "print(classification_report(y_test_binary, y_pred_no_weights, \n",
    "                           target_names=['T-shirt', 'Other']))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_imb),\n",
    "    y=y_train_imb\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights_array))\n",
    "\n",
    "print(f\"\\nComputed class weights:\")\n",
    "print(f\"  Class 0 (T-shirt): {class_weights[0]:.3f}\")\n",
    "print(f\"  Class 1 (Other): {class_weights[1]:.3f}\")\n",
    "\n",
    "# Train WITH class weights\n",
    "print(\"\\nTraining WITH class weights...\")\n",
    "model_with_weights = create_binary_classifier()\n",
    "model_with_weights.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', metrics.Precision(), metrics.Recall()]\n",
    ")\n",
    "\n",
    "history_with_weights = model_with_weights.fit(\n",
    "    X_train_imb, y_train_imb,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_valid, y_valid_binary),\n",
    "    class_weight=class_weights,  # Apply class weights\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_with_weights = (model_with_weights.predict(X_test_flat, verbose=0) > 0.5).astype(int)\n",
    "print(\"\\nResults WITH class weights:\")\n",
    "print(classification_report(y_test_binary, y_pred_with_weights,\n",
    "                           target_names=['T-shirt', 'Other']))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare class weight impact\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Confusion matrices\n",
    "cm_no_weights = confusion_matrix(y_test_binary, y_pred_no_weights)\n",
    "cm_with_weights = confusion_matrix(y_test_binary, y_pred_with_weights)\n",
    "\n",
    "sns.heatmap(cm_no_weights, annot=True, fmt='d', cmap='Reds', ax=axes[0],\n",
    "            xticklabels=['T-shirt', 'Other'],\n",
    "            yticklabels=['T-shirt', 'Other'])\n",
    "axes[0].set_xlabel('Predicted', fontsize=12)\n",
    "axes[0].set_ylabel('Actual', fontsize=12)\n",
    "axes[0].set_title('WITHOUT Class Weights', fontsize=14, fontweight='bold')\n",
    "\n",
    "sns.heatmap(cm_with_weights, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "            xticklabels=['T-shirt', 'Other'],\n",
    "            yticklabels=['T-shirt', 'Other'])\n",
    "axes[1].set_xlabel('Predicted', fontsize=12)\n",
    "axes[1].set_ylabel('Actual', fontsize=12)\n",
    "axes[1].set_title('WITH Class Weights', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation:\")\n",
    "print(\"Class weights help balance precision/recall for minority class!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom Loss Functions and Metrics\n",
    "\n",
    "Sometimes you need to implement custom loss functions or metrics for specific problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example 1: Custom weighted MSE loss\n",
    "@tf.function\n",
    "def weighted_mse(y_true, y_pred, weight_positive=2.0):\n",
    "    \"\"\"\n",
    "    Custom MSE that weights positive values more heavily.\n",
    "    Useful when predicting rare events.\n",
    "    \"\"\"\n",
    "    error = y_true - y_pred\n",
    "    squared_error = tf.square(error)\n",
    "    \n",
    "    # Apply higher weight to positive true values\n",
    "    weights = tf.where(y_true > 0, weight_positive, 1.0)\n",
    "    weighted_error = squared_error * weights\n",
    "    \n",
    "    return tf.reduce_mean(weighted_error)\n",
    "\n",
    "# Example 2: Custom F1 score metric\n",
    "class F1Score(keras.metrics.Metric):\n",
    "    \"\"\"\n",
    "    Custom F1 score metric for binary classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = metrics.Precision()\n",
    "        self.recall = metrics.Recall()\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "    \n",
    "    def result(self):\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        # F1 = 2 * (precision * recall) / (precision + recall)\n",
    "        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.precision.reset_state()\n",
    "        self.recall.reset_state()\n",
    "\n",
    "# Example 3: Focal loss implementation\n",
    "@tf.function\n",
    "def focal_loss(y_true, y_pred, gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Focal loss for binary classification.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    gamma : float\n",
    "        Focusing parameter (typically 2.0)\n",
    "    alpha : float\n",
    "        Class weight (typically 0.25)\n",
    "    \"\"\"\n",
    "    # Clip predictions to prevent log(0)\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "    \n",
    "    # Compute focal loss\n",
    "    cross_entropy = -y_true * tf.math.log(y_pred) - (1 - y_true) * tf.math.log(1 - y_pred)\n",
    "    \n",
    "    # Focal weight\n",
    "    focal_weight = tf.where(y_true == 1,\n",
    "                           alpha * tf.pow(1 - y_pred, gamma),\n",
    "                           (1 - alpha) * tf.pow(y_pred, gamma))\n",
    "    \n",
    "    focal_loss_value = focal_weight * cross_entropy\n",
    "    \n",
    "    return tf.reduce_mean(focal_loss_value)\n",
    "\n",
    "print(\"Custom loss functions and metrics defined!\")\n",
    "print(\"\\nExamples:\")\n",
    "print(\"1. weighted_mse: Penalizes errors on positive samples more\")\n",
    "print(\"2. F1Score: Custom metric for F1 score\")\n",
    "print(\"3. focal_loss: Down-weights easy examples\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train with custom focal loss\n",
    "print(\"Training with Focal Loss...\\n\")\n",
    "\n",
    "model_focal = create_binary_classifier()\n",
    "model_focal.compile(\n",
    "    optimizer='adam',\n",
    "    loss=focal_loss,  # Custom focal loss\n",
    "    metrics=['accuracy', F1Score()]  # Custom F1 metric\n",
    ")\n",
    "\n",
    "history_focal = model_focal.fit(\n",
    "    X_train_imb, y_train_imb,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_valid, y_valid_binary),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nFocal Loss model trained!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "#### Regression Losses:\n",
    "1. **MSE**: Default, penalizes outliers heavily\n",
    "2. **MAE**: Robust to outliers, same units as target\n",
    "3. **Huber**: Best of both - smooth and robust\n",
    "\n",
    "#### Classification Losses:\n",
    "1. **Binary Cross-Entropy**: Binary classification (2 classes)\n",
    "2. **Categorical Cross-Entropy**: Multi-class (mutually exclusive)\n",
    "3. **Focal Loss**: Handles class imbalance\n",
    "\n",
    "#### Metrics:\n",
    "1. **Accuracy**: Good for balanced datasets\n",
    "2. **Precision**: Minimize false positives\n",
    "3. **Recall**: Minimize false negatives\n",
    "4. **F1 Score**: Balance precision and recall\n",
    "5. **ROC-AUC**: Overall discriminative ability\n",
    "\n",
    "#### Class Imbalance Solutions:\n",
    "1. **Class weights**: Weight minority class more\n",
    "2. **Focal loss**: Down-weight easy examples\n",
    "3. **Sampling**: Over/undersample classes\n",
    "4. **Better metrics**: F1, ROC-AUC instead of accuracy\n",
    "\n",
    "### Decision Guide:\n",
    "\n",
    "**For Regression:**\n",
    "```\n",
    "Are there outliers?\n",
    "    |-- NO  → Use MSE (standard)\n",
    "    |-- YES → Use Huber or MAE\n",
    "```\n",
    "\n",
    "**For Classification:**\n",
    "```\n",
    "How many classes?\n",
    "    |-- 2 → Binary Cross-Entropy\n",
    "    |-- >2 → Categorical Cross-Entropy\n",
    "    \n",
    "Is dataset balanced?\n",
    "    |-- NO → Use class weights or Focal Loss\n",
    "    |-- YES → Standard cross-entropy is fine\n",
    "```\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "- **Module 09**: Hyperparameter Tuning for Deep Learning\n",
    "\n",
    "### Additional Resources:\n",
    "\n",
    "- [Keras Loss Functions](https://keras.io/api/losses/)\n",
    "- [Keras Metrics](https://keras.io/api/metrics/)\n",
    "- [Focal Loss Paper](https://arxiv.org/abs/1708.02002)\n",
    "- [Imbalanced Learning](https://imbalanced-learn.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Implement Custom Dice Loss\n",
    "\n",
    "**Task**: Implement the Dice loss, commonly used in image segmentation.\n",
    "\n",
    "**Dice Coefficient**:\n",
    "$$\\text{Dice} = \\frac{2 |A \\cap B|}{|A| + |B|}$$\n",
    "\n",
    "**Dice Loss**:\n",
    "$$\\text{Dice Loss} = 1 - \\text{Dice}$$\n",
    "\n",
    "**Requirements**:\n",
    "- Implement as TensorFlow function\n",
    "- Test on binary classification\n",
    "- Compare with Binary Cross-Entropy\n",
    "\n",
    "```python\n",
    "# Your code here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 1 Solution\n",
    "# Uncomment to reveal\n",
    "\n",
    "# @tf.function\n",
    "# def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "#     \"\"\"\n",
    "#     Dice loss for binary classification.\n",
    "#     \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     smooth : float\n",
    "#         Smoothing constant to avoid division by zero\n",
    "#     \"\"\"\n",
    "#     # Flatten predictions and labels\n",
    "#     y_true_f = tf.reshape(y_true, [-1])\n",
    "#     y_pred_f = tf.reshape(y_pred, [-1])\n",
    "#     \n",
    "#     # Calculate intersection and union\n",
    "#     intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "#     union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
    "#     \n",
    "#     # Dice coefficient\n",
    "#     dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "#     \n",
    "#     # Dice loss\n",
    "#     return 1.0 - dice\n",
    "# \n",
    "# # Test on binary classification\n",
    "# # (Add testing code here)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Multi-Label Classification\n",
    "\n",
    "**Task**: Implement multi-label classification (multiple labels per sample).\n",
    "\n",
    "**Scenario**: Classify Fashion-MNIST into multiple attributes:\n",
    "- Is clothing? (T-shirt, Dress, Coat, etc.)\n",
    "- Is footwear? (Sandal, Sneaker, Ankle boot)\n",
    "- Is accessory? (Bag)\n",
    "\n",
    "**Requirements**:\n",
    "- Create multi-label targets\n",
    "- Use Binary Cross-Entropy (not Categorical!)\n",
    "- Use sigmoid activation (not softmax!)\n",
    "- Evaluate with per-label metrics\n",
    "\n",
    "```python\n",
    "# Your code here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 2 Solution\n",
    "# Uncomment to reveal\n",
    "\n",
    "# # Define multi-label mapping\n",
    "# # Fashion-MNIST: 0=T-shirt, 1=Trouser, 2=Pullover, 3=Dress, 4=Coat,\n",
    "# #                5=Sandal, 6=Shirt, 7=Sneaker, 8=Bag, 9=Ankle boot\n",
    "# \n",
    "# def create_multilabel_targets(y):\n",
    "#     \"\"\"Convert to multi-label: [is_clothing, is_footwear, is_accessory]\"\"\"\n",
    "#     n = len(y)\n",
    "#     multilabel = np.zeros((n, 3))\n",
    "#     \n",
    "#     # is_clothing (0,2,3,4,6)\n",
    "#     multilabel[:, 0] = np.isin(y, [0, 2, 3, 4, 6]).astype(int)\n",
    "#     # is_footwear (5,7,9)\n",
    "#     multilabel[:, 1] = np.isin(y, [5, 7, 9]).astype(int)\n",
    "#     # is_accessory (8)\n",
    "#     multilabel[:, 2] = (y == 8).astype(int)\n",
    "#     \n",
    "#     return multilabel\n",
    "# \n",
    "# # Create multi-label targets\n",
    "# y_train_multilabel = create_multilabel_targets(y_train)\n",
    "# y_valid_multilabel = create_multilabel_targets(y_valid)\n",
    "# \n",
    "# # Model for multi-label\n",
    "# model_multilabel = models.Sequential([\n",
    "#     layers.Input(shape=(784,)),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(3, activation='sigmoid')  # Sigmoid for multi-label\n",
    "# ])\n",
    "# \n",
    "# model_multilabel.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='binary_crossentropy',  # Binary CE for multi-label\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "# \n",
    "# # Train\n",
    "# # (Add training code here)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: ROC Curve Analysis\n",
    "\n",
    "**Task**: Analyze different probability thresholds for binary classification.\n",
    "\n",
    "**Requirements**:\n",
    "- Train binary classifier\n",
    "- Plot ROC curve\n",
    "- Plot Precision-Recall curve\n",
    "- Find optimal threshold for:\n",
    "  - Maximum F1 score\n",
    "  - 95% recall (minimize false negatives)\n",
    "  - 95% precision (minimize false positives)\n",
    "- Compare trade-offs\n",
    "\n",
    "```python\n",
    "# Your code here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exercise 3 Solution\n",
    "# Uncomment to reveal\n",
    "\n",
    "# # Get predicted probabilities\n",
    "# y_proba = model_binary.predict(X_test_flat, verbose=0)\n",
    "# \n",
    "# # Compute precision-recall curve\n",
    "# precision, recall, thresholds_pr = precision_recall_curve(y_test_binary, y_proba)\n",
    "# \n",
    "# # Compute F1 for each threshold\n",
    "# f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "# \n",
    "# # Find optimal thresholds\n",
    "# idx_max_f1 = np.argmax(f1_scores)\n",
    "# optimal_threshold_f1 = thresholds_pr[idx_max_f1]\n",
    "# \n",
    "# # Threshold for 95% recall\n",
    "# idx_95_recall = np.argmin(np.abs(recall - 0.95))\n",
    "# threshold_95_recall = thresholds_pr[idx_95_recall]\n",
    "# \n",
    "# # Threshold for 95% precision\n",
    "# idx_95_precision = np.argmin(np.abs(precision - 0.95))\n",
    "# threshold_95_precision = thresholds_pr[idx_95_precision]\n",
    "# \n",
    "# print(f\"Optimal thresholds:\")\n",
    "# print(f\"  Max F1: {optimal_threshold_f1:.3f} (F1={f1_scores[idx_max_f1]:.3f})\")\n",
    "# print(f\"  95% Recall: {threshold_95_recall:.3f}\")\n",
    "# print(f\"  95% Precision: {threshold_95_precision:.3f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Congratulations!** You've completed Module 08. You now understand:\n",
    "- Different loss functions for regression and classification\n",
    "- When to use each loss function\n",
    "- Important evaluation metrics and their trade-offs\n",
    "- How to handle class imbalance\n",
    "- How to implement custom loss functions and metrics\n",
    "\n",
    "Continue to **Module 09: Hyperparameter Tuning for Deep Learning** to learn how to optimize your models!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
