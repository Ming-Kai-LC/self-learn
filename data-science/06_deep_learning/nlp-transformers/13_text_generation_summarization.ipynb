{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Module 13: Text Generation and Summarization\n\n**Difficulty**: \u2b50\u2b50\u2b50 Advanced  \n**Estimated Time**: 120 minutes  \n**Prerequisites**: Modules 08, 12\n\n## Learning Objectives\n\n1. Understand text generation techniques\n2. Implement abstractive summarization\n3. Use T5, BART for generation\n4. Evaluate with ROUGE and BLEU\n5. Build summarization systems\n\n## Text Generation\n\n### Applications:\n- Summarization\n- Translation\n- Dialogue\n- Creative writing\n- Code generation\n\n### Models:\n- **T5**: Text-to-Text Transfer Transformer\n- **BART**: Denoising autoencoder\n- **PEGASUS**: Pre-trained for summarization"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from transformers import pipeline\nimport evaluate\n\nprint('\u2713 Ready!')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Summarization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load summarizer\nsummarizer = pipeline('summarization', model='facebook/bart-large-cnn')\n\narticle = \"\"\"Climate change is one of the most pressing issues facing humanity today. \nGlobal temperatures have risen by approximately 1.1\u00b0C since pre-industrial times, \nprimarily due to greenhouse gas emissions from human activities. The consequences \ninclude more frequent extreme weather events, rising sea levels, and disruptions \nto ecosystems and agriculture. Scientists agree that immediate action is needed \nto limit warming to 1.5\u00b0C above pre-industrial levels to avoid the most catastrophic \nimpacts. This requires rapid reductions in carbon emissions across all sectors of \nthe economy, as well as adaptation measures to cope with changes already underway.\"\"\"\n\nsummary = summarizer(article, max_length=60, min_length=30, do_sample=False)\nprint(f\"Original ({len(article)} chars):\")\nprint(article)\nprint(f\"\\nSummary ({len(summary[0]['summary_text'])} chars):\")\nprint(summary[0]['summary_text'])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Evaluation Metrics\n\n### ROUGE (Recall-Oriented Understudy for Gisting Evaluation):\n- ROUGE-1: Unigram overlap\n- ROUGE-2: Bigram overlap\n- ROUGE-L: Longest common subsequence\n\n### BLEU:\n- Precision-based metric\n- Common for translation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Evaluate summarization\nrouge = evaluate.load('rouge')\n\nreference = \"Climate change requires immediate action to reduce carbon emissions.\"\nprediction = summary[0]['summary_text']\n\nscores = rouge.compute(predictions=[prediction], references=[reference])\nprint(\"ROUGE scores:\")\nfor key, value in scores.items():\n    print(f\"  {key}: {value:.3f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Exercise**: Build summarizer\n\n1. Fine-tune T5 on CNN/DailyMail\n2. Implement beam search\n3. Compare abstractive vs extractive\n4. Evaluate with ROUGE"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# YOUR CODE HERE"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nText generation and summarization are powerful applications of transformers. Models like T5 and BART achieve excellent results."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}