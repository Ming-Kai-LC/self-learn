{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 03: Pandas Basics\n",
    "\n",
    "**Estimated Time**: 60 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will:\n",
    "- Understand what Pandas is and why it's essential\n",
    "- Create and manipulate Series and DataFrames\n",
    "- Load data from CSV, Excel, and other formats\n",
    "- Select, filter, and sort data efficiently\n",
    "- Perform group-by operations and aggregations\n",
    "- Add, modify, and delete columns\n",
    "- Handle basic date/time data\n",
    "- Export data to various formats\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Modules 00-02 completed\n",
    "- NumPy fundamentals\n",
    "- Basic Python knowledge\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Pandas\n",
    "\n",
    "**Pandas** is Python's most powerful library for data manipulation and analysis.\n",
    "\n",
    "### Why Pandas?\n",
    "\n",
    "- **Tabular data**: Works like Excel or SQL, but with programming power\n",
    "- **Data cleaning**: Easily handle missing values, duplicates, and transformations\n",
    "- **Time series**: Built-in support for dates and times\n",
    "- **I/O**: Read/write CSV, Excel, SQL, JSON, and more\n",
    "- **Integration**: Works seamlessly with NumPy, Matplotlib, and scikit-learn\n",
    "\n",
    "### Real-World Analogy\n",
    "\n",
    "Think of Pandas as:\n",
    "- **Excel**: But with Python's automation and scalability\n",
    "- **SQL**: But easier to learn and more flexible\n",
    "- **Spreadsheet + Programming**: The best of both worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(\"Ready to start!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pandas Series\n",
    "\n",
    "A **Series** is a one-dimensional labeled array (like a column in Excel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Series from a list\n",
    "temperatures = pd.Series([72, 68, 75, 71, 69])\n",
    "print(\"Temperatures Series:\")\n",
    "print(temperatures)\n",
    "print(f\"\\nType: {type(temperatures)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series with custom index (labels)\n",
    "days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]\n",
    "temperatures = pd.Series([72, 68, 75, 71, 69], index=days)\n",
    "\n",
    "print(\"Labeled Series:\")\n",
    "print(temperatures)\n",
    "\n",
    "# Access by label\n",
    "print(f\"\\nWednesday temperature: {temperatures['Wednesday']}Â°F\")\n",
    "print(f\"First temperature: {temperatures[0]}Â°F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series attributes and methods\n",
    "print(\"Series Information:\")\n",
    "print(f\"Values: {temperatures.values}\")\n",
    "print(f\"Index: {temperatures.index.tolist()}\")\n",
    "print(f\"Shape: {temperatures.shape}\")\n",
    "print(f\"Size: {temperatures.size}\")\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"Mean: {temperatures.mean():.1f}Â°F\")\n",
    "print(f\"Max: {temperatures.max()}Â°F\")\n",
    "print(f\"Min: {temperatures.min()}Â°F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series operations (vectorized)\n",
    "print(\"Temperature conversions:\")\n",
    "celsius = (temperatures - 32) * 5 / 9\n",
    "print(\"\\nCelsius:\")\n",
    "print(celsius.round(1))\n",
    "\n",
    "# Boolean indexing\n",
    "print(\"\\nWarm days (>70Â°F):\")\n",
    "warm_days = temperatures[temperatures > 70]\n",
    "print(warm_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DataFrames: The Core of Pandas\n",
    "\n",
    "A **DataFrame** is a 2D labeled data structure (think spreadsheet or SQL table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from dictionary\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\"],\n",
    "    \"Age\": [25, 30, 35, 28, 32],\n",
    "    \"City\": [\"New York\", \"London\", \"Paris\", \"Tokyo\", \"Berlin\"],\n",
    "    \"Salary\": [70000, 80000, 75000, 85000, 72000],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Employee DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame information\n",
    "print(\"DataFrame Info:\")\n",
    "print(f\"Shape: {df.shape} (rows x columns)\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Data types:\\n{df.dtypes}\")\n",
    "print(f\"\\nMemory usage: {df.memory_usage().sum()} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at data\n",
    "print(\"First 3 rows:\")\n",
    "print(df.head(3))\n",
    "\n",
    "print(\"\\nLast 2 rows:\")\n",
    "print(df.tail(2))\n",
    "\n",
    "print(\"\\nRandom 2 rows:\")\n",
    "print(df.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Statistical Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nDetailed info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loading Data from Files\n",
    "\n",
    "Pandas can read data from many formats. Let's practice with our sample datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sales data\n",
    "sales_df = pd.read_csv(\"../data/sales_data.csv\")\n",
    "\n",
    "print(\"Sales Data:\")\n",
    "print(sales_df.head())\n",
    "print(f\"\\nShape: {sales_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load customer data\n",
    "customers_df = pd.read_csv(\"../data/customer_data.csv\")\n",
    "\n",
    "print(\"Customer Data:\")\n",
    "print(customers_df.head())\n",
    "print(f\"\\nColumns: {customers_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data\n",
    "print(\"Data Overview:\")\n",
    "print(f\"Total sales records: {len(sales_df)}\")\n",
    "print(f\"Total customers: {len(customers_df)}\")\n",
    "print(f\"\\nSales columns: {sales_df.columns.tolist()}\")\n",
    "print(f\"\\nFirst sale: {sales_df['Date'].iloc[0]}\")\n",
    "print(f\"Last sale: {sales_df['Date'].iloc[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selecting Data\n",
    "\n",
    "Learn different ways to select columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select single column (returns Series)\n",
    "names = df[\"Name\"]\n",
    "print(\"Names (Series):\")\n",
    "print(names)\n",
    "print(f\"Type: {type(names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select multiple columns (returns DataFrame)\n",
    "subset = df[[\"Name\", \"Salary\"]]\n",
    "print(\"Name and Salary:\")\n",
    "print(subset)\n",
    "print(f\"Type: {type(subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows by position with iloc\n",
    "print(\"First row (iloc):\")\n",
    "print(df.iloc[0])\n",
    "\n",
    "print(\"\\nFirst 3 rows, first 2 columns:\")\n",
    "print(df.iloc[:3, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows by label/condition with loc\n",
    "print(\"Row at index 0 (loc):\")\n",
    "print(df.loc[0])\n",
    "\n",
    "# Select specific rows and columns\n",
    "print(\"\\nSpecific selection:\")\n",
    "print(df.loc[0:2, [\"Name\", \"City\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Filtering Data\n",
    "\n",
    "Filter rows based on conditions (Boolean indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple filter\n",
    "high_earners = df[df[\"Salary\"] >= 75000]\n",
    "print(\"High earners (Salary >= $75,000):\")\n",
    "print(high_earners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple conditions (AND)\n",
    "young_high_earners = df[(df[\"Age\"] < 30) & (df[\"Salary\"] > 70000)]\n",
    "print(\"Young high earners (Age < 30 AND Salary > $70,000):\")\n",
    "print(young_high_earners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR condition\n",
    "special_cases = df[(df[\"Age\"] > 32) | (df[\"Salary\"] < 72000)]\n",
    "print(\"Special cases (Age > 32 OR Salary < $72,000):\")\n",
    "print(special_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by list (isin)\n",
    "selected_cities = df[df[\"City\"].isin([\"New York\", \"Tokyo\"])]\n",
    "print(\"Employees in New York or Tokyo:\")\n",
    "print(selected_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String operations\n",
    "# Using sales data\n",
    "electronics = sales_df[sales_df[\"Category\"] == \"Electronics\"]\n",
    "print(f\"Electronics sales: {len(electronics)} transactions\")\n",
    "print(electronics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sorting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by single column\n",
    "sorted_by_salary = df.sort_values(\"Salary\", ascending=False)\n",
    "print(\"Sorted by Salary (highest first):\")\n",
    "print(sorted_by_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by multiple columns\n",
    "sorted_multi = df.sort_values([\"City\", \"Age\"])\n",
    "print(\"Sorted by City, then Age:\")\n",
    "print(sorted_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top N values\n",
    "top_3_earners = df.nlargest(3, \"Salary\")\n",
    "print(\"Top 3 earners:\")\n",
    "print(top_3_earners[[\"Name\", \"Salary\"]])\n",
    "\n",
    "youngest_2 = df.nsmallest(2, \"Age\")\n",
    "print(\"\\nYoungest 2 employees:\")\n",
    "print(youngest_2[[\"Name\", \"Age\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Adding and Modifying Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column\n",
    "df[\"Bonus\"] = df[\"Salary\"] * 0.10\n",
    "print(\"With Bonus column:\")\n",
    "print(df[[\"Name\", \"Salary\", \"Bonus\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add calculated column\n",
    "df[\"Total_Compensation\"] = df[\"Salary\"] + df[\"Bonus\"]\n",
    "print(\"With Total Compensation:\")\n",
    "print(df[[\"Name\", \"Salary\", \"Bonus\", \"Total_Compensation\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional column\n",
    "df[\"Experience_Level\"] = df[\"Age\"].apply(lambda x: \"Senior\" if x >= 30 else \"Junior\")\n",
    "print(\"With Experience Level:\")\n",
    "print(df[[\"Name\", \"Age\", \"Experience_Level\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify existing values\n",
    "df_copy = df.copy()\n",
    "df_copy.loc[df_copy[\"City\"] == \"Paris\", \"City\"] = \"Paris, France\"\n",
    "print(\"Modified City values:\")\n",
    "print(df_copy[[\"Name\", \"City\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete column\n",
    "df_copy = df.copy()\n",
    "df_copy = df_copy.drop(\"Bonus\", axis=1)  # axis=1 for columns\n",
    "print(\"After dropping Bonus:\")\n",
    "print(df_copy.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Group-By Operations\n",
    "\n",
    "Group data by categories and perform aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group sales by category\n",
    "category_sales = sales_df.groupby(\"Category\")[\"Sales\"].sum()\n",
    "print(\"Total Sales by Category:\")\n",
    "print(category_sales)\n",
    "print(f\"\\nType: {type(category_sales)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple aggregations\n",
    "category_stats = sales_df.groupby(\"Category\")[\"Sales\"].agg([\"sum\", \"mean\", \"count\"])\n",
    "print(\"Sales Statistics by Category:\")\n",
    "print(category_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by multiple columns\n",
    "region_category = sales_df.groupby([\"Region\", \"Category\"])[\"Sales\"].sum()\n",
    "print(\"Sales by Region and Category:\")\n",
    "print(region_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate multiple columns\n",
    "region_summary = sales_df.groupby(\"Region\").agg({\"Sales\": [\"sum\", \"mean\"], \"Units\": \"sum\"})\n",
    "print(\"Region Summary:\")\n",
    "print(region_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Basic Date/Time Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to datetime\n",
    "sales_df[\"Date\"] = pd.to_datetime(sales_df[\"Date\"])\n",
    "print(\"Date column info:\")\n",
    "print(sales_df[\"Date\"].dtype)\n",
    "print(\"\\nFirst few dates:\")\n",
    "print(sales_df[\"Date\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date components\n",
    "sales_df[\"Year\"] = sales_df[\"Date\"].dt.year\n",
    "sales_df[\"Month\"] = sales_df[\"Date\"].dt.month\n",
    "sales_df[\"Day\"] = sales_df[\"Date\"].dt.day\n",
    "sales_df[\"DayOfWeek\"] = sales_df[\"Date\"].dt.day_name()\n",
    "\n",
    "print(\"Date components:\")\n",
    "print(sales_df[[\"Date\", \"Year\", \"Month\", \"Day\", \"DayOfWeek\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by date\n",
    "jan_15_onwards = sales_df[sales_df[\"Date\"] >= \"2024-01-15\"]\n",
    "print(f\"Sales from Jan 15 onwards: {len(jan_15_onwards)} records\")\n",
    "print(jan_15_onwards.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "df.to_csv(\"employees_export.csv\", index=False)\n",
    "print(\"Exported to employees_export.csv\")\n",
    "\n",
    "# Verify by loading\n",
    "loaded = pd.read_csv(\"employees_export.csv\")\n",
    "print(\"\\nLoaded back:\")\n",
    "print(loaded.head())\n",
    "\n",
    "# Clean up\n",
    "import os\n",
    "\n",
    "os.remove(\"employees_export.csv\")\n",
    "print(\"\\nTemp file removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Practical Example: Sales Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "sales = pd.read_csv(\"../data/sales_data.csv\")\n",
    "sales[\"Date\"] = pd.to_datetime(sales[\"Date\"])\n",
    "\n",
    "print(\"SALES ANALYSIS REPORT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Overall statistics\n",
    "total_sales = sales[\"Sales\"].sum()\n",
    "avg_sales = sales[\"Sales\"].mean()\n",
    "total_transactions = len(sales)\n",
    "\n",
    "print(f\"Total Sales: ${total_sales:,.2f}\")\n",
    "print(f\"Average Transaction: ${avg_sales:,.2f}\")\n",
    "print(f\"Total Transactions: {total_transactions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best performing category\n",
    "category_performance = (\n",
    "    sales.groupby(\"Category\")\n",
    "    .agg({\"Sales\": \"sum\", \"Units\": \"sum\"})\n",
    "    .sort_values(\"Sales\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\nPerformance by Category:\")\n",
    "print(category_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best region\n",
    "region_sales = sales.groupby(\"Region\")[\"Sales\"].sum().sort_values(ascending=False)\n",
    "print(\"\\nSales by Region:\")\n",
    "print(region_sales)\n",
    "\n",
    "best_region = region_sales.index[0]\n",
    "print(f\"\\nBest Region: {best_region} (${region_sales.iloc[0]:,.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top products\n",
    "product_sales = sales.groupby(\"Product\")[\"Sales\"].sum().sort_values(ascending=False)\n",
    "print(\"\\nTop 3 Products:\")\n",
    "print(product_sales.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Customer Analysis\n",
    "# TODO: Load customer_data.csv\n",
    "# TODO: Find the average Total_Spent by Membership_Level\n",
    "# TODO: Identify which State has the most customers\n",
    "# TODO: Calculate the total revenue from all customers\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Housing Data\n",
    "# TODO: Load housing_prices.csv\n",
    "# TODO: Find the average price by City\n",
    "# TODO: Calculate the price per square foot for each house\n",
    "# TODO: Find houses with 4+ bedrooms and price < $500,000\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Create Your Own DataFrame\n",
    "# TODO: Create a DataFrame with information about 5 books\n",
    "# Columns: Title, Author, Year, Pages, Rating (1-5)\n",
    "# TODO: Add a column for 'Category' (Fiction/Non-Fiction)\n",
    "# TODO: Find the highest-rated book\n",
    "# TODO: Calculate average pages by Category\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Key Takeaways\n",
    "\n",
    "Excellent work! You've mastered Pandas basics:\n",
    "\n",
    "âœ“ **Series and DataFrames**: Core Pandas data structures  \n",
    "âœ“ **Loading data**: Read from CSV and other formats  \n",
    "âœ“ **Selecting data**: loc, iloc, boolean indexing  \n",
    "âœ“ **Filtering**: Conditional selection with boolean operators  \n",
    "âœ“ **Sorting**: Single and multi-column sorting  \n",
    "âœ“ **Adding columns**: Create calculated and conditional columns  \n",
    "âœ“ **Group-by**: Aggregate data by categories  \n",
    "âœ“ **Date/time**: Basic datetime operations  \n",
    "âœ“ **Exporting**: Save processed data  \n",
    "\n",
    "## Next Steps\n",
    "\n",
    "**Next Module**: `04_data_cleaning.ipynb`\n",
    "\n",
    "In Module 04, you'll learn to handle messy real-world data: missing values, duplicates, and data quality issues.\n",
    "\n",
    "---\n",
    "\n",
    "**Great job!** You're building a strong foundation in data science. Keep practicing! ðŸ“Š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
