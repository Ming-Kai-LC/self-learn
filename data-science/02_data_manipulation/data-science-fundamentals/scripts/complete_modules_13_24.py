"""
Efficiently complete remaining sections of Modules 13-24 with comprehensive content.
This script generates the remaining cells for each module to maintain consistency and quality.
"""

import json


def get_grid_search_cells():
    """Grid Search section cells for Module 13."""
    return [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Grid Search\n\n",
                "Grid Search exhaustively tries all combinations of hyperparameters.\n\n",
                "### How Grid Search Works\n\n",
                "1. Define a grid of hyperparameter values\n",
                "2. Try every possible combination\n",
                "3. Evaluate each using cross-validation\n",
                "4. Return the best combination\n\n",
                "### Pros & Cons\n\n",
                "**Pros:**\n",
                "- Guaranteed to find best combination in the grid\n",
                "- Easy to understand and implement\n",
                "- Parallelizable\n\n",
                "**Cons:**\n",
                "- Exponentially slow (curse of dimensionality)\n",
                "- Wastes time on bad combinations\n",
                "- Limited to discrete values\n\n",
                "### Example Grid Size\n\n",
                "If you have:\n",
                "- Parameter A: 3 values\n",
                "- Parameter B: 4 values\n",
                "- Parameter C: 5 values\n",
                "- 5-fold CV\n\n",
                "**Total fits**: 3 Ã— 4 Ã— 5 Ã— 5 = **300 models trained!**\n\n",
                "Let's use Grid Search to tune a Random Forest!",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Grid Search Example\\n",
                "\\n",
                'print("="*60)\\n',
                'print("GRID SEARCH FOR HYPERPARAMETER TUNING")\\n',
                'print("="*60)\\n',
                "\\n",
                "# Define the parameter grid\\n",
                "param_grid = {\\n",
                "    'n_estimators': [50, 100, 200],\\n",
                "    'max_depth': [5, 10, 15, None],\\n",
                "    'min_samples_split': [2, 5, 10],\\n",
                "    'min_samples_leaf': [1, 2, 4]\\n",
                "}\\n",
                "\\n",
                'print("\\nParameter Grid:")\\n',
                "for param, values in param_grid.items():\\n",
                '    print(f"  {param}: {values}")\\n',
                "\\n",
                "total_combinations = np.prod([len(v) for v in param_grid.values()])\\n",
                'print(f"\\nTotal combinations: {total_combinations}")\\n',
                'print(f"With 5-fold CV: {total_combinations * 5} model fits!")\\n',
                "\\n",
                "# Create Grid Search object\\n",
                "rf = RandomForestClassifier(random_state=42)\\n",
                "grid_search = GridSearchCV(\\n",
                "    estimator=rf,\\n",
                "    param_grid=param_grid,\\n",
                "    cv=5,\\n",
                "    scoring='accuracy',\\n",
                "    n_jobs=-1,  # Use all CPU cores\\n",
                "    verbose=1\\n",
                ")\\n",
                "\\n",
                "# Fit Grid Search\\n",
                'print("\\nStarting Grid Search...")\\n',
                "start_time = time.time()\\n",
                "grid_search.fit(X_train_scaled, y_train)\\n",
                "elapsed_time = time.time() - start_time\\n",
                "\\n",
                "# Results\\n",
                'print("\\n" + "="*60)\\n',
                'print("GRID SEARCH RESULTS")\\n',
                'print("="*60)\\n',
                "\\n",
                'print(f"\\nBest Parameters: {grid_search.best_params_}")\\n',
                'print(f"Best CV Score: {grid_search.best_score_:.4f}")\\n',
                'print(f"Time Elapsed: {elapsed_time:.2f} seconds")\\n',
                "\\n",
                "# Test on hold-out set\\n",
                "best_model = grid_search.best_estimator_\\n",
                "test_score = best_model.score(X_test_scaled, y_test)\\n",
                'print(f"Test Score: {test_score:.4f}")\\n',
                "\\n",
                "# Show top 10 combinations\\n",
                "results_df = pd.DataFrame(grid_search.cv_results_)\\n",
                "top_10 = results_df.nlargest(10, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\\n",
                "\\n",
                'print("\\nTop 10 Hyperparameter Combinations:")\\n',
                "display(top_10)\\n",
                "\\n",
                "# Visualize results\\n",
                "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\\n",
                "\\n",
                "# 1. Effect of n_estimators\\n",
                "n_est_effect = results_df.groupby([p.split('__')[-1] for p in results_df['param_n_estimators'].astype(str)])\\n",
                "\\n",
                'print("\\nâœ“ Grid Search complete!")\\n',
                'print(f"ðŸ’¡ Best accuracy improved from default to {test_score:.4f}")',
            ],
        },
    ]


print("Grid Search cells generated successfully")
print("This script provides template for completing all modules efficiently")
