{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 06: Systematic Literature Reviews\n",
    "\n",
    "**Estimated Time**: 50 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "1. **Distinguish** systematic reviews from traditional narrative reviews\n",
    "2. **Formulate** focused research questions using PICO framework\n",
    "3. **Design** comprehensive search strategies across multiple databases\n",
    "4. **Apply** PRISMA guidelines for transparent reporting\n",
    "5. **Screen** studies using explicit inclusion/exclusion criteria\n",
    "6. **Assess** risk of bias in included studies\n",
    "7. **Extract** data systematically using standardized forms\n",
    "8. **Synthesize** findings narratively and quantitatively\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "**Science advances through synthesis, not just individual studies.**\n",
    "\n",
    "Systematic reviews:\n",
    "- **Summarize** all available evidence on a question\n",
    "- **Identify** research gaps and inconsistencies\n",
    "- **Inform** policy, practice, and future research\n",
    "- **Reduce** research waste and duplication\n",
    "- **Sit at top** of evidence hierarchy\n",
    "\n",
    "Unlike traditional \"literature reviews\" (often selective and biased), systematic reviews:\n",
    "- Use **explicit, reproducible methods**\n",
    "- **Minimize bias** through comprehensive searching\n",
    "- **Assess quality** of included studies\n",
    "- Follow **reporting standards** (PRISMA)\n",
    "\n",
    "This module teaches you to conduct rigorous, publishable systematic reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set style\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "\n",
    "os.makedirs(\"outputs/module_06\", exist_ok=True)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")\n",
    "print(\"âœ“ Output directory created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Systematic vs. Narrative Reviews\n",
    "\n",
    "### Narrative (Traditional) Literature Review\n",
    "\n",
    "**Characteristics**:\n",
    "- Broad scope\n",
    "- Selective sampling of literature\n",
    "- No explicit search strategy\n",
    "- Qualitative synthesis\n",
    "- Author's interpretation emphasized\n",
    "\n",
    "**Strengths**:\n",
    "âœ“ Provides context and background  \n",
    "âœ“ Identifies themes and trends  \n",
    "âœ“ Faster to complete  \n",
    "\n",
    "**Weaknesses**:\n",
    "âœ— Potentially biased selection  \n",
    "âœ— Not reproducible  \n",
    "âœ— May miss key studies  \n",
    "âœ— Difficult to assess completeness  \n",
    "\n",
    "### Systematic Literature Review\n",
    "\n",
    "**Characteristics**:\n",
    "- Focused, answerable question\n",
    "- Comprehensive, reproducible search\n",
    "- Explicit inclusion/exclusion criteria\n",
    "- Quality assessment of studies\n",
    "- Structured synthesis (narrative or meta-analytic)\n",
    "\n",
    "**Strengths**:\n",
    "âœ“ Minimizes bias  \n",
    "âœ“ Reproducible  \n",
    "âœ“ Comprehensive  \n",
    "âœ“ Rigorous and transparent  \n",
    "âœ“ High evidence level  \n",
    "\n",
    "**Weaknesses**:\n",
    "âœ— Time-consuming (6-18 months)  \n",
    "âœ— Resource-intensive  \n",
    "âœ— Requires team collaboration  \n",
    "âœ— May yield \"no conclusive evidence\"  \n",
    "\n",
    "### Comparison Table\n",
    "\n",
    "| Feature | Narrative Review | Systematic Review |\n",
    "|---------|-----------------|-------------------|\n",
    "| **Question** | Broad | Focused, specific |\n",
    "| **Search** | Informal, selective | Comprehensive, explicit |\n",
    "| **Selection** | Unclear criteria | Explicit criteria |\n",
    "| **Quality assessment** | Rarely done | Always done |\n",
    "| **Synthesis** | Qualitative | Narrative and/or quantitative |\n",
    "| **Reproducibility** | Low | High |\n",
    "| **Time required** | Weeks | Months |\n",
    "| **Team size** | 1 author | 2+ reviewers |\n",
    "| **Protocol** | No | Pre-registered (PROSPERO) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The PICO Framework\n",
    "\n",
    "**PICO** helps formulate focused, answerable research questions.\n",
    "\n",
    "### Components\n",
    "\n",
    "- **P** = Population/Problem\n",
    "- **I** = Intervention/Exposure\n",
    "- **C** = Comparison/Control\n",
    "- **O** = Outcome\n",
    "\n",
    "**Optional additions**:\n",
    "- **T** = Time (PICOT)\n",
    "- **S** = Study design (PICOS)\n",
    "\n",
    "### Examples\n",
    "\n",
    "#### Example 1: Clinical Question\n",
    "\n",
    "**Broad question**: \"Does exercise help depression?\"\n",
    "\n",
    "**PICO formulation**:\n",
    "- **P**: Adults with major depressive disorder\n",
    "- **I**: Aerobic exercise programs (â‰¥30 min, â‰¥3x/week)\n",
    "- **C**: Usual care or waitlist control\n",
    "- **O**: Depression severity (measured by validated scales)\n",
    "\n",
    "**Focused question**: \"In adults with major depressive disorder, do aerobic exercise programs (â‰¥30 min, â‰¥3x/week) reduce depression severity compared to usual care?\"\n",
    "\n",
    "#### Example 2: Data Science Question\n",
    "\n",
    "**Broad question**: \"Are deep learning models better?\"\n",
    "\n",
    "**PICO formulation**:\n",
    "- **P**: Image classification tasks (ImageNet, CIFAR-10)\n",
    "- **I**: Deep convolutional neural networks\n",
    "- **C**: Traditional machine learning (SVM, Random Forest)\n",
    "- **O**: Classification accuracy, F1-score\n",
    "\n",
    "**Focused question**: \"For standard image classification benchmarks, do deep CNNs achieve higher accuracy than traditional ML approaches?\"\n",
    "\n",
    "### Benefits of PICO\n",
    "\n",
    "1. **Clarifies** the research question\n",
    "2. **Guides** search strategy (generates keywords)\n",
    "3. **Defines** inclusion/exclusion criteria\n",
    "4. **Structures** data extraction\n",
    "5. **Organizes** synthesis and reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PICO worksheet generator\n",
    "\n",
    "\n",
    "def create_pico_worksheet(question_title):\n",
    "    \"\"\"\n",
    "    Generate a structured PICO worksheet for systematic review planning.\n",
    "    \"\"\"\n",
    "    pico_template = pd.DataFrame(\n",
    "        {\n",
    "            \"Component\": [\n",
    "                \"Population (P)\",\n",
    "                \"Intervention (I)\",\n",
    "                \"Comparison (C)\",\n",
    "                \"Outcome (O)\",\n",
    "                \"Time (optional)\",\n",
    "                \"Study Design (optional)\",\n",
    "            ],\n",
    "            \"Description\": [\n",
    "                \"Who is the target population? (age, condition, setting)\",\n",
    "                \"What is the intervention or exposure of interest?\",\n",
    "                \"What is it compared to? (control, standard care, alternative)\",\n",
    "                \"What outcomes are you measuring? (primary and secondary)\",\n",
    "                \"Time frame or follow-up period?\",\n",
    "                \"What study designs will you include? (RCT, cohort, etc.)\",\n",
    "            ],\n",
    "            \"Your_Answer\": [\"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "            \"Keywords_for_Search\": [\"\", \"\", \"\", \"\", \"\", \"\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    filename = f'outputs/module_06/PICO_worksheet_{question_title.replace(\" \", \"_\")}.csv'\n",
    "    pico_template.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"PICO Worksheet Template\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Research Question: {question_title}\")\n",
    "    print(\"\\n\" + pico_template.to_string(index=False))\n",
    "    print(f\"\\nâœ“ Worksheet saved to: {filename}\")\n",
    "\n",
    "    return pico_template\n",
    "\n",
    "\n",
    "# Example usage\n",
    "worksheet = create_pico_worksheet(\"Exercise_for_Depression\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXAMPLE COMPLETED PICO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "example_pico = pd.DataFrame(\n",
    "    {\n",
    "        \"Component\": [\"P\", \"I\", \"C\", \"O\"],\n",
    "        \"Element\": [\n",
    "            \"Adults (18+) with major depressive disorder\",\n",
    "            \"Aerobic exercise (â‰¥30 min, â‰¥3x/week, â‰¥4 weeks)\",\n",
    "            \"Usual care, waitlist, or no intervention\",\n",
    "            \"Depression severity (BDI, HAMD, PHQ-9)\",\n",
    "        ],\n",
    "        \"Search_Keywords\": [\n",
    "            'adult*, depress*, \"major depressive disorder\", MDD',\n",
    "            'exercise, \"physical activity\", aerobic, running, jogging, walking',\n",
    "            '\"usual care\", control, waitlist, placebo',\n",
    "            'depress*, \"depression severity\", BDI, HAMD, \"Hamilton Depression\"',\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\n\" + example_pico.to_string(index=False))\n",
    "\n",
    "print(\"\\nğŸ’¡ PICO transforms vague questions into precise, searchable queries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Search Strategy\n",
    "\n",
    "### Key Principles\n",
    "\n",
    "1. **Comprehensive**: Search multiple databases\n",
    "2. **Systematic**: Use structured search strings\n",
    "3. **Reproducible**: Document every step\n",
    "4. **Sensitive**: Prefer sensitivity over specificity (cast wide net)\n",
    "\n",
    "### Databases to Search\n",
    "\n",
    "#### General/Multidisciplinary\n",
    "- **PubMed/MEDLINE**: Biomedical sciences\n",
    "- **Web of Science**: Multidisciplinary\n",
    "- **Scopus**: Multidisciplinary, large coverage\n",
    "- **Google Scholar**: Broad, includes grey literature\n",
    "\n",
    "#### Discipline-Specific\n",
    "- **PsycINFO**: Psychology\n",
    "- **ERIC**: Education\n",
    "- **EconLit**: Economics\n",
    "- **IEEE Xplore**: Engineering/Computer Science\n",
    "- **ACM Digital Library**: Computer Science\n",
    "\n",
    "#### Grey Literature\n",
    "- **ProQuest Dissertations**: Theses/dissertations\n",
    "- **ClinicalTrials.gov**: Trial registries\n",
    "- **OpenGrey**: Grey literature\n",
    "- **Preprint servers**: arXiv, bioRxiv, medRxiv\n",
    "\n",
    "### Boolean Operators\n",
    "\n",
    "- **AND**: Narrows search (both terms must appear)\n",
    "  - `depression AND exercise`\n",
    "\n",
    "- **OR**: Broadens search (either term)\n",
    "  - `exercise OR \"physical activity\"`\n",
    "\n",
    "- **NOT**: Excludes terms\n",
    "  - `depression NOT bipolar`\n",
    "\n",
    "### Wildcards and Truncation\n",
    "\n",
    "- **Asterisk (*)**: Matches any characters\n",
    "  - `exercis*` â†’ exercise, exercises, exercising\n",
    "\n",
    "- **Question mark (?)**: Single character\n",
    "  - `wom?n` â†’ woman, women\n",
    "\n",
    "### Example Search String\n",
    "\n",
    "```\n",
    "(depress* OR \"major depressive disorder\" OR MDD OR \"depressive symptoms\")\n",
    "AND\n",
    "(exercise OR \"physical activity\" OR aerobic OR running OR jogging OR walking OR \"resistance training\")\n",
    "AND\n",
    "(RCT OR \"randomized controlled trial\" OR \"randomised controlled trial\" OR \"clinical trial\")\n",
    "```\n",
    "\n",
    "### Search Documentation\n",
    "\n",
    "For each database, record:\n",
    "1. Database name and platform\n",
    "2. Date of search\n",
    "3. Full search string\n",
    "4. Number of results\n",
    "5. Any limits applied (date range, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create search documentation template\n",
    "\n",
    "\n",
    "def create_search_log():\n",
    "    \"\"\"\n",
    "    Generate a template for documenting systematic review searches.\n",
    "    \"\"\"\n",
    "    search_log = pd.DataFrame(\n",
    "        {\n",
    "            \"Database\": [\"PubMed\", \"Web of Science\", \"Scopus\", \"PsycINFO\", \"Google Scholar\"],\n",
    "            \"Platform\": [\"NCBI\", \"Clarivate\", \"Elsevier\", \"APA\", \"Google\"],\n",
    "            \"Date_Searched\": [\"\"] * 5,\n",
    "            \"Search_String\": [\"\"] * 5,\n",
    "            \"Limits_Applied\": [\"\"] * 5,\n",
    "            \"Results_Retrieved\": [0] * 5,\n",
    "            \"Notes\": [\"\"] * 5,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    search_log.to_csv(\"outputs/module_06/search_documentation_log.csv\", index=False)\n",
    "\n",
    "    print(\"SEARCH DOCUMENTATION LOG\")\n",
    "    print(\"=\" * 80)\n",
    "    print(search_log.to_string(index=False))\n",
    "    print(\"\\nâœ“ Search log template saved to outputs/module_06/\")\n",
    "\n",
    "    return search_log\n",
    "\n",
    "\n",
    "search_log = create_search_log()\n",
    "\n",
    "# Example completed search log\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXAMPLE COMPLETED SEARCH LOG\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "example_searches = pd.DataFrame(\n",
    "    {\n",
    "        \"Database\": [\"PubMed\", \"Scopus\", \"PsycINFO\"],\n",
    "        \"Date\": [\"2024-01-15\", \"2024-01-15\", \"2024-01-16\"],\n",
    "        \"Search_String\": [\n",
    "            \"(depress*[Title/Abstract]) AND (exercise[Title/Abstract])\",\n",
    "            \"TITLE-ABS-KEY(depress*) AND TITLE-ABS-KEY(exercise)\",\n",
    "            \"AB(depression) AND AB(exercise)\",\n",
    "        ],\n",
    "        \"Results\": [1247, 1893, 456],\n",
    "        \"After_Deduplication\": [\"-\", \"-\", \"-\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\n\" + example_searches.to_string(index=False))\n",
    "print(f\"\\nTotal retrieved: {example_searches['Results'].sum()}\")\n",
    "print(\"\\nğŸ’¡ Comprehensive searching across databases is essential.\")\n",
    "print(\"   Expect overlap (duplicates) - that's normal and expected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PRISMA Guidelines\n",
    "\n",
    "**PRISMA** = Preferred Reporting Items for Systematic Reviews and Meta-Analyses\n",
    "\n",
    "### Purpose\n",
    "- Standardized reporting of systematic reviews\n",
    "- Improves transparency and completeness\n",
    "- Consists of 27-item checklist + flow diagram\n",
    "\n",
    "### PRISMA Flow Diagram Stages\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  IDENTIFICATION                         â”‚\n",
    "â”‚  Records identified through database    â”‚\n",
    "â”‚  searching (n = _____)                  â”‚\n",
    "â”‚                                         â”‚\n",
    "â”‚  Additional records from other sources  â”‚\n",
    "â”‚  (n = _____)                            â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "              â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  SCREENING                              â”‚\n",
    "â”‚  Records after duplicates removed       â”‚\n",
    "â”‚  (n = _____)                            â”‚\n",
    "â”‚                                         â”‚\n",
    "â”‚  Records screened (title/abstract)      â”‚\n",
    "â”‚  (n = _____)  â†’  Excluded (n = _____)  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "              â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ELIGIBILITY                            â”‚\n",
    "â”‚  Full-text articles assessed            â”‚\n",
    "â”‚  (n = _____)                            â”‚\n",
    "â”‚                                         â”‚\n",
    "â”‚  Excluded with reasons:                 â”‚\n",
    "â”‚  - Wrong population (n = ___)           â”‚\n",
    "â”‚  - Wrong intervention (n = ___)         â”‚\n",
    "â”‚  - Wrong outcome (n = ___)              â”‚\n",
    "â”‚  - Wrong study design (n = ___)         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "              â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  INCLUDED                               â”‚\n",
    "â”‚  Studies included in qualitative        â”‚\n",
    "â”‚  synthesis (n = _____)                  â”‚\n",
    "â”‚                                         â”‚\n",
    "â”‚  Studies included in meta-analysis      â”‚\n",
    "â”‚  (n = _____)                            â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Key Reporting Elements (Checklist)\n",
    "\n",
    "1. **Title**: Identify as systematic review\n",
    "2. **Abstract**: Structured summary\n",
    "3. **Introduction**: Rationale and objectives\n",
    "4. **Methods**:\n",
    "   - Protocol registration (PROSPERO)\n",
    "   - Eligibility criteria\n",
    "   - Information sources and search strategy\n",
    "   - Study selection process\n",
    "   - Data extraction process\n",
    "   - Risk of bias assessment\n",
    "   - Synthesis methods\n",
    "5. **Results**:\n",
    "   - Study selection (PRISMA flow)\n",
    "   - Study characteristics\n",
    "   - Risk of bias within studies\n",
    "   - Results of synthesis\n",
    "6. **Discussion**:\n",
    "   - Summary of evidence\n",
    "   - Limitations\n",
    "   - Conclusions and implications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a PRISMA flow diagram with example data\n",
    "\n",
    "# Example numbers for a hypothetical systematic review\n",
    "prisma_data = {\n",
    "    \"identification_database\": 3542,\n",
    "    \"identification_other\": 28,\n",
    "    \"after_duplicates\": 2891,\n",
    "    \"title_abstract_screened\": 2891,\n",
    "    \"title_abstract_excluded\": 2654,\n",
    "    \"fulltext_assessed\": 237,\n",
    "    \"fulltext_excluded\": 189,\n",
    "    \"excluded_reasons\": {\n",
    "        \"Wrong population\": 42,\n",
    "        \"Wrong intervention\": 38,\n",
    "        \"Wrong outcome\": 31,\n",
    "        \"Wrong design\": 45,\n",
    "        \"Insufficient data\": 33,\n",
    "    },\n",
    "    \"qualitative_synthesis\": 48,\n",
    "    \"meta_analysis\": 35,\n",
    "}\n",
    "\n",
    "# Create PRISMA flow summary\n",
    "print(\"PRISMA FLOW DIAGRAM - EXAMPLE DATA\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n1. IDENTIFICATION\")\n",
    "print(f\"   Records identified through database searching: {prisma_data['identification_database']}\")\n",
    "print(f\"   Additional records from other sources: {prisma_data['identification_other']}\")\n",
    "print(f\"   Total: {prisma_data['identification_database'] + prisma_data['identification_other']}\")\n",
    "\n",
    "duplicates_removed = (\n",
    "    prisma_data[\"identification_database\"] + prisma_data[\"identification_other\"]\n",
    ") - prisma_data[\"after_duplicates\"]\n",
    "print(f\"\\n2. SCREENING\")\n",
    "print(f\"   Duplicates removed: {duplicates_removed}\")\n",
    "print(f\"   Records after duplicates removed: {prisma_data['after_duplicates']}\")\n",
    "print(f\"   Records excluded at title/abstract: {prisma_data['title_abstract_excluded']}\")\n",
    "print(f\"   Records proceeding to full-text: {prisma_data['fulltext_assessed']}\")\n",
    "\n",
    "print(f\"\\n3. ELIGIBILITY\")\n",
    "print(f\"   Full-text articles assessed: {prisma_data['fulltext_assessed']}\")\n",
    "print(f\"   Full-text articles excluded: {prisma_data['fulltext_excluded']}\")\n",
    "print(f\"\\n   Exclusion reasons:\")\n",
    "for reason, count in prisma_data[\"excluded_reasons\"].items():\n",
    "    print(f\"     - {reason}: {count}\")\n",
    "\n",
    "print(f\"\\n4. INCLUDED\")\n",
    "print(f\"   Studies included in qualitative synthesis: {prisma_data['qualitative_synthesis']}\")\n",
    "print(\n",
    "    f\"   Studies included in quantitative synthesis (meta-analysis): {prisma_data['meta_analysis']}\"\n",
    ")\n",
    "\n",
    "# Calculate attrition at each stage\n",
    "total_start = prisma_data[\"identification_database\"] + prisma_data[\"identification_other\"]\n",
    "retention_after_dedup = prisma_data[\"after_duplicates\"] / total_start * 100\n",
    "retention_after_screen = prisma_data[\"fulltext_assessed\"] / prisma_data[\"after_duplicates\"] * 100\n",
    "retention_after_fulltext = (\n",
    "    prisma_data[\"qualitative_synthesis\"] / prisma_data[\"fulltext_assessed\"] * 100\n",
    ")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"ATTRITION ANALYSIS\")\n",
    "print(f\"Retention after deduplication: {retention_after_dedup:.1f}%\")\n",
    "print(f\"Retention after title/abstract screening: {retention_after_screen:.1f}%\")\n",
    "print(f\"Retention after full-text review: {retention_after_fulltext:.1f}%\")\n",
    "print(f\"Overall retention: {prisma_data['qualitative_synthesis'] / total_start * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Typical systematic reviews include 1-5% of initially identified records.\")\n",
    "print(f\"   High attrition is expected - it reflects rigorous screening!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PRISMA flow\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Define stages and counts\n",
    "stages = [\n",
    "    \"Identified\",\n",
    "    \"After Deduplication\",\n",
    "    \"Title/Abstract Screen\",\n",
    "    \"Full-Text Review\",\n",
    "    \"Included\",\n",
    "]\n",
    "counts = [\n",
    "    total_start,\n",
    "    prisma_data[\"after_duplicates\"],\n",
    "    prisma_data[\"fulltext_assessed\"],\n",
    "    prisma_data[\"qualitative_synthesis\"],\n",
    "    prisma_data[\"qualitative_synthesis\"],\n",
    "]\n",
    "\n",
    "# Create funnel-like visualization\n",
    "y_positions = np.arange(len(stages))\n",
    "colors_funnel = [\"#E63946\", \"#F4A261\", \"#E9C46A\", \"#2A9D8F\", \"#06A77D\"]\n",
    "\n",
    "for i, (stage, count, color) in enumerate(zip(stages[:-1], counts[:-1], colors_funnel[:-1])):\n",
    "    # Draw horizontal bar\n",
    "    bar_width = count / total_start  # Normalize to starting count\n",
    "    ax.barh(i, bar_width, height=0.6, color=color, alpha=0.7, edgecolor=\"black\", linewidth=1.5)\n",
    "\n",
    "    # Add count label\n",
    "    ax.text(bar_width + 0.02, i, f\"n = {count}\", va=\"center\", fontsize=11, fontweight=\"bold\")\n",
    "\n",
    "    # Add stage label\n",
    "    ax.text(-0.02, i, stage, ha=\"right\", va=\"center\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "# Final included (special highlighting)\n",
    "i = len(stages) - 1\n",
    "bar_width = counts[-1] / total_start\n",
    "ax.barh(i, bar_width, height=0.8, color=\"#06A77D\", alpha=0.9, edgecolor=\"black\", linewidth=2.5)\n",
    "ax.text(\n",
    "    bar_width + 0.02, i, f\"n = {counts[-1]}\\n(FINAL)\", va=\"center\", fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "ax.text(-0.02, i, stages[-1], ha=\"right\", va=\"center\", fontsize=11, fontweight=\"bold\")\n",
    "\n",
    "ax.set_xlim([-0.3, 1.2])\n",
    "ax.set_ylim([-0.5, len(stages) - 0.5])\n",
    "ax.set_xlabel(\"Proportion of Initial Records\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_title(\"PRISMA Flow: Study Selection Process\", fontsize=14, fontweight=\"bold\")\n",
    "ax.set_yticks([])\n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.grid(True, alpha=0.3, axis=\"x\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/module_06/prisma_flow.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ PRISMA flow diagram saved to outputs/module_06/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Study Selection: Inclusion and Exclusion Criteria\n",
    "\n",
    "### Two-Stage Screening\n",
    "\n",
    "#### Stage 1: Title and Abstract Screening\n",
    "- Quick initial screen\n",
    "- Liberal inclusion (\"when in doubt, include\")\n",
    "- Two independent reviewers\n",
    "- Resolve disagreements through discussion or third reviewer\n",
    "\n",
    "#### Stage 2: Full-Text Review\n",
    "- Detailed assessment against eligibility criteria\n",
    "- Two independent reviewers\n",
    "- Document reasons for exclusion\n",
    "- Calculate inter-rater reliability (Cohen's Kappa)\n",
    "\n",
    "### Defining Clear Criteria\n",
    "\n",
    "Criteria should be:\n",
    "- **Explicit**: No room for interpretation\n",
    "- **Objective**: Minimize subjective judgment\n",
    "- **PICO-based**: Aligned with research question\n",
    "- **Pre-specified**: Set before screening begins\n",
    "\n",
    "### Example Criteria\n",
    "\n",
    "**Inclusion Criteria**:\n",
    "1. **Population**: Adults (â‰¥18 years) with diagnosed MDD (DSM-5 or ICD-10)\n",
    "2. **Intervention**: Supervised aerobic exercise â‰¥30 minutes, â‰¥3x/week, â‰¥4 weeks\n",
    "3. **Comparison**: Usual care, waitlist, or no intervention\n",
    "4. **Outcome**: Depression severity measured by validated scale (BDI, HAMD, PHQ-9)\n",
    "5. **Study design**: Randomized controlled trials\n",
    "6. **Language**: English\n",
    "7. **Publication type**: Peer-reviewed journal articles\n",
    "\n",
    "**Exclusion Criteria**:\n",
    "1. Non-human studies\n",
    "2. Participants with bipolar disorder or psychotic features\n",
    "3. Exercise as part of multimodal intervention (cannot isolate effect)\n",
    "4. No pre-post depression measures\n",
    "5. Conference abstracts, dissertations (if not peer-reviewed)\n",
    "\n",
    "### Inter-Rater Reliability\n",
    "\n",
    "**Cohen's Kappa (Îº)**: Measures agreement between two raters\n",
    "\n",
    "$$\\kappa = \\frac{p_o - p_e}{1 - p_e}$$\n",
    "\n",
    "Where:\n",
    "- $p_o$ = observed agreement\n",
    "- $p_e$ = expected agreement by chance\n",
    "\n",
    "**Interpretation**:\n",
    "- Îº < 0.20: Poor\n",
    "- Îº = 0.21-0.40: Fair\n",
    "- Îº = 0.41-0.60: Moderate\n",
    "- Îº = 0.61-0.80: Good\n",
    "- Îº = 0.81-1.00: Excellent\n",
    "\n",
    "**Target**: Îº â‰¥ 0.60 for systematic reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Cohen's Kappa for inter-rater reliability\n",
    "\n",
    "\n",
    "def cohens_kappa(rater1, rater2):\n",
    "    \"\"\"\n",
    "    Calculate Cohen's Kappa for two raters.\n",
    "\n",
    "    Parameters:\n",
    "    - rater1: Array of ratings from rater 1 (0=exclude, 1=include)\n",
    "    - rater2: Array of ratings from rater 2 (0=exclude, 1=include)\n",
    "\n",
    "    Returns:\n",
    "    - kappa: Cohen's Kappa coefficient\n",
    "    \"\"\"\n",
    "    # Observed agreement\n",
    "    po = np.mean(rater1 == rater2)\n",
    "\n",
    "    # Expected agreement by chance\n",
    "    p_rater1_yes = np.mean(rater1 == 1)\n",
    "    p_rater1_no = np.mean(rater1 == 0)\n",
    "    p_rater2_yes = np.mean(rater2 == 1)\n",
    "    p_rater2_no = np.mean(rater2 == 0)\n",
    "\n",
    "    pe = (p_rater1_yes * p_rater2_yes) + (p_rater1_no * p_rater2_no)\n",
    "\n",
    "    # Cohen's Kappa\n",
    "    kappa = (po - pe) / (1 - pe)\n",
    "\n",
    "    return kappa, po, pe\n",
    "\n",
    "\n",
    "# Simulate screening decisions from two reviewers\n",
    "np.random.seed(123)\n",
    "n_studies = 200\n",
    "\n",
    "# Reviewer 1 decisions (1=include, 0=exclude)\n",
    "# Assume ~20% of studies are relevant\n",
    "rater1 = np.random.choice([0, 1], size=n_studies, p=[0.80, 0.20])\n",
    "\n",
    "# Reviewer 2 decisions (mostly agrees, but some differences)\n",
    "rater2 = rater1.copy()\n",
    "# Introduce 10% disagreement\n",
    "disagreement_indices = np.random.choice(n_studies, size=int(n_studies * 0.10), replace=False)\n",
    "rater2[disagreement_indices] = 1 - rater2[disagreement_indices]\n",
    "\n",
    "# Calculate kappa\n",
    "kappa, po, pe = cohens_kappa(rater1, rater2)\n",
    "\n",
    "print(\"INTER-RATER RELIABILITY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nNumber of studies screened: {n_studies}\")\n",
    "print(f\"\\nReviewer 1 included: {np.sum(rater1)} ({np.sum(rater1)/n_studies*100:.1f}%)\")\n",
    "print(f\"Reviewer 2 included: {np.sum(rater2)} ({np.sum(rater2)/n_studies*100:.1f}%)\")\n",
    "\n",
    "# Create confusion matrix\n",
    "both_include = np.sum((rater1 == 1) & (rater2 == 1))\n",
    "both_exclude = np.sum((rater1 == 0) & (rater2 == 0))\n",
    "r1_yes_r2_no = np.sum((rater1 == 1) & (rater2 == 0))\n",
    "r1_no_r2_yes = np.sum((rater1 == 0) & (rater2 == 1))\n",
    "\n",
    "print(f\"\\nAgreement Matrix:\")\n",
    "print(f\"  Both include: {both_include}\")\n",
    "print(f\"  Both exclude: {both_exclude}\")\n",
    "print(f\"  Rater 1 yes, Rater 2 no: {r1_yes_r2_no}\")\n",
    "print(f\"  Rater 1 no, Rater 2 yes: {r1_no_r2_yes}\")\n",
    "\n",
    "print(f\"\\nObserved agreement (po): {po:.3f} ({po*100:.1f}%)\")\n",
    "print(f\"Expected agreement by chance (pe): {pe:.3f}\")\n",
    "print(f\"\\nCohen's Kappa (Îº): {kappa:.3f}\")\n",
    "\n",
    "if kappa >= 0.81:\n",
    "    interpretation = \"Excellent\"\n",
    "elif kappa >= 0.61:\n",
    "    interpretation = \"Good\"\n",
    "elif kappa >= 0.41:\n",
    "    interpretation = \"Moderate\"\n",
    "elif kappa >= 0.21:\n",
    "    interpretation = \"Fair\"\n",
    "else:\n",
    "    interpretation = \"Poor\"\n",
    "\n",
    "print(f\"Interpretation: {interpretation}\")\n",
    "\n",
    "if kappa >= 0.60:\n",
    "    print(f\"\\nâœ“ Inter-rater reliability is acceptable (Îº â‰¥ 0.60)\")\n",
    "else:\n",
    "    print(f\"\\nâš  Inter-rater reliability is below target. Consider:\")\n",
    "    print(f\"   - Reviewing and clarifying inclusion/exclusion criteria\")\n",
    "    print(f\"   - Additional reviewer training\")\n",
    "    print(f\"   - Pilot screening to calibrate reviewers\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Disagreements should be resolved through discussion or third-party adjudication.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Risk of Bias Assessment\n",
    "\n",
    "### Why Assess Bias?\n",
    "\n",
    "Not all studies are created equal. Bias assessment:\n",
    "- Identifies weaknesses in evidence base\n",
    "- Informs confidence in findings\n",
    "- Guides sensitivity analyses\n",
    "- Prevents over-reliance on flawed studies\n",
    "\n",
    "### Common Bias Assessment Tools\n",
    "\n",
    "#### For RCTs: Cochrane Risk of Bias Tool (RoB 2)\n",
    "\n",
    "**Domains**:\n",
    "1. **Randomization process**: Adequate sequence generation and allocation concealment?\n",
    "2. **Deviations from intended interventions**: Were participants/personnel blinded?\n",
    "3. **Missing outcome data**: High attrition? Differential dropout?\n",
    "4. **Measurement of outcomes**: Were outcomes assessed objectively?\n",
    "5. **Selection of reported results**: Evidence of selective reporting?\n",
    "\n",
    "**Ratings**: Low risk | Some concerns | High risk\n",
    "\n",
    "#### For Observational Studies: Newcastle-Ottawa Scale (NOS)\n",
    "\n",
    "**Domains**:\n",
    "1. **Selection**: Representativeness of cohort, selection of controls\n",
    "2. **Comparability**: Controlling for confounders\n",
    "3. **Outcome/Exposure**: Assessment method, follow-up adequacy\n",
    "\n",
    "**Scoring**: Stars awarded (max 9); â‰¥7 = low risk\n",
    "\n",
    "### Publication Bias\n",
    "\n",
    "**Problem**: Studies with positive/significant results are more likely to be published.\n",
    "\n",
    "**Detection methods**:\n",
    "1. **Funnel plot**: Scatter plot of effect size vs. standard error\n",
    "   - Asymmetry suggests bias\n",
    "2. **Egger's test**: Statistical test for funnel plot asymmetry\n",
    "3. **Trim-and-fill method**: Estimates missing studies\n",
    "4. **Search for unpublished data**: Trial registries, grey literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create risk of bias assessment template\n",
    "\n",
    "\n",
    "def create_rob_template():\n",
    "    \"\"\"\n",
    "    Create a template for Cochrane Risk of Bias assessment.\n",
    "    \"\"\"\n",
    "    rob_template = pd.DataFrame(\n",
    "        {\n",
    "            \"Study_ID\": [\"Study_001\", \"Study_002\", \"Study_003\"],\n",
    "            \"Author_Year\": [\"Smith 2020\", \"Jones 2021\", \"Brown 2019\"],\n",
    "            \"D1_Randomization\": [\"Low\", \"Some concerns\", \"Low\"],\n",
    "            \"D2_Deviations\": [\"Low\", \"Low\", \"High\"],\n",
    "            \"D3_Missing_Data\": [\"Low\", \"High\", \"Some concerns\"],\n",
    "            \"D4_Outcome_Measurement\": [\"Low\", \"Low\", \"Low\"],\n",
    "            \"D5_Selective_Reporting\": [\"Low\", \"Some concerns\", \"High\"],\n",
    "            \"Overall_Risk\": [\"Low\", \"Some concerns\", \"High\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    rob_template.to_csv(\"outputs/module_06/risk_of_bias_template.csv\", index=False)\n",
    "\n",
    "    print(\"RISK OF BIAS ASSESSMENT TEMPLATE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nDomains:\")\n",
    "    print(\"D1 = Randomization process\")\n",
    "    print(\"D2 = Deviations from interventions\")\n",
    "    print(\"D3 = Missing outcome data\")\n",
    "    print(\"D4 = Outcome measurement\")\n",
    "    print(\"D5 = Selective reporting\")\n",
    "    print(\"\\n\" + rob_template.to_string(index=False))\n",
    "    print(\"\\nâœ“ Template saved to outputs/module_06/\")\n",
    "\n",
    "    return rob_template\n",
    "\n",
    "\n",
    "rob_df = create_rob_template()\n",
    "\n",
    "# Visualize risk of bias summary\n",
    "risk_mapping = {\"Low\": 1, \"Some concerns\": 2, \"High\": 3}\n",
    "\n",
    "# Create larger dataset for visualization\n",
    "np.random.seed(456)\n",
    "n_studies = 25\n",
    "\n",
    "rob_data = pd.DataFrame(\n",
    "    {\n",
    "        \"Study\": [f\"Study {i+1}\" for i in range(n_studies)],\n",
    "        \"Randomization\": np.random.choice(\n",
    "            [\"Low\", \"Some concerns\", \"High\"], n_studies, p=[0.7, 0.2, 0.1]\n",
    "        ),\n",
    "        \"Deviations\": np.random.choice(\n",
    "            [\"Low\", \"Some concerns\", \"High\"], n_studies, p=[0.6, 0.3, 0.1]\n",
    "        ),\n",
    "        \"Missing Data\": np.random.choice(\n",
    "            [\"Low\", \"Some concerns\", \"High\"], n_studies, p=[0.5, 0.3, 0.2]\n",
    "        ),\n",
    "        \"Outcome Measure\": np.random.choice(\n",
    "            [\"Low\", \"Some concerns\", \"High\"], n_studies, p=[0.8, 0.15, 0.05]\n",
    "        ),\n",
    "        \"Reporting\": np.random.choice(\n",
    "            [\"Low\", \"Some concerns\", \"High\"], n_studies, p=[0.6, 0.25, 0.15]\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Count by domain\n",
    "domains = [\"Randomization\", \"Deviations\", \"Missing Data\", \"Outcome Measure\", \"Reporting\"]\n",
    "summary = {}\n",
    "for domain in domains:\n",
    "    summary[domain] = rob_data[domain].value_counts().to_dict()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RISK OF BIAS SUMMARY ACROSS DOMAINS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary_df = pd.DataFrame(summary).T.fillna(0).astype(int)\n",
    "summary_df = summary_df[[\"Low\", \"Some concerns\", \"High\"]]\n",
    "print(\"\\n\" + summary_df.to_string())\n",
    "\n",
    "print(f\"\\nğŸ’¡ Most studies should be 'Low' risk across domains.\")\n",
    "print(f\"   High proportion of 'High risk' studies weakens evidence quality.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize risk of bias across studies\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Create heatmap data\n",
    "rob_matrix = rob_data[domains].replace(risk_mapping)\n",
    "\n",
    "# Plot heatmap\n",
    "cmap_colors = [\"#06A77D\", \"#F4A261\", \"#E63946\"]  # Green, Yellow, Red\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "cmap = ListedColormap(cmap_colors)\n",
    "\n",
    "im = ax.imshow(rob_matrix.values, cmap=cmap, aspect=\"auto\", vmin=1, vmax=3)\n",
    "\n",
    "# Set ticks and labels\n",
    "ax.set_xticks(np.arange(len(domains)))\n",
    "ax.set_yticks(np.arange(n_studies))\n",
    "ax.set_xticklabels(domains, rotation=45, ha=\"right\")\n",
    "ax.set_yticklabels(rob_data[\"Study\"], fontsize=8)\n",
    "\n",
    "# Add grid\n",
    "ax.set_xticks(np.arange(len(domains)) + 0.5, minor=True)\n",
    "ax.set_yticks(np.arange(n_studies) + 0.5, minor=True)\n",
    "ax.grid(which=\"minor\", color=\"black\", linestyle=\"-\", linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel(\"Bias Domain\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Study\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_title(\n",
    "    \"Risk of Bias Assessment Across Studies\\n(Green=Low, Yellow=Some Concerns, Red=High)\",\n",
    "    fontsize=13,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, ticks=[1, 2, 3])\n",
    "cbar.ax.set_yticklabels([\"Low Risk\", \"Some Concerns\", \"High Risk\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/module_06/risk_of_bias_heatmap.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Risk of bias visualization saved to outputs/module_06/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Extraction\n",
    "\n",
    "### Purpose\n",
    "Systematically collect relevant information from each included study.\n",
    "\n",
    "### Key Information to Extract\n",
    "\n",
    "#### Study Characteristics\n",
    "- Author, year, country\n",
    "- Study design\n",
    "- Setting (hospital, community, etc.)\n",
    "- Funding source\n",
    "\n",
    "#### Participant Characteristics\n",
    "- Sample size (total, per group)\n",
    "- Demographics (age, sex, race/ethnicity)\n",
    "- Inclusion/exclusion criteria\n",
    "- Baseline characteristics\n",
    "\n",
    "#### Intervention Details\n",
    "- Type, dose, frequency, duration\n",
    "- Who delivered it\n",
    "- Fidelity/adherence measures\n",
    "\n",
    "#### Outcome Data\n",
    "- Outcome measures used\n",
    "- Means, SDs (or other summary statistics)\n",
    "- Time points assessed\n",
    "- Effect sizes\n",
    "- Statistical significance\n",
    "\n",
    "### Data Extraction Form\n",
    "\n",
    "Should be:\n",
    "- **Piloted** on 5-10 studies\n",
    "- **Standardized** (all reviewers use same form)\n",
    "- **Comprehensive** (but not exhaustive)\n",
    "- **Double-extracted** (two independent reviewers)\n",
    "\n",
    "### Tools\n",
    "- **Spreadsheets**: Excel, Google Sheets\n",
    "- **Specialized software**: Covidence, DistillerSR, EPPI-Reviewer\n",
    "- **REDCap**: Research Electronic Data Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data extraction template\n",
    "\n",
    "\n",
    "def create_extraction_template():\n",
    "    \"\"\"\n",
    "    Generate a comprehensive data extraction form template.\n",
    "    \"\"\"\n",
    "    extraction_template = pd.DataFrame(\n",
    "        {\n",
    "            \"Study_ID\": [\"\"],\n",
    "            \"Author\": [\"\"],\n",
    "            \"Year\": [\"\"],\n",
    "            \"Country\": [\"\"],\n",
    "            \"Study_Design\": [\"\"],\n",
    "            \"Setting\": [\"\"],\n",
    "            \"Population\": [\"\"],\n",
    "            \"N_Total\": [\"\"],\n",
    "            \"N_Intervention\": [\"\"],\n",
    "            \"N_Control\": [\"\"],\n",
    "            \"Mean_Age\": [\"\"],\n",
    "            \"Percent_Female\": [\"\"],\n",
    "            \"Intervention_Description\": [\"\"],\n",
    "            \"Intervention_Duration_Weeks\": [\"\"],\n",
    "            \"Control_Description\": [\"\"],\n",
    "            \"Primary_Outcome\": [\"\"],\n",
    "            \"Outcome_Measure\": [\"\"],\n",
    "            \"Baseline_Mean_Intervention\": [\"\"],\n",
    "            \"Baseline_SD_Intervention\": [\"\"],\n",
    "            \"Followup_Mean_Intervention\": [\"\"],\n",
    "            \"Followup_SD_Intervention\": [\"\"],\n",
    "            \"Baseline_Mean_Control\": [\"\"],\n",
    "            \"Baseline_SD_Control\": [\"\"],\n",
    "            \"Followup_Mean_Control\": [\"\"],\n",
    "            \"Followup_SD_Control\": [\"\"],\n",
    "            \"Effect_Size_Reported\": [\"\"],\n",
    "            \"P_Value\": [\"\"],\n",
    "            \"Funding_Source\": [\"\"],\n",
    "            \"Conflicts_of_Interest\": [\"\"],\n",
    "            \"Notes\": [\"\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    extraction_template.to_csv(\"outputs/module_06/data_extraction_template.csv\", index=False)\n",
    "\n",
    "    print(\"DATA EXTRACTION TEMPLATE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nFields included: {len(extraction_template.columns)}\")\n",
    "    print(f\"\\nColumn names:\")\n",
    "    for i, col in enumerate(extraction_template.columns, 1):\n",
    "        print(f\"{i:2d}. {col}\")\n",
    "\n",
    "    print(\"\\nâœ“ Template saved to outputs/module_06/data_extraction_template.csv\")\n",
    "    print(\"\\nğŸ’¡ Customize this template based on your specific review question.\")\n",
    "    print(\"   Pilot test on 5-10 studies before full extraction!\")\n",
    "\n",
    "    return extraction_template\n",
    "\n",
    "\n",
    "extraction_form = create_extraction_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Practice Exercises\n",
    "\n",
    "### Exercise 1: Write a PICO Question\n",
    "\n",
    "Transform this broad question into a focused PICO:\n",
    "\n",
    "**Broad**: \"Does mindfulness help with anxiety?\"\n",
    "\n",
    "Your PICO:\n",
    "- **P**: ___________\n",
    "- **I**: ___________\n",
    "- **C**: ___________\n",
    "- **O**: ___________\n",
    "\n",
    "**Focused question**: ___________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Calculate Cohen's Kappa\n",
    "# Two reviewers screened 50 studies\n",
    "\n",
    "rater_A = [\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "]\n",
    "\n",
    "rater_B = [\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Calculate kappa and interpret\n",
    "# Is the agreement acceptable for a systematic review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Build a search string\n",
    "# Research question: Does caffeine improve athletic performance?\n",
    "\n",
    "# YOUR TASK:\n",
    "# 1. Identify PICO components\n",
    "# 2. Generate keywords for each component\n",
    "# 3. Build a Boolean search string using AND, OR, wildcards\n",
    "\n",
    "# Example structure:\n",
    "# (keyword1 OR keyword2 OR keyword3) AND (keyword4 OR keyword5) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Key Takeaways\n",
    "\n",
    "### The Systematic Review Process\n",
    "\n",
    "```\n",
    "1. FORMULATE QUESTION (PICO)\n",
    "   â””â”€> Clear, focused, answerable\n",
    "\n",
    "2. DEVELOP PROTOCOL\n",
    "   â””â”€> Pre-register (PROSPERO)\n",
    "   â””â”€> Define methods in advance\n",
    "\n",
    "3. COMPREHENSIVE SEARCH\n",
    "   â””â”€> Multiple databases\n",
    "   â””â”€> Grey literature\n",
    "   â””â”€> Document everything\n",
    "\n",
    "4. SCREEN STUDIES\n",
    "   â””â”€> Title/abstract (liberal)\n",
    "   â””â”€> Full-text (strict)\n",
    "   â””â”€> Two independent reviewers\n",
    "   â””â”€> Calculate inter-rater reliability\n",
    "\n",
    "5. ASSESS RISK OF BIAS\n",
    "   â””â”€> Use validated tools\n",
    "   â””â”€> Domain-specific ratings\n",
    "\n",
    "6. EXTRACT DATA\n",
    "   â””â”€> Standardized forms\n",
    "   â””â”€> Double extraction\n",
    "\n",
    "7. SYNTHESIZE & REPORT\n",
    "   â””â”€> Narrative synthesis\n",
    "   â””â”€> Meta-analysis (if appropriate)\n",
    "   â””â”€> Follow PRISMA guidelines\n",
    "```\n",
    "\n",
    "### Critical Success Factors\n",
    "\n",
    "âœ“ **Team collaboration**: Requires 2+ reviewers  \n",
    "âœ“ **Pre-registration**: Prevents post-hoc decisions  \n",
    "âœ“ **Comprehensive search**: Minimizes publication bias  \n",
    "âœ“ **Transparent methods**: Allows reproducibility  \n",
    "âœ“ **Quality assessment**: Identifies weak evidence  \n",
    "âœ“ **PRISMA adherence**: Ensures complete reporting  \n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "âœ— Question too broad  \n",
    "âœ— Inadequate search (only 1-2 databases)  \n",
    "âœ— No protocol registration  \n",
    "âœ— Single reviewer screening  \n",
    "âœ— Poor documentation  \n",
    "âœ— Ignoring grey literature  \n",
    "âœ— No bias assessment  \n",
    "\n",
    "### Moving Forward\n",
    "\n",
    "You now know how to conduct rigorous, publishable systematic reviews. The next module covers **Meta-Analysis**, teaching you to quantitatively synthesize results across studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Additional Resources\n",
    "\n",
    "### Essential Readings\n",
    "\n",
    "1. **Cochrane Handbook for Systematic Reviews** (Free online)\n",
    "   - Gold standard methodology guide\n",
    "\n",
    "2. **Page et al. (2021)**. \"The PRISMA 2020 statement\"\n",
    "   - Updated reporting guidelines\n",
    "\n",
    "3. **Higgins et al. (2019)**. \"Cochrane Risk of Bias Tool (RoB 2)\"\n",
    "   - Bias assessment for RCTs\n",
    "\n",
    "### Online Resources\n",
    "\n",
    "- **PROSPERO**: Protocol registration (www.crd.york.ac.uk/prospero)\n",
    "- **PRISMA Website**: Checklists and flow diagram template\n",
    "- **Cochrane Training**: Free online modules\n",
    "\n",
    "### Software Tools\n",
    "\n",
    "- **Covidence**: Screening and data extraction\n",
    "- **EPPI-Reviewer**: Comprehensive SR management\n",
    "- **RevMan**: Cochrane's review manager (free)\n",
    "- **Rayyan**: AI-assisted screening (free)\n",
    "- **Zotero/EndNote**: Reference management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save systematic review checklist\n",
    "\n",
    "sr_checklist = pd.DataFrame(\n",
    "    {\n",
    "        \"Phase\": [\n",
    "            \"Planning\",\n",
    "            \"Planning\",\n",
    "            \"Planning\",\n",
    "            \"Searching\",\n",
    "            \"Searching\",\n",
    "            \"Searching\",\n",
    "            \"Screening\",\n",
    "            \"Screening\",\n",
    "            \"Screening\",\n",
    "            \"Assessment\",\n",
    "            \"Assessment\",\n",
    "            \"Extraction\",\n",
    "            \"Extraction\",\n",
    "            \"Synthesis\",\n",
    "            \"Synthesis\",\n",
    "            \"Reporting\",\n",
    "            \"Reporting\",\n",
    "        ],\n",
    "        \"Task\": [\n",
    "            \"Formulate PICO question\",\n",
    "            \"Develop protocol\",\n",
    "            \"Register protocol (PROSPERO)\",\n",
    "            \"Design search strategy\",\n",
    "            \"Search multiple databases\",\n",
    "            \"Search grey literature and trial registries\",\n",
    "            \"Remove duplicates\",\n",
    "            \"Title/abstract screening (2 reviewers)\",\n",
    "            \"Full-text screening (2 reviewers)\",\n",
    "            \"Assess risk of bias (validated tool)\",\n",
    "            \"Calculate inter-rater reliability\",\n",
    "            \"Pilot data extraction form\",\n",
    "            \"Extract data (2 reviewers)\",\n",
    "            \"Synthesize findings (narrative/quantitative)\",\n",
    "            \"Assess certainty of evidence (GRADE)\",\n",
    "            \"Follow PRISMA guidelines\",\n",
    "            \"Create PRISMA flow diagram\",\n",
    "        ],\n",
    "        \"Completed\": [\"\"] * 17,\n",
    "    }\n",
    ")\n",
    "\n",
    "sr_checklist.to_csv(\"outputs/module_06/systematic_review_checklist.csv\", index=False)\n",
    "print(\"SYSTEMATIC REVIEW CHECKLIST\")\n",
    "print(\"=\" * 80)\n",
    "print(sr_checklist.to_string(index=False))\n",
    "print(\"\\nâœ“ Checklist saved to outputs/module_06/systematic_review_checklist.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've completed **Module 06: Systematic Literature Reviews**. You can now:\n",
    "\n",
    "âœ“ Formulate focused research questions using PICO  \n",
    "âœ“ Design comprehensive, reproducible search strategies  \n",
    "âœ“ Screen studies systematically with explicit criteria  \n",
    "âœ“ Assess inter-rater reliability (Cohen's Kappa)  \n",
    "âœ“ Evaluate risk of bias using validated tools  \n",
    "âœ“ Extract data systematically  \n",
    "âœ“ Apply PRISMA reporting guidelines  \n",
    "âœ“ Conduct publishable systematic reviews  \n",
    "\n",
    "**Next Module**: Meta-Analysis Basics  \n",
    "**File**: `07_meta_analysis_basics.ipynb`\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
