{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 09: Preregistration & Open Science\n",
    "\n",
    "**Estimated Time:** 45 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "1. Explain the rationale for preregistration and open science practices\n",
    "2. Identify questionable research practices (QRPs) that preregistration prevents\n",
    "3. Create a preregistration for a research study\n",
    "4. Use the Open Science Framework (OSF) for project management\n",
    "5. Understand registered reports and their benefits\n",
    "6. Apply FAIR principles to research data and materials\n",
    "7. Navigate the reproducibility crisis and solutions\n",
    "8. Handle deviations from preregistered plans appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "\n",
    "# Create output directory\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../notebooks/outputs/module_09\", exist_ok=True)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")\n",
    "print(\"âœ“ Output directory created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Preregistration Matters\n",
    "\n",
    "### The Problem: Questionable Research Practices (QRPs)\n",
    "\n",
    "**Preregistration** is the practice of publicly documenting research plans (hypotheses, methods, analyses) before data collection begins.\n",
    "\n",
    "#### Common QRPs that preregistration prevents:\n",
    "\n",
    "1. **P-hacking** (Data dredging): Testing multiple analyses and reporting only significant results\n",
    "2. **HARKing** (Hypothesizing After Results are Known): Presenting exploratory findings as confirmatory\n",
    "3. **Selective reporting**: Omitting non-significant results or conditions\n",
    "4. **Flexible stopping**: Collecting data until significance is reached\n",
    "5. **Optional outlier exclusion**: Removing data points to achieve significance\n",
    "\n",
    "Let's demonstrate the danger of p-hacking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_p_hacking(n_per_group=30, n_simulations=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Simulate p-hacking by testing multiple dependent variables.\n",
    "\n",
    "    We have NO real effect, but test 10 DVs and report the 'best' one.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Track false positive rates\n",
    "    honest_false_positives = 0  # Testing only DV1\n",
    "    phacked_false_positives = 0  # Testing all 10 DVs, reporting best p-value\n",
    "\n",
    "    for sim in range(n_simulations):\n",
    "        # Two groups with NO real difference (null hypothesis is true)\n",
    "        group1_dvs = np.random.normal(0, 1, (n_per_group, 10))  # 10 DVs\n",
    "        group2_dvs = np.random.normal(0, 1, (n_per_group, 10))  # 10 DVs\n",
    "\n",
    "        # Honest researcher: test only DV1\n",
    "        t_stat, p_value = stats.ttest_ind(group1_dvs[:, 0], group2_dvs[:, 0])\n",
    "        if p_value < 0.05:\n",
    "            honest_false_positives += 1\n",
    "\n",
    "        # P-hacker: test all 10 DVs, report the smallest p-value\n",
    "        p_values = []\n",
    "        for dv in range(10):\n",
    "            t_stat, p_value = stats.ttest_ind(group1_dvs[:, dv], group2_dvs[:, dv])\n",
    "            p_values.append(p_value)\n",
    "\n",
    "        min_p = min(p_values)\n",
    "        if min_p < 0.05:\n",
    "            phacked_false_positives += 1\n",
    "\n",
    "    honest_rate = honest_false_positives / n_simulations * 100\n",
    "    phacked_rate = phacked_false_positives / n_simulations * 100\n",
    "\n",
    "    return honest_rate, phacked_rate\n",
    "\n",
    "\n",
    "# Run simulation\n",
    "honest_rate, phacked_rate = simulate_p_hacking()\n",
    "\n",
    "print(\"ðŸ”¬ P-HACKING SIMULATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Scenario: Two groups with NO real difference (Hâ‚€ is true)\")\n",
    "print(f\"Sample size: 30 per group\")\n",
    "print(f\"Number of simulations: 1,000\\n\")\n",
    "\n",
    "print(f\"Honest researcher (tests only DV1):\")\n",
    "print(f\"  False positive rate: {honest_rate:.1f}%\")\n",
    "print(f\"  âœ“ Close to nominal 5% Type I error rate\\n\")\n",
    "\n",
    "print(f\"P-hacker (tests 10 DVs, reports 'best' one):\")\n",
    "print(f\"  False positive rate: {phacked_rate:.1f}%\")\n",
    "print(f\"  âœ— Inflated by {phacked_rate/honest_rate:.1f}x!\\n\")\n",
    "\n",
    "print(\"âš ï¸  P-hacking dramatically increases false discoveries!\")\n",
    "print(\"âœ“  Preregistration prevents this by committing to analyses upfront.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the danger of multiple testing\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left plot: False positive rate by number of tests\n",
    "n_tests = np.arange(1, 21)\n",
    "false_positive_rate = 1 - (1 - 0.05) ** n_tests\n",
    "\n",
    "axes[0].plot(n_tests, false_positive_rate * 100, \"o-\", linewidth=2, markersize=8, color=\"#e74c3c\")\n",
    "axes[0].axhline(y=5, color=\"green\", linestyle=\"--\", linewidth=2, label=\"Nominal 5%\", alpha=0.7)\n",
    "axes[0].set_xlabel(\"Number of Tests Conducted\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\n",
    "    \"Probability of At Least One\\nFalse Positive (%)\", fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "axes[0].set_title(\"The Multiple Testing Problem\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_ylim([0, 70])\n",
    "\n",
    "# Add annotations\n",
    "axes[0].annotate(\n",
    "    \"With 10 tests,\\n40% chance of\\nfalse positive!\",\n",
    "    xy=(10, false_positive_rate[9] * 100),\n",
    "    xytext=(12, 20),\n",
    "    arrowprops=dict(arrowstyle=\"->\", color=\"red\", lw=2),\n",
    "    fontsize=10,\n",
    "    color=\"red\",\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "# Right plot: Research practices comparison\n",
    "practices = [\n",
    "    \"Single\\npreregistered\\ntest\",\n",
    "    \"Multiple tests\\n(corrected)\",\n",
    "    \"P-hacking\\n(uncorrected)\",\n",
    "]\n",
    "rates = [5, 5, 40]  # Approximate rates\n",
    "colors = [\"#27ae60\", \"#f39c12\", \"#e74c3c\"]\n",
    "\n",
    "bars = axes[1].bar(practices, rates, color=colors, alpha=0.7, edgecolor=\"black\", linewidth=2)\n",
    "axes[1].axhline(y=5, color=\"green\", linestyle=\"--\", linewidth=2, alpha=0.7)\n",
    "axes[1].set_ylabel(\"False Positive Rate (%)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_title(\"Research Practices Comparison\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].set_ylim([0, 50])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, rate in zip(bars, rates):\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 1,\n",
    "        f\"{rate}%\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"../notebooks/outputs/module_09/p_hacking_demonstration.png\", dpi=300, bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Figure saved to outputs/module_09/p_hacking_demonstration.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insight\n",
    "\n",
    "Even with NO real effect, testing 10 dependent variables gives you a ~40% chance of finding at least one \"significant\" result!\n",
    "\n",
    "**Preregistration solution:** Commit to which DVs you'll test BEFORE seeing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Open Science Framework (OSF)\n",
    "\n",
    "The **Open Science Framework** (https://osf.io) is a free platform for:\n",
    "- Project management\n",
    "- Preregistration\n",
    "- Data/materials sharing\n",
    "- Collaboration\n",
    "- DOI generation\n",
    "\n",
    "### OSF Preregistration Workflow\n",
    "\n",
    "```\n",
    "1. Create OSF Project\n",
    "   â†“\n",
    "2. Choose Preregistration Template\n",
    "   â†“\n",
    "3. Complete Registration Form\n",
    "   - Research questions\n",
    "   - Hypotheses\n",
    "   - Design and methods\n",
    "   - Analysis plan\n",
    "   - Sample size justification\n",
    "   â†“\n",
    "4. Submit Registration (creates timestamped, uneditable copy)\n",
    "   â†“\n",
    "5. Embargo period (optional, 0-4 years)\n",
    "   â†“\n",
    "6. Conduct study following preregistered plan\n",
    "   â†“\n",
    "7. Report deviations transparently in manuscript\n",
    "   â†“\n",
    "8. Make registration public with publication\n",
    "```\n",
    "\n",
    "### Popular Preregistration Templates\n",
    "\n",
    "Let's create a simple preregistration template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preregistration_template(study_type=\"experiment\"):\n",
    "    \"\"\"\n",
    "    Generate a basic preregistration template.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    study_type : str\n",
    "        Type of study ('experiment', 'observational', 'meta_analysis')\n",
    "    \"\"\"\n",
    "    template = f\"\"\"\n",
    "PREREGISTRATION TEMPLATE ({study_type.upper()})\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "{'=' * 70}\n",
    "\n",
    "1. STUDY INFORMATION\n",
    "   Title: [Your study title]\n",
    "   Authors: [List all authors]\n",
    "   Research Questions: [Main questions to be addressed]\n",
    "\n",
    "2. HYPOTHESES\n",
    "   H1: [First hypothesis]\n",
    "   H2: [Second hypothesis]\n",
    "   ...\n",
    "   \n",
    "   Direction: [Directional (one-tailed) or non-directional (two-tailed)]\n",
    "\n",
    "3. DESIGN\n",
    "   Study Type: {study_type}\n",
    "   Design: [e.g., 2x2 between-subjects factorial]\n",
    "   Independent Variables: [List IVs and levels]\n",
    "   Dependent Variables: [List DVs and measurement methods]\n",
    "   \n",
    "4. SAMPLING PLAN\n",
    "   Target Population: [Define population]\n",
    "   Inclusion Criteria: [Who can participate]\n",
    "   Exclusion Criteria: [Who cannot participate]\n",
    "   Sample Size: [N = XXX]\n",
    "   Power Analysis: [Describe justification for sample size]\n",
    "   Stopping Rule: [When will data collection end?]\n",
    "\n",
    "5. PROCEDURE\n",
    "   [Detailed description of study procedures]\n",
    "   [Step-by-step participant experience]\n",
    "\n",
    "6. ANALYSIS PLAN\n",
    "   Primary Analysis:\n",
    "     - Statistical test: [e.g., independent samples t-test]\n",
    "     - Alpha level: [typically 0.05]\n",
    "     - Variables: [DV predicted by IV]\n",
    "   \n",
    "   Secondary Analyses:\n",
    "     - [List any planned secondary analyses]\n",
    "   \n",
    "   Inference Criteria:\n",
    "     - What will you conclude if H1 is supported?\n",
    "     - What will you conclude if H1 is not supported?\n",
    "\n",
    "7. DATA EXCLUSION\n",
    "   Outlier Definition: [How will outliers be identified?]\n",
    "   Outlier Treatment: [Will they be excluded or retained?]\n",
    "   Missing Data: [How will missing data be handled?]\n",
    "   Attention Checks: [Any quality control measures?]\n",
    "\n",
    "8. VARIABLES\n",
    "   Manipulated Variables:\n",
    "     - [List each variable and how it's operationalized]\n",
    "   \n",
    "   Measured Variables:\n",
    "     - [List each variable and measurement instrument]\n",
    "\n",
    "9. ADDITIONAL INFORMATION\n",
    "   Prior Studies: [Have you conducted pilot studies?]\n",
    "   Data Collection: [When will data be collected?]\n",
    "   Funding: [Any funding sources?]\n",
    "   Conflicts of Interest: [Declare any COIs]\n",
    "\n",
    "{'=' * 70}\n",
    "NOTE: This is a simplified template. Use OSF, AsPredicted, or journal-\n",
    "specific templates for actual preregistrations.\n",
    "\"\"\"\n",
    "    return template\n",
    "\n",
    "\n",
    "# Generate example template\n",
    "prereg = create_preregistration_template(\"experiment\")\n",
    "print(prereg)\n",
    "\n",
    "# Save template\n",
    "with open(\"../notebooks/outputs/module_09/preregistration_template.txt\", \"w\") as f:\n",
    "    f.write(prereg)\n",
    "\n",
    "print(\"\\nâœ“ Template saved to outputs/module_09/preregistration_template.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Completed Preregistration\n",
    "\n",
    "Let's fill out a simple preregistration for a hypothetical study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example completed preregistration\n",
    "example_prereg = \"\"\"\n",
    "PREREGISTRATION: EFFECT OF STUDY ENVIRONMENT ON EXAM PERFORMANCE\n",
    "===============================================================================\n",
    "Date: 2025-01-15\n",
    "Platform: OSF (osf.io/xxxxx)\n",
    "\n",
    "1. STUDY INFORMATION\n",
    "   Title: Does Background Music Affect Exam Performance in Undergraduates?\n",
    "   Authors: Smith, J. & Jones, A.\n",
    "   Research Question: Does listening to background music while studying \n",
    "                      affect exam performance compared to silence?\n",
    "\n",
    "2. HYPOTHESES\n",
    "   H1: Students who study with background music will score LOWER on exams\n",
    "       than students who study in silence.\n",
    "   \n",
    "   Rationale: Cognitive load theory suggests background music creates \n",
    "             interference during encoding.\n",
    "   \n",
    "   Direction: One-tailed (directional)\n",
    "\n",
    "3. DESIGN\n",
    "   Study Type: Randomized Controlled Trial (RCT)\n",
    "   Design: Between-subjects, two conditions\n",
    "   \n",
    "   IV: Study environment (2 levels)\n",
    "       - Music condition: Instrumental music at 60 dB\n",
    "       - Silence condition: <30 dB background noise\n",
    "   \n",
    "   DV: Exam score (0-100 points)\n",
    "       - 20-question multiple-choice test on assigned chapter\n",
    "       - Validated test with Î± = 0.82 reliability\n",
    "\n",
    "4. SAMPLING PLAN\n",
    "   Population: Undergraduate psychology students at State University\n",
    "   \n",
    "   Inclusion: Age 18-25, native English speakers, normal hearing\n",
    "   Exclusion: Diagnosed learning disabilities, prior course in topic\n",
    "   \n",
    "   Sample Size: N = 128 (64 per condition)\n",
    "   \n",
    "   Power Analysis:\n",
    "     - Expected effect: d = 0.5 (medium, based on Smith et al., 2023)\n",
    "     - Power: 0.80\n",
    "     - Alpha: 0.05 (one-tailed)\n",
    "     - Required N: 128\n",
    "   \n",
    "   Stopping Rule: Data collection ends when N = 128, or May 1, 2025,\n",
    "                  whichever comes first.\n",
    "\n",
    "5. PROCEDURE\n",
    "   1. Participants arrive at lab, complete consent form\n",
    "   2. Random assignment to music or silence condition (blocked randomization)\n",
    "   3. 30-minute study period with assigned textbook chapter\n",
    "   4. 10-minute break (no study materials)\n",
    "   5. 20-minute exam on chapter content\n",
    "   6. Debrief and compensation ($15)\n",
    "\n",
    "6. ANALYSIS PLAN\n",
    "   Primary Analysis:\n",
    "     - Test: Independent samples t-test (one-tailed)\n",
    "     - Alpha: 0.05\n",
    "     - Variables: Exam score ~ Study condition\n",
    "     - Software: Python (SciPy.stats)\n",
    "   \n",
    "   Effect Size: Cohen's d with 95% CI\n",
    "   \n",
    "   Inference:\n",
    "     - If p < 0.05 AND Music < Silence: H1 supported\n",
    "     - If p â‰¥ 0.05 OR Music â‰¥ Silence: H1 not supported\n",
    "   \n",
    "   No secondary analyses planned.\n",
    "\n",
    "7. DATA EXCLUSION\n",
    "   Outliers: Scores > 3 SD from condition mean will be flagged but RETAINED\n",
    "   Missing Data: Participants who don't complete exam will be excluded from\n",
    "                 analysis (but reported in CONSORT diagram)\n",
    "   Quality Check: Post-study questionnaire asks about distractions;\n",
    "                  major incidents (e.g., fire alarm) â†’ exclusion\n",
    "\n",
    "8. EXPLORATORY ANALYSES (NOT CONFIRMATORY)\n",
    "   - We may explore moderation by prior GPA\n",
    "   - We may explore correlation between study time and exam score\n",
    "   - These will be clearly labeled as exploratory in manuscript\n",
    "\n",
    "===============================================================================\n",
    "TIMESTAMP: This preregistration was submitted to OSF on 2025-01-15 at 14:32 UTC\n",
    "and cannot be edited. Data collection begins 2025-01-20.\n",
    "\"\"\"\n",
    "\n",
    "print(example_prereg)\n",
    "\n",
    "# Save example\n",
    "with open(\"../notebooks/outputs/module_09/example_preregistration.txt\", \"w\") as f:\n",
    "    f.write(example_prereg)\n",
    "\n",
    "print(\"\\nâœ“ Example saved to outputs/module_09/example_preregistration.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Registered Reports\n",
    "\n",
    "**Registered Reports** are a publication format where:\n",
    "1. **Stage 1:** Submit introduction + methods for peer review BEFORE data collection\n",
    "2. **In-principle acceptance:** If methods are sound, journal commits to publish regardless of results\n",
    "3. **Stage 2:** After data collection, submit full paper for review\n",
    "\n",
    "### Benefits\n",
    "- âœ“ Eliminates publication bias against null results\n",
    "- âœ“ Reviews focus on methods quality, not \"exciting\" results\n",
    "- âœ“ Prevents p-hacking and HARKing\n",
    "- âœ“ Reduces incentive to oversell findings\n",
    "\n",
    "### Timeline Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize registered report timeline\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Traditional publishing\n",
    "trad_stages = [\n",
    "    (\"Design Study\", 0, 2),\n",
    "    (\"Collect Data\", 2, 6),\n",
    "    (\"Analyze Data\", 6, 8),\n",
    "    (\"Write Paper\", 8, 10),\n",
    "    (\"Submit\", 10, 10.5),\n",
    "    (\"Peer Review\", 10.5, 14),\n",
    "    (\"Revisions\", 14, 16),\n",
    "    (\"Accept/Publish\", 16, 17),\n",
    "]\n",
    "\n",
    "# Registered report\n",
    "rr_stages = [\n",
    "    (\"Design Study\", 0, 2),\n",
    "    (\"Write Stage 1\", 2, 3),\n",
    "    (\"Submit Stage 1\", 3, 3.5),\n",
    "    (\"Stage 1 Review\", 3.5, 6),\n",
    "    (\"Revise Stage 1\", 6, 7),\n",
    "    (\"In-Principle\\nAcceptance\", 7, 7.5),\n",
    "    (\"Collect Data\", 7.5, 11.5),\n",
    "    (\"Analyze Data\", 11.5, 13.5),\n",
    "    (\"Write Stage 2\", 13.5, 15),\n",
    "    (\"Submit Stage 2\", 15, 15.5),\n",
    "    (\"Stage 2 Review\", 15.5, 17),\n",
    "    (\"Final Publish\", 17, 18),\n",
    "]\n",
    "\n",
    "# Plot traditional\n",
    "y_pos = 2\n",
    "for stage, start, end in trad_stages:\n",
    "    color = \"#3498db\" if \"Review\" in stage or \"Revisions\" in stage else \"#95a5a6\"\n",
    "    if \"Collect\" in stage or \"Analyze\" in stage:\n",
    "        color = \"#e74c3c\"\n",
    "    ax.barh(\n",
    "        y_pos,\n",
    "        end - start,\n",
    "        left=start,\n",
    "        height=0.6,\n",
    "        color=color,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1.5,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    ax.text(\n",
    "        (start + end) / 2,\n",
    "        y_pos,\n",
    "        stage,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontsize=9,\n",
    "        fontweight=\"bold\",\n",
    "        color=\"white\",\n",
    "    )\n",
    "\n",
    "# Plot registered report\n",
    "y_pos = 1\n",
    "for stage, start, end in rr_stages:\n",
    "    color = \"#3498db\" if \"Review\" in stage else \"#95a5a6\"\n",
    "    if \"Collect\" in stage or \"Analyze\" in stage:\n",
    "        color = \"#e74c3c\"\n",
    "    if \"Acceptance\" in stage:\n",
    "        color = \"#27ae60\"\n",
    "    ax.barh(\n",
    "        y_pos,\n",
    "        end - start,\n",
    "        left=start,\n",
    "        height=0.6,\n",
    "        color=color,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1.5,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    ax.text(\n",
    "        (start + end) / 2,\n",
    "        y_pos,\n",
    "        stage,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontsize=8,\n",
    "        fontweight=\"bold\",\n",
    "        color=\"white\",\n",
    "    )\n",
    "\n",
    "# Formatting\n",
    "ax.set_yticks([1, 2])\n",
    "ax.set_yticklabels([\"Registered Report\", \"Traditional Publishing\"], fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Months from Start\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_title(\"Publication Timeline Comparison\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "ax.set_xlim([0, 18])\n",
    "ax.grid(axis=\"x\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"#e74c3c\", edgecolor=\"black\", label=\"Research Activities\"),\n",
    "    Patch(facecolor=\"#3498db\", edgecolor=\"black\", label=\"Peer Review\"),\n",
    "    Patch(facecolor=\"#27ae60\", edgecolor=\"black\", label=\"In-Principle Acceptance\"),\n",
    "    Patch(facecolor=\"#95a5a6\", edgecolor=\"black\", label=\"Other\"),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc=\"upper right\", fontsize=10)\n",
    "\n",
    "# Add annotation\n",
    "ax.annotate(\n",
    "    \"Key difference:\\nMethods reviewed\\nBEFORE data collection\",\n",
    "    xy=(5, 1),\n",
    "    xytext=(8, 0.3),\n",
    "    arrowprops=dict(arrowstyle=\"->\", color=\"#27ae60\", lw=3),\n",
    "    fontsize=11,\n",
    "    color=\"#27ae60\",\n",
    "    fontweight=\"bold\",\n",
    "    bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"white\", edgecolor=\"#27ae60\", linewidth=2),\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"../notebooks/outputs/module_09/registered_report_timeline.png\", dpi=300, bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Timeline comparison saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Journals Offering Registered Reports\n",
    "\n",
    "Over 300 journals now offer Registered Reports format:\n",
    "- *Psychological Science*\n",
    "- *Nature Human Behaviour*\n",
    "- *Royal Society Open Science*\n",
    "- *Cortex*\n",
    "- Many more...\n",
    "\n",
    "See complete list: https://www.cos.io/initiatives/registered-reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PROSPERO for Systematic Reviews\n",
    "\n",
    "**PROSPERO** (https://www.crd.york.ac.uk/prospero/) is the international database for preregistering systematic reviews.\n",
    "\n",
    "### Why Preregister Systematic Reviews?\n",
    "\n",
    "1. Prevents selective reporting of outcomes\n",
    "2. Reduces duplication (you can see if someone already registered similar review)\n",
    "3. Increases transparency\n",
    "4. Required by Cochrane and many journals\n",
    "\n",
    "### What to Preregister:\n",
    "\n",
    "- Research question (PICO format)\n",
    "- Inclusion/exclusion criteria\n",
    "- Search strategy and databases\n",
    "- Screening process\n",
    "- Risk of bias assessment tools\n",
    "- Data extraction plan\n",
    "- Synthesis methods (meta-analysis, narrative, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. FAIR Principles for Open Data\n",
    "\n",
    "The **FAIR** principles guide open data practices:\n",
    "\n",
    "### F - Findable\n",
    "- Assign persistent identifier (DOI)\n",
    "- Rich metadata\n",
    "- Indexed in searchable resource\n",
    "\n",
    "### A - Accessible\n",
    "- Retrievable by identifier\n",
    "- Open, free protocol\n",
    "- Metadata remains even if data is removed\n",
    "\n",
    "### I - Interoperable\n",
    "- Use standard formats (CSV, not proprietary)\n",
    "- Controlled vocabularies\n",
    "- Include links to related data\n",
    "\n",
    "### R - Reusable\n",
    "- Clear usage license\n",
    "- Detailed provenance\n",
    "- Meets community standards\n",
    "\n",
    "### Data Sharing Platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison of data sharing platforms\n",
    "platforms_data = {\n",
    "    \"Platform\": [\"OSF\", \"Zenodo\", \"Figshare\", \"Dryad\", \"GitHub\", \"Dataverse\"],\n",
    "    \"Free\": [\"Yes\", \"Yes\", \"Yes\", \"Fee > 50GB\", \"Yes\", \"Yes\"],\n",
    "    \"DOI\": [\"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\"],\n",
    "    \"Size Limit\": [\"5 GB/file\", \"50 GB\", \"20 GB\", \"Unlimited\", \"100 MB/file\", \"Unlimited\"],\n",
    "    \"Versioning\": [\"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\"],\n",
    "    \"Best For\": [\"Psychology\", \"General\", \"General\", \"Ecology\", \"Code\", \"Social Science\"],\n",
    "}\n",
    "\n",
    "platforms_df = pd.DataFrame(platforms_data)\n",
    "print(\"ðŸ“Š DATA SHARING PLATFORMS COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(platforms_df.to_string(index=False))\n",
    "print(\"\\nðŸ’¡ TIP: Choose platform based on your field's norms and data size.\")\n",
    "\n",
    "# Save table\n",
    "platforms_df.to_csv(\"../notebooks/outputs/module_09/data_sharing_platforms.csv\", index=False)\n",
    "print(\"\\nâœ“ Table saved to outputs/module_09/data_sharing_platforms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a License\n",
    "\n",
    "**Creative Commons Licenses** for data/materials:\n",
    "\n",
    "- **CC0**: Public domain, no restrictions (most open)\n",
    "- **CC-BY**: Requires attribution\n",
    "- **CC-BY-SA**: Attribution + share-alike\n",
    "- **CC-BY-NC**: Attribution + non-commercial only\n",
    "\n",
    "**Code Licenses:**\n",
    "\n",
    "- **MIT**: Very permissive\n",
    "- **GPL**: Requires derivative works to also be open\n",
    "- **Apache 2.0**: Permissive with patent protection\n",
    "\n",
    "**Recommendation:** For maximum reusability, use CC0 or CC-BY for data, and MIT or Apache for code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. The Reproducibility Crisis\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "**Replication Failures:**\n",
    "- Psychology: 36% of studies replicated (Open Science Collaboration, 2015)\n",
    "- Biomedical: 11% of landmark studies replicated (Begley & Ellis, 2012)\n",
    "- Economics: 61% of studies replicated (Camerer et al., 2016)\n",
    "\n",
    "### Contributing Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize factors contributing to reproducibility crisis\n",
    "factors = [\n",
    "    \"Publication\\nBias\",\n",
    "    \"P-Hacking\",\n",
    "    \"HARKing\",\n",
    "    \"Underpowered\\nStudies\",\n",
    "    \"Poor\\nDocumentation\",\n",
    "    \"Data/Code\\nNot Shared\",\n",
    "    \"Lack of\\nReplication\",\n",
    "    \"Flexible\\nAnalyses\",\n",
    "]\n",
    "\n",
    "# Estimated contribution (illustrative)\n",
    "contributions = [25, 20, 15, 12, 10, 8, 6, 4]\n",
    "\n",
    "# Solutions for each\n",
    "solutions = [\n",
    "    \"Registered Reports\",\n",
    "    \"Preregistration\",\n",
    "    \"Preregistration\",\n",
    "    \"Power Analysis\",\n",
    "    \"Open Methods\",\n",
    "    \"Open Data/Code\",\n",
    "    \"Replication Studies\",\n",
    "    \"Preregistration\",\n",
    "]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left: Pie chart of factors\n",
    "colors = plt.cm.Reds(np.linspace(0.4, 0.9, len(factors)))\n",
    "wedges, texts, autotexts = ax1.pie(\n",
    "    contributions,\n",
    "    labels=factors,\n",
    "    autopct=\"%1.0f%%\",\n",
    "    colors=colors,\n",
    "    startangle=90,\n",
    "    textprops={\"fontsize\": 10, \"fontweight\": \"bold\"},\n",
    ")\n",
    "ax1.set_title(\n",
    "    \"Factors Contributing to\\nReproducibility Crisis\", fontsize=14, fontweight=\"bold\", pad=20\n",
    ")\n",
    "\n",
    "# Right: Solutions bar chart\n",
    "solution_counts = pd.Series(solutions).value_counts()\n",
    "colors_solutions = [\"#27ae60\", \"#3498db\", \"#e67e22\", \"#9b59b6\", \"#e74c3c\"]\n",
    "\n",
    "bars = ax2.barh(\n",
    "    solution_counts.index,\n",
    "    solution_counts.values,\n",
    "    color=colors_solutions[: len(solution_counts)],\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "ax2.set_xlabel(\"Number of Problems Addressed\", fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_title(\"Open Science Solutions\", fontsize=14, fontweight=\"bold\", pad=20)\n",
    "ax2.grid(axis=\"x\", alpha=0.3, linestyle=\"--\")\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    ax2.text(\n",
    "        width + 0.1,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{int(width)}\",\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        fontsize=11,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"../notebooks/outputs/module_09/reproducibility_crisis.png\", dpi=300, bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Reproducibility crisis visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Handling Deviations from Preregistration\n",
    "\n",
    "**Reality check:** You will probably need to deviate from your preregistration!\n",
    "\n",
    "### Common Reasons for Deviation\n",
    "\n",
    "1. Data collection issues (e.g., lower recruitment than expected)\n",
    "2. Assumption violations (e.g., non-normality requires different test)\n",
    "3. Errors in preregistration (e.g., typos, unclear wording)\n",
    "4. Unforeseen circumstances (e.g., COVID-19 pandemic)\n",
    "\n",
    "### Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviation_guide = \"\"\"\n",
    "HANDLING DEVIATIONS FROM PREREGISTRATION: DECISION TREE\n",
    "========================================================================\n",
    "\n",
    "Did you deviate from the preregistration?\n",
    "â”‚\n",
    "â”œâ”€ NO â†’ Great! Report: \"All analyses followed preregistered plan.\"\n",
    "â”‚\n",
    "â””â”€ YES â†’ Continue below...\n",
    "    â”‚\n",
    "    â””â”€ When did you decide to deviate?\n",
    "        â”‚\n",
    "        â”œâ”€ BEFORE seeing the data (e.g., during data collection)\n",
    "        â”‚   â””â”€ Action: Create a dated addendum to preregistration\n",
    "        â”‚       - Explain reason for change\n",
    "        â”‚       - Post to OSF with timestamp\n",
    "        â”‚       - Report in paper: \"We deviated from our preregistered\n",
    "        â”‚         plan before data analysis (see dated addendum at\n",
    "        â”‚         osf.io/xxxxx). Specifically, we [describe change].\"\n",
    "        â”‚\n",
    "        â””â”€ AFTER seeing the data\n",
    "            â””â”€ Was deviation necessary or optional?\n",
    "                â”‚\n",
    "                â”œâ”€ NECESSARY (e.g., assumption violation)\n",
    "                â”‚   â””â”€ Action: Report transparently\n",
    "                â”‚       - Explain why change was necessary\n",
    "                â”‚       - Describe original plan and deviation\n",
    "                â”‚       - If possible, report BOTH analyses\n",
    "                â”‚       - Report in paper: \"Due to [reason], we\n",
    "                â”‚         necessarily deviated from our preregistered\n",
    "                â”‚         analysis plan. Originally we planned [X],\n",
    "                â”‚         but [reason] required us to use [Y] instead.\"\n",
    "                â”‚\n",
    "                â””â”€ OPTIONAL (e.g., exploratory analysis)\n",
    "                    â””â”€ Action: Label as EXPLORATORY\n",
    "                        - Clearly distinguish confirmatory from exploratory\n",
    "                        - Do NOT present exploratory as confirmatory\n",
    "                        - Report in paper: \"In addition to our\n",
    "                          preregistered confirmatory analyses, we\n",
    "                          conducted the following EXPLORATORY analyses...\"\n",
    "                        - Interpret with appropriate caution\n",
    "\n",
    "========================================================================\n",
    "\n",
    "KEY PRINCIPLES:\n",
    "âœ“ TRANSPARENCY: Always report deviations clearly\n",
    "âœ“ HONESTY: Don't hide or downplay changes\n",
    "âœ“ DISTINCTION: Separate confirmatory from exploratory\n",
    "âœ“ JUSTIFICATION: Explain why deviation was necessary\n",
    "\n",
    "âŒ NEVER:\n",
    "   - Pretend deviation didn't happen\n",
    "   - Present exploratory findings as confirmatory\n",
    "   - Change preregistration after seeing data\n",
    "\n",
    "âœ“ REMEMBER: Deviations don't invalidate preregistration!\n",
    "           The goal is transparency, not perfection.\n",
    "\"\"\"\n",
    "\n",
    "print(deviation_guide)\n",
    "\n",
    "# Save guide\n",
    "with open(\"../notebooks/outputs/module_09/deviation_guide.txt\", \"w\") as f:\n",
    "    f.write(deviation_guide)\n",
    "\n",
    "print(\"\\nâœ“ Deviation guide saved to outputs/module_09/deviation_guide.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Deviation Reporting\n",
    "\n",
    "**Good example from a published paper:**\n",
    "\n",
    "> *\"We preregistered our hypotheses and analysis plan (osf.io/abc123). We deviated from our preregistration in two ways. First, we originally planned to use ANOVA but discovered severe violations of homogeneity of variance (Levene's test, p < .001), so we used Welch's ANOVA instead. Second, we preregistered N = 200 but only recruited N = 156 due to pandemic-related disruptions. Our sensitivity analysis indicated we still had 80% power to detect d = 0.46, slightly larger than our anticipated d = 0.40. In addition to our confirmatory analyses, we report exploratory analyses of potential moderators in Appendix B.\"*\n",
    "\n",
    "This demonstrates:\n",
    "- âœ“ Clear statement of deviations\n",
    "- âœ“ Justification for each change\n",
    "- âœ“ Impact assessment (power analysis)\n",
    "- âœ“ Distinction between confirmatory and exploratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Practical Checklist\n",
    "\n",
    "### Before Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive preregistration checklist\n",
    "checklist = \"\"\"\n",
    "PREREGISTRATION CHECKLIST\n",
    "==================================================\n",
    "Use this before submitting your preregistration.\n",
    "\n",
    "STUDY DESIGN\n",
    "â˜ Research question clearly stated\n",
    "â˜ Hypotheses are specific and testable\n",
    "â˜ Direction specified (one-tailed vs. two-tailed)\n",
    "â˜ Independent and dependent variables operationalized\n",
    "â˜ Study design justified (RCT, quasi-experimental, etc.)\n",
    "\n",
    "SAMPLING\n",
    "â˜ Target population defined\n",
    "â˜ Inclusion/exclusion criteria specified\n",
    "â˜ Sample size justified with power analysis\n",
    "â˜ Stopping rule stated (when does data collection end?)\n",
    "â˜ Recruitment strategy described\n",
    "\n",
    "PROCEDURE\n",
    "â˜ Step-by-step procedure documented\n",
    "â˜ Randomization method specified (if applicable)\n",
    "â˜ Blinding procedures described (if applicable)\n",
    "â˜ Materials shared or described in detail\n",
    "\n",
    "ANALYSIS PLAN\n",
    "â˜ Primary statistical test(s) specified\n",
    "â˜ Alpha level stated (typically 0.05)\n",
    "â˜ Primary dependent variable(s) identified\n",
    "â˜ Covariates listed (if any)\n",
    "â˜ Inference criteria clear (what constitutes support for H1?)\n",
    "â˜ Secondary analyses described (if any)\n",
    "â˜ Exploratory analyses distinguished from confirmatory\n",
    "\n",
    "DATA QUALITY\n",
    "â˜ Outlier definition and treatment specified\n",
    "â˜ Missing data plan described\n",
    "â˜ Attention check criteria stated (if applicable)\n",
    "â˜ Data exclusion rules predefined\n",
    "\n",
    "DOCUMENTATION\n",
    "â˜ Preregistration submitted to public registry (OSF, AsPredicted, PROSPERO)\n",
    "â˜ Timestamp/DOI obtained\n",
    "â˜ All collaborators have reviewed preregistration\n",
    "â˜ Preregistration will be made public (set embargo if needed)\n",
    "\n",
    "AFTER DATA COLLECTION\n",
    "â˜ Compare actual procedures to preregistration\n",
    "â˜ Document any deviations with justification\n",
    "â˜ Report confirmatory vs. exploratory analyses separately\n",
    "â˜ Link to preregistration in manuscript\n",
    "â˜ Share data and code (if possible)\n",
    "\n",
    "==================================================\n",
    "ðŸ’¡ TIP: It's better to have an imperfect preregistration\n",
    "        than none at all. You can always report deviations!\n",
    "\"\"\"\n",
    "\n",
    "print(checklist)\n",
    "\n",
    "# Save checklist\n",
    "with open(\"../notebooks/outputs/module_09/preregistration_checklist.txt\", \"w\") as f:\n",
    "    f.write(checklist)\n",
    "\n",
    "print(\"\\nâœ“ Checklist saved to outputs/module_09/preregistration_checklist.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Practice Exercise\n",
    "\n",
    "### Scenario: Sleep and Memory Study\n",
    "\n",
    "You're planning a study to test whether sleep quality affects memory consolidation. Create a preregistration addressing:\n",
    "\n",
    "1. **Research Question:** Does sleep quality predict memory consolidation?\n",
    "\n",
    "2. **Design:** Observational study\n",
    "   - Participants complete memory task before bed\n",
    "   - Sleep quality measured with actigraphy\n",
    "   - Memory test repeated next morning\n",
    "\n",
    "3. **Your Task:** Complete this preregistration template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_template = \"\"\"\n",
    "PRACTICE PREREGISTRATION: SLEEP AND MEMORY\n",
    "========================================================================\n",
    "\n",
    "INSTRUCTIONS: Fill in each section with your planned details.\n",
    "\n",
    "1. HYPOTHESES\n",
    "   H1: [Your directional hypothesis about sleep quality and memory]\n",
    "   \n",
    "   Direction: [One-tailed or two-tailed? Why?]\n",
    "\n",
    "2. VARIABLES\n",
    "   Primary IV: [How will you measure sleep quality?]\n",
    "               [What metric? (e.g., sleep efficiency, total sleep time)]\n",
    "   \n",
    "   Primary DV: [How will you measure memory consolidation?]\n",
    "               [e.g., % retention from night before to morning]\n",
    "   \n",
    "   Covariates: [What variables might you need to control for?]\n",
    "               [e.g., age, baseline memory, caffeine consumption]\n",
    "\n",
    "3. SAMPLE\n",
    "   N = [How many participants?]\n",
    "   \n",
    "   Power justification:\n",
    "   [Use a power analysis to justify your N]\n",
    "   [What effect size are you powered to detect?]\n",
    "   \n",
    "   Inclusion: [Who can participate?]\n",
    "   Exclusion: [Who cannot? (e.g., sleep disorders, medications)]\n",
    "\n",
    "4. ANALYSIS PLAN\n",
    "   Primary test: [What statistical test? (e.g., correlation, regression)]\n",
    "   \n",
    "   Model: [If regression, what will your model be?]\n",
    "          [e.g., Memory retention ~ Sleep quality + Age + Baseline memory]\n",
    "   \n",
    "   Alpha: [Significance level]\n",
    "   \n",
    "   Inference: [When will you conclude H1 is supported?]\n",
    "\n",
    "5. DATA QUALITY\n",
    "   Outliers: [How will you identify outliers?]\n",
    "             [Will you exclude or retain them?]\n",
    "   \n",
    "   Missing data: [What if actigraphy fails for some participants?]\n",
    "   \n",
    "   Quality checks: [Any attention checks or manipulation checks?]\n",
    "\n",
    "========================================================================\n",
    "\n",
    "REFLECTION QUESTIONS:\n",
    "1. What are the weaknesses of your design?\n",
    "2. What alternative explanations exist for your predicted results?\n",
    "3. What would you do if your hypothesis is NOT supported?\n",
    "4. Are there any \"researcher degrees of freedom\" you need to constrain?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(exercise_template)\n",
    "\n",
    "# Save exercise\n",
    "with open(\"../notebooks/outputs/module_09/practice_preregistration.txt\", \"w\") as f:\n",
    "    f.write(exercise_template)\n",
    "\n",
    "print(\"\\nâœ“ Practice exercise saved to outputs/module_09/practice_preregistration.txt\")\n",
    "print(\"\\nðŸ’¡ Take 15-20 minutes to complete this exercise on your own.\")\n",
    "print(\"   Compare your answers with published preregistrations on OSF.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Preregistration prevents QRPs**\n",
    "   - P-hacking and HARKing inflate false positive rates\n",
    "   - Committing to analyses upfront maintains Î± = 0.05\n",
    "\n",
    "2. **Multiple platforms available**\n",
    "   - OSF: General purpose, flexible\n",
    "   - AsPredicted: Quick, streamlined\n",
    "   - PROSPERO: Systematic reviews\n",
    "   - ClinicalTrials.gov: Clinical trials\n",
    "\n",
    "3. **Registered Reports eliminate publication bias**\n",
    "   - Stage 1 review before data collection\n",
    "   - In-principle acceptance regardless of results\n",
    "   - Growing adoption across journals\n",
    "\n",
    "4. **FAIR principles guide open data**\n",
    "   - Findable: DOIs and metadata\n",
    "   - Accessible: Open repositories\n",
    "   - Interoperable: Standard formats\n",
    "   - Reusable: Clear licenses\n",
    "\n",
    "5. **Deviations are okay if reported transparently**\n",
    "   - Document reasons for changes\n",
    "   - Distinguish confirmatory from exploratory\n",
    "   - The goal is transparency, not perfection\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "âœ“ **Do:**\n",
    "- Preregister before looking at the data\n",
    "- Be as specific as possible\n",
    "- Report all deviations transparently\n",
    "- Share data and materials when possible\n",
    "- Distinguish confirmatory from exploratory analyses\n",
    "\n",
    "âœ— **Don't:**\n",
    "- Edit preregistration after seeing data\n",
    "- Present exploratory findings as confirmatory\n",
    "- Hide deviations or failed studies\n",
    "- Let perfect be the enemy of good\n",
    "\n",
    "### Impact\n",
    "\n",
    "Open science practices:\n",
    "- Improve credibility of findings\n",
    "- Accelerate scientific progress\n",
    "- Increase public trust in science\n",
    "- Reduce research waste\n",
    "- Make science more equitable and accessible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "### Platforms\n",
    "- Open Science Framework: https://osf.io\n",
    "- AsPredicted: https://aspredicted.org\n",
    "- PROSPERO: https://www.crd.york.ac.uk/prospero/\n",
    "- ClinicalTrials.gov: https://clinicaltrials.gov\n",
    "- Registered Reports: https://www.cos.io/initiatives/registered-reports\n",
    "\n",
    "### Readings\n",
    "- Nosek, B. A., et al. (2018). The preregistration revolution. *PNAS, 115*(11), 2600-2606.\n",
    "- Simmons, J. P., et al. (2011). False-positive psychology. *Psychological Science, 22*(11), 1359-1366.\n",
    "- Chambers, C. (2017). *The Seven Deadly Sins of Psychology*. Princeton University Press.\n",
    "- Wilkinson, M. D., et al. (2016). The FAIR Guiding Principles. *Scientific Data, 3*, 160018.\n",
    "- Open Science Collaboration (2015). Estimating the reproducibility of psychological science. *Science, 349*(6251), aac4716.\n",
    "\n",
    "### Tutorials\n",
    "- OSF Preregistration Guide: https://help.osf.io/hc/en-us/articles/360019738834\n",
    "- APA Preregistration Template: https://osf.io/jea94/\n",
    "- Center for Open Science YouTube: https://www.youtube.com/c/CenterforOpenScience\n",
    "\n",
    "### Tools\n",
    "- Power analysis: G*Power, pwr package (R), statsmodels (Python)\n",
    "- Preregistration templates: OSF has 20+ templates for different study types\n",
    "- Data repositories: Zenodo, Figshare, Dryad, Dataverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In **Module 10: Advanced Reproducibility & Containerization**, you'll learn:\n",
    "- Computational reproducibility with Docker and containers\n",
    "- Version control for data and models (DVC, Git-LFS)\n",
    "- Workflow automation with Snakemake and Make\n",
    "- Dependency management (conda, pip, renv)\n",
    "- Reproducible random number generation\n",
    "- Creating reproducible computational environments\n",
    "\n",
    "Continue your journey toward fully transparent and reproducible research! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
