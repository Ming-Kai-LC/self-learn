{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 07: Reproducible Research\n",
    "\n",
    "**Estimated Time:** 40 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will be able to:\n",
    "\n",
    "1. âœ… Understand what reproducibility means in data science research\n",
    "2. âœ… Set up reproducible computational environments\n",
    "3. âœ… Organize code for reproducibility and maintainability\n",
    "4. âœ… Control randomness in experiments\n",
    "5. âœ… Manage dependencies and versions effectively\n",
    "6. âœ… Apply best practices for data versioning\n",
    "\n",
    "## Why Reproducibility Matters\n",
    "\n",
    "**Reproducibility** is the cornerstone of trustworthy research. If other researchers (or even you in 6 months!) cannot reproduce your results, the findings lose credibility.\n",
    "\n",
    "### Real-World Impact:\n",
    "- ðŸ”¬ **Science Crisis**: Studies estimate that 50-90% of published research may not be reproducible\n",
    "- ðŸ’° **Cost**: Irreproducible research costs billions in wasted resources\n",
    "- ðŸ† **Career**: Reproducible work builds reputation and enables collaboration\n",
    "- âš–ï¸ **Legal**: In healthcare, finance, and criminal justice, reproducibility can be legally required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"outputs/module07\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"âœ… Module 07: Reproducible Research - Setup Complete!\")\n",
    "print(f\"ðŸ“ Outputs will be saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Understanding Reproducibility\n",
    "\n",
    "### Types of Reproducibility\n",
    "\n",
    "There are three main types:\n",
    "\n",
    "#### 1. **Computational Reproducibility** ðŸ–¥ï¸\n",
    "- Same data + Same code + Same environment = **Same results**\n",
    "- This is the minimum standard for data science\n",
    "- Focus: Environment, dependencies, random seeds\n",
    "\n",
    "#### 2. **Empirical Reproducibility** ðŸ”¬\n",
    "- Same methodology + New data collection = **Consistent findings**\n",
    "- Tests if the effect is real, not just a fluke\n",
    "- Focus: Methodology documentation, protocols\n",
    "\n",
    "#### 3. **Statistical Reproducibility** ðŸ“Š\n",
    "- Same data + Different analysis = **Robust conclusions**\n",
    "- Tests sensitivity to analytical choices\n",
    "- Focus: Transparency about decisions, reporting all analyses\n",
    "\n",
    "### The Reproducibility Spectrum\n",
    "\n",
    "```\n",
    "Not Reproducible â†â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â†’ Fully Reproducible\n",
    "       |\n",
    "       |-- No documentation\n",
    "       |-- Manual steps\n",
    "       |-- Hard-coded paths\n",
    "       |-- Version conflicts\n",
    "       |                  |\n",
    "       |                  |-- Basic documentation\n",
    "       |                  |-- Some automation\n",
    "       |                  |-- Relative paths\n",
    "       |                  |                     |\n",
    "       |                  |                     |-- Complete documentation\n",
    "       |                  |                     |-- Fully automated\n",
    "       |                  |                     |-- Version control\n",
    "       |                  |                     |-- Containerized\n",
    "       |                  |                     |-- Public data/code\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Demonstrating non-reproducible vs reproducible code\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NON-REPRODUCIBLE CODE EXAMPLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# âŒ BAD: Non-reproducible\n",
    "bad_example = \"\"\"\n",
    "# No random seed set\n",
    "data = np.random.randn(100)  \n",
    "# Hard-coded absolute path\n",
    "df = pd.read_csv('C:/Users/John/data.csv')  \n",
    "# No version info\n",
    "from sklearn.model import MyModel  \n",
    "\"\"\"\n",
    "print(bad_example)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"REPRODUCIBLE CODE EXAMPLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# âœ… GOOD: Reproducible\n",
    "good_example = \"\"\"\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)  \n",
    "data = np.random.randn(100)\n",
    "\n",
    "# Use relative paths\n",
    "data_dir = os.path.join('..', 'data')\n",
    "df = pd.read_csv(os.path.join(data_dir, 'data.csv'))\n",
    "\n",
    "# Document versions in requirements.txt\n",
    "# scikit-learn==1.3.0\n",
    "from sklearn.model import MyModel\n",
    "\"\"\"\n",
    "print(good_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing reproducibility challenges\n",
    "\n",
    "challenges = {\n",
    "    \"Environment\\nDifferences\": 35,\n",
    "    \"Random\\nSeeds\": 25,\n",
    "    \"Data\\nVersioning\": 20,\n",
    "    \"Dependency\\nConflicts\": 15,\n",
    "    \"Documentation\\nGaps\": 5,\n",
    "}\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart\n",
    "colors = sns.color_palette(\"Set2\", len(challenges))\n",
    "ax1.pie(\n",
    "    challenges.values(), labels=challenges.keys(), autopct=\"%1.1f%%\", startangle=90, colors=colors\n",
    ")\n",
    "ax1.set_title(\"Common Reproducibility Challenges\\n(% of issues)\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Bar chart\n",
    "bars = ax2.barh(list(challenges.keys()), list(challenges.values()), color=colors)\n",
    "ax2.set_xlabel(\"Percentage (%)\", fontsize=12)\n",
    "ax2.set_title(\"Reproducibility Challenges by Type\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, value) in enumerate(zip(bars, challenges.values())):\n",
    "    ax2.text(value + 1, i, f\"{value}%\", va=\"center\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(output_dir, \"reproducibility_challenges.png\"), dpi=300, bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"\\nðŸ’¡ Key Insight: Environment differences and random seeds cause 60% of reproducibility issues!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Reproducible Environments\n",
    "\n",
    "### ðŸ“¦ Virtual Environments\n",
    "\n",
    "Virtual environments isolate project dependencies, preventing conflicts.\n",
    "\n",
    "#### Why Use Virtual Environments?\n",
    "- âœ… **Isolation**: Different projects can use different library versions\n",
    "- âœ… **Portability**: Easy to share exact environment setup\n",
    "- âœ… **Reproducibility**: Ensures consistent results across machines\n",
    "\n",
    "#### Common Tools:\n",
    "\n",
    "| Tool | Best For | Pros | Cons |\n",
    "|------|----------|------|------|\n",
    "| **venv** | Python-only projects | Built-in, simple | Python only |\n",
    "| **conda** | Data science, multi-language | Handles non-Python deps | Slower, larger |\n",
    "| **Docker** | Production, complex stacks | Complete isolation | Steeper learning curve |\n",
    "\n",
    "### Creating Virtual Environments\n",
    "\n",
    "```bash\n",
    "# Using venv (Python 3.3+)\n",
    "python -m venv myenv\n",
    "source myenv/bin/activate  # On Windows: myenv\\Scripts\\activate\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Using conda\n",
    "conda create -n myenv python=3.10\n",
    "conda activate myenv\n",
    "conda install --file requirements.txt\n",
    "\n",
    "# Using Docker\n",
    "docker build -t my-research-env .\n",
    "docker run -v $(pwd):/workspace my-research-env\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document your current environment\n",
    "\n",
    "\n",
    "def document_environment():\n",
    "    \"\"\"\n",
    "    Capture comprehensive environment information.\n",
    "\n",
    "    This is crucial for reproducibility!\n",
    "    \"\"\"\n",
    "    env_info = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"python_version\": sys.version,\n",
    "        \"platform\": platform.platform(),\n",
    "        \"machine\": platform.machine(),\n",
    "        \"processor\": platform.processor(),\n",
    "    }\n",
    "\n",
    "    # Get package versions\n",
    "    import importlib.metadata\n",
    "\n",
    "    key_packages = [\"numpy\", \"pandas\", \"matplotlib\", \"seaborn\", \"scikit-learn\", \"scipy\"]\n",
    "\n",
    "    package_versions = {}\n",
    "    for pkg in key_packages:\n",
    "        try:\n",
    "            package_versions[pkg] = importlib.metadata.version(pkg)\n",
    "        except importlib.metadata.PackageNotFoundError:\n",
    "            package_versions[pkg] = \"Not installed\"\n",
    "\n",
    "    return env_info, package_versions\n",
    "\n",
    "\n",
    "# Document current environment\n",
    "env_info, packages = document_environment()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ENVIRONMENT DOCUMENTATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nðŸ“… Timestamp: {env_info['timestamp']}\")\n",
    "print(f\"ðŸ Python: {env_info['python_version'].split()[0]}\")\n",
    "print(f\"ðŸ’» Platform: {env_info['platform']}\")\n",
    "print(f\"ðŸ–¥ï¸  Machine: {env_info['machine']}\")\n",
    "\n",
    "print(\"\\nðŸ“¦ Package Versions:\")\n",
    "print(\"-\" * 60)\n",
    "for pkg, version in packages.items():\n",
    "    print(f\"  {pkg:20s}: {version}\")\n",
    "\n",
    "# Save to file\n",
    "env_df = pd.DataFrame(\n",
    "    [{\"Category\": \"System\", \"Item\": k, \"Value\": v} for k, v in env_info.items()]\n",
    "    + [{\"Category\": \"Package\", \"Item\": k, \"Value\": v} for k, v in packages.items()]\n",
    ")\n",
    "\n",
    "env_df.to_csv(os.path.join(output_dir, \"environment_info.csv\"), index=False)\n",
    "print(f\"\\nâœ… Environment info saved to {output_dir}/environment_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a requirements.txt template\n",
    "\n",
    "\n",
    "def generate_requirements_template():\n",
    "    \"\"\"\n",
    "    Generate a well-documented requirements.txt file.\n",
    "    \"\"\"\n",
    "    template = \"\"\"# Research Project Dependencies\n",
    "# Generated: {timestamp}\n",
    "# Python Version: {python_version}\n",
    "\n",
    "# Core Scientific Computing\n",
    "numpy>=1.24.0\n",
    "pandas>=2.0.0\n",
    "scipy>=1.10.0\n",
    "\n",
    "# Visualization\n",
    "matplotlib>=3.7.0\n",
    "seaborn>=0.12.0\n",
    "\n",
    "# Machine Learning\n",
    "scikit-learn>=1.3.0\n",
    "\n",
    "# Statistical Analysis\n",
    "statsmodels>=0.14.0\n",
    "\n",
    "# Jupyter\n",
    "jupyter>=1.0.0\n",
    "notebook>=7.0.0\n",
    "ipywidgets>=8.0.0\n",
    "\n",
    "# Utility\n",
    "python-dateutil>=2.8.0\n",
    "pytz>=2023.3\n",
    "\n",
    "# Development (optional)\n",
    "# pytest>=7.4.0\n",
    "# black>=23.0.0\n",
    "# flake8>=6.0.0\n",
    "\"\"\".format(\n",
    "        timestamp=datetime.now().strftime(\"%Y-%m-%d\"), python_version=sys.version.split()[0]\n",
    "    )\n",
    "\n",
    "    return template\n",
    "\n",
    "\n",
    "requirements = generate_requirements_template()\n",
    "print(\"ðŸ“„ REQUIREMENTS.TXT TEMPLATE\")\n",
    "print(\"=\" * 60)\n",
    "print(requirements)\n",
    "\n",
    "# Save template\n",
    "with open(os.path.join(output_dir, \"requirements_template.txt\"), \"w\") as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "print(f\"\\nâœ… Template saved to {output_dir}/requirements_template.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Controlling Randomness\n",
    "\n",
    "### ðŸŽ² Random Seeds\n",
    "\n",
    "Many data science operations involve randomness:\n",
    "- Train/test splits\n",
    "- Random initialization of models\n",
    "- Data shuffling\n",
    "- Random sampling\n",
    "\n",
    "**Setting random seeds ensures these operations are reproducible.**\n",
    "\n",
    "### Best Practices:\n",
    "1. âœ… Set seeds at the **start** of your notebook/script\n",
    "2. âœ… Set seeds for **all** libraries you use (NumPy, Python random, TensorFlow, PyTorch, etc.)\n",
    "3. âœ… Document the seed value in your code and paper\n",
    "4. âœ… Use the **same seed** across related experiments for fair comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the importance of random seeds\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DEMONSTRATION: Effect of Random Seeds\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# WITHOUT seed (non-reproducible)\n",
    "print(\"\\nâŒ WITHOUT SEED (Run this cell multiple times - results change!)\")\n",
    "data_no_seed = np.random.randn(5)\n",
    "print(f\"Random data: {data_no_seed}\")\n",
    "\n",
    "# WITH seed (reproducible)\n",
    "print(\"\\nâœ… WITH SEED (Run this cell multiple times - results stay the same!)\")\n",
    "np.random.seed(42)\n",
    "data_with_seed = np.random.randn(5)\n",
    "print(f\"Random data: {data_with_seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive seed setting function\n",
    "\n",
    "\n",
    "def set_all_seeds(seed=42):\n",
    "    \"\"\"\n",
    "    Set random seeds for all common libraries.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    seed : int\n",
    "        The random seed value (default: 42)\n",
    "\n",
    "    Note:\n",
    "    -----\n",
    "    Call this function at the START of your notebook/script!\n",
    "    \"\"\"\n",
    "    # Python's built-in random\n",
    "    import random\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # TensorFlow (if installed)\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "\n",
    "        tf.random.set_seed(seed)\n",
    "        print(f\"âœ… TensorFlow seed set to {seed}\")\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    # PyTorch (if installed)\n",
    "    try:\n",
    "        import torch\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "        print(f\"âœ… PyTorch seed set to {seed}\")\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    print(f\"âœ… Python random seed set to {seed}\")\n",
    "    print(f\"âœ… NumPy seed set to {seed}\")\n",
    "\n",
    "    return seed\n",
    "\n",
    "\n",
    "# Set all seeds\n",
    "RANDOM_SEED = 42  # Document this clearly!\n",
    "set_all_seeds(RANDOM_SEED)\n",
    "\n",
    "print(f\"\\nðŸ”’ All random operations are now reproducible with seed={RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reproducibility with seeds\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create synthetic data\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100, 1)\n",
    "y = 3 * X.squeeze() + 2 + np.random.randn(100) * 0.5\n",
    "\n",
    "# Compare results with and without seed\n",
    "results = []\n",
    "\n",
    "for trial in range(5):\n",
    "    # Without seed - different split each time\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "    score_no_seed = model.score(X_test, y_test)\n",
    "\n",
    "    # With seed - same split every time\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "    score_with_seed = model.score(X_test, y_test)\n",
    "\n",
    "    results.append(\n",
    "        {\"Trial\": trial + 1, \"Without Seed\": score_no_seed, \"With Seed\": score_with_seed}\n",
    "    )\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(\n",
    "    x - width / 2,\n",
    "    results_df[\"Without Seed\"],\n",
    "    width,\n",
    "    label=\"Without Seed (Non-reproducible)\",\n",
    "    alpha=0.8,\n",
    "    color=\"coral\",\n",
    ")\n",
    "bars2 = ax.bar(\n",
    "    x + width / 2,\n",
    "    results_df[\"With Seed\"],\n",
    "    width,\n",
    "    label=\"With Seed (Reproducible)\",\n",
    "    alpha=0.8,\n",
    "    color=\"lightblue\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Trial\", fontsize=12)\n",
    "ax.set_ylabel(\"RÂ² Score\", fontsize=12)\n",
    "ax.set_title(\n",
    "    \"Impact of Random Seeds on Model Performance\\n(Same data, different train/test splits)\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(results_df[\"Trial\"])\n",
    "ax.legend()\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"seed_impact.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Results Summary:\")\n",
    "print(results_df.to_string(index=False))\n",
    "print(f\"\\nWithout Seed - Std Dev: {results_df['Without Seed'].std():.6f}\")\n",
    "print(f\"With Seed - Std Dev: {results_df['With Seed'].std():.6f}\")\n",
    "print(\"\\nðŸ’¡ Notice: With seed, the score is IDENTICAL across all trials!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Code Organization\n",
    "\n",
    "### ðŸ“ Project Structure\n",
    "\n",
    "A well-organized project structure is essential for reproducibility.\n",
    "\n",
    "#### Recommended Structure:\n",
    "\n",
    "```\n",
    "my-research-project/\n",
    "â”‚\n",
    "â”œâ”€â”€ README.md                 # Project overview and instructions\n",
    "â”œâ”€â”€ requirements.txt          # Python dependencies\n",
    "â”œâ”€â”€ environment.yml           # Conda environment (if using conda)\n",
    "â”œâ”€â”€ .gitignore               # Files to exclude from version control\n",
    "â”‚\n",
    "â”œâ”€â”€ data/                    # Data files\n",
    "â”‚   â”œâ”€â”€ raw/                 # Original, immutable data\n",
    "â”‚   â”œâ”€â”€ processed/           # Cleaned and processed data\n",
    "â”‚   â””â”€â”€ README.md            # Data documentation\n",
    "â”‚\n",
    "â”œâ”€â”€ notebooks/               # Jupyter notebooks\n",
    "â”‚   â”œâ”€â”€ 01_exploration.ipynb\n",
    "â”‚   â”œâ”€â”€ 02_analysis.ipynb\n",
    "â”‚   â””â”€â”€ outputs/             # Notebook outputs\n",
    "â”‚\n",
    "â”œâ”€â”€ src/                     # Source code\n",
    "â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”œâ”€â”€ data_processing.py\n",
    "â”‚   â”œâ”€â”€ models.py\n",
    "â”‚   â””â”€â”€ utils.py\n",
    "â”‚\n",
    "â”œâ”€â”€ tests/                   # Unit tests\n",
    "â”‚   â””â”€â”€ test_data_processing.py\n",
    "â”‚\n",
    "â”œâ”€â”€ results/                 # Analysis outputs\n",
    "â”‚   â”œâ”€â”€ figures/\n",
    "â”‚   â””â”€â”€ tables/\n",
    "â”‚\n",
    "â””â”€â”€ docs/                    # Documentation\n",
    "    â””â”€â”€ methodology.md\n",
    "```\n",
    "\n",
    "### Coding Best Practices\n",
    "\n",
    "#### 1. Use Relative Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âŒ BAD: Absolute paths (not portable)\n",
    "bad_path = \"C:/Users/John/Documents/project/data.csv\"\n",
    "\n",
    "# âœ… GOOD: Relative paths (portable)\n",
    "import os\n",
    "\n",
    "# Get the project root\n",
    "project_root = os.path.dirname(os.path.abspath(\".\"))\n",
    "data_dir = os.path.join(project_root, \"data\", \"raw\")\n",
    "good_path = os.path.join(data_dir, \"data.csv\")\n",
    "\n",
    "print(f\"âœ… Portable path: {good_path}\")\n",
    "print(\"\\nðŸ’¡ This will work on any machine, regardless of username or OS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Write Modular, Reusable Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âŒ BAD: Repeated code\n",
    "print(\"âŒ BAD APPROACH:\")\n",
    "print(\n",
    "    \"\"\"data1 = pd.read_csv('file1.csv')\n",
    "data1 = data1.dropna()\n",
    "data1['value'] = (data1['value'] - data1['value'].mean()) / data1['value'].std()\n",
    "\n",
    "data2 = pd.read_csv('file2.csv')\n",
    "data2 = data2.dropna()\n",
    "data2['value'] = (data2['value'] - data2['value'].mean()) / data2['value'].std()\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# âœ… GOOD: Reusable function\n",
    "print(\"âœ… GOOD APPROACH:\")\n",
    "\n",
    "\n",
    "def load_and_preprocess(filepath, normalize_col=None):\n",
    "    \"\"\"\n",
    "    Load CSV and perform standard preprocessing.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : str\n",
    "        Path to CSV file\n",
    "    normalize_col : str, optional\n",
    "        Column to normalize (z-score)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Processed data\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    data = pd.read_csv(filepath)\n",
    "\n",
    "    # Remove missing values\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Normalize if specified\n",
    "    if normalize_col and normalize_col in data.columns:\n",
    "        mean = data[normalize_col].mean()\n",
    "        std = data[normalize_col].std()\n",
    "        data[normalize_col] = (data[normalize_col] - mean) / std\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "print(\n",
    "    \"\"\"def load_and_preprocess(filepath, normalize_col=None):\n",
    "    # Load, clean, and normalize data\n",
    "    ...\n",
    "\n",
    "data1 = load_and_preprocess('file1.csv', normalize_col='value')\n",
    "data2 = load_and_preprocess('file2.csv', normalize_col='value')\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ’¡ Benefits: DRY (Don't Repeat Yourself), easier to maintain, fewer bugs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Document Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_effect_size(group1, group2, method=\"cohen_d\"):\n",
    "    \"\"\"\n",
    "    Calculate effect size between two groups.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    group1 : array-like\n",
    "        Values from group 1\n",
    "    group2 : array-like\n",
    "        Values from group 2\n",
    "    method : str, default='cohen_d'\n",
    "        Effect size method. Options: 'cohen_d', 'hedges_g'\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Effect size value\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    Cohen's d interpretation:\n",
    "    - Small: d = 0.2\n",
    "    - Medium: d = 0.5\n",
    "    - Large: d = 0.8\n",
    "\n",
    "    References:\n",
    "    -----------\n",
    "    Cohen, J. (1988). Statistical power analysis for the behavioral sciences.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> group1 = [1, 2, 3, 4, 5]\n",
    "    >>> group2 = [2, 3, 4, 5, 6]\n",
    "    >>> calculate_effect_size(group1, group2)\n",
    "    0.632...\n",
    "    \"\"\"\n",
    "    mean1, mean2 = np.mean(group1), np.mean(group2)\n",
    "    std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "\n",
    "    # Pooled standard deviation\n",
    "    pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\n",
    "\n",
    "    if method == \"cohen_d\":\n",
    "        return (mean1 - mean2) / pooled_std\n",
    "    elif method == \"hedges_g\":\n",
    "        # Hedges' g includes a correction for small sample sizes\n",
    "        j = 1 - (3 / (4 * (n1 + n2) - 9))\n",
    "        return ((mean1 - mean2) / pooled_std) * j\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(42)\n",
    "control = np.random.normal(100, 15, 50)\n",
    "treatment = np.random.normal(110, 15, 50)\n",
    "\n",
    "effect_size = calculate_effect_size(control, treatment)\n",
    "print(f\"Cohen's d: {effect_size:.3f}\")\n",
    "print(\n",
    "    f\"Interpretation: {'Large' if abs(effect_size) >= 0.8 else 'Medium' if abs(effect_size) >= 0.5 else 'Small'} effect\"\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Well-documented function with:\")\n",
    "print(\"   â€¢ Clear parameter descriptions\")\n",
    "print(\"   â€¢ Return value documentation\")\n",
    "print(\"   â€¢ Interpretation guidelines\")\n",
    "print(\"   â€¢ References to original papers\")\n",
    "print(\"   â€¢ Usage examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Data Versioning and Management\n",
    "\n",
    "### ðŸ“Š Why Version Data?\n",
    "\n",
    "Code isn't the only thing that changes - data does too!\n",
    "\n",
    "- ðŸ”„ **Data updates**: New data collected over time\n",
    "- ðŸ› ï¸ **Processing changes**: Improved cleaning methods\n",
    "- ðŸ› **Error corrections**: Fixing mistakes in data\n",
    "- ðŸŽ¯ **Different subsets**: Various analysis focuses\n",
    "\n",
    "### Data Versioning Strategies:\n",
    "\n",
    "#### 1. **File Naming Convention**\n",
    "```\n",
    "data_v1.0_2024-01-15.csv\n",
    "data_v1.1_2024-02-20.csv  (minor cleaning update)\n",
    "data_v2.0_2024-03-10.csv  (major schema change)\n",
    "```\n",
    "\n",
    "#### 2. **Separate Raw and Processed**\n",
    "```\n",
    "data/\n",
    "â”œâ”€â”€ raw/              # NEVER modify these!\n",
    "â”‚   â””â”€â”€ survey_responses.csv\n",
    "â””â”€â”€ processed/        # Generated from raw\n",
    "    â”œâ”€â”€ survey_cleaned_v1.csv\n",
    "    â””â”€â”€ survey_cleaned_v2.csv\n",
    "```\n",
    "\n",
    "#### 3. **Use DVC (Data Version Control)**\n",
    "Like Git, but for data:\n",
    "```bash\n",
    "dvc init\n",
    "dvc add data/large_dataset.csv\n",
    "git add data/large_dataset.csv.dvc\n",
    "git commit -m \"Add dataset v1\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data versioning helper\n",
    "\n",
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def create_data_manifest(data, description, version, author):\n",
    "    \"\"\"\n",
    "    Create a manifest file documenting dataset properties.\n",
    "\n",
    "    This helps track what changed between versions.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        The dataset\n",
    "    description : str\n",
    "        What this version contains\n",
    "    version : str\n",
    "        Version number (e.g., '1.0', '2.1')\n",
    "    author : str\n",
    "        Who created this version\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Manifest information\n",
    "    \"\"\"\n",
    "    # Calculate hash of data (for integrity checking)\n",
    "    data_hash = hashlib.md5(pd.util.hash_pandas_object(data, index=True).values).hexdigest()\n",
    "\n",
    "    manifest = {\n",
    "        \"version\": version,\n",
    "        \"created_at\": datetime.now().isoformat(),\n",
    "        \"author\": author,\n",
    "        \"description\": description,\n",
    "        \"data_hash\": data_hash,\n",
    "        \"shape\": {\"rows\": len(data), \"columns\": len(data.columns)},\n",
    "        \"columns\": list(data.columns),\n",
    "        \"dtypes\": data.dtypes.astype(str).to_dict(),\n",
    "        \"missing_values\": data.isnull().sum().to_dict(),\n",
    "        \"memory_usage_mb\": data.memory_usage(deep=True).sum() / 1024**2,\n",
    "    }\n",
    "\n",
    "    return manifest\n",
    "\n",
    "\n",
    "# Example: Version our sample data\n",
    "np.random.seed(42)\n",
    "sample_data = pd.DataFrame(\n",
    "    {\n",
    "        \"user_id\": range(1, 101),\n",
    "        \"age\": np.random.randint(18, 80, 100),\n",
    "        \"score\": np.random.randn(100) * 10 + 50,\n",
    "        \"category\": np.random.choice([\"A\", \"B\", \"C\"], 100),\n",
    "    }\n",
    ")\n",
    "\n",
    "manifest = create_data_manifest(\n",
    "    data=sample_data,\n",
    "    description=\"Initial dataset from user survey\",\n",
    "    version=\"1.0\",\n",
    "    author=\"Research Team\",\n",
    ")\n",
    "\n",
    "print(\"ðŸ“‹ DATA MANIFEST\")\n",
    "print(\"=\" * 60)\n",
    "print(json.dumps(manifest, indent=2))\n",
    "\n",
    "# Save manifest\n",
    "manifest_path = os.path.join(output_dir, \"data_manifest_v1.0.json\")\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ… Manifest saved to {manifest_path}\")\n",
    "print(\"\\nðŸ’¡ Store this with your data to track changes over time!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Reproducibility Checklist\n",
    "\n",
    "### âœ… Before Sharing Your Research\n",
    "\n",
    "Use this checklist to ensure your work is reproducible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a comprehensive reproducibility checklist\n",
    "\n",
    "\n",
    "def create_reproducibility_checklist():\n",
    "    \"\"\"\n",
    "    Generate a comprehensive reproducibility checklist.\n",
    "    \"\"\"\n",
    "    checklist = {\n",
    "        \"ðŸŒ Environment\": [\n",
    "            \"â˜ Virtual environment created (venv/conda)\",\n",
    "            \"â˜ requirements.txt or environment.yml included\",\n",
    "            \"â˜ Python version documented\",\n",
    "            \"â˜ OS and platform documented (if relevant)\",\n",
    "        ],\n",
    "        \"ðŸŽ² Randomness\": [\n",
    "            \"â˜ Random seeds set for all libraries\",\n",
    "            \"â˜ Seed values documented in code and paper\",\n",
    "            \"â˜ Stochastic processes clearly noted\",\n",
    "        ],\n",
    "        \"ðŸ’¾ Data\": [\n",
    "            \"â˜ Data sources documented\",\n",
    "            \"â˜ Data collection date recorded\",\n",
    "            \"â˜ Raw data preserved (never modified)\",\n",
    "            \"â˜ Data processing pipeline documented\",\n",
    "            \"â˜ Data version tracked\",\n",
    "            \"â˜ Synthetic/example data provided (if original data is private)\",\n",
    "        ],\n",
    "        \"ðŸ“ Code\": [\n",
    "            \"â˜ Code uses relative paths (not absolute)\",\n",
    "            \"â˜ Functions are well-documented with docstrings\",\n",
    "            \"â˜ Code is modular and reusable\",\n",
    "            \"â˜ No hard-coded values (use constants/config files)\",\n",
    "            \"â˜ Code is version controlled (Git)\",\n",
    "        ],\n",
    "        \"ðŸ“‚ Organization\": [\n",
    "            \"â˜ Clear project structure\",\n",
    "            \"â˜ README.md with setup instructions\",\n",
    "            \"â˜ Separate directories for raw/processed data\",\n",
    "            \"â˜ Results/outputs clearly organized\",\n",
    "        ],\n",
    "        \"ðŸ“– Documentation\": [\n",
    "            \"â˜ Installation instructions included\",\n",
    "            \"â˜ Usage examples provided\",\n",
    "            \"â˜ Methodological choices explained\",\n",
    "            \"â˜ Known limitations documented\",\n",
    "            \"â˜ License file included\",\n",
    "        ],\n",
    "        \"ðŸ§ª Testing\": [\n",
    "            \"â˜ Code runs from scratch on clean environment\",\n",
    "            \"â˜ Results match reported values\",\n",
    "            \"â˜ Someone else can run your code\",\n",
    "        ],\n",
    "        \"ðŸŒ Sharing\": [\n",
    "            \"â˜ Code available in public repository (GitHub, GitLab)\",\n",
    "            \"â˜ Data available (or access instructions provided)\",\n",
    "            \"â˜ Permanent DOI obtained (Zenodo, FigShare)\",\n",
    "            \"â˜ Repository archived\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    return checklist\n",
    "\n",
    "\n",
    "checklist = create_reproducibility_checklist()\n",
    "\n",
    "print(\"âœ… REPRODUCIBILITY CHECKLIST\")\n",
    "print(\"=\" * 60)\n",
    "for category, items in checklist.items():\n",
    "    print(f\"\\n{category}\")\n",
    "    for item in items:\n",
    "        print(f\"  {item}\")\n",
    "\n",
    "# Save as markdown\n",
    "checklist_md = \"# Reproducibility Checklist\\n\\n\"\n",
    "for category, items in checklist.items():\n",
    "    checklist_md += f\"## {category}\\n\\n\"\n",
    "    for item in items:\n",
    "        checklist_md += f\"- {item}\\n\"\n",
    "    checklist_md += \"\\n\"\n",
    "\n",
    "with open(os.path.join(output_dir, \"reproducibility_checklist.md\"), \"w\") as f:\n",
    "    f.write(checklist_md)\n",
    "\n",
    "print(f\"\\nâœ… Checklist saved to {output_dir}/reproducibility_checklist.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practice Exercises\n",
    "\n",
    "### Exercise 1: Environment Documentation\n",
    "\n",
    "**Task:** Document your current environment and create a requirements.txt file.\n",
    "\n",
    "1. Run the `document_environment()` function\n",
    "2. Export your current packages: `pip freeze > requirements.txt`\n",
    "3. Review the requirements.txt and remove unnecessary packages\n",
    "\n",
    "### Exercise 2: Reproducibility Test\n",
    "\n",
    "**Task:** Test if your code is reproducible.\n",
    "\n",
    "1. Create a simple analysis with random elements\n",
    "2. Run it twice WITHOUT setting seeds - compare results\n",
    "3. Run it twice WITH seeds - verify results match\n",
    "\n",
    "### Exercise 3: Project Structure\n",
    "\n",
    "**Task:** Reorganize a messy project.\n",
    "\n",
    "Given this structure:\n",
    "```\n",
    "project/\n",
    "â”œâ”€â”€ analysis_final_FINAL_v2.ipynb\n",
    "â”œâ”€â”€ data.csv\n",
    "â”œâ”€â”€ data_cleaned.csv\n",
    "â””â”€â”€ plot1.png\n",
    "```\n",
    "\n",
    "Reorganize it into a proper structure with raw/processed data, organized notebooks, and clear outputs.\n",
    "\n",
    "### Exercise 4: Data Versioning\n",
    "\n",
    "**Task:** Create manifests for multiple data versions.\n",
    "\n",
    "1. Load a dataset\n",
    "2. Create version 1.0 manifest\n",
    "3. Modify the data (add rows, change values)\n",
    "4. Create version 2.0 manifest\n",
    "5. Compare the manifests to see what changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 Solution: Reproducibility Test\n",
    "\n",
    "print(\"ðŸŽ¯ EXERCISE 2: Reproducibility Test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create synthetic dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nâŒ Test 1: WITHOUT SEED (Non-reproducible)\")\n",
    "print(\"-\" * 60)\n",
    "results_no_seed = []\n",
    "for i in range(3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model = RandomForestClassifier(n_estimators=10)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    results_no_seed.append(accuracy)\n",
    "    print(f\"Run {i+1}: Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nStandard Deviation: {np.std(results_no_seed):.6f}\")\n",
    "\n",
    "print(\"\\nâœ… Test 2: WITH SEED (Reproducible)\")\n",
    "print(\"-\" * 60)\n",
    "results_with_seed = []\n",
    "for i in range(3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    results_with_seed.append(accuracy)\n",
    "    print(f\"Run {i+1}: Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nStandard Deviation: {np.std(results_with_seed):.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ’¡ Conclusion:\")\n",
    "print(f\"   Without seed: Results vary (std = {np.std(results_no_seed):.6f})\")\n",
    "print(f\"   With seed: Results identical (std = {np.std(results_with_seed):.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Key Takeaways\n",
    "\n",
    "### ðŸŽ¯ What We Learned\n",
    "\n",
    "1. **Reproducibility Types**\n",
    "   - Computational: Same code + data + environment = same results\n",
    "   - Empirical: Same methodology + new data = consistent findings\n",
    "   - Statistical: Same data + different analysis = robust conclusions\n",
    "\n",
    "2. **Environment Management**\n",
    "   - Use virtual environments (venv, conda, Docker)\n",
    "   - Document all dependencies with version numbers\n",
    "   - Record system information (Python version, OS, etc.)\n",
    "\n",
    "3. **Random Seed Control**\n",
    "   - Set seeds for ALL libraries at the start\n",
    "   - Document seed values clearly\n",
    "   - Use same seed across related experiments\n",
    "\n",
    "4. **Code Organization**\n",
    "   - Use clear project structure\n",
    "   - Write modular, reusable functions\n",
    "   - Use relative paths, never absolute\n",
    "   - Document everything with docstrings\n",
    "\n",
    "5. **Data Versioning**\n",
    "   - Never modify raw data\n",
    "   - Use version numbers and dates\n",
    "   - Create data manifests\n",
    "   - Consider DVC for large datasets\n",
    "\n",
    "### ðŸ“š Best Practices Summary\n",
    "\n",
    "| Practice | Why It Matters | How To Do It |\n",
    "|----------|---------------|-------------|\n",
    "| **Set random seeds** | Ensures consistent results | `np.random.seed(42)` at start |\n",
    "| **Use virtual environments** | Prevents dependency conflicts | `python -m venv myenv` |\n",
    "| **Document dependencies** | Others can recreate environment | `pip freeze > requirements.txt` |\n",
    "| **Relative paths** | Code works on any machine | `os.path.join()` instead of hard-coded paths |\n",
    "| **Version data** | Track changes over time | Use naming conventions + manifests |\n",
    "| **Test reproducibility** | Verify it works from scratch | Run in fresh environment |\n",
    "\n",
    "### ðŸš€ Next Steps\n",
    "\n",
    "1. **Apply the checklist** to your current project\n",
    "2. **Create a template** project structure you can reuse\n",
    "3. **Practice** setting up reproducible environments\n",
    "4. **Share your code** on GitHub with complete documentation\n",
    "\n",
    "### ðŸ’¡ Remember\n",
    "\n",
    "> \"If you can't reproduce it, it's not science - it's anecdote.\"\n",
    "\n",
    "Reproducibility is not just good practice - it's essential for trustworthy research!\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "### Tools\n",
    "- **DVC**: Data Version Control - https://dvc.org/\n",
    "- **Docker**: Containerization - https://www.docker.com/\n",
    "- **Conda**: Package management - https://docs.conda.io/\n",
    "- **Poetry**: Dependency management - https://python-poetry.org/\n",
    "\n",
    "### Reading\n",
    "- \"The Practice of Reproducible Research\" (free online book)\n",
    "- \"Good Enough Practices in Scientific Computing\" (Wilson et al., 2017)\n",
    "- \"Ten Simple Rules for Reproducible Computational Research\" (Sandve et al., 2013)\n",
    "\n",
    "### Guides\n",
    "- The Turing Way: Guide for Reproducible Research\n",
    "- ROpenSci Reproducibility Guide\n",
    "- Project TIER Protocol\n",
    "\n",
    "---\n",
    "\n",
    "**Next Module:** [08_documentation_version_control.ipynb](08_documentation_version_control.ipynb) - Learn about documenting your research and using version control effectively!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
