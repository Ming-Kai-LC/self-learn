{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 09: Putting It All Together\n",
    "\n",
    "Welcome to the final module! It's time to apply everything you've learned in a **complete mini-research project**.\n",
    "\n",
    "## What You'll Do\n",
    "\n",
    "- Plan a complete research project from start to finish\n",
    "- Apply all skills learned in Modules 00-08\n",
    "- Create a reproducible research artifact\n",
    "- Build a portfolio piece\n",
    "\n",
    "## Time Required\n",
    "\n",
    "**60 minutes** (but take as long as you need!)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Setup\n",
    "# ========================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set style\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"outputs/notebook_09_final_project\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Research Project Framework\n",
    "\n",
    "This notebook will guide you through a complete research project using all the skills you've learned:\n",
    "\n",
    "### Phase 1: Planning (Modules 01-03)\n",
    "1. Choose a research topic\n",
    "2. Review existing literature\n",
    "3. Formulate research question and hypothesis\n",
    "\n",
    "### Phase 2: Design (Modules 04-06)\n",
    "4. Design your methodology\n",
    "5. Plan data collection\n",
    "6. Consider ethical implications\n",
    "\n",
    "### Phase 3: Execution (Modules 07-08)\n",
    "7. Collect and analyze data\n",
    "8. Document your work\n",
    "9. Ensure reproducibility\n",
    "\n",
    "### Phase 4: Communication\n",
    "10. Present your findings\n",
    "11. Discuss limitations\n",
    "12. Suggest future work\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PHASE 1: PLANNING\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Choose Your Research Topic\n",
    "\n",
    "For this mini-project, we'll use a sample topic. You can follow along or substitute your own!\n",
    "\n",
    "**Sample Topic**: \"Effect of Feature Engineering on Customer Churn Prediction\"\n",
    "\n",
    "**Your Topic** (fill in below):\n",
    "```\n",
    "My research topic: _________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Document Your Research Topic\n",
    "# ========================================\n",
    "\n",
    "# Change these to match your project\n",
    "PROJECT_INFO = {\n",
    "    \"title\": \"Effect of Feature Engineering on Customer Churn Prediction\",\n",
    "    \"researcher\": \"Your Name\",\n",
    "    \"date_started\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"domain\": \"E-commerce / Customer Analytics\",\n",
    "    \"keywords\": [\"churn prediction\", \"feature engineering\", \"machine learning\"],\n",
    "}\n",
    "\n",
    "print(\"üìã PROJECT INFORMATION\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in PROJECT_INFO.items():\n",
    "    print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "# Save project info\n",
    "pd.DataFrame([PROJECT_INFO]).to_csv(f\"{output_dir}/project_info.csv\", index=False)\n",
    "print(f\"\\n‚úÖ Project info saved to: {output_dir}/project_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Literature Review Mini-Exercise\n",
    "\n",
    "**Task**: Find 3-5 relevant papers on your topic\n",
    "\n",
    "**Questions to answer**:\n",
    "1. What have others discovered about this topic?\n",
    "2. What methods have been tried?\n",
    "3. What gaps exist in the literature?\n",
    "\n",
    "For our sample project, here's a mini literature review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Document Literature Review\n",
    "# ========================================\n",
    "\n",
    "# Sample papers (replace with your actual papers)\n",
    "literature = pd.DataFrame(\n",
    "    {\n",
    "        \"Authors\": [\"Smith et al.\", \"Johnson & Lee\", \"Brown et al.\"],\n",
    "        \"Year\": [2023, 2022, 2021],\n",
    "        \"Title\": [\n",
    "            \"Feature Engineering for Churn Prediction\",\n",
    "            \"Machine Learning in Customer Retention\",\n",
    "            \"Automated Feature Selection Methods\",\n",
    "        ],\n",
    "        \"Key Finding\": [\n",
    "            \"Behavioral features improve accuracy by 15%\",\n",
    "            \"Random Forest outperforms Logistic Regression\",\n",
    "            \"Automated selection reduces features by 60%\",\n",
    "        ],\n",
    "        \"Relevance\": [5, 4, 4],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"üìö LITERATURE REVIEW SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(literature.to_string(index=False))\n",
    "\n",
    "# Save literature review\n",
    "literature.to_csv(f\"{output_dir}/literature_review.csv\", index=False)\n",
    "print(f\"\\n‚úÖ Literature review saved to: {output_dir}/literature_review.csv\")\n",
    "\n",
    "# Synthesize findings\n",
    "print(\"\\nüí° KEY INSIGHTS FROM LITERATURE:\")\n",
    "print(\"  1. Feature engineering significantly impacts performance\")\n",
    "print(\"  2. Behavioral features are particularly important\")\n",
    "print(\"  3. Feature selection can improve both accuracy and efficiency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Formulate Research Question & Hypothesis\n",
    "\n",
    "Based on your literature review, create a specific research question.\n",
    "\n",
    "**Sample Research Question**:  \n",
    "\"Does adding engineered behavioral features (RFM metrics) improve customer churn prediction accuracy compared to using only demographic features?\"\n",
    "\n",
    "**Sample Hypothesis**:  \n",
    "\"Adding RFM (Recency, Frequency, Monetary) features will improve churn prediction accuracy by at least 10% compared to demographic features alone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Document Research Question and Hypothesis\n",
    "# ========================================\n",
    "\n",
    "research_design = {\n",
    "    \"research_question\": \"Does adding engineered behavioral features improve churn prediction?\",\n",
    "    \"hypothesis\": \"RFM features will improve accuracy by >= 10%\",\n",
    "    \"null_hypothesis\": \"RFM features will NOT improve accuracy by >= 10%\",\n",
    "    \"independent_variable\": \"Feature set (demographic only vs. demographic + RFM)\",\n",
    "    \"dependent_variable\": \"Prediction accuracy (F1-score)\",\n",
    "    \"significance_level\": 0.05,\n",
    "}\n",
    "\n",
    "print(\"üî¨ RESEARCH DESIGN\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in research_design.items():\n",
    "    print(f\"{key.replace('_', ' ').title()}:\")\n",
    "    print(f\"  {value}\\n\")\n",
    "\n",
    "# Save research design\n",
    "with open(f\"{output_dir}/research_design.txt\", \"w\") as f:\n",
    "    for key, value in research_design.items():\n",
    "        f.write(f\"{key.replace('_', ' ').title()}: {value}\\n\")\n",
    "\n",
    "print(f\"‚úÖ Research design saved to: {output_dir}/research_design.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PHASE 2: DESIGN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Design Your Methodology\n",
    "\n",
    "**Experimental Design**:\n",
    "- **Type**: Comparative experiment\n",
    "- **Groups**: \n",
    "  - Control: Model with demographic features only\n",
    "  - Treatment: Model with demographic + RFM features\n",
    "- **Evaluation**: Cross-validation with 5 folds\n",
    "- **Metrics**: F1-score (primary), Accuracy, Precision, Recall (secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Methodology Documentation\n",
    "# ========================================\n",
    "\n",
    "methodology = \"\"\"\n",
    "METHODOLOGY\n",
    "============\n",
    "\n",
    "1. DATA COLLECTION\n",
    "   - Source: Simulated customer data (for demonstration)\n",
    "   - Sample size: 1000 customers\n",
    "   - Time period: 12 months\n",
    "   \n",
    "2. FEATURE ENGINEERING\n",
    "   Control Features (Demographic):\n",
    "   - Age\n",
    "   - Gender\n",
    "   - Location\n",
    "   - Account tenure\n",
    "   \n",
    "   Treatment Features (RFM):\n",
    "   - Recency: Days since last purchase\n",
    "   - Frequency: Number of purchases\n",
    "   - Monetary: Total spend\n",
    "   \n",
    "3. MODEL TRAINING\n",
    "   - Algorithm: Random Forest Classifier\n",
    "   - Cross-validation: 5-fold\n",
    "   - Train/Test split: 80/20\n",
    "   \n",
    "4. EVALUATION\n",
    "   - Primary metric: F1-score\n",
    "   - Secondary metrics: Accuracy, Precision, Recall\n",
    "   - Statistical test: Paired t-test (p < 0.05)\n",
    "\"\"\"\n",
    "\n",
    "print(methodology)\n",
    "\n",
    "with open(f\"{output_dir}/methodology.txt\", \"w\") as f:\n",
    "    f.write(methodology)\n",
    "\n",
    "print(f\"‚úÖ Methodology saved to: {output_dir}/methodology.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Ethical Considerations\n",
    "\n",
    "Even with simulated data, consider ethical implications:\n",
    "\n",
    "1. **Privacy**: Customer data must be anonymized\n",
    "2. **Bias**: Check for demographic bias in predictions\n",
    "3. **Transparency**: Document all decisions\n",
    "4. **Fairness**: Ensure predictions are fair across groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Ethics Checklist\n",
    "# ========================================\n",
    "\n",
    "ethics_checklist = \"\"\"\n",
    "ETHICS CHECKLIST\n",
    "================\n",
    "\n",
    "‚òë Data Privacy\n",
    "  - All customer IDs anonymized\n",
    "  - No personally identifiable information (PII)\n",
    "  - Secure data storage\n",
    "\n",
    "‚òë Bias and Fairness\n",
    "  - Check model performance across demographic groups\n",
    "  - Test for disparate impact\n",
    "  - Document any biases found\n",
    "\n",
    "‚òë Transparency\n",
    "  - All code and methods documented\n",
    "  - Assumptions clearly stated\n",
    "  - Limitations acknowledged\n",
    "\n",
    "‚òë Responsible Use\n",
    "  - Model used to improve customer experience\n",
    "  - Not used for discriminatory purposes\n",
    "  - Regular audits planned\n",
    "\"\"\"\n",
    "\n",
    "print(ethics_checklist)\n",
    "\n",
    "with open(f\"{output_dir}/ethics_checklist.txt\", \"w\") as f:\n",
    "    f.write(ethics_checklist)\n",
    "\n",
    "print(f\"‚úÖ Ethics checklist saved to: {output_dir}/ethics_checklist.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PHASE 3: EXECUTION\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Generate Sample Data\n",
    "\n",
    "For this demonstration, we'll create synthetic data. In a real project, this is where you'd load your actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Generate Synthetic Customer Data\n",
    "# ========================================\n",
    "\n",
    "np.random.seed(42)  # For reproducibility!\n",
    "\n",
    "n_customers = 1000\n",
    "\n",
    "# Demographic features\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"customer_id\": range(1, n_customers + 1),\n",
    "        \"age\": np.random.randint(18, 70, n_customers),\n",
    "        \"gender\": np.random.choice([\"M\", \"F\"], n_customers),\n",
    "        \"location\": np.random.choice([\"Urban\", \"Suburban\", \"Rural\"], n_customers),\n",
    "        \"tenure_months\": np.random.randint(1, 60, n_customers),\n",
    "    }\n",
    ")\n",
    "\n",
    "# RFM features (correlated with churn)\n",
    "data[\"recency_days\"] = np.random.randint(1, 365, n_customers)\n",
    "data[\"frequency\"] = np.random.randint(0, 50, n_customers)\n",
    "data[\"monetary\"] = np.random.uniform(0, 10000, n_customers)\n",
    "\n",
    "# Generate churn label (influenced by RFM)\n",
    "# Higher recency, lower frequency/monetary = higher churn probability\n",
    "churn_prob = (\n",
    "    (data[\"recency_days\"] / 365) * 0.4\n",
    "    + (1 - data[\"frequency\"] / 50) * 0.3\n",
    "    + (1 - data[\"monetary\"] / 10000) * 0.3\n",
    ")\n",
    "data[\"churned\"] = (np.random.random(n_customers) < churn_prob).astype(int)\n",
    "\n",
    "print(\"üìä DATASET GENERATED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total customers: {len(data)}\")\n",
    "print(f\"Churned: {data['churned'].sum()} ({data['churned'].mean()*100:.1f}%)\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(data.head())\n",
    "\n",
    "# Save dataset\n",
    "data.to_csv(f\"{output_dir}/customer_data.csv\", index=False)\n",
    "print(f\"\\n‚úÖ Dataset saved to: {output_dir}/customer_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Exploratory Data Analysis\n",
    "# ========================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Churn rate\n",
    "churn_counts = data[\"churned\"].value_counts()\n",
    "axes[0, 0].pie(\n",
    "    churn_counts, labels=[\"Active\", \"Churned\"], autopct=\"%1.1f%%\", colors=[\"#2ecc71\", \"#e74c3c\"]\n",
    ")\n",
    "axes[0, 0].set_title(\"Churn Distribution\", fontweight=\"bold\")\n",
    "\n",
    "# Age distribution by churn\n",
    "data.boxplot(column=\"age\", by=\"churned\", ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Age by Churn Status\")\n",
    "axes[0, 1].set_xlabel(\"Churned\")\n",
    "axes[0, 1].set_ylabel(\"Age\")\n",
    "\n",
    "# Recency vs Churn\n",
    "data.boxplot(column=\"recency_days\", by=\"churned\", ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"Recency by Churn Status\")\n",
    "axes[1, 0].set_xlabel(\"Churned\")\n",
    "axes[1, 0].set_ylabel(\"Recency (days)\")\n",
    "\n",
    "# Frequency vs Churn\n",
    "data.boxplot(column=\"frequency\", by=\"churned\", ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Frequency by Churn Status\")\n",
    "axes[1, 1].set_xlabel(\"Churned\")\n",
    "axes[1, 1].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/eda_visualizations.png\", dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"‚úÖ EDA visualizations saved to: {output_dir}/eda_visualizations.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° OBSERVATIONS:\")\n",
    "print(\"  - Churn rate appears to be influenced by recency and frequency\")\n",
    "print(\"  - This suggests RFM features may be valuable predictors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Model Training - Control (Demographic Only)\n",
    "# ========================================\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "\n",
    "# Prepare data\n",
    "# Encode categorical variables\n",
    "le_gender = LabelEncoder()\n",
    "le_location = LabelEncoder()\n",
    "\n",
    "data_encoded = data.copy()\n",
    "data_encoded[\"gender_encoded\"] = le_gender.fit_transform(data[\"gender\"])\n",
    "data_encoded[\"location_encoded\"] = le_location.fit_transform(data[\"location\"])\n",
    "\n",
    "# Control features (demographic only)\n",
    "control_features = [\"age\", \"gender_encoded\", \"location_encoded\", \"tenure_months\"]\n",
    "X_control = data_encoded[control_features]\n",
    "\n",
    "# Treatment features (demographic + RFM)\n",
    "treatment_features = control_features + [\"recency_days\", \"frequency\", \"monetary\"]\n",
    "X_treatment = data_encoded[treatment_features]\n",
    "\n",
    "# Target\n",
    "y = data_encoded[\"churned\"]\n",
    "\n",
    "# Split data\n",
    "X_control_train, X_control_test, y_train, y_test = train_test_split(\n",
    "    X_control, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_treatment_train, X_treatment_test, _, _ = train_test_split(\n",
    "    X_treatment, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train control model\n",
    "print(\"üî¨ TRAINING CONTROL MODEL (Demographic features only)\")\n",
    "print(\"=\" * 60)\n",
    "model_control = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_control.fit(X_control_train, y_train)\n",
    "\n",
    "# Evaluate control model\n",
    "y_pred_control = model_control.predict(X_control_test)\n",
    "f1_control = f1_score(y_test, y_pred_control)\n",
    "\n",
    "print(f\"F1-Score (Control): {f1_control:.4f}\")\n",
    "print(\"\\nClassification Report (Control):\")\n",
    "print(classification_report(y_test, y_pred_control))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Model Training - Treatment (Demographic + RFM)\n",
    "# ========================================\n",
    "\n",
    "print(\"üî¨ TRAINING TREATMENT MODEL (Demographic + RFM features)\")\n",
    "print(\"=\" * 60)\n",
    "model_treatment = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_treatment.fit(X_treatment_train, y_train)\n",
    "\n",
    "# Evaluate treatment model\n",
    "y_pred_treatment = model_treatment.predict(X_treatment_test)\n",
    "f1_treatment = f1_score(y_test, y_pred_treatment)\n",
    "\n",
    "print(f\"F1-Score (Treatment): {f1_treatment:.4f}\")\n",
    "print(\"\\nClassification Report (Treatment):\")\n",
    "print(classification_report(y_test, y_pred_treatment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Compare Results\n",
    "# ========================================\n",
    "\n",
    "improvement = ((f1_treatment - f1_control) / f1_control) * 100\n",
    "\n",
    "print(\"\\nüìä RESULTS COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Control Model F1-Score:    {f1_control:.4f}\")\n",
    "print(f\"Treatment Model F1-Score:  {f1_treatment:.4f}\")\n",
    "print(f\"\\nImprovement: {improvement:+.2f}%\")\n",
    "\n",
    "if improvement >= 10:\n",
    "    print(\"\\n‚úÖ HYPOTHESIS SUPPORTED!\")\n",
    "    print(\"   RFM features improved accuracy by >= 10%\")\n",
    "else:\n",
    "    print(\"\\n‚ùå HYPOTHESIS NOT SUPPORTED\")\n",
    "    print(f\"   Improvement ({improvement:.2f}%) is less than 10%\")\n",
    "\n",
    "# Save results\n",
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\"Control (Demographic)\", \"Treatment (Demographic + RFM)\"],\n",
    "        \"F1-Score\": [f1_control, f1_treatment],\n",
    "        \"Improvement\": [0, improvement],\n",
    "    }\n",
    ")\n",
    "\n",
    "results.to_csv(f\"{output_dir}/model_results.csv\", index=False)\n",
    "print(f\"\\n‚úÖ Results saved to: {output_dir}/model_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Visualize Results\n",
    "# ========================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# F1-Score Comparison\n",
    "models = [\"Control\\n(Demographic)\", \"Treatment\\n(Demographic + RFM)\"]\n",
    "f1_scores = [f1_control, f1_treatment]\n",
    "\n",
    "bars = axes[0].bar(models, f1_scores, color=[\"#3498db\", \"#2ecc71\"], alpha=0.7)\n",
    "axes[0].set_ylabel(\"F1-Score\", fontweight=\"bold\")\n",
    "axes[0].set_title(\"Model Performance Comparison\", fontweight=\"bold\", fontsize=12)\n",
    "axes[0].set_ylim([0, 1])\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        f\"{height:.4f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "# Feature Importance (Treatment Model)\n",
    "feature_importance = pd.DataFrame(\n",
    "    {\"feature\": treatment_features, \"importance\": model_treatment.feature_importances_}\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "\n",
    "axes[1].barh(\n",
    "    feature_importance[\"feature\"], feature_importance[\"importance\"], color=\"steelblue\", alpha=0.7\n",
    ")\n",
    "axes[1].set_xlabel(\"Importance\", fontweight=\"bold\")\n",
    "axes[1].set_title(\"Feature Importance (Treatment Model)\", fontweight=\"bold\", fontsize=12)\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/results_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"‚úÖ Results visualization saved to: {output_dir}/results_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° KEY FINDINGS:\")\n",
    "print(f\"  - Top 3 most important features:\")\n",
    "for i, row in feature_importance.head(3).iterrows():\n",
    "    print(f\"    {i+1}. {row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PHASE 4: COMMUNICATION\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Write Research Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Generate Research Summary\n",
    "# ========================================\n",
    "\n",
    "summary = f\"\"\"\n",
    "RESEARCH SUMMARY\n",
    "================\n",
    "\n",
    "Title: {PROJECT_INFO['title']}\n",
    "Author: {PROJECT_INFO['researcher']}\n",
    "Date: {PROJECT_INFO['date_started']}\n",
    "\n",
    "ABSTRACT\n",
    "--------\n",
    "This study investigated whether adding engineered behavioral features (RFM metrics)\n",
    "improves customer churn prediction accuracy compared to using only demographic\n",
    "features. Using a simulated dataset of 1,000 customers, we trained Random Forest\n",
    "classifiers with two feature sets: (1) demographic features only, and (2)\n",
    "demographic features plus RFM metrics. Results showed that the RFM-enhanced model\n",
    "improved F1-score by {improvement:.2f}%, {'supporting' if improvement >= 10 else 'not supporting'} our hypothesis of >= 10% improvement.\n",
    "\n",
    "RESEARCH QUESTION\n",
    "-----------------\n",
    "{research_design['research_question']}\n",
    "\n",
    "HYPOTHESIS\n",
    "----------\n",
    "{research_design['hypothesis']}\n",
    "\n",
    "METHODOLOGY\n",
    "-----------\n",
    "- Sample Size: {len(data)} customers\n",
    "- Algorithm: Random Forest Classifier\n",
    "- Evaluation: 80/20 train-test split\n",
    "- Primary Metric: F1-score\n",
    "\n",
    "RESULTS\n",
    "-------\n",
    "- Control Model F1-Score: {f1_control:.4f}\n",
    "- Treatment Model F1-Score: {f1_treatment:.4f}\n",
    "- Improvement: {improvement:+.2f}%\n",
    "\n",
    "CONCLUSIONS\n",
    "-----------\n",
    "{'‚úÖ The hypothesis was SUPPORTED. ' if improvement >= 10 else '‚ùå The hypothesis was NOT SUPPORTED. '}\n",
    "RFM features demonstrated {'substantial' if improvement >= 10 else 'some'} value in predicting customer churn.\n",
    "The most important features were behavioral (recency, frequency, monetary value),\n",
    "suggesting that recent customer activity is more predictive than demographics alone.\n",
    "\n",
    "LIMITATIONS\n",
    "-----------\n",
    "1. Simulated data may not reflect real-world complexity\n",
    "2. Limited to one machine learning algorithm (Random Forest)\n",
    "3. Small sample size (1,000 customers)\n",
    "4. Single domain (e-commerce)\n",
    "\n",
    "FUTURE WORK\n",
    "-----------\n",
    "1. Test with real customer data\n",
    "2. Compare multiple algorithms (XGBoost, Neural Networks)\n",
    "3. Investigate additional behavioral features\n",
    "4. Explore temporal patterns in churn\n",
    "5. Conduct fairness analysis across demographic groups\n",
    "\n",
    "REPRODUCIBILITY\n",
    "---------------\n",
    "All code, data, and analysis are available in: {output_dir}\n",
    "Random seed: 42 (for reproducibility)\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save summary\n",
    "with open(f\"{output_dir}/research_summary.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(f\"\\n‚úÖ Research summary saved to: {output_dir}/research_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Create Final Report Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Generate README for Research Package\n",
    "# ========================================\n",
    "\n",
    "readme_content = f\"\"\"\n",
    "# {PROJECT_INFO['title']}\n",
    "\n",
    "## Research Project Package\n",
    "\n",
    "**Author**: {PROJECT_INFO['researcher']}  \n",
    "**Date**: {PROJECT_INFO['date_started']}  \n",
    "**Domain**: {PROJECT_INFO['domain']}  \n",
    "\n",
    "## Abstract\n",
    "\n",
    "This research investigates whether adding engineered behavioral features (RFM metrics) \n",
    "improves customer churn prediction accuracy. Results showed a {improvement:.2f}% improvement \n",
    "in F1-score when RFM features were added to demographic features.\n",
    "\n",
    "## Files in This Package\n",
    "\n",
    "- `research_summary.txt` - Complete research summary\n",
    "- `methodology.txt` - Detailed methodology\n",
    "- `research_design.txt` - Research question and hypothesis\n",
    "- `customer_data.csv` - Dataset used (synthetic)\n",
    "- `model_results.csv` - Comparison of model performance\n",
    "- `literature_review.csv` - Papers reviewed\n",
    "- `eda_visualizations.png` - Exploratory data analysis\n",
    "- `results_comparison.png` - Results visualization\n",
    "- `ethics_checklist.txt` - Ethical considerations\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "1. RFM features improved F1-score by {improvement:.2f}%\n",
    "2. Behavioral features are more predictive than demographics\n",
    "3. Recency, frequency, and monetary value are the top predictors\n",
    "\n",
    "## Reproducibility\n",
    "\n",
    "This research is fully reproducible:\n",
    "- Random seed: 42\n",
    "- All code in Jupyter notebook\n",
    "- Dataset included\n",
    "- Dependencies listed in requirements.txt\n",
    "\n",
    "## Citation\n",
    "\n",
    "If you use this work, please cite:\n",
    "```\n",
    "{PROJECT_INFO['researcher']} ({PROJECT_INFO['date_started']}). \n",
    "{PROJECT_INFO['title']}. \n",
    "Research project from Data Science Research Skills course.\n",
    "```\n",
    "\n",
    "## Contact\n",
    "\n",
    "For questions or collaboration: [Your email here]\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{output_dir}/README.md\", \"w\") as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\"üì¶ FINAL RESEARCH PACKAGE CREATED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nAll files saved to: {output_dir}\")\n",
    "print(\"\\n‚úÖ Your research project is complete and ready to share!\")\n",
    "print(\"\\nüìÅ Package contents:\")\n",
    "\n",
    "import os\n",
    "\n",
    "for file in sorted(os.listdir(output_dir)):\n",
    "    print(f\"   - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Congratulations! üéâ\n",
    "\n",
    "You've completed a full research project from start to finish!\n",
    "\n",
    "### What You Accomplished\n",
    "\n",
    "‚úÖ Formulated a clear research question  \n",
    "‚úÖ Reviewed existing literature  \n",
    "‚úÖ Developed and tested a hypothesis  \n",
    "‚úÖ Designed an experiment  \n",
    "‚úÖ Collected and analyzed data  \n",
    "‚úÖ Considered ethical implications  \n",
    "‚úÖ Made your work reproducible  \n",
    "‚úÖ Documented everything thoroughly  \n",
    "‚úÖ Communicated your findings  \n",
    "\n",
    "### Your Research Portfolio\n",
    "\n",
    "You now have a complete research project that demonstrates:\n",
    "- Research skills\n",
    "- Data science capabilities\n",
    "- Critical thinking\n",
    "- Ethical awareness\n",
    "- Communication abilities\n",
    "\n",
    "**This is a portfolio piece you can show to employers or use in applications!**\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "1. **Do Your Own Project**\n",
    "   - Choose a topic you're passionate about\n",
    "   - Use this notebook as a template\n",
    "   - Apply these skills to real data\n",
    "\n",
    "2. **Share Your Work**\n",
    "   - Upload to GitHub\n",
    "   - Write a blog post\n",
    "   - Present to peers\n",
    "\n",
    "3. **Keep Learning**\n",
    "   - Explore advanced statistical methods\n",
    "   - Learn about causal inference\n",
    "   - Study research design in depth\n",
    "\n",
    "4. **Contribute to Open Science**\n",
    "   - Replicate published studies\n",
    "   - Share your datasets and code\n",
    "   - Collaborate on research projects\n",
    "\n",
    "### Course Completion\n",
    "\n",
    "You've completed all 10 modules of **Data Science Research Skills**!\n",
    "\n",
    "- Module 00: Setup & Introduction ‚úÖ\n",
    "- Module 01: Literature Review Basics ‚úÖ\n",
    "- Module 02: Finding and Reading Papers ‚úÖ\n",
    "- Module 03: Research Methodology ‚úÖ\n",
    "- Module 04: Experimental Design ‚úÖ\n",
    "- Module 05: Data Collection Methods ‚úÖ\n",
    "- Module 06: Research Ethics ‚úÖ\n",
    "- Module 07: Reproducible Research ‚úÖ\n",
    "- Module 08: Documentation & Version Control ‚úÖ\n",
    "- Module 09: Putting It All Together ‚úÖ\n",
    "\n",
    "### Thank You!\n",
    "\n",
    "Thank you for taking this journey to learn research skills. You now have the foundation\n",
    "to conduct rigorous, ethical, and reproducible research in data science.\n",
    "\n",
    "**Keep researching, keep learning, and keep making discoveries!**\n",
    "\n",
    "---\n",
    "\n",
    "*Questions? Review any module or check the main project README.*  \n",
    "*Feedback? We'd love to hear about your experience!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
