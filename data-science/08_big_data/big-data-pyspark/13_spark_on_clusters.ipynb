{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 13: Spark on Clusters\n",
    "\n",
    "**Difficulty**: ⭐⭐⭐  \n",
    "**Estimated Time**: 70 minutes  \n",
    "**Prerequisites**: \n",
    "- [Module 01: PySpark Setup and Spark Session](01_pyspark_setup_and_spark_session.ipynb)\n",
    "- [Module 12: Performance Optimization](12_performance_optimization.ipynb)\n",
    "- Understanding of distributed computing concepts\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Understand Spark cluster architecture (Driver, Executors, Cluster Manager)\n",
    "2. Compare deployment modes (Local, Standalone, YARN, Kubernetes, Mesos)\n",
    "3. Configure resource allocation (cores, memory, executors) for optimal performance\n",
    "4. Submit Spark applications using spark-submit with appropriate configurations\n",
    "5. Monitor and troubleshoot Spark jobs using the web UI and logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spark Cluster Architecture\n",
    "\n",
    "**Components:**\n",
    "\n",
    "1. **Driver Program**:\n",
    "   - Runs the main() function\n",
    "   - Creates SparkContext\n",
    "   - Converts user code to tasks\n",
    "   - Schedules tasks on executors\n",
    "   - Collects results\n",
    "\n",
    "2. **Cluster Manager**:\n",
    "   - Allocates resources across applications\n",
    "   - Types: Standalone, YARN, Kubernetes, Mesos\n",
    "   - Starts and stops executors\n",
    "\n",
    "3. **Executors**:\n",
    "   - Run on worker nodes\n",
    "   - Execute tasks assigned by driver\n",
    "   - Store data in memory/disk\n",
    "   - Return results to driver\n",
    "\n",
    "4. **Tasks**:\n",
    "   - Unit of work sent to executors\n",
    "   - One task per partition\n",
    "   - Multiple tasks run in parallel\n",
    "\n",
    "**Execution Flow:**\n",
    "\n",
    "```\n",
    "User Code → Driver → Cluster Manager → Executors → Tasks\n",
    "                ↓                                      ↓\n",
    "            Schedule                              Results\n",
    "                ↓                                      ↓\n",
    "           Collect Results ←←←←←←←←←←←←←←←←←←←←←←←←←←←←\n",
    "```\n",
    "\n",
    "**Memory Structure:**\n",
    "\n",
    "Each executor has:\n",
    "- **Execution Memory**: For shuffles, joins, sorts, aggregations\n",
    "- **Storage Memory**: For cached data\n",
    "- **User Memory**: For user data structures\n",
    "- **Reserved Memory**: For Spark internal use\n",
    "\n",
    "Default split: 60% execution/storage, 40% user+reserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deployment Modes\n",
    "\n",
    "### Local Mode\n",
    "\n",
    "**Characteristics:**\n",
    "- Runs on single machine\n",
    "- Simulates cluster with threads\n",
    "- Great for development and testing\n",
    "- Limited by single machine resources\n",
    "\n",
    "**Syntax:**\n",
    "- `local`: 1 thread\n",
    "- `local[4]`: 4 threads\n",
    "- `local[*]`: All available cores\n",
    "\n",
    "**When to use:**\n",
    "- Development and debugging\n",
    "- Small datasets that fit on one machine\n",
    "- Testing code before cluster deployment\n",
    "\n",
    "### Standalone Mode\n",
    "\n",
    "**Characteristics:**\n",
    "- Spark's built-in cluster manager\n",
    "- Simple to set up\n",
    "- Good for dedicated Spark clusters\n",
    "- No resource sharing with other frameworks\n",
    "\n",
    "**Components:**\n",
    "- Master process: Manages cluster\n",
    "- Worker processes: Run executors\n",
    "- Drivers: Submit applications\n",
    "\n",
    "**Start commands:**\n",
    "```bash\n",
    "# Start master\n",
    "./sbin/start-master.sh\n",
    "\n",
    "# Start worker\n",
    "./sbin/start-worker.sh spark://master-host:7077\n",
    "```\n",
    "\n",
    "### YARN Mode\n",
    "\n",
    "**Characteristics:**\n",
    "- Hadoop's resource manager\n",
    "- Share cluster with MapReduce, Hive, etc.\n",
    "- Enterprise-grade resource management\n",
    "- Most common in production\n",
    "\n",
    "**Modes:**\n",
    "- **Client mode**: Driver runs on client machine\n",
    "- **Cluster mode**: Driver runs on YARN cluster\n",
    "\n",
    "**When to use:**\n",
    "- Hadoop ecosystem integration\n",
    "- Multi-tenant clusters\n",
    "- Enterprise deployments\n",
    "\n",
    "### Kubernetes Mode\n",
    "\n",
    "**Characteristics:**\n",
    "- Container orchestration\n",
    "- Cloud-native deployments\n",
    "- Dynamic scaling\n",
    "- Integration with modern DevOps tools\n",
    "\n",
    "**Benefits:**\n",
    "- Resource isolation\n",
    "- Auto-scaling\n",
    "- Easy updates and rollbacks\n",
    "- Cloud provider support\n",
    "\n",
    "**When to use:**\n",
    "- Cloud deployments (AWS EKS, GCP GKE, Azure AKS)\n",
    "- Microservices architecture\n",
    "- Modern CI/CD pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, we'll demonstrate concepts in local mode\n",
    "# But the principles apply to all cluster modes\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, avg, sum as spark_sum\n",
    "import time\n",
    "\n",
    "# Create SparkSession in local mode\n",
    "# local[*] means use all available cores\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark on Clusters\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Master: {spark.sparkContext.master}\")\n",
    "print(f\"App Name: {spark.sparkContext.appName}\")\n",
    "print(f\"Default Parallelism: {spark.sparkContext.defaultParallelism}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resource Allocation\n",
    "\n",
    "**Key Resources:**\n",
    "\n",
    "1. **Number of Executors**\n",
    "2. **Cores per Executor**\n",
    "3. **Memory per Executor**\n",
    "4. **Driver Memory**\n",
    "\n",
    "**Configuration Parameters:**\n",
    "\n",
    "```bash\n",
    "--num-executors <N>           # Number of executors (YARN only)\n",
    "--executor-cores <N>          # Cores per executor\n",
    "--executor-memory <MEM>       # Memory per executor (e.g., 4g)\n",
    "--driver-cores <N>            # Cores for driver\n",
    "--driver-memory <MEM>         # Memory for driver\n",
    "--total-executor-cores <N>    # Total cores across all executors (Standalone)\n",
    "```\n",
    "\n",
    "**Resource Calculation Example:**\n",
    "\n",
    "Cluster: 10 nodes, 16 cores/node, 64GB RAM/node\n",
    "\n",
    "**Conservative Approach:**\n",
    "- Leave 1 core and 1GB for OS/services per node\n",
    "- Available: 15 cores, 63GB per node\n",
    "\n",
    "**Option 1: More Executors (better parallelism)**\n",
    "- Executors per node: 3\n",
    "- Cores per executor: 5\n",
    "- Memory per executor: 19GB (63/3, leave some overhead)\n",
    "- Total executors: 30 (3 * 10)\n",
    "- Total cores: 150 (30 * 5)\n",
    "\n",
    "**Option 2: Fewer, Larger Executors**\n",
    "- Executors per node: 1\n",
    "- Cores per executor: 15\n",
    "- Memory per executor: 60GB\n",
    "- Total executors: 10\n",
    "- Total cores: 150\n",
    "\n",
    "**Recommendation:**\n",
    "- **Cores per executor**: 4-6 (sweet spot for HDFS throughput)\n",
    "- **Memory per executor**: 8-16GB (not too large to avoid GC issues)\n",
    "- **Executors**: More smaller executors > fewer large ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View current resource configuration\n",
    "print(\"=== Current Resource Configuration ===\")\n",
    "\n",
    "configs = [\n",
    "    (\"spark.driver.memory\", \"Driver Memory\"),\n",
    "    (\"spark.executor.memory\", \"Executor Memory\"),\n",
    "    (\"spark.executor.cores\", \"Executor Cores\"),\n",
    "    (\"spark.driver.cores\", \"Driver Cores\"),\n",
    "    (\"spark.executor.instances\", \"Number of Executors\"),\n",
    "    (\"spark.dynamicAllocation.enabled\", \"Dynamic Allocation\"),\n",
    "    (\"spark.default.parallelism\", \"Default Parallelism\"),\n",
    "    (\"spark.sql.shuffle.partitions\", \"Shuffle Partitions\")\n",
    "]\n",
    "\n",
    "for config_key, config_name in configs:\n",
    "    try:\n",
    "        value = spark.conf.get(config_key)\n",
    "        print(f\"{config_name:<25}: {value}\")\n",
    "    except:\n",
    "        print(f\"{config_name:<25}: (not set / default)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submitting Applications with spark-submit\n",
    "\n",
    "**spark-submit** is the standard way to submit Spark applications to a cluster.\n",
    "\n",
    "**Basic Syntax:**\n",
    "\n",
    "```bash\n",
    "spark-submit \\\n",
    "  --master <master-url> \\\n",
    "  --deploy-mode <client|cluster> \\\n",
    "  --class <main-class> \\\n",
    "  --name <app-name> \\\n",
    "  --conf <key=value> \\\n",
    "  --executor-memory <MEM> \\\n",
    "  --num-executors <N> \\\n",
    "  --executor-cores <N> \\\n",
    "  application.jar [app-args]\n",
    "```\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "### Local Mode:\n",
    "```bash\n",
    "spark-submit \\\n",
    "  --master local[4] \\\n",
    "  my_script.py\n",
    "```\n",
    "\n",
    "### Standalone Cluster:\n",
    "```bash\n",
    "spark-submit \\\n",
    "  --master spark://master-host:7077 \\\n",
    "  --deploy-mode cluster \\\n",
    "  --executor-memory 4G \\\n",
    "  --total-executor-cores 8 \\\n",
    "  my_script.py\n",
    "```\n",
    "\n",
    "### YARN Cluster:\n",
    "```bash\n",
    "spark-submit \\\n",
    "  --master yarn \\\n",
    "  --deploy-mode cluster \\\n",
    "  --num-executors 10 \\\n",
    "  --executor-cores 5 \\\n",
    "  --executor-memory 8G \\\n",
    "  --driver-memory 4G \\\n",
    "  --conf spark.sql.shuffle.partitions=200 \\\n",
    "  --conf spark.default.parallelism=100 \\\n",
    "  --files config.conf \\\n",
    "  --py-files dependencies.zip \\\n",
    "  my_script.py arg1 arg2\n",
    "```\n",
    "\n",
    "### Kubernetes:\n",
    "```bash\n",
    "spark-submit \\\n",
    "  --master k8s://https://kubernetes-api:443 \\\n",
    "  --deploy-mode cluster \\\n",
    "  --name spark-pi \\\n",
    "  --conf spark.executor.instances=5 \\\n",
    "  --conf spark.kubernetes.container.image=spark:latest \\\n",
    "  local:///opt/spark/examples/jars/spark-examples.jar\n",
    "```\n",
    "\n",
    "**Common Options:**\n",
    "\n",
    "- `--master`: Cluster manager URL\n",
    "- `--deploy-mode`: Where to run the driver (client/cluster)\n",
    "- `--name`: Application name (appears in UI)\n",
    "- `--conf`: Spark configuration property\n",
    "- `--files`: Files to distribute to executors\n",
    "- `--py-files`: Python dependencies (.zip, .egg, .py)\n",
    "- `--packages`: Maven coordinates for dependencies\n",
    "- `--jars`: Additional JARs to include\n",
    "- `--driver-java-options`: JVM options for driver\n",
    "- `--executor-java-options`: JVM options for executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a simple PySpark script\n",
    "# In production, you'd submit this with spark-submit\n",
    "\n",
    "script_content = '''\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, avg\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # Create Spark session\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Example ETL Job\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # Read data (would be from HDFS/S3 in production)\n",
    "    df = spark.range(0, 1000000).toDF(\"id\") \\\n",
    "        .withColumn(\"value\", col(\"id\") * 2)\n",
    "    \n",
    "    # Process\n",
    "    result = df.filter(col(\"value\") > 1000) \\\n",
    "        .groupBy((col(\"value\") % 100).alias(\"bucket\")) \\\n",
    "        .agg(count(\"*\").alias(\"count\"), avg(\"value\").alias(\"avg_value\"))\n",
    "    \n",
    "    # Show results\n",
    "    result.show(10)\n",
    "    \n",
    "    # Write output (would be to HDFS/S3 in production)\n",
    "    result.write.mode(\"overwrite\").parquet(\"/tmp/output\")\n",
    "    \n",
    "    spark.stop()\n",
    "    print(\"Job completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Save script\n",
    "with open(\"/tmp/example_job.py\", \"w\") as f:\n",
    "    f.write(script_content)\n",
    "\n",
    "print(\"Example script saved to /tmp/example_job.py\")\n",
    "print(\"\\nTo submit this job, you would use:\")\n",
    "print(\"\"\"\\n\nspark-submit \\\\\n",
    "  --master yarn \\\\\n",
    "  --deploy-mode cluster \\\\\n",
    "  --num-executors 5 \\\\\n",
    "  --executor-cores 4 \\\\\n",
    "  --executor-memory 8G \\\\\n",
    "  --driver-memory 4G \\\\\n",
    "  /tmp/example_job.py\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Monitoring and Troubleshooting\n",
    "\n",
    "**Spark Web UI:**\n",
    "\n",
    "Default URLs:\n",
    "- Standalone Master: http://master:8080\n",
    "- Application UI: http://driver:4040\n",
    "- History Server: http://server:18080\n",
    "\n",
    "**Important Tabs:**\n",
    "\n",
    "1. **Jobs**: Overview of all jobs\n",
    "   - Total time, stages, tasks\n",
    "   - Failed/succeeded tasks\n",
    "\n",
    "2. **Stages**: Detailed stage information\n",
    "   - Task execution time\n",
    "   - Shuffle read/write\n",
    "   - GC time\n",
    "   - Skewed tasks (identify stragglers)\n",
    "\n",
    "3. **Storage**: Cached RDDs/DataFrames\n",
    "   - Memory used\n",
    "   - Partitions cached\n",
    "\n",
    "4. **Environment**: Configuration settings\n",
    "   - Verify resource allocation\n",
    "   - Check property values\n",
    "\n",
    "5. **Executors**: Executor metrics\n",
    "   - Memory usage\n",
    "   - Task distribution\n",
    "   - Failed tasks\n",
    "   - GC time\n",
    "\n",
    "6. **SQL**: DataFrame/SQL queries\n",
    "   - Execution plans\n",
    "   - Query duration\n",
    "   - Physical plans with metrics\n",
    "\n",
    "**Key Metrics to Monitor:**\n",
    "\n",
    "- **Task Time**: Should be relatively even across tasks\n",
    "- **Shuffle Read/Write**: Large shuffles indicate optimization opportunities\n",
    "- **GC Time**: >10% of task time indicates memory pressure\n",
    "- **Spill (Memory/Disk)**: Indicates need for more memory\n",
    "- **Task Skew**: Some tasks taking much longer than others\n",
    "\n",
    "**Common Issues and Solutions:**\n",
    "\n",
    "1. **Out of Memory**:\n",
    "   - Increase executor memory\n",
    "   - Reduce partition size\n",
    "   - Avoid collect() on large DataFrames\n",
    "   - Unpersist unused cached data\n",
    "\n",
    "2. **Slow Shuffles**:\n",
    "   - Use broadcast joins\n",
    "   - Increase parallelism\n",
    "   - Filter data early\n",
    "   - Pre-partition data\n",
    "\n",
    "3. **Task Skew**:\n",
    "   - Repartition with salt keys\n",
    "   - Use adaptive query execution\n",
    "   - Filter outliers\n",
    "\n",
    "4. **High GC Time**:\n",
    "   - Increase executor memory\n",
    "   - Tune GC settings\n",
    "   - Reduce object creation\n",
    "   - Use serialized storage\n",
    "\n",
    "5. **Stragglers** (few slow tasks):\n",
    "   - Enable speculative execution\n",
    "   - Check for data skew\n",
    "   - Look for failing nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate monitoring in local mode\n",
    "# The Web UI is available at http://localhost:4040 while the session is active\n",
    "\n",
    "print(\"=== Spark Web UI ===\")\n",
    "print(f\"\\nApplication UI: http://localhost:4040\")\n",
    "print(\"\\nNote: Open this URL in your browser while the Spark session is running\")\n",
    "print(\"\\nYou can explore:\")\n",
    "print(\"  - Jobs: See all executed jobs\")\n",
    "print(\"  - Stages: Detailed stage metrics\")\n",
    "print(\"  - Storage: Cached DataFrames\")\n",
    "print(\"  - Environment: Configuration\")\n",
    "print(\"  - Executors: Resource usage\")\n",
    "print(\"  - SQL: DataFrame queries and plans\")\n",
    "\n",
    "# Create some activity to monitor\n",
    "print(\"\\nCreating sample workload to monitor...\")\n",
    "\n",
    "df = spark.range(0, 5000000).toDF(\"id\") \\\n",
    "    .withColumn(\"value\", col(\"id\") % 1000)\n",
    "\n",
    "# Cache to see in Storage tab\n",
    "df.cache()\n",
    "\n",
    "# Run some operations to see in Jobs/Stages\n",
    "result1 = df.groupBy(\"value\").count().count()\n",
    "result2 = df.filter(col(\"value\") > 500).count()\n",
    "\n",
    "print(f\"\\nWorkload completed:\")\n",
    "print(f\"  - Grouped aggregation: {result1} groups\")\n",
    "print(f\"  - Filtered count: {result2:,} rows\")\n",
    "print(\"\\nCheck the Web UI to see execution details!\")\n",
    "\n",
    "# Show what's in cache\n",
    "print(\"\\n=== Cached DataFrames ===\")\n",
    "print(f\"Cached DataFrame has {df.rdd.getNumPartitions()} partitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get application metrics programmatically\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print(\"=== Application Metrics ===\")\n",
    "print(f\"\\nApplication ID: {sc.applicationId}\")\n",
    "print(f\"Application Name: {sc.appName}\")\n",
    "print(f\"Master: {sc.master}\")\n",
    "print(f\"Default Parallelism: {sc.defaultParallelism}\")\n",
    "print(f\"\\nSpark Version: {sc.version}\")\n",
    "\n",
    "# Get status tracker for detailed metrics\n",
    "status = sc.statusTracker()\n",
    "print(f\"\\nActive Jobs: {len(status.getActiveJobIds())}\")\n",
    "print(f\"Active Stages: {len(status.getActiveStageIds())}\")\n",
    "\n",
    "# Cleanup\n",
    "df.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Production Best Practices\n",
    "\n",
    "### Configuration Best Practices\n",
    "\n",
    "**1. Resource Allocation:**\n",
    "```python\n",
    "# Use configuration files instead of hardcoding\n",
    "spark-submit \\\n",
    "  --properties-file cluster-config.conf \\\n",
    "  my_app.py\n",
    "```\n",
    "\n",
    "**2. Dynamic Allocation:**\n",
    "```\n",
    "spark.dynamicAllocation.enabled=true\n",
    "spark.dynamicAllocation.minExecutors=2\n",
    "spark.dynamicAllocation.maxExecutors=20\n",
    "spark.dynamicAllocation.initialExecutors=5\n",
    "```\n",
    "\n",
    "**3. Compression:**\n",
    "```\n",
    "spark.sql.parquet.compression.codec=snappy\n",
    "spark.broadcast.compress=true\n",
    "spark.shuffle.compress=true\n",
    "```\n",
    "\n",
    "**4. Serialization:**\n",
    "```\n",
    "spark.serializer=org.apache.spark.serializer.KryoSerializer\n",
    "spark.kryoserializer.buffer.max=512m\n",
    "```\n",
    "\n",
    "**5. Adaptive Query Execution:**\n",
    "```\n",
    "spark.sql.adaptive.enabled=true\n",
    "spark.sql.adaptive.coalescePartitions.enabled=true\n",
    "spark.sql.adaptive.skewJoin.enabled=true\n",
    "```\n",
    "\n",
    "### Deployment Checklist\n",
    "\n",
    "- [ ] Test with representative data volume\n",
    "- [ ] Configure appropriate resources\n",
    "- [ ] Enable logging and monitoring\n",
    "- [ ] Set up alerting for failures\n",
    "- [ ] Configure checkpointing for streaming\n",
    "- [ ] Use external metastore (Hive)\n",
    "- [ ] Implement retry logic\n",
    "- [ ] Document dependencies\n",
    "- [ ] Version control configuration\n",
    "- [ ] Set up CI/CD pipeline\n",
    "\n",
    "### Security Considerations\n",
    "\n",
    "1. **Authentication**: Kerberos for YARN, RBAC for K8s\n",
    "2. **Encryption**: Enable at-rest and in-transit\n",
    "3. **Access Control**: Limit who can submit jobs\n",
    "4. **Network Isolation**: Use VPCs/subnets\n",
    "5. **Secrets Management**: Use vault services\n",
    "\n",
    "### Logging and Monitoring\n",
    "\n",
    "**Structured Logging:**\n",
    "```python\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)s %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Job started\")\n",
    "logger.info(f\"Processing {row_count} rows\")\n",
    "logger.error(f\"Failed to process: {error}\")\n",
    "```\n",
    "\n",
    "**Metrics Collection:**\n",
    "- Use Spark metrics system\n",
    "- Export to Prometheus/Grafana\n",
    "- Track custom metrics\n",
    "- Set up dashboards\n",
    "\n",
    "**Log Aggregation:**\n",
    "- Use ELK stack (Elasticsearch, Logstash, Kibana)\n",
    "- Or Splunk for enterprise\n",
    "- Centralize logs from all executors\n",
    "- Enable log rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Production-ready configuration\n",
    "\n",
    "production_config = \"\"\"\n",
    "# cluster-config.conf - Production Spark Configuration\n",
    "\n",
    "# Application\n",
    "spark.app.name=ProductionETLJob\n",
    "\n",
    "# Resources\n",
    "spark.executor.instances=10\n",
    "spark.executor.cores=5\n",
    "spark.executor.memory=8g\n",
    "spark.driver.memory=4g\n",
    "spark.driver.cores=2\n",
    "\n",
    "# Performance\n",
    "spark.sql.shuffle.partitions=200\n",
    "spark.default.parallelism=100\n",
    "spark.sql.autoBroadcastJoinThreshold=50m\n",
    "\n",
    "# Adaptive Query Execution\n",
    "spark.sql.adaptive.enabled=true\n",
    "spark.sql.adaptive.coalescePartitions.enabled=true\n",
    "spark.sql.adaptive.skewJoin.enabled=true\n",
    "\n",
    "# Dynamic Allocation\n",
    "spark.dynamicAllocation.enabled=true\n",
    "spark.dynamicAllocation.minExecutors=2\n",
    "spark.dynamicAllocation.maxExecutors=20\n",
    "spark.dynamicAllocation.initialExecutors=5\n",
    "spark.dynamicAllocation.executorIdleTimeout=60s\n",
    "\n",
    "# Serialization\n",
    "spark.serializer=org.apache.spark.serializer.KryoSerializer\n",
    "spark.kryoserializer.buffer.max=512m\n",
    "\n",
    "# Compression\n",
    "spark.sql.parquet.compression.codec=snappy\n",
    "spark.broadcast.compress=true\n",
    "spark.shuffle.compress=true\n",
    "spark.io.compression.codec=snappy\n",
    "\n",
    "# Memory Management\n",
    "spark.memory.fraction=0.6\n",
    "spark.memory.storageFraction=0.5\n",
    "\n",
    "# Speculation (for stragglers)\n",
    "spark.speculation=true\n",
    "spark.speculation.interval=100ms\n",
    "spark.speculation.multiplier=1.5\n",
    "\n",
    "# Logging\n",
    "spark.eventLog.enabled=true\n",
    "spark.eventLog.dir=hdfs:///spark-logs\n",
    "spark.history.fs.logDirectory=hdfs:///spark-logs\n",
    "\n",
    "# Checkpointing (for streaming)\n",
    "spark.sql.streaming.checkpointLocation=/checkpoints\n",
    "\n",
    "# Network\n",
    "spark.network.timeout=300s\n",
    "spark.executor.heartbeatInterval=10s\n",
    "\"\"\"\n",
    "\n",
    "print(\"Production Configuration File:\")\n",
    "print(production_config)\n",
    "\n",
    "# Save configuration\n",
    "with open(\"/tmp/cluster-config.conf\", \"w\") as f:\n",
    "    f.write(production_config)\n",
    "\n",
    "print(\"\\nConfiguration saved to /tmp/cluster-config.conf\")\n",
    "print(\"\\nUse with: spark-submit --properties-file /tmp/cluster-config.conf app.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exercises\n",
    "\n",
    "These exercises focus on understanding concepts rather than hands-on cluster setup (which requires actual cluster infrastructure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Resource Calculation\n",
    "\n",
    "Calculate optimal resource allocation for a Spark cluster.\n",
    "\n",
    "**Scenario:**\n",
    "- Cluster: 20 nodes\n",
    "- Per node: 32 cores, 128GB RAM\n",
    "- Reserve: 1 core and 2GB per node for OS\n",
    "\n",
    "**Tasks:**\n",
    "1. Calculate total available resources\n",
    "2. Determine optimal executor configuration (3 different options)\n",
    "3. For each option, calculate: num executors, cores/executor, memory/executor\n",
    "4. Justify which option you'd choose and why\n",
    "5. Write the spark-submit command with your chosen configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your calculations here\n",
    "# TODO: Calculate available resources\n",
    "# TODO: Design 3 different resource allocation strategies\n",
    "# TODO: Compare and choose the best option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Configuration Tuning\n",
    "\n",
    "Create appropriate Spark configurations for different scenarios.\n",
    "\n",
    "**Tasks:**\n",
    "1. Configuration for streaming application (low latency)\n",
    "2. Configuration for large batch ETL (high throughput)\n",
    "3. Configuration for iterative ML training (lots of caching)\n",
    "4. Explain your choices for each scenario\n",
    "5. Identify which settings are most critical for each use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# TODO: Create config for streaming\n",
    "# TODO: Create config for batch ETL\n",
    "# TODO: Create config for ML training\n",
    "# TODO: Document reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Troubleshooting Analysis\n",
    "\n",
    "Analyze and diagnose common cluster issues.\n",
    "\n",
    "**Scenarios:**\n",
    "\n",
    "1. **Scenario A**: Job taking 10x longer than expected, Web UI shows:\n",
    "   - 95% of tasks finish in 1 minute\n",
    "   - 5% of tasks taking 15+ minutes\n",
    "   - Large shuffle write size\n",
    "\n",
    "2. **Scenario B**: executors keep failing with OOM errors:\n",
    "   - Executor memory: 4GB\n",
    "   - GC time >50% of task time\n",
    "   - Many cached DataFrames\n",
    "\n",
    "3. **Scenario C**: Slow join operation:\n",
    "   - Two large tables (1TB and 10GB)\n",
    "   - Using SortMergeJoin\n",
    "   - autoBroadcastJoinThreshold=10MB\n",
    "\n",
    "**Tasks:**\n",
    "- Diagnose the root cause for each scenario\n",
    "- Propose 2-3 solutions for each\n",
    "- Explain the trade-offs of each solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your analysis here\n",
    "# TODO: Analyze each scenario\n",
    "# TODO: Propose solutions\n",
    "# TODO: Discuss trade-offs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exercise Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1: Resource Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster specifications\n",
    "num_nodes = 20\n",
    "cores_per_node = 32\n",
    "ram_per_node_gb = 128\n",
    "\n",
    "# Reserved resources\n",
    "reserved_cores = 1\n",
    "reserved_ram_gb = 2\n",
    "\n",
    "# Available resources per node\n",
    "available_cores = cores_per_node - reserved_cores\n",
    "available_ram = ram_per_node_gb - reserved_ram_gb\n",
    "\n",
    "print(\"=== Cluster Resources ===\")\n",
    "print(f\"Total nodes: {num_nodes}\")\n",
    "print(f\"Per node: {cores_per_node} cores, {ram_per_node_gb}GB RAM\")\n",
    "print(f\"Available per node: {available_cores} cores, {available_ram}GB RAM\")\n",
    "print(f\"\\nTotal available: {available_cores * num_nodes} cores, {available_ram * num_nodes}GB RAM\")\n",
    "\n",
    "print(\"\\n=== Option 1: Balanced (Recommended) ===\")\n",
    "opt1_cores_per_exec = 5\n",
    "opt1_execs_per_node = available_cores // opt1_cores_per_exec\n",
    "opt1_mem_per_exec = (available_ram // opt1_execs_per_node) - 1  # Leave 1GB overhead\n",
    "opt1_total_execs = opt1_execs_per_node * num_nodes\n",
    "\n",
    "print(f\"Cores per executor: {opt1_cores_per_exec}\")\n",
    "print(f\"Executors per node: {opt1_execs_per_node}\")\n",
    "print(f\"Memory per executor: {opt1_mem_per_exec}GB\")\n",
    "print(f\"Total executors: {opt1_total_execs}\")\n",
    "print(f\"Total cores: {opt1_total_execs * opt1_cores_per_exec}\")\n",
    "print(\"Pros: Good balance, optimal for HDFS throughput\")\n",
    "\n",
    "print(\"\\n=== Option 2: High Parallelism ===\")\n",
    "opt2_cores_per_exec = 3\n",
    "opt2_execs_per_node = available_cores // opt2_cores_per_exec\n",
    "opt2_mem_per_exec = (available_ram // opt2_execs_per_node) - 1\n",
    "opt2_total_execs = opt2_execs_per_node * num_nodes\n",
    "\n",
    "print(f\"Cores per executor: {opt2_cores_per_exec}\")\n",
    "print(f\"Executors per node: {opt2_execs_per_node}\")\n",
    "print(f\"Memory per executor: {opt2_mem_per_exec}GB\")\n",
    "print(f\"Total executors: {opt2_total_execs}\")\n",
    "print(f\"Total cores: {opt2_total_execs * opt2_cores_per_exec}\")\n",
    "print(\"Pros: More parallelism, better for many small tasks\")\n",
    "print(\"Cons: More overhead, less memory per executor\")\n",
    "\n",
    "print(\"\\n=== Option 3: Memory Intensive ===\")\n",
    "opt3_cores_per_exec = 10\n",
    "opt3_execs_per_node = available_cores // opt3_cores_per_exec\n",
    "opt3_mem_per_exec = (available_ram // opt3_execs_per_node) - 2  # More overhead for large memory\n",
    "opt3_total_execs = opt3_execs_per_node * num_nodes\n",
    "\n",
    "print(f\"Cores per executor: {opt3_cores_per_exec}\")\n",
    "print(f\"Executors per node: {opt3_execs_per_node}\")\n",
    "print(f\"Memory per executor: {opt3_mem_per_exec}GB\")\n",
    "print(f\"Total executors: {opt3_total_execs}\")\n",
    "print(f\"Total cores: {opt3_total_execs * opt3_cores_per_exec}\")\n",
    "print(\"Pros: Lots of memory for large aggregations\")\n",
    "print(\"Cons: Fewer executors, potential GC issues\")\n",
    "\n",
    "print(\"\\n=== Recommendation ===\")\n",
    "print(\"Choose Option 1 (Balanced) for most workloads\")\n",
    "print(\"Reasoning:\")\n",
    "print(\"  - 5 cores/executor is sweet spot for HDFS throughput\")\n",
    "print(\"  - 20GB/executor is reasonable (not too large for GC)\")\n",
    "print(\"  - 124 executors provides good parallelism\")\n",
    "\n",
    "print(\"\\n=== spark-submit Command ===\")\n",
    "print(f\"\"\"\n",
    "spark-submit \\\\\n",
    "  --master yarn \\\\\n",
    "  --deploy-mode cluster \\\\\n",
    "  --num-executors {opt1_total_execs} \\\\\n",
    "  --executor-cores {opt1_cores_per_exec} \\\\\n",
    "  --executor-memory {opt1_mem_per_exec}G \\\\\n",
    "  --driver-memory 8G \\\\\n",
    "  --driver-cores 4 \\\\\n",
    "  --conf spark.sql.shuffle.partitions=400 \\\\\n",
    "  --conf spark.default.parallelism=200 \\\\\n",
    "  my_application.py\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2: Configuration Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration 1: Streaming Application (Low Latency)\n",
    "streaming_config = \"\"\"\n",
    "# Streaming Application - Low Latency Configuration\n",
    "\n",
    "# Small, frequent micro-batches\n",
    "spark.sql.shuffle.partitions=50  # Fewer partitions for low latency\n",
    "spark.streaming.backpressure.enabled=true  # Handle rate fluctuations\n",
    "spark.streaming.kafka.maxRatePerPartition=1000  # Control ingestion rate\n",
    "\n",
    "# Optimize for speed\n",
    "spark.speculation=true  # Handle stragglers quickly\n",
    "spark.speculation.interval=50ms\n",
    "spark.task.cpus=1  # More tasks in parallel\n",
    "\n",
    "# Memory (moderate, streaming usually has smaller state)\n",
    "spark.executor.memory=4g\n",
    "spark.executor.cores=2\n",
    "\n",
    "# Checkpointing\n",
    "spark.sql.streaming.checkpointLocation=/streaming-checkpoints\n",
    "spark.cleaner.referenceTracking.cleanCheckpoints=true\n",
    "\n",
    "# Network (important for streaming)\n",
    "spark.network.timeout=120s\n",
    "\n",
    "Rationale:\n",
    "- Fewer shuffle partitions for lower latency\n",
    "- Backpressure to handle variable input rates\n",
    "- Speculation to quickly recover from slow tasks\n",
    "- Moderate resources (streaming usually processes smaller batches)\n",
    "\"\"\"\n",
    "\n",
    "print(streaming_config)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Configuration 2: Batch ETL (High Throughput)\n",
    "batch_config = \"\"\"\n",
    "# Batch ETL - High Throughput Configuration\n",
    "\n",
    "# Large resources for processing big data\n",
    "spark.executor.instances=50\n",
    "spark.executor.cores=5\n",
    "spark.executor.memory=16g\n",
    "spark.driver.memory=8g\n",
    "\n",
    "# High parallelism\n",
    "spark.sql.shuffle.partitions=400  # Many partitions for large data\n",
    "spark.default.parallelism=200\n",
    "\n",
    "# Compression (save space and I/O)\n",
    "spark.sql.parquet.compression.codec=snappy\n",
    "spark.broadcast.compress=true\n",
    "spark.shuffle.compress=true\n",
    "\n",
    "# Adaptive execution (handle varying data sizes)\n",
    "spark.sql.adaptive.enabled=true\n",
    "spark.sql.adaptive.coalescePartitions.enabled=true\n",
    "spark.sql.adaptive.skewJoin.enabled=true\n",
    "\n",
    "# Dynamic allocation (scale up/down as needed)\n",
    "spark.dynamicAllocation.enabled=true\n",
    "spark.dynamicAllocation.minExecutors=10\n",
    "spark.dynamicAllocation.maxExecutors=100\n",
    "\n",
    "# Large broadcast threshold (common in ETL for dimension tables)\n",
    "spark.sql.autoBroadcastJoinThreshold=100m\n",
    "\n",
    "Rationale:\n",
    "- Large resources to process big datasets quickly\n",
    "- High parallelism to maximize throughput\n",
    "- Compression to reduce I/O\n",
    "- Adaptive execution to handle data skew\n",
    "- Dynamic allocation for cost efficiency\n",
    "\"\"\"\n",
    "\n",
    "print(batch_config)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Configuration 3: ML Training (Caching Heavy)\n",
    "ml_config = \"\"\"\n",
    "# ML Training - Caching Heavy Configuration\n",
    "\n",
    "# Large memory for caching datasets\n",
    "spark.executor.memory=24g\n",
    "spark.driver.memory=12g\n",
    "spark.executor.cores=6\n",
    "\n",
    "# Memory management (favor storage for caching)\n",
    "spark.memory.fraction=0.7  # More memory for execution/storage\n",
    "spark.memory.storageFraction=0.6  # More storage within that\n",
    "\n",
    "# Serialization (important for large cached objects)\n",
    "spark.serializer=org.apache.spark.serializer.KryoSerializer\n",
    "spark.kryoserializer.buffer.max=1024m\n",
    "\n",
    "# Moderate parallelism (ML often iterates on same data)\n",
    "spark.sql.shuffle.partitions=100\n",
    "\n",
    "# No dynamic allocation (want consistent resources)\n",
    "spark.dynamicAllocation.enabled=false\n",
    "spark.executor.instances=20\n",
    "\n",
    "# Checkpointing for iterative algorithms\n",
    "spark.cleaner.referenceTracking.cleanCheckpoints=true\n",
    "spark.cleaner.periodicGC.interval=10min\n",
    "\n",
    "# Larger broadcast (ML models can be sizeable)\n",
    "spark.sql.autoBroadcastJoinThreshold=200m\n",
    "\n",
    "Rationale:\n",
    "- Very large memory to cache training data in RAM\n",
    "- High storage fraction to prioritize caching\n",
    "- Kryo serialization for efficient object storage\n",
    "- Fixed resources (no dynamic allocation for predictable performance)\n",
    "- Regular GC to manage memory from iterations\n",
    "\"\"\"\n",
    "\n",
    "print(ml_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3: Troubleshooting Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "troubleshooting = \"\"\"\n",
    "=== SCENARIO A: Task Skew and Slow Stragglers ===\n",
    "\n",
    "Symptoms:\n",
    "- 95% tasks finish in 1 minute\n",
    "- 5% tasks taking 15+ minutes\n",
    "- Large shuffle write size\n",
    "\n",
    "Diagnosis:\n",
    "ROOT CAUSE: Data skew - some partitions have much more data than others\n",
    "\n",
    "The 5% slow tasks are processing disproportionately large partitions.\n",
    "Large shuffle indicates data redistribution is happening.\n",
    "\n",
    "Solutions:\n",
    "\n",
    "1. Enable Adaptive Query Execution (AQE):\n",
    "   spark.sql.adaptive.enabled=true\n",
    "   spark.sql.adaptive.skewJoin.enabled=true\n",
    "   \n",
    "   Pros: Automatic skew handling, no code changes\n",
    "   Cons: Requires Spark 3.0+, adds small overhead\n",
    "\n",
    "2. Add salt to skewed keys:\n",
    "   df.withColumn(\"salted_key\", concat(col(\"key\"), lit(\"_\"), rand() * 10))\n",
    "   \n",
    "   Pros: Distributes skewed keys across partitions\n",
    "   Cons: Requires code changes, more complex logic\n",
    "\n",
    "3. Filter outliers if acceptable:\n",
    "   df.filter(col(\"partition_key\").isin(common_values))\n",
    "   \n",
    "   Pros: Simple, fast\n",
    "   Cons: Loses data, not always acceptable\n",
    "\n",
    "4. Enable speculation:\n",
    "   spark.speculation=true\n",
    "   \n",
    "   Pros: Re-runs slow tasks on other executors\n",
    "   Cons: Uses extra resources, doesn't fix root cause\n",
    "\n",
    "Recommendation: Use AQE (#1) + salting (#2) for severe skew\n",
    "\n",
    "===============================================================================\n",
    "\n",
    "=== SCENARIO B: Out of Memory Errors ===\n",
    "\n",
    "Symptoms:\n",
    "- Executors failing with OOM\n",
    "- Executor memory: 4GB\n",
    "- GC time >50% of task time\n",
    "- Many cached DataFrames\n",
    "\n",
    "Diagnosis:\n",
    "ROOT CAUSE: Insufficient memory + excessive caching + high GC overhead\n",
    "\n",
    "The executors don't have enough memory for both caching and execution.\n",
    "High GC time indicates memory pressure.\n",
    "\n",
    "Solutions:\n",
    "\n",
    "1. Increase executor memory:\n",
    "   spark.executor.memory=12g\n",
    "   \n",
    "   Pros: More headroom for caching and execution\n",
    "   Cons: Requires cluster resources, may hit GC issues if too large\n",
    "\n",
    "2. Unpersist unused cached data:\n",
    "   df.unpersist()\n",
    "   \n",
    "   Pros: Frees memory immediately\n",
    "   Cons: Must track what's needed\n",
    "\n",
    "3. Use serialized caching:\n",
    "   df.persist(StorageLevel.MEMORY_ONLY_SER)\n",
    "   \n",
    "   Pros: Uses less memory (compressed)\n",
    "   Cons: Slower access (deserialization overhead)\n",
    "\n",
    "4. Adjust memory fractions:\n",
    "   spark.memory.fraction=0.7\n",
    "   spark.memory.storageFraction=0.3\n",
    "   \n",
    "   Pros: Allocates more to execution vs storage\n",
    "   Cons: May evict cached data more frequently\n",
    "\n",
    "5. Increase number of partitions:\n",
    "   spark.sql.shuffle.partitions=400\n",
    "   \n",
    "   Pros: Smaller partitions use less memory per task\n",
    "   Cons: More tasks, higher overhead\n",
    "\n",
    "Recommendation: Increase memory (#1) + unpersist unused cache (#2)\n",
    "\n",
    "===============================================================================\n",
    "\n",
    "=== SCENARIO C: Slow Join Operation ===\n",
    "\n",
    "Symptoms:\n",
    "- Two tables: 1TB and 10GB\n",
    "- Using SortMergeJoin\n",
    "- autoBroadcastJoinThreshold=10MB\n",
    "\n",
    "Diagnosis:\n",
    "ROOT CAUSE: Using shuffle join instead of broadcast join\n",
    "\n",
    "The 10GB table is above the 10MB threshold, so Spark uses expensive\n",
    "SortMergeJoin instead of BroadcastHashJoin.\n",
    "\n",
    "Solutions:\n",
    "\n",
    "1. Increase broadcast threshold:\n",
    "   spark.sql.autoBroadcastJoinThreshold=15g\n",
    "   \n",
    "   Pros: Enables broadcast join automatically\n",
    "   Cons: Requires sufficient driver/executor memory\n",
    "\n",
    "2. Explicit broadcast hint:\n",
    "   large_table.join(broadcast(small_table), \"key\")\n",
    "   \n",
    "   Pros: Guaranteed broadcast join\n",
    "   Cons: Must ensure table fits in memory\n",
    "\n",
    "3. Filter small table first:\n",
    "   filtered_small = small_table.filter(col(\"active\") == true)\n",
    "   large_table.join(broadcast(filtered_small), \"key\")\n",
    "   \n",
    "   Pros: Reduces broadcast size\n",
    "   Cons: Only works if filtering is possible\n",
    "\n",
    "4. Partition both tables by join key:\n",
    "   large_partitioned = large_table.repartition(\"key\")\n",
    "   small_partitioned = small_table.repartition(\"key\")\n",
    "   \n",
    "   Pros: Co-locates matching keys, reduces shuffle\n",
    "   Cons: Requires upfront repartitioning\n",
    "\n",
    "Recommendation: Increase threshold (#1) or use explicit broadcast (#2)\n",
    "\n",
    "Trade-offs:\n",
    "- Broadcast uses driver memory (limit: ~8GB typically)\n",
    "- Broadcast sends data to all executors (network cost)\n",
    "- But eliminates shuffle for 1TB table (huge savings!)\n",
    "- If 10GB doesn't fit in memory, use partitioning (#4)\n",
    "\n",
    "===============================================================================\n",
    "\"\"\"\n",
    "\n",
    "print(troubleshooting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "Congratulations! You've learned how to deploy and manage Spark on clusters.\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Cluster Architecture**:\n",
    "   - Driver orchestrates, executors execute\n",
    "   - Cluster manager allocates resources\n",
    "   - Tasks are units of parallel work\n",
    "   - Memory divided into execution and storage\n",
    "\n",
    "2. **Deployment Modes**:\n",
    "   - Local: Development and testing\n",
    "   - Standalone: Simple dedicated clusters\n",
    "   - YARN: Hadoop integration, most common in enterprise\n",
    "   - Kubernetes: Cloud-native, containerized deployments\n",
    "\n",
    "3. **Resource Allocation**:\n",
    "   - Balance: cores, memory, number of executors\n",
    "   - Sweet spot: 4-6 cores per executor\n",
    "   - Memory: 8-16GB per executor (avoid GC issues)\n",
    "   - Leave resources for OS and overhead\n",
    "\n",
    "4. **spark-submit**:\n",
    "   - Standard way to submit applications\n",
    "   - Configure resources, dependencies, and properties\n",
    "   - Use configuration files for production\n",
    "   - Different syntax for different cluster managers\n",
    "\n",
    "5. **Monitoring**:\n",
    "   - Web UI provides detailed metrics\n",
    "   - Watch for: task skew, GC time, shuffle size\n",
    "   - Enable event logging and history server\n",
    "   - Set up alerting for production jobs\n",
    "\n",
    "6. **Best Practices**:\n",
    "   - Enable adaptive query execution\n",
    "   - Use dynamic allocation for variable workloads\n",
    "   - Configure compression and serialization\n",
    "   - Implement structured logging\n",
    "   - Version control configurations\n",
    "\n",
    "### Production Deployment Checklist:\n",
    "\n",
    "- [ ] Calculate appropriate resource allocation\n",
    "- [ ] Create production configuration file\n",
    "- [ ] Test with representative data volume\n",
    "- [ ] Set up monitoring and alerting\n",
    "- [ ] Configure logging and log aggregation\n",
    "- [ ] Enable checkpointing for streaming\n",
    "- [ ] Implement retry logic for failures\n",
    "- [ ] Document dependencies and versions\n",
    "- [ ] Set up CI/CD pipeline\n",
    "- [ ] Configure security (auth, encryption)\n",
    "\n",
    "### Common Production Issues:\n",
    "\n",
    "1. **Under-resourced**: Jobs slow or failing\n",
    "   - Solution: Increase memory, cores, or executors\n",
    "\n",
    "2. **Over-resourced**: Wasting cluster capacity\n",
    "   - Solution: Enable dynamic allocation\n",
    "\n",
    "3. **Memory pressure**: High GC time, OOM\n",
    "   - Solution: More memory, unpersist cache, tune fractions\n",
    "\n",
    "4. **Data skew**: Few slow tasks\n",
    "   - Solution: AQE, salting, repartitioning\n",
    "\n",
    "5. **Slow shuffles**: Large data movement\n",
    "   - Solution: Broadcast joins, pre-partitioning, filtering\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In [Module 14: Final Project - ETL Pipeline with ML](14_final_project_etl_pipeline_with_ml.ipynb), you'll:\n",
    "- Build an end-to-end production pipeline\n",
    "- Integrate ETL, feature engineering, and ML\n",
    "- Apply all concepts from previous modules\n",
    "- Create a deployable Spark application\n",
    "- Implement production best practices\n",
    "\n",
    "### Additional Resources:\n",
    "\n",
    "- [Cluster Mode Overview](https://spark.apache.org/docs/latest/cluster-overview.html)\n",
    "- [Submitting Applications](https://spark.apache.org/docs/latest/submitting-applications.html)\n",
    "- [Running on YARN](https://spark.apache.org/docs/latest/running-on-yarn.html)\n",
    "- [Running on Kubernetes](https://spark.apache.org/docs/latest/running-on-kubernetes.html)\n",
    "- [Monitoring and Instrumentation](https://spark.apache.org/docs/latest/monitoring.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "spark.stop()\n",
    "print(\"Spark session stopped. Excellent work on understanding Spark clusters!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
