{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Fundamentals\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- Convert between different color spaces (RGB, HSV, Grayscale)\n",
    "- Track objects by color using HSV\n",
    "- Apply various thresholding techniques\n",
    "- Smooth and filter images to reduce noise\n",
    "- Enhance image contrast with histogram equalization\n",
    "- Denoise images effectively\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**â±ï¸ Estimated Time**: 90-120 minutes  \n",
    "**ðŸ“š Level**: Intermediate  \n",
    "**ðŸ“‹ Prerequisites**: Completed notebooks 00-02\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Color Space Conversions\n",
    "\n",
    "### What are Color Spaces?\n",
    "\n",
    "A **color space** is a specific organization of colors. Different color spaces are useful for different tasks:\n",
    "\n",
    "- **BGR/RGB**: Standard color representation (Blue-Green-Red / Red-Green-Blue)\n",
    "- **Grayscale**: Single channel (0-255), no color information\n",
    "- **HSV**: Hue-Saturation-Value (best for color-based detection)\n",
    "- **LAB**: Lightness + A/B color channels (perceptually uniform)\n",
    "\n",
    "### Why HSV?\n",
    "\n",
    "HSV is excellent for color tracking because:\n",
    "- **Hue** represents the actual color (0-179 in OpenCV)\n",
    "- **Saturation** represents color intensity (0-255)\n",
    "- **Value** represents brightness (0-255)\n",
    "- Separates color from brightness!\n",
    "\n",
    "### Converting Color Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a colorful test image\n",
    "test_img = np.zeros((300, 500, 3), dtype=np.uint8)\n",
    "test_img[0:100, :] = [0, 0, 255]  # Red top\n",
    "test_img[100:200, :] = [0, 255, 0]  # Green middle\n",
    "test_img[200:300, :] = [255, 0, 0]  # Blue bottom\n",
    "\n",
    "# Convert to different color spaces\n",
    "gray = cv.cvtColor(test_img, cv.COLOR_BGR2GRAY)\n",
    "hsv = cv.cvtColor(test_img, cv.COLOR_BGR2HSV)\n",
    "lab = cv.cvtColor(test_img, cv.COLOR_BGR2LAB)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(cv.cvtColor(test_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Original (BGR)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(gray, cmap=\"gray\")\n",
    "plt.title(\"Grayscale\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(hsv)\n",
    "plt.title(\"HSV\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Split and show HSV channels\n",
    "h, s, v = cv.split(hsv)\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(h, cmap=\"hsv\")\n",
    "plt.title(\"H (Hue) - Color\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(s, cmap=\"gray\")\n",
    "plt.title(\"S (Saturation) - Intensity\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(v, cmap=\"gray\")\n",
    "plt.title(\"V (Value) - Brightness\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Original shape: {test_img.shape}\")\n",
    "print(f\"Grayscale shape: {gray.shape}\")\n",
    "print(f\"HSV shape: {hsv.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Tracking with HSV\n",
    "\n",
    "Let's track a specific color (red) using HSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image with colored objects\n",
    "scene = np.ones((400, 600, 3), dtype=np.uint8) * 200\n",
    "\n",
    "# Add colored circles\n",
    "cv.circle(scene, (150, 150), 60, (0, 0, 255), -1)  # Red circle\n",
    "cv.circle(scene, (300, 150), 60, (0, 255, 0), -1)  # Green circle\n",
    "cv.circle(scene, (450, 150), 60, (255, 0, 0), -1)  # Blue circle\n",
    "cv.circle(scene, (150, 300), 60, (0, 0, 200), -1)  # Dark red circle\n",
    "cv.circle(scene, (450, 300), 60, (0, 128, 255), -1)  # Orange circle\n",
    "\n",
    "# Convert to HSV\n",
    "hsv_scene = cv.cvtColor(scene, cv.COLOR_BGR2HSV)\n",
    "\n",
    "# Define range for red color in HSV\n",
    "# Red wraps around in HSV (0-10 and 170-180)\n",
    "lower_red1 = np.array([0, 100, 100])\n",
    "upper_red1 = np.array([10, 255, 255])\n",
    "lower_red2 = np.array([170, 100, 100])\n",
    "upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "# Create masks\n",
    "mask1 = cv.inRange(hsv_scene, lower_red1, upper_red1)\n",
    "mask2 = cv.inRange(hsv_scene, lower_red2, upper_red2)\n",
    "red_mask = cv.bitwise_or(mask1, mask2)\n",
    "\n",
    "# Apply mask\n",
    "red_only = cv.bitwise_and(scene, scene, mask=red_mask)\n",
    "\n",
    "# Find contours of red objects\n",
    "contours, _ = cv.findContours(red_mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw bounding boxes\n",
    "result = scene.copy()\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv.boundingRect(contour)\n",
    "    cv.rectangle(result, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "    # Draw circle\n",
    "    (cx, cy), radius = cv.minEnclosingCircle(contour)\n",
    "    cv.circle(result, (int(cx), int(cy)), int(radius), (255, 0, 255), 2)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(cv.cvtColor(scene, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Scene\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(red_mask, cmap=\"gray\")\n",
    "plt.title(\"Red Mask (HSV filtering)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(cv.cvtColor(red_only, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Red Objects Only\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(cv.cvtColor(result, cv.COLOR_BGR2RGB))\n",
    "plt.title(f\"Detection ({len(contours)} red objects found)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Red objects detected: {len(contours)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Image Thresholding\n",
    "\n",
    "### What is Thresholding?\n",
    "\n",
    "**Thresholding** converts grayscale images to binary (black and white) images. It's used for:\n",
    "- Separating objects from background\n",
    "- Document scanning\n",
    "- Feature extraction\n",
    "- Preparing images for further processing\n",
    "\n",
    "### Simple Thresholding\n",
    "\n",
    "Apply a fixed threshold value to all pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test image with varying intensity\n",
    "threshold_img = np.zeros((300, 500), dtype=np.uint8)\n",
    "for i in range(5):\n",
    "    intensity = 50 + i * 40\n",
    "    threshold_img[:, i * 100 : (i + 1) * 100] = intensity\n",
    "\n",
    "# Add some shapes\n",
    "cv.circle(threshold_img, (100, 150), 50, 200, -1)\n",
    "cv.rectangle(threshold_img, (250, 100), (350, 200), 100, -1)\n",
    "cv.rectangle(threshold_img, (400, 120), (480, 180), 255, -1)\n",
    "\n",
    "# Apply different threshold types\n",
    "_, binary = cv.threshold(threshold_img, 127, 255, cv.THRESH_BINARY)\n",
    "_, binary_inv = cv.threshold(threshold_img, 127, 255, cv.THRESH_BINARY_INV)\n",
    "_, trunc = cv.threshold(threshold_img, 127, 255, cv.THRESH_TRUNC)\n",
    "_, tozero = cv.threshold(threshold_img, 127, 255, cv.THRESH_TOZERO)\n",
    "_, tozero_inv = cv.threshold(threshold_img, 127, 255, cv.THRESH_TOZERO_INV)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(threshold_img, cmap=\"gray\")\n",
    "plt.title(\"Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(binary, cmap=\"gray\")\n",
    "plt.title(\"THRESH_BINARY\\n(>127: white, â‰¤127: black)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(binary_inv, cmap=\"gray\")\n",
    "plt.title(\"THRESH_BINARY_INV\\n(>127: black, â‰¤127: white)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(trunc, cmap=\"gray\")\n",
    "plt.title(\"THRESH_TRUNC\\n(>127: 127, â‰¤127: unchanged)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(tozero, cmap=\"gray\")\n",
    "plt.title(\"THRESH_TOZERO\\n(>127: unchanged, â‰¤127: 0)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(tozero_inv, cmap=\"gray\")\n",
    "plt.title(\"THRESH_TOZERO_INV\\n(>127: 0, â‰¤127: unchanged)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Thresholding\n",
    "\n",
    "Calculates threshold for small regions, better for varying lighting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image with gradient lighting\n",
    "gradient_img = np.zeros((300, 500), dtype=np.uint8)\n",
    "for i in range(300):\n",
    "    for j in range(500):\n",
    "        gradient_img[i, j] = int((i / 300) * 150 + 50)\n",
    "\n",
    "# Add text-like patterns\n",
    "cv.putText(gradient_img, \"ADAPTIVE\", (50, 100), cv.FONT_HERSHEY_SIMPLEX, 2, 255, 4)\n",
    "cv.putText(gradient_img, \"THRESHOLD\", (50, 200), cv.FONT_HERSHEY_SIMPLEX, 2, 255, 4)\n",
    "\n",
    "# Simple threshold (fails with gradient)\n",
    "_, simple_thresh = cv.threshold(gradient_img, 127, 255, cv.THRESH_BINARY)\n",
    "\n",
    "# Adaptive threshold (handles gradient)\n",
    "adaptive_mean = cv.adaptiveThreshold(\n",
    "    gradient_img, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY, 11, 2\n",
    ")\n",
    "adaptive_gaussian = cv.adaptiveThreshold(\n",
    "    gradient_img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2\n",
    ")\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(gradient_img, cmap=\"gray\")\n",
    "plt.title(\"Original (Gradient Lighting)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(simple_thresh, cmap=\"gray\")\n",
    "plt.title(\"Simple Threshold (FAILS!)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(adaptive_mean, cmap=\"gray\")\n",
    "plt.title(\"Adaptive (Mean)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(adaptive_gaussian, cmap=\"gray\")\n",
    "plt.title(\"Adaptive (Gaussian)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Adaptive thresholding handles varying illumination!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otsu's Thresholding\n",
    "\n",
    "Automatically finds optimal threshold value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bimodal image (two distinct intensity regions)\n",
    "bimodal = np.zeros((300, 500), dtype=np.uint8)\n",
    "bimodal[:, :250] = 80  # Dark region\n",
    "bimodal[:, 250:] = 180  # Bright region\n",
    "\n",
    "# Add noise\n",
    "noise = np.random.normal(0, 20, bimodal.shape).astype(np.int16)\n",
    "bimodal = np.clip(bimodal.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Add shapes\n",
    "cv.circle(bimodal, (125, 150), 50, 60, -1)\n",
    "cv.rectangle(bimodal, (320, 100), (420, 200), 200, -1)\n",
    "\n",
    "# Simple threshold (manual)\n",
    "_, manual_thresh = cv.threshold(bimodal, 127, 255, cv.THRESH_BINARY)\n",
    "\n",
    "# Otsu's threshold (automatic)\n",
    "otsu_value, otsu_thresh = cv.threshold(bimodal, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(bimodal, cmap=\"gray\")\n",
    "plt.title(\"Original (Bimodal)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(manual_thresh, cmap=\"gray\")\n",
    "plt.title(\"Manual Threshold (127)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(otsu_thresh, cmap=\"gray\")\n",
    "plt.title(f\"Otsu's Threshold ({otsu_value:.0f})\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Otsu automatically found optimal threshold: {otsu_value:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Image Smoothing and Filtering\n",
    "\n",
    "### Why Smooth Images?\n",
    "\n",
    "- Reduce noise\n",
    "- Blur details\n",
    "- Prepare for edge detection\n",
    "- Remove artifacts\n",
    "\n",
    "### Understanding Kernels\n",
    "\n",
    "A **kernel** (or filter) is a small matrix used to apply effects. Common sizes: 3Ã—3, 5Ã—5, 7Ã—7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create noisy image\n",
    "clean_img = np.ones((300, 300), dtype=np.uint8) * 128\n",
    "cv.circle(clean_img, (150, 150), 80, 200, -1)\n",
    "cv.rectangle(clean_img, (50, 50), (100, 100), 50, -1)\n",
    "\n",
    "# Add Gaussian noise\n",
    "noise = np.random.normal(0, 25, clean_img.shape).astype(np.int16)\n",
    "noisy_img = np.clip(clean_img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Add salt and pepper noise\n",
    "salt_pepper = noisy_img.copy()\n",
    "salt = np.random.random(salt_pepper.shape) > 0.97\n",
    "pepper = np.random.random(salt_pepper.shape) < 0.03\n",
    "salt_pepper[salt] = 255\n",
    "salt_pepper[pepper] = 0\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(clean_img, cmap=\"gray\")\n",
    "plt.title(\"Clean Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(noisy_img, cmap=\"gray\")\n",
    "plt.title(\"With Gaussian Noise\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(salt_pepper, cmap=\"gray\")\n",
    "plt.title(\"With Salt & Pepper Noise\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging (Box Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply averaging with different kernel sizes\n",
    "avg_3x3 = cv.blur(noisy_img, (3, 3))\n",
    "avg_5x5 = cv.blur(noisy_img, (5, 5))\n",
    "avg_9x9 = cv.blur(noisy_img, (9, 9))\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(noisy_img, cmap=\"gray\")\n",
    "plt.title(\"Noisy Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(avg_3x3, cmap=\"gray\")\n",
    "plt.title(\"Averaging 3Ã—3\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(avg_5x5, cmap=\"gray\")\n",
    "plt.title(\"Averaging 5Ã—5\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(avg_9x9, cmap=\"gray\")\n",
    "plt.title(\"Averaging 9Ã—9 (more blur)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Blurring\n",
    "\n",
    "Better than averaging - gives more weight to nearby pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Gaussian blur\n",
    "gaussian_3x3 = cv.GaussianBlur(noisy_img, (3, 3), 0)\n",
    "gaussian_5x5 = cv.GaussianBlur(noisy_img, (5, 5), 0)\n",
    "gaussian_9x9 = cv.GaussianBlur(noisy_img, (9, 9), 0)\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(noisy_img, cmap=\"gray\")\n",
    "plt.title(\"Noisy Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(gaussian_3x3, cmap=\"gray\")\n",
    "plt.title(\"Gaussian Blur 3Ã—3\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(gaussian_5x5, cmap=\"gray\")\n",
    "plt.title(\"Gaussian Blur 5Ã—5\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(gaussian_9x9, cmap=\"gray\")\n",
    "plt.title(\"Gaussian Blur 9Ã—9\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Filtering\n",
    "\n",
    "Excellent for salt-and-pepper noise, preserves edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare on salt-and-pepper noise\n",
    "avg_sp = cv.blur(salt_pepper, (5, 5))\n",
    "gaussian_sp = cv.GaussianBlur(salt_pepper, (5, 5), 0)\n",
    "median_sp = cv.medianBlur(salt_pepper, 5)\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(salt_pepper, cmap=\"gray\")\n",
    "plt.title(\"Salt & Pepper Noise\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(avg_sp, cmap=\"gray\")\n",
    "plt.title(\"Averaging (Poor)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(gaussian_sp, cmap=\"gray\")\n",
    "plt.title(\"Gaussian (Poor)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(median_sp, cmap=\"gray\")\n",
    "plt.title(\"Median (Excellent!) âœ“\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Median filter is best for salt-and-pepper noise!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilateral Filtering\n",
    "\n",
    "Reduces noise while preserving edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image with edges\n",
    "edge_img = np.ones((300, 300), dtype=np.uint8) * 50\n",
    "cv.rectangle(edge_img, (50, 50), (250, 250), 200, -1)\n",
    "cv.circle(edge_img, (150, 150), 60, 100, -1)\n",
    "\n",
    "# Add noise\n",
    "noise = np.random.normal(0, 20, edge_img.shape).astype(np.int16)\n",
    "noisy_edge = np.clip(edge_img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Compare filters\n",
    "gaussian_edge = cv.GaussianBlur(noisy_edge, (9, 9), 0)\n",
    "bilateral_edge = cv.bilateralFilter(noisy_edge, 9, 75, 75)\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(noisy_edge, cmap=\"gray\")\n",
    "plt.title(\"Noisy (with edges)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(gaussian_edge, cmap=\"gray\")\n",
    "plt.title(\"Gaussian (blurs edges)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(bilateral_edge, cmap=\"gray\")\n",
    "plt.title(\"Bilateral (preserves edges!) âœ“\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Bilateral filter preserves edges while smoothing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Histogram Equalization\n",
    "\n",
    "### What is Histogram Equalization?\n",
    "\n",
    "Improves image contrast by spreading out intensity values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Parameter Tuning Tips for CLAHE\n",
    "\n",
    "**clipLimit** (default: 2.0):\n",
    "- Lower values (1.0-2.0): Less contrast enhancement, more natural\n",
    "- Higher values (3.0-8.0): More contrast, but may introduce noise\n",
    "- Too high (>10): Over-enhancement, unnatural appearance\n",
    "\n",
    "**tileGridSize** (default: (8,8)):\n",
    "- Smaller tiles (4,4): More local adaptation, may create visible grid artifacts\n",
    "- Larger tiles (16,16): Smoother results, less local adaptation\n",
    "- Try: (8,8) for balanced results\n",
    "\n",
    "**When to use**: Low-contrast images, medical images, underwater images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Image Denoising\n",
    "\n",
    "### Non-Local Means Denoising\n",
    "\n",
    "Advanced denoising technique that compares patches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create color image with noise\n",
    "color_clean = np.zeros((200, 300, 3), dtype=np.uint8)\n",
    "color_clean[:, :100] = [200, 100, 50]\n",
    "color_clean[:, 100:200] = [50, 200, 100]\n",
    "color_clean[:, 200:] = [100, 50, 200]\n",
    "\n",
    "# Add significant noise\n",
    "noise_color = np.random.normal(0, 30, color_clean.shape).astype(np.int16)\n",
    "color_noisy = np.clip(color_clean.astype(np.int16) + noise_color, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Denoise\n",
    "denoised = cv.fastNlMeansDenoisingColored(color_noisy, None, 10, 10, 7, 21)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv.cvtColor(color_clean, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Clean Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(cv.cvtColor(color_noisy, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Noisy\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv.cvtColor(denoised, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Denoised (NL-Means)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Non-Local Means denoising effectively removes noise!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Practical Exercises\n",
    "\n",
    "### Exercise 1: Build a Color Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a scene and track blue objects\n",
    "# Hint: Use HSV color space\n",
    "# Blue in HSV: H=90-130, S=50-255, V=50-255\n",
    "\n",
    "# Your code here!\n",
    "exercise_scene = np.ones((400, 600, 3), dtype=np.uint8) * 180\n",
    "cv.circle(exercise_scene, (100, 200), 50, (255, 0, 0), -1)  # Blue\n",
    "cv.circle(exercise_scene, (300, 200), 50, (0, 255, 0), -1)  # Green\n",
    "cv.circle(exercise_scene, (500, 200), 50, (200, 100, 0), -1)  # Teal (partial blue)\n",
    "\n",
    "# Convert and detect blue\n",
    "hsv_ex = cv.cvtColor(exercise_scene, cv.COLOR_BGR2HSV)\n",
    "blue_mask = cv.inRange(hsv_ex, np.array([90, 50, 50]), np.array([130, 255, 255]))\n",
    "blue_result = cv.bitwise_and(exercise_scene, exercise_scene, mask=blue_mask)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv.cvtColor(exercise_scene, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Scene\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(blue_mask, cmap=\"gray\")\n",
    "plt.title(\"Blue Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv.cvtColor(blue_result, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Blue Objects\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Compare Thresholding Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create image and compare simple, adaptive, and Otsu thresholding\n",
    "# Which works best for which scenario?\n",
    "\n",
    "print(\"Try creating different types of images (uniform lighting, gradient, etc.)\")\n",
    "print(\"and see which thresholding method works best!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Denoise Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add different types of noise and test different filters\n",
    "# - Gaussian noise â†’ Which filter works best?\n",
    "# - Salt & pepper â†’ Which filter works best?\n",
    "# - Mixed noise â†’ Which filter works best?\n",
    "\n",
    "print(\"Experiment with different noise types and filters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Congratulations! You've completed Image Processing Fundamentals. You now know:\n",
    "\n",
    "âœ“ Color space conversions (BGR, HSV, Grayscale)  \n",
    "âœ“ Color-based object tracking with HSV  \n",
    "âœ“ Thresholding techniques (simple, adaptive, Otsu's)  \n",
    "âœ“ Image smoothing (averaging, Gaussian, median, bilateral)  \n",
    "âœ“ Histogram equalization for contrast enhancement  \n",
    "âœ“ Advanced denoising with NL-Means  \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **HSV is best for color detection** - separates color from brightness\n",
    "2. **Adaptive thresholding handles varying light** - better than simple threshold\n",
    "3. **Otsu finds optimal threshold automatically** - for bimodal images\n",
    "4. **Median filter best for salt-and-pepper** - preserves edges\n",
    "5. **Bilateral filter preserves edges** - while smoothing\n",
    "6. **CLAHE better than histogram equalization** - avoids over-amplification\n",
    "\n",
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "In the next notebook (**04_image_transformations.ipynb**), you'll learn:\n",
    "- Geometric transformations (scaling, rotation, translation)\n",
    "- Perspective transformation\n",
    "- Image warping\n",
    "- Watermarking techniques\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "- **Document Scanning**: Thresholding for clean text\n",
    "- **Object Tracking**: HSV-based color detection\n",
    "- **Medical Imaging**: Denoising and contrast enhancement\n",
    "- **Quality Control**: Defect detection with thresholding\n",
    "- **Photography**: Noise reduction and enhancement\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Coding!** ðŸŽ¨ðŸ“Š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
