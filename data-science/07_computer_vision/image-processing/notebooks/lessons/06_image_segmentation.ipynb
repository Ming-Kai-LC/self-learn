{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Image Segmentation\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- Understand image segmentation concepts and applications\n",
    "- Apply supervised and unsupervised thresholding\n",
    "- Use the watershed algorithm for object separation\n",
    "- Implement marker-based watershed segmentation\n",
    "- Count and separate overlapping objects\n",
    "- Build automated object counting systems\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4v7qowl2ztk",
   "source": "---\n\n**‚è±Ô∏è Estimated Time**: 90-120 minutes  \n**üìö Level**: Intermediate to Advanced  \n**üìã Prerequisites**: Completed notebooks 00-05\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "# Configure matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Introduction to Image Segmentation\n",
    "\n",
    "### What is Image Segmentation?\n",
    "\n",
    "**Image segmentation** is the process of partitioning an image into multiple segments (regions or objects). The goal is to simplify the image representation and make it more meaningful for analysis.\n",
    "\n",
    "### Types of Segmentation:\n",
    "- **Semantic Segmentation** - Classify each pixel into a category\n",
    "- **Instance Segmentation** - Identify individual object instances\n",
    "- **Thresholding-based** - Separate foreground from background\n",
    "- **Region-based** - Group similar pixels together\n",
    "- **Edge-based** - Find boundaries between regions\n",
    "\n",
    "### Applications:\n",
    "- **Medical Imaging**: Tumor detection, organ segmentation\n",
    "- **Autonomous Driving**: Road, pedestrian, vehicle detection\n",
    "- **Manufacturing**: Defect detection, quality control\n",
    "- **Biology**: Cell counting, microscopy analysis\n",
    "- **Satellite Imagery**: Land use classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Thresholding for Segmentation\n",
    "\n",
    "### Supervised Thresholding\n",
    "\n",
    "In **supervised thresholding**, you manually select the threshold value based on your knowledge of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample image with objects\n",
    "supervised_img = np.ones((300, 400), dtype=np.uint8) * 50  # Dark background\n",
    "\n",
    "# Add objects with different intensities\n",
    "cv.circle(supervised_img, (100, 100), 40, 150, -1)\n",
    "cv.circle(supervised_img, (200, 100), 40, 180, -1)\n",
    "cv.circle(supervised_img, (300, 100), 40, 200, -1)\n",
    "cv.rectangle(supervised_img, (50, 180), (150, 250), 160, -1)\n",
    "cv.rectangle(supervised_img, (200, 180), (350, 250), 190, -1)\n",
    "\n",
    "# Try different manual thresholds\n",
    "_, thresh_100 = cv.threshold(supervised_img, 100, 255, cv.THRESH_BINARY)\n",
    "_, thresh_140 = cv.threshold(supervised_img, 140, 255, cv.THRESH_BINARY)\n",
    "_, thresh_170 = cv.threshold(supervised_img, 170, 255, cv.THRESH_BINARY)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(supervised_img, cmap=\"gray\")\n",
    "plt.title(\"Original Image\", fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(thresh_100, cmap=\"gray\")\n",
    "plt.title(\"Threshold = 100\\n(All objects captured)\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(thresh_140, cmap=\"gray\")\n",
    "plt.title(\"Threshold = 140\\n(Some objects lost)\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(thresh_170, cmap=\"gray\")\n",
    "plt.title(\"Threshold = 170\\n(Only brightest objects)\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Supervised thresholding requires manual threshold selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": "### üí° Parameter Tuning Tips for Watershed Segmentation\n\n**Distance Transform Threshold** (0.0-1.0):\n- Lower (0.3-0.5): More markers, more segments (over-segmentation)\n- Higher (0.6-0.8): Fewer markers, merged segments (under-segmentation)\n- Typical: 0.5-0.7 for most applications\n\n**Morphological Operations (before watershed)**:\n- More iterations: Cleaner background, but may merge close objects\n- Fewer iterations: Preserves object boundaries, but noisier\n\n**Connectivity** (for connected components):\n- 4-connectivity: Conservative, may split diagonal connections\n- 8-connectivity: Includes diagonals, more connected regions\n\n**When to adjust**:\n- Over-segmentation (too many regions): Increase distance threshold, more erosion iterations\n- Under-segmentation (merged objects): Decrease distance threshold, less erosion"
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": "### üí° Parameter Tuning Tips for Watershed Segmentation\n\n**Distance Transform Threshold** (0.0-1.0):\n- Lower (0.3-0.5): More markers, more segments (over-segmentation)\n- Higher (0.6-0.8): Fewer markers, merged segments (under-segmentation)\n- Typical: 0.5-0.7 for most applications\n\n**Morphological Operations (before watershed)**:\n- More iterations: Cleaner background, but may merge close objects\n- Fewer iterations: Preserves object boundaries, but noisier\n\n**Connectivity** (for connected components):\n- 4-connectivity: Conservative, may split diagonal connections\n- 8-connectivity: Includes diagonals, more connected regions\n\n**When to adjust**:\n- Over-segmentation (too many regions): Increase distance threshold, more erosion iterations\n- Under-segmentation (merged objects): Decrease distance threshold, less erosion"
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Watershed Algorithm - Theory\n",
    "\n",
    "### What is the Watershed Algorithm?\n",
    "\n",
    "The **watershed algorithm** treats the image as a topographic surface:\n",
    "- **Dark pixels** = Valleys (low elevation)\n",
    "- **Bright pixels** = Peaks (high elevation)\n",
    "- **Watershed lines** = Boundaries between regions\n",
    "\n",
    "### How it Works:\n",
    "1. Start filling water from the valleys (local minima)\n",
    "2. Water from different valleys will meet at watershed lines\n",
    "3. These lines represent object boundaries\n",
    "\n",
    "### Problem: Over-segmentation\n",
    "- Watershed can create too many regions due to noise\n",
    "- **Solution**: Use **markers** to guide segmentation\n",
    "\n",
    "### Marker-Based Watershed:\n",
    "1. **Sure foreground** - Definitely part of objects\n",
    "2. **Sure background** - Definitely background\n",
    "3. **Unknown region** - Boundary area to be determined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Basic Watershed Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image with overlapping circles\n",
    "coins_img = np.zeros((300, 400), dtype=np.uint8)\n",
    "\n",
    "# Add overlapping circles (simulating coins)\n",
    "cv.circle(coins_img, (100, 150), 50, 255, -1)\n",
    "cv.circle(coins_img, (160, 150), 50, 255, -1)\n",
    "cv.circle(coins_img, (130, 210), 50, 255, -1)\n",
    "cv.circle(coins_img, (300, 150), 45, 255, -1)\n",
    "\n",
    "# Visualize the \"topographic\" view\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(coins_img, cmap=\"gray\")\n",
    "plt.title(\"Overlapping Circles (Coins)\", fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(coins_img, cmap=\"terrain\")\n",
    "plt.title(\"Topographic View (Watershed Analogy)\", fontsize=14)\n",
    "plt.colorbar(label=\"Elevation\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Count connected components (before watershed)\n",
    "num_labels, labels = cv.connectedComponents(coins_img)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(labels, cmap=\"nipy_spectral\")\n",
    "plt.title(f\"Simple Thresholding: {num_labels-1} objects\\n(Should be 4!)\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Without watershed: Found {num_labels-1} objects (incorrect!)\")\n",
    "print(\"The touching circles are counted as one object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Marker-Based Watershed Implementation\n",
    "\n",
    "### Step-by-Step Process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Noise removal using morphology\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "opening = cv.morphologyEx(coins_img, cv.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "# Step 2: Sure background area (dilate)\n",
    "sure_bg = cv.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "# Step 3: Sure foreground area using distance transform\n",
    "dist_transform = cv.distanceTransform(opening, cv.DIST_L2, 5)\n",
    "_, sure_fg = cv.threshold(dist_transform, 0.5 * dist_transform.max(), 255, 0)\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "# Step 4: Unknown region (background - foreground)\n",
    "unknown = cv.subtract(sure_bg, sure_fg)\n",
    "\n",
    "# Visualize the regions\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(coins_img, cmap=\"gray\")\n",
    "plt.title(\"1. Original Image\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(opening, cmap=\"gray\")\n",
    "plt.title(\"2. After Opening (noise removed)\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(sure_bg, cmap=\"gray\")\n",
    "plt.title(\"3. Sure Background (dilated)\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(dist_transform, cmap=\"hot\")\n",
    "plt.title(\"4. Distance Transform\", fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(sure_fg, cmap=\"gray\")\n",
    "plt.title(\"5. Sure Foreground (peaks)\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(unknown, cmap=\"gray\")\n",
    "plt.title(\"6. Unknown Region (to segment)\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Prepared regions for watershed segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Label markers\n",
    "_, markers = cv.connectedComponents(sure_fg)\n",
    "\n",
    "# Step 6: Add 1 to all labels so background is not 0, but 1\n",
    "markers = markers + 1\n",
    "\n",
    "# Step 7: Mark unknown region as 0\n",
    "markers[unknown == 255] = 0\n",
    "\n",
    "# Visualize markers\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(sure_fg, cmap=\"gray\")\n",
    "plt.title(\"Sure Foreground\", fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(markers, cmap=\"nipy_spectral\")\n",
    "plt.title(f\"Markers (Before Watershed)\\n{markers.max()} regions marked\", fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Step 8: Apply watershed (need color image)\n",
    "coins_color = cv.cvtColor(coins_img, cv.COLOR_GRAY2BGR)\n",
    "markers_watershed = cv.watershed(coins_color, markers)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(markers_watershed, cmap=\"nipy_spectral\")\n",
    "plt.title(f\"After Watershed\\nBoundaries marked as -1\", fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Watershed found {markers.max()-1} objects\")\n",
    "print(f\"Boundary pixels marked as -1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Mark boundaries in red on original image\n",
    "result = coins_color.copy()\n",
    "result[markers_watershed == -1] = [0, 0, 255]  # Red boundaries\n",
    "\n",
    "# Draw bounding boxes around each object\n",
    "result_boxes = coins_color.copy()\n",
    "for marker_id in range(2, markers.max() + 1):\n",
    "    mask = np.uint8(markers_watershed == marker_id)\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        x, y, w, h = cv.boundingRect(contours[0])\n",
    "        cv.rectangle(result_boxes, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv.putText(\n",
    "            result_boxes,\n",
    "            str(marker_id - 1),\n",
    "            (x + 5, y + 20),\n",
    "            cv.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            (255, 255, 0),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "# Display final results\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv.cvtColor(coins_color, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Overlapping Circles\", fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(cv.cvtColor(result, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Watershed Boundaries (Red)\", fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv.cvtColor(result_boxes, cv.COLOR_BGR2RGB))\n",
    "plt.title(f\"Detected Objects: {markers.max()-1}\", fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Successfully separated {markers.max()-1} overlapping objects!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Coin Counting Application\n",
    "\n",
    "Let's build a more realistic coin counting example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create more realistic coin image\n",
    "coin_scene = np.zeros((400, 500), dtype=np.uint8)\n",
    "\n",
    "# Add multiple overlapping coins with slight variations\n",
    "np.random.seed(42)\n",
    "coin_positions = [\n",
    "    (80, 100, 45),\n",
    "    (150, 110, 48),\n",
    "    (90, 180, 46),\n",
    "    (180, 190, 44),\n",
    "    (260, 120, 50),\n",
    "    (340, 130, 47),\n",
    "    (290, 210, 45),\n",
    "    (380, 220, 46),\n",
    "    (430, 140, 48),\n",
    "    (150, 290, 44),\n",
    "    (240, 310, 49),\n",
    "    (350, 320, 45),\n",
    "]\n",
    "\n",
    "for x, y, r in coin_positions:\n",
    "    intensity = np.random.randint(200, 240)\n",
    "    cv.circle(coin_scene, (x, y), r, intensity, -1)\n",
    "\n",
    "# Add some noise\n",
    "noise = np.random.normal(0, 10, coin_scene.shape).astype(np.int16)\n",
    "coin_scene = np.clip(coin_scene.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Apply watershed\n",
    "# 1. Threshold\n",
    "_, binary = cv.threshold(coin_scene, 100, 255, cv.THRESH_BINARY)\n",
    "\n",
    "# 2. Noise removal\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "opening = cv.morphologyEx(binary, cv.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "# 3. Sure background\n",
    "sure_bg = cv.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "# 4. Distance transform for sure foreground\n",
    "dist_transform = cv.distanceTransform(opening, cv.DIST_L2, 5)\n",
    "_, sure_fg = cv.threshold(dist_transform, 0.4 * dist_transform.max(), 255, 0)\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "# 5. Unknown region\n",
    "unknown = cv.subtract(sure_bg, sure_fg)\n",
    "\n",
    "# 6. Marker labeling\n",
    "_, markers = cv.connectedComponents(sure_fg)\n",
    "markers = markers + 1\n",
    "markers[unknown == 255] = 0\n",
    "\n",
    "# 7. Watershed\n",
    "coin_color = cv.cvtColor(coin_scene, cv.COLOR_GRAY2BGR)\n",
    "markers = cv.watershed(coin_color, markers)\n",
    "\n",
    "# 8. Count and mark coins\n",
    "coin_result = coin_color.copy()\n",
    "coin_result[markers == -1] = [0, 0, 255]\n",
    "\n",
    "num_coins = markers.max() - 1\n",
    "\n",
    "# Draw circles around each coin\n",
    "for marker_id in range(2, markers.max() + 1):\n",
    "    mask = np.uint8(markers == marker_id)\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        (x, y), radius = cv.minEnclosingCircle(contours[0])\n",
    "        cv.circle(coin_result, (int(x), int(y)), int(radius), (0, 255, 0), 2)\n",
    "        cv.putText(\n",
    "            coin_result,\n",
    "            str(marker_id - 1),\n",
    "            (int(x) - 10, int(y) + 5),\n",
    "            cv.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            (255, 255, 0),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(coin_scene, cmap=\"gray\")\n",
    "plt.title(\"Coin Image (with overlaps)\", fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(markers, cmap=\"nipy_spectral\")\n",
    "plt.title(f\"Watershed Segmentation\\n{num_coins} regions found\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv.cvtColor(coin_result, cv.COLOR_BGR2RGB))\n",
    "plt.title(f\"Coin Counter Result\\nTotal Coins: {num_coins}\", fontsize=14, fontweight=\"bold\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"COIN COUNTING RESULT: {num_coins} coins detected\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Cell Counting Application\n",
    "\n",
    "Watershed is particularly useful in microscopy for counting cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate microscopy image with cells\n",
    "cell_img = np.zeros((400, 500), dtype=np.uint8)\n",
    "\n",
    "# Add cell-like circles\n",
    "np.random.seed(123)\n",
    "cell_positions = []\n",
    "for _ in range(25):\n",
    "    x = np.random.randint(40, 460)\n",
    "    y = np.random.randint(40, 360)\n",
    "    r = np.random.randint(18, 28)\n",
    "    cell_positions.append((x, y, r))\n",
    "\n",
    "for x, y, r in cell_positions:\n",
    "    intensity = np.random.randint(180, 230)\n",
    "    cv.circle(cell_img, (x, y), r, intensity, -1)\n",
    "    # Add nucleus (brighter center)\n",
    "    cv.circle(\n",
    "        cell_img,\n",
    "        (x + np.random.randint(-3, 3), y + np.random.randint(-3, 3)),\n",
    "        int(r * 0.4),\n",
    "        250,\n",
    "        -1,\n",
    "    )\n",
    "\n",
    "# Add background texture\n",
    "noise = np.random.normal(30, 15, cell_img.shape).astype(np.int16)\n",
    "cell_img = np.clip(cell_img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Apply Gaussian blur to smooth\n",
    "cell_img = cv.GaussianBlur(cell_img, (5, 5), 0)\n",
    "\n",
    "# Watershed segmentation\n",
    "# 1. Otsu thresholding\n",
    "_, binary = cv.threshold(cell_img, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "\n",
    "# 2. Noise removal\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "opening = cv.morphologyEx(binary, cv.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "# 3. Sure background\n",
    "sure_bg = cv.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "# 4. Sure foreground (distance transform)\n",
    "dist_transform = cv.distanceTransform(opening, cv.DIST_L2, 5)\n",
    "_, sure_fg = cv.threshold(dist_transform, 0.5 * dist_transform.max(), 255, 0)\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "# 5. Unknown region\n",
    "unknown = cv.subtract(sure_bg, sure_fg)\n",
    "\n",
    "# 6. Markers\n",
    "_, markers = cv.connectedComponents(sure_fg)\n",
    "markers = markers + 1\n",
    "markers[unknown == 255] = 0\n",
    "\n",
    "# 7. Watershed\n",
    "cell_color = cv.cvtColor(cell_img, cv.COLOR_GRAY2BGR)\n",
    "markers = cv.watershed(cell_color, markers)\n",
    "\n",
    "# 8. Analyze results\n",
    "cell_result = cell_color.copy()\n",
    "cell_result[markers == -1] = [0, 0, 255]\n",
    "\n",
    "num_cells = markers.max() - 1\n",
    "\n",
    "# Calculate cell sizes\n",
    "cell_sizes = []\n",
    "for marker_id in range(2, markers.max() + 1):\n",
    "    mask = np.uint8(markers == marker_id)\n",
    "    area = np.sum(mask)\n",
    "    cell_sizes.append(area)\n",
    "\n",
    "    # Draw contour\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        cv.drawContours(cell_result, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(cell_img, cmap=\"gray\")\n",
    "plt.title(\"Microscopy Image (Simulated)\", fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(binary, cmap=\"gray\")\n",
    "plt.title(\"After Otsu Thresholding\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(dist_transform, cmap=\"hot\")\n",
    "plt.title(\"Distance Transform\", fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(sure_fg, cmap=\"gray\")\n",
    "plt.title(\"Sure Foreground (Seeds)\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(markers, cmap=\"nipy_spectral\")\n",
    "plt.title(f\"Watershed Result\\n{num_cells} cells segmented\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(cv.cvtColor(cell_result, cv.COLOR_BGR2RGB))\n",
    "plt.title(f\"Cell Detection\\nTotal: {num_cells} cells\", fontsize=14, fontweight=\"bold\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"CELL ANALYSIS REPORT\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total cells detected: {num_cells}\")\n",
    "print(f\"Average cell size: {np.mean(cell_sizes):.1f} pixels\")\n",
    "print(f\"Smallest cell: {np.min(cell_sizes)} pixels\")\n",
    "print(f\"Largest cell: {np.max(cell_sizes)} pixels\")\n",
    "print(f\"Standard deviation: {np.std(cell_sizes):.1f} pixels\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Comparison - Simple Threshold vs Watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create challenging image with many overlapping objects\n",
    "challenge_img = np.zeros((300, 400), dtype=np.uint8)\n",
    "\n",
    "# Add many overlapping circles\n",
    "circles = [\n",
    "    (80, 80, 40),\n",
    "    (130, 80, 38),\n",
    "    (180, 85, 42),\n",
    "    (100, 140, 39),\n",
    "    (155, 145, 41),\n",
    "    (95, 200, 40),\n",
    "    (160, 205, 38),\n",
    "    (250, 100, 45),\n",
    "    (300, 110, 43),\n",
    "    (270, 180, 40),\n",
    "    (330, 190, 42),\n",
    "]\n",
    "\n",
    "for x, y, r in circles:\n",
    "    cv.circle(challenge_img, (x, y), r, 220, -1)\n",
    "\n",
    "# Method 1: Simple connected components\n",
    "_, binary_simple = cv.threshold(challenge_img, 100, 255, cv.THRESH_BINARY)\n",
    "num_simple, labels_simple = cv.connectedComponents(binary_simple)\n",
    "\n",
    "# Method 2: Watershed\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "opening = cv.morphologyEx(binary_simple, cv.MORPH_OPEN, kernel, iterations=2)\n",
    "sure_bg = cv.dilate(opening, kernel, iterations=3)\n",
    "dist_transform = cv.distanceTransform(opening, cv.DIST_L2, 5)\n",
    "_, sure_fg = cv.threshold(dist_transform, 0.5 * dist_transform.max(), 255, 0)\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv.subtract(sure_bg, sure_fg)\n",
    "_, markers = cv.connectedComponents(sure_fg)\n",
    "markers = markers + 1\n",
    "markers[unknown == 255] = 0\n",
    "challenge_color = cv.cvtColor(challenge_img, cv.COLOR_GRAY2BGR)\n",
    "markers = cv.watershed(challenge_color, markers)\n",
    "num_watershed = markers.max() - 1\n",
    "\n",
    "# Visualize comparison\n",
    "result_simple = challenge_color.copy()\n",
    "result_watershed = challenge_color.copy()\n",
    "result_watershed[markers == -1] = [0, 0, 255]\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(challenge_img, cmap=\"gray\")\n",
    "plt.title(\"Original: 11 Overlapping Objects\", fontsize=14, fontweight=\"bold\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(labels_simple, cmap=\"nipy_spectral\")\n",
    "plt.title(f\"Simple Threshold\\nDetected: {num_simple-1} objects ‚ùå\", fontsize=12, color=\"red\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(cv.cvtColor(result_simple, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Simple Threshold Result\\n(Fails with overlaps)\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(dist_transform, cmap=\"hot\")\n",
    "plt.title(\"Distance Transform\\n(Shows object centers)\", fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(markers, cmap=\"nipy_spectral\")\n",
    "plt.title(\n",
    "    f\"Watershed Segmentation\\nDetected: {num_watershed} objects ‚úì\", fontsize=12, color=\"green\"\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(cv.cvtColor(result_watershed, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Watershed Result\\n(Separates overlaps!)\", fontsize=12)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"COMPARISON RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Ground truth: 11 objects\")\n",
    "print(f\"Simple threshold: {num_simple-1} objects (INCORRECT)\")\n",
    "print(f\"Watershed: {num_watershed} objects (CORRECT!)\")\n",
    "print(f\"\\nWatershed successfully separates overlapping objects!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Practical Exercises\n",
    "\n",
    "### Exercise 1: Adjust Watershed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Take the coin counting example above\n",
    "# Experiment with different parameters:\n",
    "# - Distance transform threshold (0.3, 0.4, 0.5, 0.6, 0.7)\n",
    "# - Morphological opening iterations\n",
    "# - Dilation iterations for sure background\n",
    "# See how each parameter affects segmentation quality\n",
    "\n",
    "print(\"Try different parameter values and observe the results!\")\n",
    "print(\"Hint: Lower distance threshold = more aggressive separation\")\n",
    "print(\"Hint: Higher distance threshold = more conservative separation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "### Exercise 2: Build an Automated Object Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a function that takes an image and returns:\n",
    "# - Number of objects\n",
    "# - Average object size\n",
    "# - List of object areas\n",
    "# - Visualized result with labels\n",
    "\n",
    "\n",
    "def count_objects(image, dist_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Count objects in an image using watershed segmentation.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input grayscale image\n",
    "    - dist_threshold: Distance transform threshold (0-1)\n",
    "\n",
    "    Returns:\n",
    "    - num_objects: Number of detected objects\n",
    "    - areas: List of object areas\n",
    "    - result_image: Segmented result image\n",
    "    \"\"\"\n",
    "    # Your implementation here!\n",
    "    pass\n",
    "\n",
    "\n",
    "print(\"Implement the count_objects function!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "### Exercise 3: Handle Different Object Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create an image with:\n",
    "# - Different sized objects (small, medium, large)\n",
    "# - Different shapes (circles, ellipses, rectangles)\n",
    "# - Varying brightness levels\n",
    "# Apply watershed and see how well it handles diversity\n",
    "\n",
    "print(\"Test watershed robustness with diverse objects!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Congratulations! You've completed Image Segmentation. You now know:\n",
    "\n",
    "‚úì Image segmentation concepts and applications  \n",
    "‚úì Supervised vs unsupervised thresholding  \n",
    "‚úì Otsu's automatic thresholding  \n",
    "‚úì Watershed algorithm theory and implementation  \n",
    "‚úì Marker-based watershed segmentation  \n",
    "‚úì Distance transform for marker creation  \n",
    "‚úì Separating overlapping objects  \n",
    "‚úì Object counting and size analysis  \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Watershed treats image as topography** - valleys and peaks\n",
    "2. **Markers guide segmentation** - prevents over-segmentation\n",
    "3. **Distance transform finds object centers** - creates good markers\n",
    "4. **Morphology is essential** - opening removes noise, dilation finds background\n",
    "5. **Watershed separates touching objects** - where simple threshold fails\n",
    "6. **Parameters matter** - distance threshold controls separation aggressiveness\n",
    "7. **Works best on blob-like objects** - circles, cells, coins\n",
    "\n",
    "---\n",
    "\n",
    "## Watershed Algorithm Steps Summary\n",
    "\n",
    "1. **Preprocessing** - Threshold, denoise with opening\n",
    "2. **Sure background** - Dilate to get definite background\n",
    "3. **Distance transform** - Find distance to nearest background pixel\n",
    "4. **Sure foreground** - Threshold distance transform to get object centers\n",
    "5. **Unknown region** - Subtract foreground from background\n",
    "6. **Create markers** - Label connected components\n",
    "7. **Apply watershed** - Find boundaries between markers\n",
    "8. **Extract results** - Count objects, analyze sizes, draw boundaries\n",
    "\n",
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "In the next notebook (**07_feature_detection.ipynb**), you'll learn:\n",
    "- Corner detection (Harris, Shi-Tomasi)\n",
    "- Scale-invariant features (SIFT)\n",
    "- Fast feature detection (FAST, ORB)\n",
    "- Feature descriptors and keypoints\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "- **Medical Imaging**: Cell counting, tumor segmentation, tissue analysis\n",
    "- **Manufacturing**: Part counting, defect detection, quality inspection\n",
    "- **Agriculture**: Fruit counting, crop analysis, yield estimation\n",
    "- **Biology**: Microscopy analysis, colony counting, organism tracking\n",
    "- **Materials Science**: Particle analysis, grain size measurement\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Coding!** üî¨üìä"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
