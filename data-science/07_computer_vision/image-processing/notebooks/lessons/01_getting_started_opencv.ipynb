{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with OpenCV\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- Load and display images using OpenCV\n",
    "- Save images to files\n",
    "- Work with video files and webcam feeds\n",
    "- Draw shapes (lines, rectangles, circles, etc.) on images\n",
    "- Add text to images\n",
    "- Understand the \"Tiga Sekawan\" and \"Empat Sekawan\" concepts\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**‚è±Ô∏è Estimated Time**: 60-90 minutes  \n",
    "**üìö Level**: Beginner  \n",
    "**üìã Prerequisites**: Completed notebook 00 (Setup and Introduction)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the libraries we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Configure matplotlib for better display in notebooks\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory for this notebook\n",
    "output_dir = \"outputs/notebook_01\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Output directory created: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Working with Images\n",
    "\n",
    "### The \"Tiga Sekawan\" (Three Companions)\n",
    "\n",
    "When working with images in OpenCV, you'll use these three essential functions:\n",
    "\n",
    "1. **`cv.imread()`** - Read an image from a file\n",
    "2. **`cv.imshow()`** - Display an image in a window\n",
    "3. **`cv.waitKey()`** - Wait for a keyboard press\n",
    "\n",
    "### Loading an Image\n",
    "\n",
    "Let's start by creating a sample image to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample image (since we might not have external images yet)\n",
    "# Create a colorful gradient image\n",
    "sample_image = np.zeros((400, 600, 3), dtype=np.uint8)\n",
    "\n",
    "# Create a gradient effect\n",
    "for i in range(400):\n",
    "    for j in range(600):\n",
    "        sample_image[i, j] = [int(i / 400 * 255), int(j / 600 * 255), 128]\n",
    "\n",
    "# Save this as our sample image\n",
    "try:\n",
    "    success = cv.imwrite(f\"{output_dir}/sample_image.jpg\", sample_image)\n",
    "    if not success:\n",
    "        raise IOError(\"Failed to save image\")\n",
    "    print(f\"Sample image created and saved as '{output_dir}/sample_image.jpg'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving image: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's load the image using cv.imread()\n",
    "img = cv.imread(f\"{output_dir}/sample_image.jpg\")\n",
    "\n",
    "# Check if image was loaded successfully\n",
    "if img is None:\n",
    "    print(\"Error: Could not load image!\")\n",
    "else:\n",
    "    print(\"Image loaded successfully!\")\n",
    "    print(f\"Image shape: {img.shape}\")  # (height, width, channels)\n",
    "    print(f\"Image size: {img.size} pixels\")  # total number of elements\n",
    "    print(f\"Image data type: {img.dtype}\")  # data type of pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Images\n",
    "\n",
    "**Important Note**: OpenCV uses BGR (Blue-Green-Red) color format, while most other libraries use RGB (Red-Green-Blue).\n",
    "\n",
    "When displaying images with Matplotlib, we need to convert BGR to RGB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display using Matplotlib (recommended for Jupyter notebooks)\n",
    "# Convert BGR to RGB for correct color display\n",
    "img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"Sample Image (RGB)\")\n",
    "plt.axis(\"off\")  # Hide axis\n",
    "plt.show()\n",
    "\n",
    "print(\"Image displayed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if we don't convert BGR to RGB?\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# BGR (incorrect colors)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Without BGR‚ÜíRGB Conversion (Wrong Colors!)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# RGB (correct colors)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"With BGR‚ÜíRGB Conversion (Correct Colors!)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Images\n",
    "\n",
    "You can save images using `cv.imwrite()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the image with a new name\n",
    "try:\n",
    "    success = cv.imwrite(f\"{output_dir}/saved_image.jpg\", img)\n",
    "    if not success:\n",
    "        raise IOError(\"Failed to save image\")\n",
    "    print(f\"Image saved successfully as '{output_dir}/saved_image.jpg'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving image: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Working with Video\n",
    "\n",
    "### The \"Empat Sekawan\" (Four Companions)\n",
    "\n",
    "For video processing, you need four essential functions:\n",
    "\n",
    "1. **`cv.VideoCapture()`** - Capture video from camera or file\n",
    "2. **`cap.read()`** - Read a frame from the video\n",
    "3. **`cv.imshow()`** - Display the frame\n",
    "4. **`cap.release()`** - Release the video capture object\n",
    "\n",
    "### Understanding Video\n",
    "\n",
    "A video is simply a sequence of images (called frames) displayed rapidly:\n",
    "- Typical frame rate: 24-30 frames per second (fps)\n",
    "- Each frame is an image that can be processed individually\n",
    "\n",
    "### Creating a Sample Video\n",
    "\n",
    "Let's create a simple animated video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample video (a moving circle)\n",
    "# Video parameters\n",
    "frame_width = 640\n",
    "frame_height = 480\n",
    "fps = 30\n",
    "duration = 3  # seconds\n",
    "total_frames = fps * duration\n",
    "\n",
    "try:\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv.VideoWriter_fourcc(*\"mp4v\")  # or 'XVID'\n",
    "    out = cv.VideoWriter(f\"{output_dir}/sample_video.mp4\", fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    if not out.isOpened():\n",
    "        raise IOError(\"Failed to open video writer\")\n",
    "\n",
    "    # Create frames with a moving circle\n",
    "    for i in range(total_frames):\n",
    "        # Create a blank frame\n",
    "        frame = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)\n",
    "\n",
    "        # Calculate circle position (moves from left to right)\n",
    "        x = int((i / total_frames) * frame_width)\n",
    "        y = frame_height // 2\n",
    "\n",
    "        # Draw a red circle\n",
    "        cv.circle(frame, (x, y), 30, (0, 0, 255), -1)\n",
    "\n",
    "        # Write the frame\n",
    "        out.write(frame)\n",
    "\n",
    "    # Release the video writer\n",
    "    out.release()\n",
    "    print(f\"Sample video created: {total_frames} frames at {fps} fps\")\n",
    "    print(f\"Video saved as '{output_dir}/sample_video.mp4'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating video: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Video from File\n",
    "\n",
    "Now let's read the video we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video file\n",
    "cap = cv.VideoCapture(f\"{output_dir}/sample_video.mp4\")\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file\")\n",
    "else:\n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv.CAP_PROP_FPS))\n",
    "    frame_count = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(\"Video Properties:\")\n",
    "    print(f\"  Resolution: {width}x{height}\")\n",
    "    print(f\"  FPS: {fps}\")\n",
    "    print(f\"  Total frames: {frame_count}\")\n",
    "    print(f\"  Duration: {frame_count/fps:.2f} seconds\")\n",
    "\n",
    "    # Release the capture\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and display specific frames\n",
    "cap = cv.VideoCapture(f\"{output_dir}/sample_video.mp4\")\n",
    "\n",
    "# Display frames at different time points\n",
    "frame_numbers = [0, 30, 60]  # Frame 0, 30, and 60\n",
    "frames = []\n",
    "\n",
    "for frame_num in frame_numbers:\n",
    "    # Set the frame position\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, frame_num)\n",
    "\n",
    "    # Read the frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        frames.append(cv.cvtColor(frame, cv.COLOR_BGR2RGB))\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Display the frames\n",
    "plt.figure(figsize=(15, 4))\n",
    "for i, frame in enumerate(frames):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(frame)\n",
    "    plt.title(f\"Frame {frame_numbers[i]}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Displayed three frames from the video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to Grayscale (for Faster Processing)\n",
    "\n",
    "Grayscale images are often used in video processing because:\n",
    "- They're faster to process (1 channel instead of 3)\n",
    "- They require less memory\n",
    "- Many computer vision algorithms work better with grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a frame and convert to grayscale\n",
    "cap = cv.VideoCapture(f\"{output_dir}/sample_video.mp4\")\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    # Convert to grayscale\n",
    "    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display comparison\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv.cvtColor(frame, cv.COLOR_BGR2RGB))\n",
    "    plt.title(\"Original (Color)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(gray_frame, cmap=\"gray\")\n",
    "    plt.title(\"Grayscale\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Color frame shape: {frame.shape}\")\n",
    "    print(f\"Gray frame shape: {gray_frame.shape}\")\n",
    "    print(f\"Memory reduced by ~{(1 - gray_frame.size/frame.size)*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Drawing Functions in OpenCV\n",
    "\n",
    "OpenCV provides powerful functions to draw shapes and text on images. This is useful for:\n",
    "- Marking detected objects\n",
    "- Creating annotations\n",
    "- Visualizing results\n",
    "- Creating graphics\n",
    "\n",
    "### Creating a Canvas\n",
    "\n",
    "Let's create a blank canvas to draw on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a white canvas\n",
    "canvas = np.ones((512, 512, 3), dtype=np.uint8) * 255\n",
    "\n",
    "print(\"Canvas created (512x512 pixels, white background)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a line\n",
    "# cv.line(image, start_point, end_point, color, thickness)\n",
    "line_img = canvas.copy()\n",
    "\n",
    "# Draw a blue diagonal line\n",
    "cv.line(line_img, (50, 50), (450, 450), (255, 0, 0), 3)\n",
    "\n",
    "# Draw a red horizontal line\n",
    "cv.line(line_img, (50, 256), (450, 256), (0, 0, 255), 5)\n",
    "\n",
    "# Draw a green vertical line\n",
    "cv.line(line_img, (256, 50), (256, 450), (0, 255, 0), 2)\n",
    "\n",
    "plt.imshow(cv.cvtColor(line_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Drawing Lines\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing Rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw rectangles\n",
    "# cv.rectangle(image, top_left, bottom_right, color, thickness)\n",
    "# Use thickness=-1 for filled rectangle\n",
    "rect_img = canvas.copy()\n",
    "\n",
    "# Filled red rectangle\n",
    "cv.rectangle(rect_img, (50, 50), (200, 150), (0, 0, 255), -1)\n",
    "\n",
    "# Blue rectangle outline\n",
    "cv.rectangle(rect_img, (250, 250), (450, 400), (255, 0, 0), 3)\n",
    "\n",
    "# Green rectangle with thin outline\n",
    "cv.rectangle(rect_img, (50, 300), (150, 450), (0, 255, 0), 2)\n",
    "\n",
    "plt.imshow(cv.cvtColor(rect_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Drawing Rectangles\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw circles\n",
    "# cv.circle(image, center, radius, color, thickness)\n",
    "circle_img = canvas.copy()\n",
    "\n",
    "# Filled yellow circle\n",
    "cv.circle(circle_img, (256, 256), 100, (0, 255, 255), -1)\n",
    "\n",
    "# Red circle outline\n",
    "cv.circle(circle_img, (150, 150), 60, (0, 0, 255), 3)\n",
    "\n",
    "# Blue circle with thick outline\n",
    "cv.circle(circle_img, (380, 380), 80, (255, 0, 0), 5)\n",
    "\n",
    "plt.imshow(cv.cvtColor(circle_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Drawing Circles\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing Ellipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw ellipses\n",
    "# cv.ellipse(image, center, (major_axis, minor_axis), angle, start_angle, end_angle, color, thickness)\n",
    "ellipse_img = canvas.copy()\n",
    "\n",
    "# Full ellipse (0¬∞ to 360¬∞)\n",
    "cv.ellipse(ellipse_img, (256, 256), (150, 80), 0, 0, 360, (255, 0, 0), 3)\n",
    "\n",
    "# Half ellipse (0¬∞ to 180¬∞) - rotated 45¬∞\n",
    "cv.ellipse(ellipse_img, (256, 256), (100, 60), 45, 0, 180, (0, 255, 0), 2)\n",
    "\n",
    "# Quarter ellipse (filled)\n",
    "cv.ellipse(ellipse_img, (400, 100), (70, 40), 0, 0, 90, (0, 0, 255), -1)\n",
    "\n",
    "plt.imshow(cv.cvtColor(ellipse_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Drawing Ellipses\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw polygons\n",
    "# cv.polylines(image, [points], is_closed, color, thickness)\n",
    "poly_img = canvas.copy()\n",
    "\n",
    "# Triangle (closed)\n",
    "triangle = np.array([[256, 100], [150, 300], [362, 300]], np.int32)\n",
    "cv.polylines(poly_img, [triangle], True, (0, 0, 255), 3)\n",
    "\n",
    "# Pentagon (filled)\n",
    "pentagon = np.array([[100, 100], [180, 70], [220, 130], [180, 180], [100, 150]], np.int32)\n",
    "cv.fillPoly(poly_img, [pentagon], (255, 0, 0))\n",
    "\n",
    "# Star shape (open - not closed)\n",
    "star = np.array(\n",
    "    [\n",
    "        [400, 400],\n",
    "        [420, 450],\n",
    "        [450, 460],\n",
    "        [420, 480],\n",
    "        [430, 510],\n",
    "        [400, 490],\n",
    "        [370, 510],\n",
    "        [380, 480],\n",
    "        [350, 460],\n",
    "        [380, 450],\n",
    "    ],\n",
    "    np.int32,\n",
    ")\n",
    "cv.polylines(poly_img, [star], False, (0, 255, 0), 2)\n",
    "\n",
    "plt.imshow(cv.cvtColor(poly_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Drawing Polygons\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Text to Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add text to images\n",
    "# cv.putText(image, text, position, font, font_scale, color, thickness)\n",
    "text_img = canvas.copy()\n",
    "\n",
    "# Different fonts\n",
    "font1 = cv.FONT_HERSHEY_SIMPLEX\n",
    "font2 = cv.FONT_HERSHEY_COMPLEX\n",
    "font3 = cv.FONT_HERSHEY_SCRIPT_SIMPLEX\n",
    "\n",
    "# Add text with different fonts and styles\n",
    "cv.putText(text_img, \"HERSHEY_SIMPLEX\", (50, 100), font1, 1, (0, 0, 0), 2)\n",
    "cv.putText(text_img, \"HERSHEY_COMPLEX\", (50, 200), font2, 1, (255, 0, 0), 2)\n",
    "cv.putText(text_img, \"SCRIPT_SIMPLEX\", (50, 300), font3, 1, (0, 255, 0), 2)\n",
    "\n",
    "# Large bold text\n",
    "cv.putText(text_img, \"OpenCV!\", (100, 450), font1, 2, (0, 0, 255), 4)\n",
    "\n",
    "plt.imshow(cv.cvtColor(text_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Adding Text\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining All Drawing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complex drawing\n",
    "art = np.ones((512, 512, 3), dtype=np.uint8) * 255\n",
    "\n",
    "# Draw a house\n",
    "# House base (rectangle)\n",
    "cv.rectangle(art, (150, 250), (350, 450), (139, 69, 19), -1)\n",
    "\n",
    "# Roof (triangle)\n",
    "roof = np.array([[250, 150], [100, 250], [400, 250]], np.int32)\n",
    "cv.fillPoly(art, [roof], (0, 0, 200))\n",
    "\n",
    "# Door (rectangle)\n",
    "cv.rectangle(art, (220, 350), (280, 450), (101, 67, 33), -1)\n",
    "\n",
    "# Windows (rectangles)\n",
    "cv.rectangle(art, (170, 280), (220, 320), (135, 206, 235), -1)\n",
    "cv.rectangle(art, (280, 280), (330, 320), (135, 206, 235), -1)\n",
    "\n",
    "# Sun (circle)\n",
    "cv.circle(art, (450, 80), 40, (0, 255, 255), -1)\n",
    "\n",
    "# Ground (line)\n",
    "cv.line(art, (0, 450), (512, 450), (0, 100, 0), 3)\n",
    "\n",
    "# Title\n",
    "cv.putText(art, \"My House\", (180, 500), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "plt.imshow(cv.cvtColor(art, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Combined Drawing - A House\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Save the artwork\n",
    "try:\n",
    "    success = cv.imwrite(f\"{output_dir}/my_house.jpg\", art)\n",
    "    if not success:\n",
    "        raise IOError(\"Failed to save image\")\n",
    "    print(f\"Artwork saved as '{output_dir}/my_house.jpg'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving artwork: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Practical Exercises\n",
    "\n",
    "### Exercise 1: Create the OpenCV Logo\n",
    "\n",
    "Try to recreate the OpenCV logo (or any logo you like) using drawing functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Create your own logo\n",
    "# TODO: Use drawing functions to create a logo or icon\n",
    "\n",
    "logo = np.ones((400, 400, 3), dtype=np.uint8) * 255\n",
    "\n",
    "# Your code here - be creative!\n",
    "# Hints:\n",
    "# - Use circles for round shapes\n",
    "# - Use rectangles for boxes\n",
    "# - Use lines for connections\n",
    "# - Use text to add labels\n",
    "\n",
    "# Example starter code (replace with your design):\n",
    "cv.circle(logo, (200, 200), 80, (255, 0, 0), -1)\n",
    "cv.putText(logo, \"LOGO\", (140, 210), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "plt.imshow(cv.cvtColor(logo, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"My Logo\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Create an Animated GIF\n",
    "\n",
    "Create a simple animation by drawing shapes at different positions across multiple frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Create an animation\n",
    "# TODO: Create multiple frames showing an object moving or changing\n",
    "\n",
    "frames_list = []\n",
    "num_frames = 10\n",
    "\n",
    "for i in range(num_frames):\n",
    "    frame = np.ones((300, 400, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    # TODO: Draw something that changes position/size/color\n",
    "    # Hint: Use the variable 'i' to change properties\n",
    "\n",
    "    # Example: A growing circle\n",
    "    radius = 20 + (i * 10)\n",
    "    cv.circle(frame, (200, 150), radius, (0, 0, 255), -1)\n",
    "\n",
    "    frames_list.append(cv.cvtColor(frame, cv.COLOR_BGR2RGB))\n",
    "\n",
    "# Display some frames\n",
    "plt.figure(figsize=(15, 3))\n",
    "for idx, frame_num in enumerate([0, 4, 9]):\n",
    "    plt.subplot(1, 3, idx + 1)\n",
    "    plt.imshow(frames_list[frame_num])\n",
    "    plt.title(f\"Frame {frame_num}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Draw a Simple Face\n",
    "\n",
    "Create a smiley face using circles, ellipses, and arcs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Draw a face\n",
    "# TODO: Create a smiley face\n",
    "\n",
    "face = np.ones((400, 400, 3), dtype=np.uint8) * 255\n",
    "\n",
    "# Hints:\n",
    "# - Face outline: large circle\n",
    "# - Eyes: two small filled circles\n",
    "# - Smile: an arc (use cv.ellipse with partial angles)\n",
    "\n",
    "# Your code here!\n",
    "\n",
    "plt.imshow(cv.cvtColor(face, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Smiley Face\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup\n",
    "\n",
    "The following cell allows you to clean up generated files if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Cleanup generated files\n",
    "# Uncomment the lines below if you want to remove the generated files\n",
    "\n",
    "# import shutil\n",
    "# if os.path.exists(output_dir):\n",
    "#     shutil.rmtree(output_dir)\n",
    "#     print(f\"Cleaned up {output_dir}\")\n",
    "# else:\n",
    "#     print(f\"{output_dir} does not exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Congratulations! You've completed the \"Getting Started with OpenCV\" notebook. You now know:\n",
    "\n",
    "‚úì How to load, display, and save images  \n",
    "‚úì The \"Tiga Sekawan\" for images (imread, imshow, waitKey)  \n",
    "‚úì The \"Empat Sekawan\" for videos (VideoCapture, read, imshow, release)  \n",
    "‚úì How to work with video files  \n",
    "‚úì How to convert images to grayscale  \n",
    "‚úì How to draw lines, rectangles, circles, ellipses, and polygons  \n",
    "‚úì How to add text to images  \n",
    "‚úì The difference between BGR and RGB color formats  \n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **OpenCV uses BGR** (not RGB) - always convert for display with Matplotlib\n",
    "2. **Images are NumPy arrays** - you can use array operations on them\n",
    "3. **Videos are sequences of frames** - each frame is an image\n",
    "4. **Grayscale is faster** - use it when color is not important\n",
    "5. **Drawing functions are powerful** - useful for visualization and annotation\n",
    "\n",
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "In the next notebook (**02_image_basics_roi.ipynb**), you'll learn:\n",
    "- How to access and modify individual pixels\n",
    "- How to work with image properties (size, shape, type)\n",
    "- **Region of Interest (ROI)** - selecting specific parts of images\n",
    "- **Region of Non-Interest (RONI)** - masking unwanted areas\n",
    "- Splitting and merging color channels\n",
    "- Image arithmetic operations (addition, blending)\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "The skills you learned in this notebook are used in:\n",
    "\n",
    "- **Object Detection**: Drawing bounding boxes around detected objects\n",
    "- **Face Recognition**: Marking facial features with shapes\n",
    "- **Video Surveillance**: Processing video feeds frame by frame\n",
    "- **Augmented Reality**: Drawing virtual objects on real images\n",
    "- **Medical Imaging**: Annotating X-rays and scans\n",
    "- **Sports Analysis**: Tracking player movements in videos\n",
    "\n",
    "Keep practicing and experimenting!\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Coding!** üé®üì∑"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
