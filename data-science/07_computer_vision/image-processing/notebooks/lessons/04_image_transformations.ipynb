{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: Image Transformations\n",
    "\n",
    "Welcome to Module 4! In this notebook, you'll learn how to **transform** images in various ways.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "By the end of this module, you'll be able to:\n",
    "- **Resize** images while maintaining quality\n",
    "- **Translate** (shift) images in any direction\n",
    "- **Rotate** images around any point\n",
    "- **Correct perspective** distortion (like in document scanning)\n",
    "- Understand different **interpolation methods**\n",
    "- Implement basic **watermarking** techniques\n",
    "- Measure image quality with **PSNR**\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "- ðŸ“± **Photo resizing** for social media and web\n",
    "- ðŸ“„ **Document scanning** apps (perspective correction)\n",
    "- ðŸ”„ **Image alignment** for stitching panoramas\n",
    "- ðŸ” **Digital watermarking** for copyright protection\n",
    "- ðŸŽ¨ **Photo editing** tools\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**â±ï¸ Estimated Time**: 90-120 minutes  \n",
    "**ðŸ“š Level**: Intermediate  \n",
    "**ðŸ“‹ Prerequisites**: Completed notebooks 00-03\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# For inline plotting in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Set default figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display images side by side\n",
    "def show_images(images, titles, figsize=(15, 5), cmap=None):\n",
    "    \"\"\"\n",
    "    Display multiple images in a row.\n",
    "\n",
    "    Parameters:\n",
    "    - images: list of images to display\n",
    "    - titles: list of titles for each image\n",
    "    - figsize: tuple for figure size\n",
    "    - cmap: colormap (use 'gray' for grayscale images)\n",
    "    \"\"\"\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (img, title) in enumerate(zip(images, titles)):\n",
    "        if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "            # Convert BGR to RGB for color images\n",
    "            axes[i].imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            # Grayscale image\n",
    "            axes[i].imshow(img, cmap=\"gray\" if cmap is None else cmap)\n",
    "        axes[i].set_title(title)\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"âœ“ Helper function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample image with text and shapes for testing\n",
    "img = np.ones((400, 600, 3), dtype=np.uint8) * 255  # White background\n",
    "\n",
    "# Draw some shapes and text\n",
    "cv.rectangle(img, (50, 50), (250, 250), (255, 0, 0), -1)  # Blue rectangle\n",
    "cv.circle(img, (450, 150), 80, (0, 255, 0), -1)  # Green circle\n",
    "cv.ellipse(img, (300, 300), (100, 50), 45, 0, 360, (0, 0, 255), -1)  # Red ellipse\n",
    "cv.putText(img, \"TRANSFORM\", (150, 380), cv.FONT_HERSHEY_DUPLEX, 1.5, (0, 0, 0), 3)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Sample Image for Transformations\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Sample image created: {img.shape[1]}x{img.shape[0]} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Scaling (Resizing Images)\n",
    "\n",
    "**Scaling** changes the size of an image. You can make it larger (upscaling) or smaller (downscaling).\n",
    "\n",
    "### Key Function: `cv.resize()`\n",
    "\n",
    "```python\n",
    "resized = cv.resize(img, (new_width, new_height), interpolation=method)\n",
    "```\n",
    "\n",
    "### Interpolation Methods\n",
    "\n",
    "When resizing, pixels need to be **interpolated** (estimated). Different methods give different quality:\n",
    "\n",
    "| Method | Description | Best For |\n",
    "|--------|-------------|----------|\n",
    "| `INTER_NEAREST` | Nearest neighbor (fastest) | Quick previews, pixel art |\n",
    "| `INTER_LINEAR` | Bilinear interpolation | General shrinking |\n",
    "| `INTER_CUBIC` | Bicubic interpolation | High-quality resizing |\n",
    "| `INTER_LANCZOS4` | Lanczos (best quality) | Professional photography |\n",
    "| `INTER_AREA` | Pixel area relation | Shrinking images |\n",
    "\n",
    "**Rule of thumb**:\n",
    "- **Shrinking**: Use `INTER_AREA` or `INTER_LINEAR`\n",
    "- **Enlarging**: Use `INTER_CUBIC` or `INTER_LANCZOS4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Resize to specific dimensions\n",
    "\n",
    "# Shrink to 300x200 pixels\n",
    "small = cv.resize(img, (300, 200), interpolation=cv.INTER_AREA)\n",
    "\n",
    "# Enlarge to 900x600 pixels\n",
    "large = cv.resize(img, (900, 600), interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "show_images(\n",
    "    [small, img, large],\n",
    "    [\n",
    "        f\"Small ({small.shape[1]}x{small.shape[0]})\",\n",
    "        f\"Original ({img.shape[1]}x{img.shape[0]})\",\n",
    "        f\"Large ({large.shape[1]}x{large.shape[0]})\",\n",
    "    ],\n",
    "    figsize=(18, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Resize by scaling factor (maintaining aspect ratio)\n",
    "\n",
    "scale_percent = 50  # Resize to 50% of original size\n",
    "width = int(img.shape[1] * scale_percent / 100)\n",
    "height = int(img.shape[0] * scale_percent / 100)\n",
    "\n",
    "resized_50 = cv.resize(img, (width, height), interpolation=cv.INTER_AREA)\n",
    "\n",
    "print(f\"Original: {img.shape[1]}x{img.shape[0]}\")\n",
    "print(f\"50% scale: {resized_50.shape[1]}x{resized_50.shape[0]}\")\n",
    "\n",
    "show_images([img, resized_50], [\"Original\", \"50% Scale\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Compare interpolation methods\n",
    "\n",
    "# Create a small image for upscaling test\n",
    "small_test = cv.resize(img, (150, 100), interpolation=cv.INTER_AREA)\n",
    "\n",
    "# Upscale using different methods\n",
    "nearest = cv.resize(small_test, (600, 400), interpolation=cv.INTER_NEAREST)\n",
    "linear = cv.resize(small_test, (600, 400), interpolation=cv.INTER_LINEAR)\n",
    "cubic = cv.resize(small_test, (600, 400), interpolation=cv.INTER_CUBIC)\n",
    "lanczos = cv.resize(small_test, (600, 400), interpolation=cv.INTER_LANCZOS4)\n",
    "\n",
    "# Display comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "methods = [nearest, linear, cubic, lanczos]\n",
    "titles = [\n",
    "    \"INTER_NEAREST (Blocky)\",\n",
    "    \"INTER_LINEAR (Good)\",\n",
    "    \"INTER_CUBIC (Better)\",\n",
    "    \"INTER_LANCZOS4 (Best)\",\n",
    "]\n",
    "\n",
    "for i, (method, title) in enumerate(zip(methods, titles)):\n",
    "    row, col = i // 2, i % 2\n",
    "    axes[row, col].imshow(cv.cvtColor(method, cv.COLOR_BGR2RGB))\n",
    "    axes[row, col].set_title(title, fontsize=14)\n",
    "    axes[row, col].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice: NEAREST is blocky, while LANCZOS4 is smoothest!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Translation (Shifting Images)\n",
    "\n",
    "**Translation** means moving an image horizontally and/or vertically without rotating or resizing.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. Create a **translation matrix** (2x3 matrix)\n",
    "2. Use `cv.warpAffine()` to apply the transformation\n",
    "\n",
    "### Translation Matrix\n",
    "\n",
    "```\n",
    "M = | 1  0  tx |\n",
    "    | 0  1  ty |\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `tx` = horizontal shift (positive = right, negative = left)\n",
    "- `ty` = vertical shift (positive = down, negative = up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Shift image right and down\n",
    "\n",
    "tx = 100  # Move 100 pixels right\n",
    "ty = 50  # Move 50 pixels down\n",
    "\n",
    "# Create translation matrix\n",
    "M_translate = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "\n",
    "# Apply translation\n",
    "rows, cols = img.shape[:2]\n",
    "translated = cv.warpAffine(img, M_translate, (cols, rows))\n",
    "\n",
    "show_images([img, translated], [\"Original\", f\"Translated ({tx}px right, {ty}px down)\"])\n",
    "\n",
    "print(f\"Translation matrix:\\n{M_translate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Shift in different directions\n",
    "\n",
    "# Right\n",
    "M_right = np.float32([[1, 0, 100], [0, 1, 0]])\n",
    "shift_right = cv.warpAffine(img, M_right, (cols, rows))\n",
    "\n",
    "# Left\n",
    "M_left = np.float32([[1, 0, -100], [0, 1, 0]])\n",
    "shift_left = cv.warpAffine(img, M_left, (cols, rows))\n",
    "\n",
    "# Up\n",
    "M_up = np.float32([[1, 0, 0], [0, 1, -50]])\n",
    "shift_up = cv.warpAffine(img, M_up, (cols, rows))\n",
    "\n",
    "# Down\n",
    "M_down = np.float32([[1, 0, 0], [0, 1, 50]])\n",
    "shift_down = cv.warpAffine(img, M_down, (cols, rows))\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "shifts = [shift_right, shift_left, shift_up, shift_down]\n",
    "titles = [\"Right (+100, 0)\", \"Left (-100, 0)\", \"Up (0, -50)\", \"Down (0, +50)\"]\n",
    "\n",
    "for i, (shifted, title) in enumerate(zip(shifts, titles)):\n",
    "    row, col = i // 2, i % 2\n",
    "    axes[row, col].imshow(cv.cvtColor(shifted, cv.COLOR_BGR2RGB))\n",
    "    axes[row, col].set_title(title, fontsize=14)\n",
    "    axes[row, col].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Rotation\n",
    "\n",
    "**Rotation** spins an image around a center point by a specified angle.\n",
    "\n",
    "### Key Functions\n",
    "\n",
    "```python\n",
    "# Get rotation matrix\n",
    "M = cv.getRotationMatrix2D(center, angle, scale)\n",
    "\n",
    "# Apply rotation\n",
    "rotated = cv.warpAffine(img, M, (width, height))\n",
    "```\n",
    "\n",
    "Parameters:\n",
    "- `center`: Tuple (x, y) - point to rotate around\n",
    "- `angle`: Rotation angle in **degrees** (positive = counter-clockwise)\n",
    "- `scale`: Scaling factor (1.0 = no scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Rotate around image center\n",
    "\n",
    "# Get image center\n",
    "center_x = cols // 2\n",
    "center_y = rows // 2\n",
    "center = (center_x, center_y)\n",
    "\n",
    "# Rotate 45 degrees counter-clockwise\n",
    "angle = 45\n",
    "scale = 1.0\n",
    "\n",
    "# Get rotation matrix\n",
    "M_rotate = cv.getRotationMatrix2D(center, angle, scale)\n",
    "\n",
    "# Apply rotation\n",
    "rotated = cv.warpAffine(img, M_rotate, (cols, rows))\n",
    "\n",
    "show_images([img, rotated], [\"Original\", f\"Rotated {angle}Â°\"])\n",
    "\n",
    "print(f\"Rotation matrix:\\n{M_rotate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Rotate at different angles\n",
    "\n",
    "angles = [0, 45, 90, 135, 180, 270]\n",
    "rotated_images = []\n",
    "\n",
    "for angle in angles:\n",
    "    M = cv.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated_img = cv.warpAffine(img, M, (cols, rows))\n",
    "    rotated_images.append(rotated_img)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (rotated_img, angle) in enumerate(zip(rotated_images, angles)):\n",
    "    axes[i].imshow(cv.cvtColor(rotated_img, cv.COLOR_BGR2RGB))\n",
    "    axes[i].set_title(f\"{angle}Â°\", fontsize=14)\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Rotate without cropping (expand canvas)\n",
    "\n",
    "angle = 45\n",
    "\n",
    "# Calculate new bounding dimensions\n",
    "radians = np.deg2rad(angle)\n",
    "sin = abs(np.sin(radians))\n",
    "cos = abs(np.cos(radians))\n",
    "\n",
    "new_width = int((rows * sin) + (cols * cos))\n",
    "new_height = int((rows * cos) + (cols * sin))\n",
    "\n",
    "# Get rotation matrix\n",
    "M = cv.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "# Adjust translation to center the image\n",
    "M[0, 2] += (new_width / 2) - center_x\n",
    "M[1, 2] += (new_height / 2) - center_y\n",
    "\n",
    "# Apply rotation with expanded canvas\n",
    "rotated_full = cv.warpAffine(\n",
    "    img, M, (new_width, new_height), borderMode=cv.BORDER_CONSTANT, borderValue=(255, 255, 255)\n",
    ")\n",
    "\n",
    "# Compare cropped vs full\n",
    "M_crop = cv.getRotationMatrix2D(center, angle, 1.0)\n",
    "rotated_crop = cv.warpAffine(img, M_crop, (cols, rows))\n",
    "\n",
    "show_images(\n",
    "    [rotated_crop, rotated_full],\n",
    "    [\"Rotated (Cropped)\", \"Rotated (Full - No Cropping)\"],\n",
    "    figsize=(16, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Perspective Transformation\n",
    "\n",
    "**Perspective transformation** corrects the perspective distortion of images (like photos of documents taken at an angle).\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. Define **4 source points** (corners in original image)\n",
    "2. Define **4 destination points** (where corners should be)\n",
    "3. Get transformation matrix with `cv.getPerspectiveTransform()`\n",
    "4. Apply with `cv.warpPerspective()`\n",
    "\n",
    "**Use Cases**:\n",
    "- Document scanning apps\n",
    "- Correcting photos of whiteboards\n",
    "- Bird's eye view transformation\n",
    "- License plate normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simulate document scanning\n",
    "\n",
    "# Create a \"document\" image\n",
    "doc = np.ones((400, 300, 3), dtype=np.uint8) * 255\n",
    "cv.rectangle(doc, (20, 20), (280, 380), (0, 0, 0), 3)\n",
    "cv.putText(doc, \"DOCUMENT\", (50, 100), cv.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 2)\n",
    "cv.putText(doc, \"Line 1\", (40, 180), cv.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "cv.putText(doc, \"Line 2\", (40, 230), cv.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "cv.putText(doc, \"Line 3\", (40, 280), cv.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "\n",
    "# Apply perspective distortion (simulate angled photo)\n",
    "src_pts = np.float32([[0, 0], [300, 0], [300, 400], [0, 400]])\n",
    "dst_pts_skewed = np.float32([[50, 30], [280, 10], [320, 380], [20, 390]])\n",
    "\n",
    "M_skew = cv.getPerspectiveTransform(src_pts, dst_pts_skewed)\n",
    "skewed = cv.warpPerspective(\n",
    "    doc, M_skew, (400, 400), borderMode=cv.BORDER_CONSTANT, borderValue=(200, 200, 200)\n",
    ")\n",
    "\n",
    "# Now correct the perspective\n",
    "# Source points: corners of skewed document\n",
    "src_correction = np.float32([[50, 30], [280, 10], [320, 380], [20, 390]])\n",
    "\n",
    "# Destination points: where we want corners to be (rectangular)\n",
    "dst_correction = np.float32([[0, 0], [300, 0], [300, 400], [0, 400]])\n",
    "\n",
    "# Get perspective transform matrix\n",
    "M_correct = cv.getPerspectiveTransform(src_correction, dst_correction)\n",
    "\n",
    "# Apply correction\n",
    "corrected = cv.warpPerspective(skewed, M_correct, (300, 400))\n",
    "\n",
    "# Display\n",
    "show_images(\n",
    "    [doc, skewed, corrected],\n",
    "    [\"Original Document\", \"Skewed (Angled Photo)\", \"Corrected (Scanned)\"],\n",
    "    figsize=(18, 5),\n",
    ")\n",
    "\n",
    "print(\"âœ“ Perspective transformation applied!\")\n",
    "print(\"This is how document scanning apps work!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Digital Watermarking - LSB Method\n",
    "\n",
    "**Digital watermarking** embeds hidden information (like copyright data) into images.\n",
    "\n",
    "### LSB (Least Significant Bit) Method\n",
    "\n",
    "**Concept**: Modify the least significant bit of pixel values to hide information.\n",
    "\n",
    "**Why it works**:\n",
    "- Changing the last bit of a pixel (e.g., 255 â†’ 254) is imperceptible to human eyes\n",
    "- Can hide entire images or text\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "Pixel value: 10110110 (182)\n",
    "Hidden bit:  1\n",
    "New value:   10110111 (183)  â† Difference of 1 is invisible!\n",
    "```\n",
    "\n",
    "### Advantages and Disadvantages\n",
    "\n",
    "**Advantages**:\n",
    "- âœ… Simple to implement\n",
    "- âœ… Imperceptible to human eye\n",
    "- âœ… High capacity (can hide lots of data)\n",
    "\n",
    "**Disadvantages**:\n",
    "- âŒ Not robust (destroyed by compression, resizing, rotation)\n",
    "- âŒ Easy to remove if someone knows about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Simple LSB watermarking\n",
    "\n",
    "\n",
    "def embed_watermark_lsb(host_img, watermark_img):\n",
    "    \"\"\"\n",
    "    Embed watermark into host image using LSB method.\n",
    "\n",
    "    Parameters:\n",
    "    - host_img: Original image (will be modified)\n",
    "    - watermark_img: Watermark to hide (must be smaller or equal size)\n",
    "\n",
    "    Returns:\n",
    "    - watermarked: Image with embedded watermark\n",
    "    \"\"\"\n",
    "    # Ensure images are same size (resize watermark if needed)\n",
    "    if watermark_img.shape != host_img.shape:\n",
    "        watermark_img = cv.resize(watermark_img, (host_img.shape[1], host_img.shape[0]))\n",
    "\n",
    "    # Convert to binary (threshold)\n",
    "    if len(watermark_img.shape) == 3:\n",
    "        watermark_gray = cv.cvtColor(watermark_img, cv.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        watermark_gray = watermark_img\n",
    "\n",
    "    _, watermark_binary = cv.threshold(watermark_gray, 127, 1, cv.THRESH_BINARY)\n",
    "\n",
    "    # Create watermarked image\n",
    "    watermarked = host_img.copy()\n",
    "\n",
    "    # Embed watermark in blue channel (LSB)\n",
    "    # Clear LSB, then set it to watermark bit\n",
    "    watermarked[:, :, 0] = (watermarked[:, :, 0] & 0xFE) | watermark_binary\n",
    "\n",
    "    return watermarked\n",
    "\n",
    "\n",
    "def extract_watermark_lsb(watermarked_img):\n",
    "    \"\"\"\n",
    "    Extract watermark from watermarked image.\n",
    "\n",
    "    Parameters:\n",
    "    - watermarked_img: Image with embedded watermark\n",
    "\n",
    "    Returns:\n",
    "    - watermark: Extracted watermark\n",
    "    \"\"\"\n",
    "    # Extract LSB from blue channel\n",
    "    watermark = (watermarked_img[:, :, 0] & 1) * 255\n",
    "\n",
    "    return watermark.astype(np.uint8)\n",
    "\n",
    "\n",
    "print(\"âœ“ Watermarking functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a watermark (simple text)\n",
    "watermark = np.zeros((400, 600), dtype=np.uint8)\n",
    "cv.putText(watermark, \"COPYRIGHT\", (150, 220), cv.FONT_HERSHEY_DUPLEX, 2, 255, 4)\n",
    "\n",
    "# Embed watermark into our sample image\n",
    "watermarked = embed_watermark_lsb(img, watermark)\n",
    "\n",
    "# Extract watermark\n",
    "extracted = extract_watermark_lsb(watermarked)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title(\"Original Image\", fontsize=14)\n",
    "axes[0, 0].axis(\"off\")\n",
    "\n",
    "axes[0, 1].imshow(watermark, cmap=\"gray\")\n",
    "axes[0, 1].set_title(\"Watermark to Hide\", fontsize=14)\n",
    "axes[0, 1].axis(\"off\")\n",
    "\n",
    "axes[1, 0].imshow(cv.cvtColor(watermarked, cv.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title(\"Watermarked Image (Looks Same!)\", fontsize=14)\n",
    "axes[1, 0].axis(\"off\")\n",
    "\n",
    "axes[1, 1].imshow(extracted, cmap=\"gray\")\n",
    "axes[1, 1].set_title(\"Extracted Watermark\", fontsize=14)\n",
    "axes[1, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice: The watermarked image looks identical to the original!\")\n",
    "print(\"But the watermark is hidden in the LSB and can be extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Measuring Image Quality - PSNR\n",
    "\n",
    "**PSNR** (Peak Signal-to-Noise Ratio) measures how much an image has been degraded.\n",
    "\n",
    "### Formula\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{m \\times n} \\sum_{i=0}^{m-1} \\sum_{j=0}^{n-1} [I(i,j) - K(i,j)]^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{PSNR} = 10 \\cdot \\log_{10}\\left(\\frac{MAX^2}{MSE}\\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- `MSE` = Mean Squared Error\n",
    "- `MAX` = Maximum pixel value (255 for 8-bit images)\n",
    "\n",
    "### Interpreting PSNR\n",
    "\n",
    "| PSNR (dB) | Quality |\n",
    "|-----------|----------|\n",
    "| > 40 | Excellent (imperceptible difference) |\n",
    "| 30-40 | Good (small differences) |\n",
    "| 20-30 | Fair (noticeable differences) |\n",
    "| < 20 | Poor (significant degradation) |\n",
    "\n",
    "**Higher PSNR = Better quality (less degradation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(original, modified):\n",
    "    \"\"\"\n",
    "    Calculate PSNR between two images.\n",
    "\n",
    "    Parameters:\n",
    "    - original: Original image\n",
    "    - modified: Modified image\n",
    "\n",
    "    Returns:\n",
    "    - psnr: PSNR value in dB\n",
    "    \"\"\"\n",
    "    # Ensure images are same size\n",
    "    if original.shape != modified.shape:\n",
    "        modified = cv.resize(modified, (original.shape[1], original.shape[0]))\n",
    "\n",
    "    # Calculate MSE\n",
    "    mse = np.mean((original.astype(float) - modified.astype(float)) ** 2)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if mse == 0:\n",
    "        return float(\"inf\")  # Images are identical\n",
    "\n",
    "    # Calculate PSNR\n",
    "    max_pixel = 255.0\n",
    "    psnr = 10 * np.log10((max_pixel**2) / mse)\n",
    "\n",
    "    return psnr\n",
    "\n",
    "\n",
    "print(\"âœ“ PSNR function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test PSNR with different quality images\n",
    "\n",
    "# 1. Watermarked image (should have very high PSNR)\n",
    "psnr_watermark = calculate_psnr(img, watermarked)\n",
    "\n",
    "# 2. Slightly compressed (add small noise)\n",
    "noise = np.random.normal(0, 5, img.shape).astype(np.int16)\n",
    "slightly_degraded = np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "psnr_slight = calculate_psnr(img, slightly_degraded)\n",
    "\n",
    "# 3. Heavily compressed (add more noise)\n",
    "noise_heavy = np.random.normal(0, 20, img.shape).astype(np.int16)\n",
    "heavily_degraded = np.clip(img.astype(np.int16) + noise_heavy, 0, 255).astype(np.uint8)\n",
    "psnr_heavy = calculate_psnr(img, heavily_degraded)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title(\"Original Image\", fontsize=14)\n",
    "axes[0, 0].axis(\"off\")\n",
    "\n",
    "axes[0, 1].imshow(cv.cvtColor(watermarked, cv.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title(f\"Watermarked\\nPSNR: {psnr_watermark:.2f} dB (Excellent)\", fontsize=14)\n",
    "axes[0, 1].axis(\"off\")\n",
    "\n",
    "axes[1, 0].imshow(cv.cvtColor(slightly_degraded, cv.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title(f\"Slightly Degraded\\nPSNR: {psnr_slight:.2f} dB (Good)\", fontsize=14)\n",
    "axes[1, 0].axis(\"off\")\n",
    "\n",
    "axes[1, 1].imshow(cv.cvtColor(heavily_degraded, cv.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title(f\"Heavily Degraded\\nPSNR: {psnr_heavy:.2f} dB (Fair)\", fontsize=14)\n",
    "axes[1, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPSNR Summary:\")\n",
    "print(f\"Watermarked:        {psnr_watermark:.2f} dB (Imperceptible)\")\n",
    "print(f\"Slightly Degraded:  {psnr_slight:.2f} dB\")\n",
    "print(f\"Heavily Degraded:   {psnr_heavy:.2f} dB\")\n",
    "print(\"\\nHigher PSNR = Better quality!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Practical Exercises\n",
    "\n",
    "Now it's your turn to practice! Try these exercises to reinforce your learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Photo Resizer Tool\n",
    "\n",
    "Create a tool that resizes an image for different social media platforms:\n",
    "- Instagram Post: 1080x1080\n",
    "- Instagram Story: 1080x1920\n",
    "- Twitter Header: 1500x500\n",
    "\n",
    "Compare the quality using different interpolation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "\n",
    "# TODO: Resize 'img' to Instagram Post size (1080x1080)\n",
    "# TODO: Try INTER_LINEAR, INTER_CUBIC, and INTER_LANCZOS4\n",
    "# TODO: Display all three and compare quality\n",
    "\n",
    "# Hint: Use cv.resize() with different interpolation methods\n",
    "\n",
    "# Your solution:\n",
    "instagram_linear = cv.resize(img, (1080, 1080), interpolation=cv.INTER_LINEAR)\n",
    "instagram_cubic = cv.resize(img, (1080, 1080), interpolation=cv.INTER_CUBIC)\n",
    "instagram_lanczos = cv.resize(img, (1080, 1080), interpolation=cv.INTER_LANCZOS4)\n",
    "\n",
    "show_images(\n",
    "    [instagram_linear, instagram_cubic, instagram_lanczos],\n",
    "    [\"LINEAR\", \"CUBIC\", \"LANCZOS4\"],\n",
    "    figsize=(18, 6),\n",
    ")\n",
    "\n",
    "print(\"âœ“ Exercise 1 complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Create a 360Â° Rotation Animation\n",
    "\n",
    "Create a list of images rotated from 0Â° to 360Â° in 30Â° increments.\n",
    "Display them in a grid to show the rotation sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "\n",
    "# TODO: Create rotations from 0Â° to 360Â° in 30Â° steps\n",
    "# TODO: Display in a 3x4 grid\n",
    "\n",
    "# Your solution:\n",
    "angles = range(0, 360, 30)\n",
    "center = (img.shape[1] // 2, img.shape[0] // 2)\n",
    "rotation_sequence = []\n",
    "\n",
    "for angle in angles:\n",
    "    M = cv.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "    rotation_sequence.append(rotated)\n",
    "\n",
    "# Display in 3x4 grid\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (rotated, angle) in enumerate(zip(rotation_sequence, angles)):\n",
    "    axes[i].imshow(cv.cvtColor(rotated, cv.COLOR_BGR2RGB))\n",
    "    axes[i].set_title(f\"{angle}Â°\")\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Exercise 2 complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Test Watermark Robustness\n",
    "\n",
    "Test how robust the LSB watermark is by:\n",
    "1. Adding noise to the watermarked image\n",
    "2. Resizing it\n",
    "3. Rotating it slightly\n",
    "\n",
    "Try to extract the watermark after each modification and see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "\n",
    "# TODO: Add small noise to watermarked image\n",
    "# TODO: Try to extract watermark from noisy version\n",
    "# TODO: Compare with original extracted watermark\n",
    "\n",
    "# Your solution:\n",
    "# Add noise\n",
    "noise = np.random.normal(0, 3, watermarked.shape).astype(np.int16)\n",
    "watermarked_noisy = np.clip(watermarked.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Resize (50% then back to original size)\n",
    "small = cv.resize(watermarked, (300, 200), interpolation=cv.INTER_AREA)\n",
    "watermarked_resized = cv.resize(small, (600, 400), interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "# Extract watermarks\n",
    "extracted_noisy = extract_watermark_lsb(watermarked_noisy)\n",
    "extracted_resized = extract_watermark_lsb(watermarked_resized)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].imshow(extracted, cmap=\"gray\")\n",
    "axes[0, 0].set_title(\"Original Extracted Watermark\")\n",
    "axes[0, 0].axis(\"off\")\n",
    "\n",
    "axes[0, 1].imshow(cv.cvtColor(watermarked_noisy, cv.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title(\"Watermarked + Noise\")\n",
    "axes[0, 1].axis(\"off\")\n",
    "\n",
    "axes[1, 0].imshow(extracted_noisy, cmap=\"gray\")\n",
    "axes[1, 0].set_title(\"Extracted from Noisy (Degraded!)\")\n",
    "axes[1, 0].axis(\"off\")\n",
    "\n",
    "axes[1, 1].imshow(extracted_resized, cmap=\"gray\")\n",
    "axes[1, 1].set_title(\"Extracted from Resized (Destroyed!)\")\n",
    "axes[1, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Exercise 3 complete!\")\n",
    "print(\"Notice: LSB watermarking is NOT robust to modifications!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Congratulations! You've learned about **Image Transformations**! ðŸŽ‰\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Scaling (Resizing)**:\n",
    "   - Use `cv.resize()` with appropriate interpolation\n",
    "   - INTER_AREA for shrinking, INTER_CUBIC/LANCZOS4 for enlarging\n",
    "\n",
    "2. **Translation (Shifting)**:\n",
    "   - Create translation matrix with `np.float32([[1, 0, tx], [0, 1, ty]])`\n",
    "   - Apply with `cv.warpAffine()`\n",
    "\n",
    "3. **Rotation**:\n",
    "   - Get rotation matrix with `cv.getRotationMatrix2D(center, angle, scale)`\n",
    "   - Apply with `cv.warpAffine()`\n",
    "   - Can rotate around any point\n",
    "\n",
    "4. **Perspective Transformation**:\n",
    "   - Define 4 source and destination points\n",
    "   - Use `cv.getPerspectiveTransform()` and `cv.warpPerspective()`\n",
    "   - Perfect for document scanning and correction\n",
    "\n",
    "5. **Digital Watermarking**:\n",
    "   - LSB method hides data in least significant bits\n",
    "   - Imperceptible but not robust to modifications\n",
    "   - Use PSNR to measure quality (higher = better)\n",
    "\n",
    "### Real-World Applications You Can Build\n",
    "\n",
    "- ðŸ“± Photo resizer for social media\n",
    "- ðŸ“„ Document scanner app\n",
    "- ðŸŽ¨ Photo editor with rotation/flip tools\n",
    "- ðŸ” Copyright protection system\n",
    "- ðŸ—ºï¸ Image alignment for panoramas\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next module, you'll learn about **Morphological Operations** - powerful techniques for processing binary images and detecting shapes!\n",
    "\n",
    "---\n",
    "\n",
    "**Great work! You're making excellent progress!** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
