{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Hand Gesture Recognition (BONUS)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- Understand MediaPipe framework for hand tracking\n",
    "- Detect and track hand landmarks in real-time\n",
    "- Recognize hand gestures from landmark positions\n",
    "- Calculate distances and angles between fingers\n",
    "- Build gesture-controlled applications\n",
    "- Create interactive computer vision projects\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q5a652obc8r",
   "source": "---\n\n**‚è±Ô∏è Estimated Time**: 60-90 minutes  \n**üìö Level**: Intermediate  \n**üìã Prerequisites**: Completed notebooks 00-08\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Configure matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv.__version__}\")\n",
    "\n",
    "# Try to import MediaPipe\n",
    "try:\n",
    "    import mediapipe as mp\n",
    "\n",
    "    MEDIAPIPE_AVAILABLE = True\n",
    "    print(f\"MediaPipe version: {mp.__version__}\")\n",
    "    print(\"‚úì MediaPipe is installed and ready!\")\n",
    "except ImportError:\n",
    "    MEDIAPIPE_AVAILABLE = False\n",
    "    print(\"\\n‚ö† MediaPipe not installed\")\n",
    "    print(\"To install: pip install mediapipe\")\n",
    "    print(\"\\nThis notebook will demonstrate concepts with simulations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Introduction to Hand Gesture Recognition\n",
    "\n",
    "### What is Hand Gesture Recognition?\n",
    "\n",
    "**Hand gesture recognition** detects and interprets hand movements and poses to control applications without physical contact.\n",
    "\n",
    "### Applications:\n",
    "\n",
    "- **Gaming** - Control games with hand gestures\n",
    "- **Sign Language Translation** - Help hearing-impaired communication\n",
    "- **Virtual Reality** - Natural interaction with VR environments\n",
    "- **Smart Home Control** - Control devices with gestures\n",
    "- **Touchless Interfaces** - Hygiene-friendly controls\n",
    "- **Presentation Control** - Navigate slides with gestures\n",
    "\n",
    "### Traditional vs Modern Approaches:\n",
    "\n",
    "**Traditional (Classical CV)**:\n",
    "- Skin color detection\n",
    "- Contour analysis\n",
    "- Complex, lighting-sensitive\n",
    "\n",
    "**Modern (Deep Learning)**:\n",
    "- MediaPipe, TensorFlow models\n",
    "- Pre-trained, robust\n",
    "- Real-time, accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: MediaPipe Hand Tracking\n",
    "\n",
    "### What is MediaPipe?\n",
    "\n",
    "**MediaPipe** is Google's open-source framework for building ML pipelines. The Hand solution provides:\n",
    "\n",
    "- **21 hand landmarks** per hand\n",
    "- **Real-time performance** (30+ FPS)\n",
    "- **Multi-hand tracking** (up to 2 hands)\n",
    "- **3D coordinates** (x, y, z)\n",
    "\n",
    "### Hand Landmarks:\n",
    "\n",
    "```\n",
    "    8   12  16  20    (fingertips)\n",
    "    |   |   |   |\n",
    "    7   11  15  19\n",
    "    |   |   |   |\n",
    "    6   10  14  18\n",
    "    |   |   |   |\n",
    "    5   9   13  17\n",
    "     \\ | |  /\n",
    "       4\n",
    "       |\n",
    "  2 - 3\n",
    "  |   \n",
    "  1\n",
    "  |\n",
    "  0 (wrist)\n",
    "```\n",
    "\n",
    "**Finger indices**:\n",
    "- Thumb: 1-4\n",
    "- Index: 5-8\n",
    "- Middle: 9-12\n",
    "- Ring: 13-16\n",
    "- Pinky: 17-20\n",
    "- Wrist: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### Visualize Hand Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visualization of hand landmark structure\n",
    "def draw_hand_landmarks_diagram():\n",
    "    \"\"\"\n",
    "    Draw a diagram showing hand landmark positions and indices.\n",
    "    \"\"\"\n",
    "    img = np.ones((500, 400, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    # Define hand landmark positions (simplified)\n",
    "    landmarks = {\n",
    "        0: (200, 400),  # Wrist\n",
    "        1: (180, 350),\n",
    "        2: (160, 310),\n",
    "        3: (145, 270),\n",
    "        4: (130, 230),  # Thumb tip\n",
    "        5: (200, 300),\n",
    "        6: (200, 240),\n",
    "        7: (200, 180),\n",
    "        8: (200, 120),  # Index tip\n",
    "        9: (240, 300),\n",
    "        10: (245, 230),\n",
    "        11: (250, 170),\n",
    "        12: (250, 110),  # Middle tip\n",
    "        13: (280, 310),\n",
    "        14: (290, 240),\n",
    "        15: (295, 180),\n",
    "        16: (295, 125),  # Ring tip\n",
    "        17: (315, 330),\n",
    "        18: (325, 260),\n",
    "        19: (330, 200),\n",
    "        20: (332, 145),  # Pinky tip\n",
    "    }\n",
    "\n",
    "    # Define connections\n",
    "    connections = [\n",
    "        (0, 1),\n",
    "        (1, 2),\n",
    "        (2, 3),\n",
    "        (3, 4),  # Thumb\n",
    "        (0, 5),\n",
    "        (5, 6),\n",
    "        (6, 7),\n",
    "        (7, 8),  # Index\n",
    "        (5, 9),\n",
    "        (9, 10),\n",
    "        (10, 11),\n",
    "        (11, 12),  # Middle\n",
    "        (9, 13),\n",
    "        (13, 14),\n",
    "        (14, 15),\n",
    "        (15, 16),  # Ring\n",
    "        (13, 17),\n",
    "        (0, 17),\n",
    "        (17, 18),\n",
    "        (18, 19),\n",
    "        (19, 20),  # Pinky\n",
    "    ]\n",
    "\n",
    "    # Draw connections\n",
    "    for conn in connections:\n",
    "        pt1 = landmarks[conn[0]]\n",
    "        pt2 = landmarks[conn[1]]\n",
    "        cv.line(img, pt1, pt2, (200, 200, 200), 3)\n",
    "\n",
    "    # Draw landmarks\n",
    "    for idx, pt in landmarks.items():\n",
    "        # Color code by finger\n",
    "        if idx == 0:\n",
    "            color = (0, 0, 255)  # Wrist - red\n",
    "        elif idx <= 4:\n",
    "            color = (255, 0, 0)  # Thumb - blue\n",
    "        elif idx <= 8:\n",
    "            color = (0, 255, 0)  # Index - green\n",
    "        elif idx <= 12:\n",
    "            color = (255, 255, 0)  # Middle - cyan\n",
    "        elif idx <= 16:\n",
    "            color = (255, 0, 255)  # Ring - magenta\n",
    "        else:\n",
    "            color = (0, 255, 255)  # Pinky - yellow\n",
    "\n",
    "        cv.circle(img, pt, 8, color, -1)\n",
    "        cv.circle(img, pt, 8, (0, 0, 0), 2)\n",
    "\n",
    "        # Add index number\n",
    "        cv.putText(\n",
    "            img, str(idx), (pt[0] - 10, pt[1] - 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2\n",
    "        )\n",
    "\n",
    "    # Add legend\n",
    "    legend_y = 30\n",
    "    cv.putText(\n",
    "        img,\n",
    "        \"Hand Landmarks (21 points)\",\n",
    "        (10, legend_y),\n",
    "        cv.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (0, 0, 0),\n",
    "        2,\n",
    "    )\n",
    "    legend_y += 30\n",
    "    cv.putText(img, \"0: Wrist\", (10, legend_y), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    legend_y += 25\n",
    "    cv.putText(img, \"1-4: Thumb\", (10, legend_y), cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    legend_y += 25\n",
    "    cv.putText(img, \"5-8: Index\", (10, legend_y), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    legend_y += 25\n",
    "    cv.putText(img, \"9-12: Middle\", (10, legend_y), cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "    legend_y += 25\n",
    "    cv.putText(img, \"13-16: Ring\", (10, legend_y), cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)\n",
    "    legend_y += 25\n",
    "    cv.putText(img, \"17-20: Pinky\", (10, legend_y), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# Display\n",
    "diagram = draw_hand_landmarks_diagram()\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.imshow(cv.cvtColor(diagram, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"MediaPipe Hand Landmark Structure\", fontsize=14, fontweight=\"bold\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"MediaPipe tracks 21 landmarks per hand\")\n",
    "print(\"Each landmark has (x, y, z) coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Hand Detection with MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MEDIAPIPE_AVAILABLE:\n",
    "    # Initialize MediaPipe Hands\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "    # Create a test image with hand (simulated)\n",
    "    # In practice, you would use camera input\n",
    "    test_hand = np.ones((480, 640, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    # Draw a simulated hand\n",
    "    cv.putText(\n",
    "        test_hand,\n",
    "        \"Note: Use real hand image or webcam\",\n",
    "        (50, 50),\n",
    "        cv.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (0, 0, 255),\n",
    "        2,\n",
    "    )\n",
    "    cv.putText(\n",
    "        test_hand,\n",
    "        \"for MediaPipe hand detection\",\n",
    "        (50, 80),\n",
    "        cv.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (0, 0, 255),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "    # Example: How to use MediaPipe Hands\n",
    "    print(\"MediaPipe Hands Usage:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\n",
    "        \"\"\"    \n",
    "    # Initialize\n",
    "    with mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as hands:\n",
    "        \n",
    "        # Process image\n",
    "        image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        results = hands.process(image_rgb)\n",
    "        \n",
    "        # Check if hands detected\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Draw landmarks\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "                # Access individual landmarks\n",
    "                for idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                    # landmark.x, landmark.y, landmark.z\n",
    "                    pass\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv.cvtColor(test_hand, cv.COLOR_BGR2RGB))\n",
    "    plt.title(\"MediaPipe Hand Detection Example\", fontsize=14)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"MediaPipe not available - showing conceptual example\")\n",
    "    print(\"\\nInstall MediaPipe to enable hand tracking:\")\n",
    "    print(\"  pip install mediapipe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Gesture Recognition - Calculating Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(p1, p2):\n",
    "    \"\"\"\n",
    "    Calculate Euclidean distance between two points.\n",
    "    \"\"\"\n",
    "    return math.sqrt((p2[0] - p1[0]) ** 2 + (p2[1] - p1[1]) ** 2)\n",
    "\n",
    "\n",
    "def calculate_angle(p1, p2, p3):\n",
    "    \"\"\"\n",
    "    Calculate angle at p2 formed by p1-p2-p3.\n",
    "    \"\"\"\n",
    "    v1 = (p1[0] - p2[0], p1[1] - p2[1])\n",
    "    v2 = (p3[0] - p2[0], p3[1] - p2[1])\n",
    "\n",
    "    dot_product = v1[0] * v2[0] + v1[1] * v2[1]\n",
    "    mag1 = math.sqrt(v1[0] ** 2 + v1[1] ** 2)\n",
    "    mag2 = math.sqrt(v2[0] ** 2 + v2[1] ** 2)\n",
    "\n",
    "    if mag1 == 0 or mag2 == 0:\n",
    "        return 0\n",
    "\n",
    "    cos_angle = dot_product / (mag1 * mag2)\n",
    "    cos_angle = max(-1, min(1, cos_angle))  # Clamp to [-1, 1]\n",
    "    angle = math.acos(cos_angle)\n",
    "    return math.degrees(angle)\n",
    "\n",
    "\n",
    "# Demonstrate with example points\n",
    "demo_img = np.ones((400, 600, 3), dtype=np.uint8) * 255\n",
    "\n",
    "# Example 1: Distance\n",
    "p1 = (100, 200)\n",
    "p2 = (300, 200)\n",
    "cv.circle(demo_img, p1, 10, (255, 0, 0), -1)\n",
    "cv.circle(demo_img, p2, 10, (0, 255, 0), -1)\n",
    "cv.line(demo_img, p1, p2, (0, 0, 255), 2)\n",
    "dist = calculate_distance(p1, p2)\n",
    "mid = ((p1[0] + p2[0]) // 2, (p1[1] + p2[1]) // 2)\n",
    "cv.putText(\n",
    "    demo_img,\n",
    "    f\"Distance: {dist:.1f}px\",\n",
    "    (mid[0] - 70, mid[1] - 10),\n",
    "    cv.FONT_HERSHEY_SIMPLEX,\n",
    "    0.6,\n",
    "    (0, 0, 255),\n",
    "    2,\n",
    ")\n",
    "\n",
    "# Example 2: Angle\n",
    "p3 = (400, 100)\n",
    "p4 = (400, 250)\n",
    "p5 = (500, 200)\n",
    "cv.circle(demo_img, p3, 10, (255, 0, 255), -1)\n",
    "cv.circle(demo_img, p4, 10, (255, 0, 255), -1)\n",
    "cv.circle(demo_img, p5, 10, (255, 0, 255), -1)\n",
    "cv.line(demo_img, p3, p4, (128, 128, 128), 2)\n",
    "cv.line(demo_img, p5, p4, (128, 128, 128), 2)\n",
    "angle = calculate_angle(p3, p4, p5)\n",
    "cv.putText(\n",
    "    demo_img,\n",
    "    f\"Angle: {angle:.1f} deg\",\n",
    "    (p4[0] + 10, p4[1]),\n",
    "    cv.FONT_HERSHEY_SIMPLEX,\n",
    "    0.6,\n",
    "    (255, 0, 255),\n",
    "    2,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(cv.cvtColor(demo_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Calculating Distances and Angles\", fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"These measurements are key to gesture recognition!\")\n",
    "print(\"Examples:\")\n",
    "print(\"  - Pinch: Distance between thumb tip and index tip\")\n",
    "print(\"  - Finger bent: Angle at finger joint\")\n",
    "print(\"  - Pointing: Angle of index finger relative to hand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Common Hand Gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_finger_extended(landmarks, finger_tip_idx, finger_pip_idx):\n",
    "    \"\"\"\n",
    "    Check if finger is extended by comparing tip and PIP y-coordinates.\n",
    "\n",
    "    Args:\n",
    "        landmarks: List of 21 (x, y) tuples\n",
    "        finger_tip_idx: Index of fingertip\n",
    "        finger_pip_idx: Index of PIP joint\n",
    "    \"\"\"\n",
    "    return landmarks[finger_tip_idx][1] < landmarks[finger_pip_idx][1]\n",
    "\n",
    "\n",
    "def detect_gesture(landmarks):\n",
    "    \"\"\"\n",
    "    Detect common gestures from hand landmarks.\n",
    "\n",
    "    Returns: gesture name\n",
    "    \"\"\"\n",
    "    # Check which fingers are extended\n",
    "    thumb_extended = landmarks[4][0] < landmarks[3][0]  # Thumb is horizontal\n",
    "    index_extended = is_finger_extended(landmarks, 8, 6)\n",
    "    middle_extended = is_finger_extended(landmarks, 12, 10)\n",
    "    ring_extended = is_finger_extended(landmarks, 16, 14)\n",
    "    pinky_extended = is_finger_extended(landmarks, 20, 18)\n",
    "\n",
    "    fingers_up = [thumb_extended, index_extended, middle_extended, ring_extended, pinky_extended]\n",
    "    count = sum(fingers_up)\n",
    "\n",
    "    # Detect gestures\n",
    "    if count == 0:\n",
    "        return \"Fist\"\n",
    "    elif count == 5:\n",
    "        return \"Open Palm\"\n",
    "    elif fingers_up == [False, True, False, False, False]:\n",
    "        return \"Pointing (Index)\"\n",
    "    elif fingers_up == [True, False, False, False, False]:\n",
    "        return \"Thumbs Up\"\n",
    "    elif fingers_up == [False, True, True, False, False]:\n",
    "        return \"Peace Sign\"\n",
    "    elif fingers_up == [True, True, False, False, False]:\n",
    "        # Check pinch gesture\n",
    "        dist = calculate_distance(landmarks[4], landmarks[8])\n",
    "        if dist < 30:\n",
    "            return \"Pinch\"\n",
    "        else:\n",
    "            return \"Gun\"\n",
    "    elif count == 3 and not ring_extended:\n",
    "        return \"OK Sign\"\n",
    "    else:\n",
    "        return f\"{count} Fingers Up\"\n",
    "\n",
    "\n",
    "# Visualize different gestures\n",
    "gestures_img = np.ones((600, 800, 3), dtype=np.uint8) * 240\n",
    "\n",
    "gesture_examples = [\n",
    "    (\"Fist\", \"All fingers closed\"),\n",
    "    (\"Open Palm\", \"All fingers extended\"),\n",
    "    (\"Pointing\", \"Index finger extended\"),\n",
    "    (\"Thumbs Up\", \"Thumb extended up\"),\n",
    "    (\"Peace Sign\", \"Index + Middle extended\"),\n",
    "    (\"Pinch\", \"Thumb touches index tip\"),\n",
    "]\n",
    "\n",
    "y_pos = 50\n",
    "cv.putText(\n",
    "    gestures_img, \"Common Hand Gestures\", (250, 30), cv.FONT_HERSHEY_DUPLEX, 1.2, (0, 0, 0), 2\n",
    ")\n",
    "\n",
    "for i, (gesture, description) in enumerate(gesture_examples):\n",
    "    cv.putText(\n",
    "        gestures_img, f\"{i+1}. {gesture}\", (50, y_pos), cv.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 200), 2\n",
    "    )\n",
    "    cv.putText(\n",
    "        gestures_img,\n",
    "        f\"   {description}\",\n",
    "        (50, y_pos + 30),\n",
    "        cv.FONT_HERSHEY_SIMPLEX,\n",
    "        0.6,\n",
    "        (80, 80, 80),\n",
    "        1,\n",
    "    )\n",
    "    y_pos += 90\n",
    "\n",
    "# Add detection logic summary\n",
    "cv.rectangle(gestures_img, (420, 50), (780, 550), (220, 220, 255), 2)\n",
    "cv.putText(gestures_img, \"Detection Logic:\", (440, 80), cv.FONT_HERSHEY_DUPLEX, 0.7, (0, 0, 150), 2)\n",
    "\n",
    "logic_points = [\n",
    "    \"1. Track 21 landmarks\",\n",
    "    \"2. Check finger positions\",\n",
    "    \"3. Calculate distances\",\n",
    "    \"4. Measure angles\",\n",
    "    \"5. Compare to patterns\",\n",
    "    \"6. Identify gesture\",\n",
    "    \"\",\n",
    "    \"Key Measurements:\",\n",
    "    \"- Fingertip vs PIP\",\n",
    "    \"- Thumb vs palm\",\n",
    "    \"- Tip-to-tip distance\",\n",
    "    \"- Joint angles\",\n",
    "]\n",
    "\n",
    "logic_y = 110\n",
    "for point in logic_points:\n",
    "    if point == \"\":\n",
    "        logic_y += 20\n",
    "    else:\n",
    "        cv.putText(\n",
    "            gestures_img, point, (450, logic_y), cv.FONT_HERSHEY_SIMPLEX, 0.5, (50, 50, 50), 1\n",
    "        )\n",
    "        logic_y += 30\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(cv.cvtColor(gestures_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Gesture Recognition Reference\", fontsize=14, fontweight=\"bold\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGesture recognition combines:\")\n",
    "print(\"  1. Landmark detection (MediaPipe)\")\n",
    "print(\"  2. Geometric calculations (distances, angles)\")\n",
    "print(\"  3. Pattern matching (gesture rules)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Finger Counting Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fingers(landmarks):\n",
    "    \"\"\"\n",
    "    Count number of extended fingers.\n",
    "    \"\"\"\n",
    "    fingers = []\n",
    "\n",
    "    # Thumb (special case - horizontal)\n",
    "    if landmarks[4][0] < landmarks[3][0]:  # Right hand\n",
    "        fingers.append(1)\n",
    "    else:\n",
    "        fingers.append(0)\n",
    "\n",
    "    # Other fingers (vertical)\n",
    "    finger_tips = [8, 12, 16, 20]\n",
    "    finger_pips = [6, 10, 14, 18]\n",
    "\n",
    "    for tip, pip in zip(finger_tips, finger_pips):\n",
    "        if landmarks[tip][1] < landmarks[pip][1]:\n",
    "            fingers.append(1)\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "\n",
    "    return sum(fingers), fingers\n",
    "\n",
    "\n",
    "# Simulate different finger counts\n",
    "finger_count_img = np.ones((400, 900, 3), dtype=np.uint8) * 250\n",
    "\n",
    "cv.putText(\n",
    "    finger_count_img,\n",
    "    \"Finger Counting Application\",\n",
    "    (250, 40),\n",
    "    cv.FONT_HERSHEY_DUPLEX,\n",
    "    1,\n",
    "    (0, 0, 0),\n",
    "    2,\n",
    ")\n",
    "\n",
    "# Example positions for different counts\n",
    "examples = [\n",
    "    (0, \"Fist\", \"[0,0,0,0,0]\"),\n",
    "    (1, \"One\", \"[0,1,0,0,0]\"),\n",
    "    (2, \"Two\", \"[0,1,1,0,0]\"),\n",
    "    (3, \"Three\", \"[0,1,1,1,0]\"),\n",
    "    (4, \"Four\", \"[0,1,1,1,1]\"),\n",
    "    (5, \"Five\", \"[1,1,1,1,1]\"),\n",
    "]\n",
    "\n",
    "x_start = 50\n",
    "y_pos = 120\n",
    "spacing = 140\n",
    "\n",
    "for i, (count, name, pattern) in enumerate(examples):\n",
    "    x = x_start + (i % 3) * spacing * 2\n",
    "    y = y_pos + (i // 3) * 150\n",
    "\n",
    "    # Draw circle for visualization\n",
    "    cv.circle(finger_count_img, (x + 40, y), 50, (200, 200, 255), -1)\n",
    "    cv.circle(finger_count_img, (x + 40, y), 50, (100, 100, 200), 3)\n",
    "\n",
    "    # Draw count\n",
    "    cv.putText(\n",
    "        finger_count_img, str(count), (x + 20, y + 20), cv.FONT_HERSHEY_DUPLEX, 1.5, (0, 0, 150), 3\n",
    "    )\n",
    "\n",
    "    # Draw name\n",
    "    cv.putText(finger_count_img, name, (x, y + 70), cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "\n",
    "    # Draw pattern\n",
    "    cv.putText(\n",
    "        finger_count_img,\n",
    "        pattern,\n",
    "        (x - 20, y + 100),\n",
    "        cv.FONT_HERSHEY_SIMPLEX,\n",
    "        0.5,\n",
    "        (100, 100, 100),\n",
    "        1,\n",
    "    )\n",
    "\n",
    "# Add usage note\n",
    "cv.rectangle(finger_count_img, (20, 320), (880, 380), (200, 255, 200), -1)\n",
    "cv.putText(\n",
    "    finger_count_img,\n",
    "    \"Applications: Number input, Volume control, Slide navigation\",\n",
    "    (40, 350),\n",
    "    cv.FONT_HERSHEY_SIMPLEX,\n",
    "    0.7,\n",
    "    (0, 100, 0),\n",
    "    2,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(16, 7))\n",
    "plt.imshow(cv.cvtColor(finger_count_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Finger Counting with Hand Gestures\", fontsize=14, fontweight=\"bold\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Finger counting is one of the simplest gesture recognition tasks\")\n",
    "print(\"It can be used for:\")\n",
    "print(\"  - Number input without keyboard\")\n",
    "print(\"  - Volume control (0-10)\")\n",
    "print(\"  - Page/slide navigation\")\n",
    "print(\"  - Game controls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Virtual Drawing Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a virtual drawing application\n",
    "canvas_width, canvas_height = 800, 600\n",
    "canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255\n",
    "\n",
    "# Simulate hand trajectory\n",
    "np.random.seed(42)\n",
    "trajectory = []\n",
    "x, y = 100, 300\n",
    "for i in range(100):\n",
    "    x += np.random.randint(-10, 10)\n",
    "    y += np.random.randint(-10, 10)\n",
    "    x = max(50, min(750, x))\n",
    "    y = max(50, min(550, y))\n",
    "    trajectory.append((x, y))\n",
    "\n",
    "# Draw trajectory\n",
    "for i in range(1, len(trajectory)):\n",
    "    cv.line(canvas, trajectory[i - 1], trajectory[i], (0, 0, 255), 3)\n",
    "\n",
    "# Draw current hand position\n",
    "current_pos = trajectory[-1]\n",
    "cv.circle(canvas, current_pos, 15, (0, 255, 0), -1)\n",
    "cv.circle(canvas, current_pos, 15, (0, 200, 0), 3)\n",
    "\n",
    "# Add UI elements\n",
    "cv.rectangle(canvas, (0, 0), (canvas_width, 50), (240, 240, 240), -1)\n",
    "cv.putText(\n",
    "    canvas,\n",
    "    \"Virtual Drawing with Hand Tracking\",\n",
    "    (20, 35),\n",
    "    cv.FONT_HERSHEY_DUPLEX,\n",
    "    0.8,\n",
    "    (0, 0, 0),\n",
    "    2,\n",
    ")\n",
    "\n",
    "# Color palette\n",
    "colors = [(0, 0, 255), (0, 255, 0), (255, 0, 0), (255, 255, 0), (255, 0, 255)]\n",
    "for i, color in enumerate(colors):\n",
    "    cv.circle(canvas, (650 + i * 30, 25), 12, color, -1)\n",
    "    cv.circle(canvas, (650 + i * 30, 25), 12, (100, 100, 100), 2)\n",
    "\n",
    "# Instructions\n",
    "instructions = [\n",
    "    \"How it works:\",\n",
    "    \"1. Track index finger tip position\",\n",
    "    \"2. When index finger extended: Draw\",\n",
    "    \"3. When fist closed: Stop drawing\",\n",
    "    \"4. Two fingers up: Change color\",\n",
    "    \"5. Open palm: Clear canvas\",\n",
    "]\n",
    "\n",
    "inst_img = np.ones((250, 400, 3), dtype=np.uint8) * 250\n",
    "y_inst = 30\n",
    "for inst in instructions:\n",
    "    cv.putText(inst_img, inst, (10, y_inst), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "    y_inst += 35\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cv.cvtColor(canvas, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Virtual Drawing Canvas\", fontsize=14, fontweight=\"bold\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cv.cvtColor(inst_img, cv.COLOR_BGR2RGB))\n",
    "plt.title(\"Instructions\", fontsize=14)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVirtual drawing demonstrates:\")\n",
    "print(\"  ‚úì Real-time hand tracking\")\n",
    "print(\"  ‚úì Gesture-based controls\")\n",
    "print(\"  ‚úì State management (draw/don't draw)\")\n",
    "print(\"  ‚úì Interactive applications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Practical Exercises\n",
    "\n",
    "### Exercise 1: Install and Test MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Install MediaPipe and test with webcam\n",
    "# pip install mediapipe\n",
    "# Use webcam to detect your hand in real-time\n",
    "# Draw landmarks on the video feed\n",
    "\n",
    "print(\"Try MediaPipe with your webcam!\")\n",
    "print(\"Hint: Use cv.VideoCapture(0) for webcam input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "### Exercise 2: Build a Gesture Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create an application that:\n",
    "# - Shows numbers 1-5 based on finger count\n",
    "# - Displays the gesture name\n",
    "# - Shows finger states (which are up/down)\n",
    "# - Works in real-time with webcam\n",
    "\n",
    "print(\"Build a real-time finger counter!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### Exercise 3: Volume Control with Pinch Gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create volume control application:\n",
    "# - Measure distance between thumb and index finger\n",
    "# - Map distance (0-200px) to volume (0-100%)\n",
    "# - Display volume bar\n",
    "# - (Optional) Control actual system volume with pycaw\n",
    "\n",
    "print(\"Build gesture-controlled volume!\")\n",
    "print(\"Hint: Use calculate_distance() between landmarks 4 and 8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Congratulations! You've completed the Hand Gesture Recognition notebook and the entire Image Processing series! You now know:\n",
    "\n",
    "‚úì Hand gesture recognition concepts and applications  \n",
    "‚úì MediaPipe framework for hand tracking  \n",
    "‚úì 21 hand landmarks and their structure  \n",
    "‚úì Calculating distances and angles between points  \n",
    "‚úì Common gesture patterns (fist, peace, pointing, etc.)  \n",
    "‚úì Finger counting algorithms  \n",
    "‚úì Building interactive gesture-controlled apps  \n",
    "‚úì Real-time hand tracking techniques  \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **MediaPipe is powerful** - Pre-trained, accurate, real-time\n",
    "2. **21 landmarks per hand** - Wrist + 4 points per finger\n",
    "3. **Geometric calculations are key** - Distances and angles\n",
    "4. **Simple rules work well** - Extended vs bent fingers\n",
    "5. **Real-time is possible** - 30+ FPS on modern hardware\n",
    "6. **Many applications** - Gaming, accessibility, AR, IoT\n",
    "7. **Combine with other CV** - Face + hands, object + gestures\n",
    "\n",
    "---\n",
    "\n",
    "## Complete Image Processing Series Summary\n",
    "\n",
    "You've completed all 9 notebooks:\n",
    "\n",
    "1. ‚úÖ **Setup & Introduction** - OpenCV basics\n",
    "2. ‚úÖ **Getting Started** - Images, videos, drawing\n",
    "3. ‚úÖ **Image Basics & ROI** - Pixels, channels, regions\n",
    "4. ‚úÖ **Image Processing Fundamentals** - Color spaces, thresholding, filtering\n",
    "5. ‚úÖ **Image Transformations** - Scaling, rotation, warping\n",
    "6. ‚úÖ **Morphological Operations** - Erosion, dilation, gradients\n",
    "7. ‚úÖ **Image Segmentation** - Watershed algorithm\n",
    "8. ‚úÖ **Feature Detection** - SIFT, ORB, Harris corners\n",
    "9. ‚úÖ **Feature Matching** - Object recognition, homography\n",
    "10. ‚úÖ **Hand Gesture Recognition** - MediaPipe, gestures (BONUS)\n",
    "\n",
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "Continue your computer vision journey:\n",
    "\n",
    "- **Deep Learning CV**: CNNs, object detection (YOLO, Faster R-CNN)\n",
    "- **Face Recognition**: FaceNet, DeepFace\n",
    "- **Pose Estimation**: MediaPipe Pose, OpenPose\n",
    "- **Optical Flow**: Motion analysis\n",
    "- **3D Computer Vision**: Stereo vision, depth estimation\n",
    "- **Video Analysis**: Action recognition, tracking\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "- **Gaming**: Gesture controls, VR/AR interactions\n",
    "- **Healthcare**: Physical therapy monitoring, sign language translation\n",
    "- **Smart Home**: Touchless device control\n",
    "- **Automotive**: Driver attention monitoring\n",
    "- **Retail**: Gesture-based shopping interfaces\n",
    "- **Education**: Interactive learning tools\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations on completing the series! Keep exploring and building!** üéâüëãüöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
