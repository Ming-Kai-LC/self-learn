{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Selection and Analysis\n",
    "\n",
    "**Objective**: Choose a computationally expensive problem suitable for parallelization\n",
    "\n",
    "---\n",
    "\n",
    "## Criteria for Good Problem Selection\n",
    "\n",
    "A good parallel computing problem should have:\n",
    "\n",
    "1. **Computational Intensity**: Takes significant time to compute serially\n",
    "2. **Data Parallelism**: Can be broken into independent tasks\n",
    "3. **Scalability**: Performance improves with more processors/cores\n",
    "4. **Practical Application**: Solves a real-world problem\n",
    "5. **Measurable Performance**: Clear metrics for speedup\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Domain Analysis\n",
    "\n",
    "### 1. Image Processing\n",
    "\n",
    "**Examples**:\n",
    "- Image filtering (Gaussian blur, edge detection)\n",
    "- Image transformations (rotation, scaling)\n",
    "- Feature extraction\n",
    "- Hough Transform for line/circle detection\n",
    "\n",
    "**Parallelization Potential**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n",
    "- Each pixel can be processed independently\n",
    "- GPU-friendly (massive data parallelism)\n",
    "- Easy to visualize results\n",
    "\n",
    "**Difficulty**: Beginner to Intermediate\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Matrix Operations\n",
    "\n",
    "**Examples**:\n",
    "- Matrix multiplication\n",
    "- Matrix inversion\n",
    "- Solving linear equations (Gaussian elimination)\n",
    "- Eigenvalue computation\n",
    "\n",
    "**Parallelization Potential**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n",
    "- Row/column operations are independent\n",
    "- Block-based parallelism\n",
    "- Well-studied algorithms\n",
    "\n",
    "**Difficulty**: Intermediate\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Monte Carlo Simulations\n",
    "\n",
    "**Examples**:\n",
    "- Pi estimation\n",
    "- Option pricing in finance\n",
    "- Random walk simulations\n",
    "- Statistical sampling\n",
    "\n",
    "**Parallelization Potential**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n",
    "- Embarrassingly parallel (perfect for parallelization)\n",
    "- Each simulation is independent\n",
    "- Easy to scale\n",
    "\n",
    "**Difficulty**: Beginner\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Machine Learning\n",
    "\n",
    "**Examples**:\n",
    "- K-means clustering\n",
    "- K-nearest neighbors classification\n",
    "- Neural network training\n",
    "- Decision tree ensemble (Random Forest)\n",
    "\n",
    "**Parallelization Potential**: ‚≠ê‚≠ê‚≠ê‚≠ê\n",
    "- Training iterations can be parallelized\n",
    "- Data can be split across workers\n",
    "- Model parallelism possible\n",
    "\n",
    "**Difficulty**: Intermediate to Advanced\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Numerical Simulations\n",
    "\n",
    "**Examples**:\n",
    "- N-body simulations (planetary motion)\n",
    "- Molecular dynamics\n",
    "- Heat diffusion (PDE solvers)\n",
    "- Fluid dynamics\n",
    "\n",
    "**Parallelization Potential**: ‚≠ê‚≠ê‚≠ê‚≠ê\n",
    "- Spatial decomposition\n",
    "- Time-stepping parallelism\n",
    "- Scientifically interesting\n",
    "\n",
    "**Difficulty**: Advanced\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Graph Processing\n",
    "\n",
    "**Examples**:\n",
    "- Shortest path algorithms\n",
    "- PageRank\n",
    "- Community detection\n",
    "- Graph coloring\n",
    "\n",
    "**Parallelization Potential**: ‚≠ê‚≠ê‚≠ê\n",
    "- Some algorithms are harder to parallelize\n",
    "- Load balancing can be challenging\n",
    "- Good for learning distributed computing\n",
    "\n",
    "**Difficulty**: Intermediate to Advanced\n",
    "\n",
    "---\n",
    "\n",
    "## Recommended Problems for This Assignment\n",
    "\n",
    "Based on grading criteria and effort required:\n",
    "\n",
    "### Top Choices:\n",
    "\n",
    "1. **Image Processing with Multiple Filters** ‚úÖ\n",
    "   - Apply Gaussian blur, edge detection, sharpening\n",
    "   - Compare serial vs OpenMP vs CUDA\n",
    "   - Visual results are impressive\n",
    "   - Easy to measure speedup\n",
    "\n",
    "2. **Matrix Operations Suite** ‚úÖ\n",
    "   - Matrix multiplication + solving linear systems\n",
    "   - Multiple parallel strategies (row, column, block)\n",
    "   - Clear performance metrics\n",
    "   - Educational value\n",
    "\n",
    "3. **Monte Carlo Simulations** ‚úÖ\n",
    "   - Pi estimation + option pricing\n",
    "   - Perfect for learning parallelism\n",
    "   - Easy to explain and demonstrate\n",
    "   - Good for testing multiple platforms\n",
    "\n",
    "4. **K-Means Clustering** ‚úÖ\n",
    "   - Practical ML application\n",
    "   - Iterative algorithm (interesting to parallelize)\n",
    "   - Can visualize clusters\n",
    "   - Real datasets available\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Selection Worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# YOUR PROBLEM SELECTION - HEAT DIFFUSION\n# Team: [Your Name/Team Name]\n# Date: November 2025\n\nproblem_selection = {\n    'title': \"High-Performance 2D Heat Diffusion Simulator with Multi-Platform Parallelization\",\n    'domain': \"Numerical Simulations (Partial Differential Equations)\",\n    'specific_problem': \"Solve 2D heat equation using finite difference method on large grids (up to 4096√ó4096)\",\n    'why_parallel': \"Each grid cell update is independent within time step - perfect for data parallelism. O(n¬≤√ót) complexity requires parallelization for large grids.\",\n    'expected_speedup': \"6-8x with OpenMP (8 cores), 50-200x with CUDA (GPU)\",\n    'platforms': \"Serial baseline ‚Üí OpenMP (CPU multi-core) ‚Üí CUDA/Numba (GPU)\",\n}\n\nprint(\"=\" * 80)\nprint(\"SELECTED PROBLEM: HEAT DIFFUSION SIMULATION\")\nprint(\"=\" * 80)\nfor key, value in problem_selection.items():\n    print(f\"\\n{key.upper().replace('_', ' ')}:\")\n    print(f\"  {value}\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ Problem selected! This is an excellent choice for parallel processing.\")\nprint(\"=\" * 80)",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Computational Complexity Analysis\n",
    "\n",
    "Understanding the computational complexity helps justify parallelization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "import numpy as np\nimport time\nimport matplotlib\nmatplotlib.use('Agg')  # Non-interactive backend\nimport matplotlib.pyplot as plt\nimport sys\nsys.path.append('.')\n\n# Import our heat diffusion implementation\nfrom heat_diffusion_serial import HeatDiffusion2D\n\n# Demonstrate computational growth for heat diffusion\nsizes = [50, 100, 200, 400]\nnum_steps = 100  # Fixed number of time steps\ntimes = []\n\nprint(\"Heat Diffusion Computational Growth Analysis\")\nprint(\"=\" * 70)\nprint(f\"{'Grid Size':<15} {'Total Cells':<15} {'Time (s)':<12} {'Complexity':<15}\")\nprint(\"-\" * 70)\n\nfor size in sizes:\n    # Create simulator\n    sim = HeatDiffusion2D(nx=size, ny=size, alpha=0.01, dt=0.0001)\n    sim.set_initial_conditions(\"center_hot\")\n    \n    # Measure execution time\n    start = time.time()\n    sim.simulate(num_steps=num_steps, verbose=False)\n    elapsed = time.time() - start\n    \n    times.append(elapsed)\n    total_cells = size * size\n    complexity = total_cells * num_steps\n    \n    print(f\"{size}√ó{size:<11} {total_cells:<15,} {elapsed:<12.4f} O({size}¬≤ √ó {num_steps})\")\n\nprint(\"-\" * 70)\nprint(f\"\\n‚ö†Ô∏è This demonstrates why parallelization is needed!\")\nprint(f\"When grid size doubles (50‚Üí100), time increases by ~{times[1]/times[0]:.1f}x\")\nprint(f\"When grid size doubles again (100‚Üí200), time increases by ~{times[2]/times[1]:.1f}x\")\nprint(f\"\\nFor 4096√ó4096 grid with 10,000 steps:\")\nestimated_4k = times[-1] * (4096/400)**2 * (10000/100)\nprint(f\"  Estimated serial time: ~{estimated_4k/60:.1f} minutes\")\nprint(f\"  With 8x speedup (OpenMP): ~{estimated_4k/60/8:.1f} minutes\")\nprint(f\"  With 100x speedup (CUDA): ~{estimated_4k/100:.1f} seconds\")\n\n# Plot computational growth\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(sizes, times, 'o-', linewidth=2, markersize=10, color='red')\nplt.xlabel('Grid Size (N√óN)', fontsize=12)\nplt.ylabel('Execution Time (seconds)', fontsize=12)\nplt.title('Heat Diffusion: Computational Growth O(N¬≤)', fontsize=14, fontweight='bold')\nplt.grid(True, alpha=0.3)\n\n# Plot complexity\nplt.subplot(1, 2, 2)\ncells = [s*s for s in sizes]\nplt.plot(cells, times, 's-', linewidth=2, markersize=10, color='blue')\nplt.xlabel('Total Grid Cells (N¬≤)', fontsize=12)\nplt.ylabel('Execution Time (seconds)', fontsize=12)\nplt.title('Time vs. Problem Size (100 time steps)', fontsize=14, fontweight='bold')\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('heat_diffusion_complexity.png', dpi=150, bbox_inches='tight')\nprint(\"\\n‚úì Plot saved to heat_diffusion_complexity.png\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parallelization Strategy\n",
    "\n",
    "For your chosen problem, identify:\n",
    "\n",
    "### Data Decomposition\n",
    "How will you split the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Heat Diffusion: Data Decomposition Strategies\ngrid_width = 1024\ngrid_height = 1024\nnum_cores = 8\n\nprint(\"HEAT DIFFUSION: DATA DECOMPOSITION STRATEGIES\")\nprint(\"=\" * 70)\nprint(f\"Grid size: {grid_width} √ó {grid_height} = {grid_width * grid_height:,} cells\")\nprint(f\"Available cores: {num_cores}\")\nprint()\n\n# Strategy 1: Row-based decomposition (OpenMP)\nrows_per_core = grid_height // num_cores\ncells_per_core = rows_per_core * grid_width\nprint(\"Strategy 1: ROW-BASED DECOMPOSITION (Best for OpenMP)\")\nprint(f\"  Each core processes: {rows_per_core} rows √ó {grid_width} cols = {cells_per_core:,} cells\")\nprint(f\"  Communication: Only at row boundaries (for boundary conditions)\")\nprint(f\"  Load balance: Perfect (equal rows per core)\")\nprint()\n\n# Strategy 2: Block-based decomposition\nblocks_x = 4\nblocks_y = 2\nblock_width = grid_width // blocks_x\nblock_height = grid_height // blocks_y\ncells_per_block = block_width * block_height\nprint(\"Strategy 2: BLOCK-BASED DECOMPOSITION (Alternative)\")\nprint(f\"  Grid divided into: {blocks_x}√ó{blocks_y} = {blocks_x*blocks_y} blocks\")\nprint(f\"  Each block: {block_width}√ó{block_height} = {cells_per_block:,} cells\")\nprint(f\"  Communication: At all block boundaries\")\nprint()\n\n# Strategy 3: Cell-based for GPU (CUDA)\nthreads_per_block = 16\nblocks_needed_x = (grid_width + threads_per_block - 1) // threads_per_block\nblocks_needed_y = (grid_height + threads_per_block - 1) // threads_per_block\ntotal_gpu_threads = threads_per_block * threads_per_block * blocks_needed_x * blocks_needed_y\nprint(\"Strategy 3: CELL-BASED DECOMPOSITION (Best for CUDA GPU)\")\nprint(f\"  One thread per cell (massive parallelism)\")\nprint(f\"  Thread blocks: {threads_per_block}√ó{threads_per_block} = {threads_per_block**2} threads/block\")\nprint(f\"  Grid of blocks: {blocks_needed_x}√ó{blocks_needed_y} = {blocks_needed_x * blocks_needed_y} blocks\")\nprint(f\"  Total GPU threads: {total_gpu_threads:,}\")\nprint(f\"  Parallelism ratio: {total_gpu_threads / num_cores:,.0f}x more than CPU cores\")\nprint()\n\nprint(\"=\" * 70)\nprint(\"CHOSEN STRATEGY: Row-based for OpenMP, Cell-based for CUDA\")\nprint(\"=\" * 70)\n\n# Visualize decomposition (save to file instead of showing)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n\n# Row-based decomposition\nax1.set_xlim(0, grid_width)\nax1.set_ylim(0, grid_height)\ncolors = plt.cm.Set3(np.linspace(0, 1, num_cores))\nfor i in range(num_cores):\n    y_start = i * rows_per_core\n    y_end = (i + 1) * rows_per_core\n    ax1.fill_between([0, grid_width], y_start, y_end, alpha=0.5, color=colors[i], label=f'Core {i}')\n    ax1.axhline(y=y_start, color='black', linewidth=2)\nax1.axhline(y=grid_height, color='black', linewidth=2)\nax1.set_title(f'Row-based Decomposition ({num_cores} cores)', fontsize=14, fontweight='bold')\nax1.set_xlabel('X (columns)', fontsize=12)\nax1.set_ylabel('Y (rows)', fontsize=12)\nax1.legend(loc='center right', fontsize=8)\nax1.grid(True, alpha=0.2)\n\n# GPU thread block decomposition\nax2.set_xlim(0, grid_width)\nax2.set_ylim(0, grid_height)\n# Draw thread blocks\nfor i in range(0, blocks_needed_x + 1):\n    ax2.axvline(x=i * threads_per_block, color='blue', linewidth=1, alpha=0.6)\nfor j in range(0, blocks_needed_y + 1):\n    ax2.axhline(y=j * threads_per_block, color='blue', linewidth=1, alpha=0.6)\n# Highlight a few blocks\nax2.fill_between([0, threads_per_block], 0, threads_per_block, alpha=0.3, color='green', label='Thread block (16√ó16)')\nax2.text(threads_per_block/2, threads_per_block/2, f'{threads_per_block}√ó{threads_per_block}\\nthreads', \n         ha='center', va='center', fontsize=10, fontweight='bold')\nax2.set_title(f'GPU Thread Block Layout ({blocks_needed_x}√ó{blocks_needed_y} blocks)', fontsize=14, fontweight='bold')\nax2.set_xlabel('X (columns)', fontsize=12)\nax2.set_ylabel('Y (rows)', fontsize=12)\nax2.legend(loc='upper right', fontsize=10)\nax2.grid(True, alpha=0.2)\n\nplt.tight_layout()\nplt.savefig('heat_diffusion_decomposition.png', dpi=150, bbox_inches='tight')\nprint(\"\\n‚úì Visualization saved to heat_diffusion_decomposition.png\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dependencies and Communication\n",
    "\n",
    "Identify if your problem has:\n",
    "\n",
    "1. **No dependencies** (Embarrassingly parallel)\n",
    "   - Each task completely independent\n",
    "   - Example: Monte Carlo simulations\n",
    "\n",
    "2. **Local dependencies** (Stencil operations)\n",
    "   - Tasks need data from neighbors\n",
    "   - Example: Image convolution\n",
    "\n",
    "3. **Global dependencies** (Reductions)\n",
    "   - Tasks need to combine results\n",
    "   - Example: Computing average, sum, max\n",
    "\n",
    "4. **Iterative dependencies**\n",
    "   - Results from one iteration affect next\n",
    "   - Example: K-means clustering, gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Heat Diffusion: Dependency and Communication Analysis\n\nheat_diffusion_analysis = {\n    'independence_level': \"HIGH - Each cell update is independent within a time step\",\n    'communication_pattern': \"Local (5-point stencil) - Each cell needs 4 neighbors\",\n    'synchronization_needs': \"Barrier after each time step (all cells must complete before next iteration)\",\n    'load_balance': \"Static - All cells require equal computation\",\n    'memory_pattern': \"Regular (structured grid access)\",\n    'parallelization_type': \"Data parallelism (SPMD model)\"\n}\n\nprint(\"HEAT DIFFUSION: DEPENDENCY ANALYSIS\")\nprint(\"=\" * 70)\nfor key, value in heat_diffusion_analysis.items():\n    print(f\"\\n{key.upper().replace('_', ' ')}:\")\n    print(f\"  {value}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"PARALLELIZATION ASSESSMENT\")\nprint(\"=\" * 70)\n\n# Calculate communication overhead\ngrid_size = 1024\nboundary_cells = 4 * grid_size  # Cells that need neighbor communication\ninterior_cells = (grid_size - 2) ** 2  # Cells that don't need boundary handling\ntotal_cells = grid_size ** 2\n\nprint(f\"\\nFor {grid_size}√ó{grid_size} grid:\")\nprint(f\"  Total cells: {total_cells:,}\")\nprint(f\"  Interior cells: {interior_cells:,} ({interior_cells/total_cells*100:.1f}%)\")\nprint(f\"  Boundary cells: {boundary_cells:,} ({boundary_cells/total_cells*100:.1f}%)\")\nprint(f\"\\n  ‚Üí {interior_cells/total_cells*100:.1f}% of cells are fully independent\")\nprint(f\"  ‚Üí Communication overhead is minimal!\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"5-POINT STENCIL PATTERN\")\nprint(\"=\" * 70)\nprint(\"\"\"\nFor each cell T[i,j], we need:\n  \n          T[i-1, j]\n              ‚Üì\n  T[i, j-1] ‚Üí T[i, j] ‚Üê T[i, j+1]\n              ‚Üë\n          T[i+1, j]\n\nUpdate formula:\n  T_new[i,j] = T[i,j] + Œ±*Œît/(Œîx)¬≤ * (\n      T[i+1,j] + T[i-1,j] + T[i,j+1] + T[i,j-1] - 4*T[i,j]\n  )\n\nKey insights:\n  ‚úì All reads from current array (T)\n  ‚úì All writes to separate array (T_new)  \n  ‚úì NO read-write conflicts within time step\n  ‚úì Perfect for parallelization!\n\"\"\")\n\nprint(\"=\" * 70)\nprint(\"PARALLELIZATION STRATEGY\")\nprint(\"=\" * 70)\nprint(\"\"\"\nOpenMP (CPU):\n  - Parallelize outer loop over rows\n  - Each thread processes rows_per_thread rows\n  - Barrier synchronization after each time step\n  - Expected speedup: 6-8x on 8 cores\n\nCUDA (GPU):\n  - One CUDA thread per grid cell\n  - Massive parallelism (millions of threads)\n  - Shared memory for neighbor access optimization\n  - Expected speedup: 50-200x vs serial\n\"\"\")\n\nprint(\"‚úÖ Heat diffusion is HIGHLY PARALLELIZABLE!\")\nprint(\"=\" * 70)",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Expected Performance Gains\n",
    "\n",
    "Calculate theoretical speedup using **Amdahl's Law**:\n",
    "\n",
    "$$Speedup = \\frac{1}{(1-P) + \\frac{P}{N}}$$\n",
    "\n",
    "Where:\n",
    "- P = Proportion of program that can be parallelized (0 to 1)\n",
    "- N = Number of processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def amdahl_speedup(P, N):\n",
    "    \"\"\"Calculate theoretical speedup using Amdahl's Law\"\"\"\n",
    "    return 1 / ((1 - P) + (P / N))\n",
    "\n",
    "# Test different parallelization percentages\n",
    "processors = np.arange(1, 17)\n",
    "parallel_portions = [0.5, 0.75, 0.90, 0.95, 0.99]\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "for P in parallel_portions:\n",
    "    speedups = [amdahl_speedup(P, N) for N in processors]\n",
    "    plt.plot(processors, speedups, marker='o', label=f'P = {P:.0%}')\n",
    "\n",
    "plt.plot(processors, processors, 'k--', label='Ideal (linear)', linewidth=2)\n",
    "plt.xlabel('Number of Processors', fontsize=12)\n",
    "plt.ylabel('Speedup', fontsize=12)\n",
    "plt.title(\"Amdahl's Law: Theoretical Speedup vs Parallelizable Portion\", fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate for your expected scenario\n",
    "your_P = 0.95  # Assume 95% of code can be parallelized\n",
    "your_N = 8     # Your CPU cores\n",
    "\n",
    "expected_speedup = amdahl_speedup(your_P, your_N)\n",
    "print(f\"\\nExpected speedup with {your_N} cores and {your_P:.0%} parallelizable code:\")\n",
    "print(f\"Theoretical maximum: {expected_speedup:.2f}x\")\n",
    "print(f\"\\nRealistic expectation (70% of theoretical): {expected_speedup * 0.7:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Uniqueness Check\n",
    "\n",
    "‚ö†Ô∏è **Remember**: Each group must have a UNIQUE title and solution\n",
    "\n",
    "To ensure uniqueness:\n",
    "1. Choose a specific application domain\n",
    "2. Combine multiple techniques\n",
    "3. Add creative twists\n",
    "\n",
    "### Examples of Unique Titles:\n",
    "\n",
    "Instead of: \"Matrix Multiplication using OpenMP\"  \n",
    "Make it: \"Adaptive Block-Based Matrix Multiplication with Dynamic Load Balancing\"\n",
    "\n",
    "Instead of: \"Image Filtering\"  \n",
    "Make it: \"Real-Time Video Processing Pipeline with Multi-Stage Parallel Filters\"\n",
    "\n",
    "Instead of: \"Monte Carlo Pi Estimation\"  \n",
    "Make it: \"Hybrid CPU-GPU Monte Carlo Framework for Financial Option Pricing\"\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "import pandas as pd\n\n# Create a decision matrix for problem selection\nproblems = [\n    {'name': 'Image Processing', 'complexity': 3, 'parallel_potential': 5, 'uniqueness': 4, 'interest': 5},\n    {'name': 'Matrix Operations', 'complexity': 4, 'parallel_potential': 5, 'uniqueness': 3, 'interest': 3},\n    {'name': 'Monte Carlo', 'complexity': 2, 'parallel_potential': 5, 'uniqueness': 3, 'interest': 4},\n    {'name': 'K-Means Clustering', 'complexity': 3, 'parallel_potential': 4, 'uniqueness': 4, 'interest': 4},\n    {'name': 'Heat Diffusion (2D PDE)', 'complexity': 4, 'parallel_potential': 5, 'uniqueness': 5, 'interest': 5},\n    {'name': 'N-Body Simulation', 'complexity': 5, 'parallel_potential': 4, 'uniqueness': 5, 'interest': 5},\n]\n\ndf = pd.DataFrame(problems)\ndf['total_score'] = df['complexity'] + df['parallel_potential'] + df['uniqueness'] + df['interest']\ndf = df.sort_values('total_score', ascending=False)\n\nprint(\"Problem Selection Decision Matrix\")\nprint(\"=\" * 80)\nprint(df.to_string(index=False))\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Scoring (1-5): Higher is better\")\nprint(\"  Complexity: Technical challenge (good for learning)\")\nprint(\"  Parallel Potential: How well it parallelizes\")\nprint(\"  Uniqueness: Stands out from other groups\")\nprint(\"  Interest: Team enthusiasm and motivation\")\nprint(\"=\" * 80)\n\n# Highlight selected problem\nselected = df[df['name'] == 'Heat Diffusion (2D PDE)'].iloc[0]\nprint(f\"\\nüèÜ SELECTED: {selected['name']}\")\nprint(f\"   Total Score: {selected['total_score']}/20\")\nprint(f\"   Rank: #{df.index.get_loc(df[df['name'] == 'Heat Diffusion (2D PDE)'].index[0]) + 1} out of {len(df)}\")\nprint(\"\\n‚úÖ Excellent choice for demonstrating parallel programming skills!\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Final Problem Statement Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# FINAL PROBLEM STATEMENT - HEAT DIFFUSION\n\nfinal_problem = \"\"\"\n================================================================================\nHIGH-PERFORMANCE 2D HEAT DIFFUSION SIMULATOR \nWITH MULTI-PLATFORM PARALLELIZATION\n================================================================================\n\nPROBLEM DOMAIN: \n  Numerical Simulations / Partial Differential Equations (PDEs)\n\nSPECIFIC PROBLEM:\n  Simulate heat distribution over a 2D plate using the finite difference method\n  to solve the heat equation: ‚àÇT/‚àÇt = Œ± * ‚àá¬≤T\n  \n  INPUT:\n    - 2D grid (sizes: 1024√ó1024 to 4096√ó4096 cells)\n    - Initial temperature distribution\n    - Boundary conditions (constant, insulated, or periodic)\n    - Material properties (thermal diffusivity Œ±)\n    - Time parameters (time step Œît, number of steps)\n  \n  PROCESSING:\n    - Apply 5-point stencil finite difference method\n    - Update each cell based on its 4 neighbors\n    - Iterate over thousands of time steps (10,000 - 100,000)\n    - Ensure numerical stability (CFL condition)\n  \n  OUTPUT:\n    - Final temperature distribution (2D array)\n    - Temperature evolution over time (animation)\n    - Performance metrics (execution time, speedup, efficiency)\n    - Validation results (energy conservation, convergence)\n\nWHY PARALLELIZATION IS NEEDED:\n  COMPUTATIONAL BOTTLENECK:\n    - Time Complexity: O(n¬≤ √ó t) where n is grid size, t is time steps\n    - For 2048√ó2048 grid with 10,000 steps: ~42 billion operations\n    - Serial execution time: 2-4 minutes (estimated)\n    - Each time step requires updating >4 million cells\n  \n  TYPICAL DATA SIZES:\n    - Small:  1024√ó1024  √ó 10,000 steps = 10 billion operations\n    - Medium: 2048√ó2048  √ó 10,000 steps = 42 billion operations  \n    - Large:  4096√ó4096  √ó 10,000 steps = 168 billion operations\n  \n  SERIAL PERFORMANCE BASELINE:\n    - 1024√ó1024: ~20 seconds (current measurement)\n    - 2048√ó2048: ~80 seconds (estimated)\n    - 4096√ó4096: ~320 seconds (5+ minutes estimated)\n  \n  ‚Üí Parallelization can reduce these times by 6-200x!\n\nPARALLELIZATION APPROACH:\n\n  1. SERIAL BASELINE (COMPLETE ‚úÖ):\n     - Pure Python with NumPy\n     - Establishes correctness and performance baseline\n     - Throughput: ~0.78 Mcells/s\n  \n  2. OPENMP (CPU MULTI-CORE):\n     - Data decomposition: Row-based splitting\n     - Parallel programming model: SPMD (loop parallelism)\n     - Technology: Python multiprocessing / Numba with parallel=True\n     - Synchronization: Barrier after each time step\n     - Load balancing: Static (equal rows per thread)\n     - Target hardware: 8-core CPU\n     - Expected speedup: 6-8x (70-80% parallel efficiency)\n  \n  3. CUDA (GPU ACCELERATION):\n     - Data decomposition: One thread per grid cell\n     - Parallel programming model: Massive data parallelism\n     - Technology: Numba CUDA / CuPy\n     - Thread organization: 16√ó16 thread blocks\n     - Memory optimization: Shared memory for neighbors\n     - Target hardware: NVIDIA GPU (thousands of cores)\n     - Expected speedup: 50-200x vs serial\n  \n  4. OPTIMIZATION TECHNIQUES:\n     - Memory access optimization (cache-friendly patterns)\n     - Double buffering (ping-pong arrays)\n     - Minimize boundary condition overhead\n     - Hybrid CPU-GPU approach (advanced)\n\nEXPECTED OUTCOMES:\n\n  PERFORMANCE IMPROVEMENTS:\n    - OpenMP (8 cores): 6.0x speedup, 75% efficiency\n    - CUDA (GPU): 100x speedup for 2048√ó2048 grid\n    - Reduce 4096√ó4096 simulation from 5 minutes to <3 seconds\n  \n  PLATFORMS TO TEST:\n    - Serial: Pure Python baseline\n    - OpenMP: Multi-core CPU (test with 1, 2, 4, 8 threads)\n    - CUDA: NVIDIA GPU\n    - Comparison: Serial vs OpenMP vs CUDA on same problem\n  \n  INSIGHTS TO GAIN:\n    - Understanding of strong and weak scaling\n    - Impact of memory bandwidth on GPU performance\n    - Amdahl's Law validation with real measurements\n    - Trade-offs between CPU and GPU parallelism\n    - Best practices for PDE solver parallelization\n\nUNIQUENESS:\n\n  WHAT MAKES THIS PROJECT DIFFERENT:\n    1. Multi-platform comparison (3 implementations)\n    2. Real physics simulation with validation\n    3. Progressive parallelization journey (serial ‚Üí shared memory ‚Üí GPU)\n    4. Comprehensive performance analysis with scaling studies\n    5. Beautiful visualization (heatmaps and animations)\n    6. Educational value (learn parallel programming through PDEs)\n  \n  NOVEL ASPECTS:\n    - Combination of numerical methods + parallel computing\n    - Focus on both correctness (energy conservation) and performance\n    - Complete software engineering (testing, documentation, benchmarking)\n    - Real-world application (thermal engineering, materials science)\n\nSUCCESS CRITERIA:\n  Minimum (Pass):\n    ‚úÖ Working serial implementation\n    ‚ñ° Working OpenMP implementation (>2x speedup)\n    ‚ñ° Complete documentation and report\n  \n  Target (Excellent):\n    ‚úÖ Working serial implementation (DONE)\n    ‚ñ° Working OpenMP implementation (>6x speedup)\n    ‚ñ° Working CUDA implementation (>50x speedup)\n    ‚ñ° Comprehensive performance analysis\n    ‚ñ° Publication-quality results\n    ‚ñ° Professional presentation with live demo\n\nCURRENT STATUS:\n  ‚úÖ Phase 1: Serial implementation COMPLETE\n  ‚è≥ Phase 2: OpenMP parallelization (NEXT)\n  ‚è≥ Phase 3: CUDA GPU implementation\n  ‚è≥ Phase 4: Performance analysis and reporting\n\n================================================================================\n\"\"\"\n\nprint(final_problem)\nprint(\"\\n\" + \"=\" * 80)\nprint(\"üí° This problem statement will be used in your proposal!\")\nprint(\"=\" * 80)\nprint(\"\\n‚úÖ Problem selection COMPLETE - Ready for literature review!\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Once you've selected your problem:\n",
    "\n",
    "1. ‚úÖ Complete the problem analysis above\n",
    "2. ‚úÖ Verify uniqueness with your tutor\n",
    "3. ‚úÖ Move to `02_literature_review.ipynb`\n",
    "4. ‚úÖ Start researching existing solutions\n",
    "\n",
    "---\n",
    "\n",
    "## Team Discussion Questions\n",
    "\n",
    "Before moving forward, discuss with your team:\n",
    "\n",
    "1. Do we all understand the problem?\n",
    "2. Do we have the skills to implement this?\n",
    "3. Can we complete it in the given timeframe?\n",
    "4. Is it different enough from other groups?\n",
    "5. Are we excited about this problem?\n",
    "\n",
    "If you answered YES to all questions, proceed to literature review! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}