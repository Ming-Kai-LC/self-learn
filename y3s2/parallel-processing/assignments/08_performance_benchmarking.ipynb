{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 08: Performance Benchmarking and Analysis\n",
    "\n",
    "**Difficulty**: ⭐⭐\n",
    "\n",
    "**Estimated Time**: 75 minutes\n",
    "\n",
    "**Prerequisites**: \n",
    "- Module 05: Serial Implementation\n",
    "- Module 06: Multi-Core Parallelization\n",
    "- Module 07: GPU Acceleration\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Design comprehensive benchmark suites for parallel programs\n",
    "2. Measure and analyze speedup and efficiency metrics\n",
    "3. Conduct strong and weak scaling experiments\n",
    "4. Apply statistical methods to performance data\n",
    "5. Create professional visualizations of benchmark results\n",
    "6. Identify performance bottlenecks through systematic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from typing import Tuple, List, Dict, Callable\n",
    "from dataclasses import dataclass\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try importing GPU support\n",
    "try:\n",
    "    from numba import cuda\n",
    "    GPU_AVAILABLE = cuda.is_available()\n",
    "except:\n",
    "    GPU_AVAILABLE = False\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# System info\n",
    "num_cores = cpu_count()\n",
    "print(f\"System Information:\")\n",
    "print(f\"  CPU cores: {num_cores}\")\n",
    "print(f\"  GPU available: {GPU_AVAILABLE}\")\n",
    "if GPU_AVAILABLE:\n",
    "    gpu = cuda.get_current_device()\n",
    "    print(f\"  GPU: {gpu.name.decode('utf-8')}\")\n",
    "print(f\"  NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Benchmark Framework\n",
    "\n",
    "Let's create a reusable framework for performance testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BenchmarkResult:\n",
    "    \"\"\"\n",
    "    Store results from a benchmark run.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    problem_size: int\n",
    "    num_workers: int  # cores or threads\n",
    "    times: List[float]  # multiple runs\n",
    "    \n",
    "    @property\n",
    "    def mean_time(self) -> float:\n",
    "        return np.mean(self.times)\n",
    "    \n",
    "    @property\n",
    "    def std_time(self) -> float:\n",
    "        return np.std(self.times)\n",
    "    \n",
    "    @property\n",
    "    def min_time(self) -> float:\n",
    "        return np.min(self.times)\n",
    "    \n",
    "    @property\n",
    "    def max_time(self) -> float:\n",
    "        return np.max(self.times)\n",
    "    \n",
    "    def confidence_interval(self, confidence=0.95) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Calculate confidence interval for mean time.\n",
    "        \"\"\"\n",
    "        from scipy import stats\n",
    "        ci = stats.t.interval(confidence, len(self.times)-1, \n",
    "                             loc=self.mean_time, \n",
    "                             scale=stats.sem(self.times))\n",
    "        return ci\n",
    "\n",
    "\n",
    "class BenchmarkSuite:\n",
    "    \"\"\"\n",
    "    Framework for running and analyzing benchmarks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results: List[BenchmarkResult] = []\n",
    "    \n",
    "    def run_benchmark(self, \n",
    "                     name: str,\n",
    "                     func: Callable,\n",
    "                     args: tuple,\n",
    "                     problem_size: int,\n",
    "                     num_workers: int = 1,\n",
    "                     num_runs: int = 5,\n",
    "                     warmup_runs: int = 1) -> BenchmarkResult:\n",
    "        \"\"\"\n",
    "        Run a benchmark with multiple iterations.\n",
    "        \n",
    "        Args:\n",
    "            name: Benchmark name\n",
    "            func: Function to benchmark\n",
    "            args: Arguments to pass to func\n",
    "            problem_size: Size of problem (for scaling analysis)\n",
    "            num_workers: Number of cores/threads used\n",
    "            num_runs: Number of timed runs\n",
    "            warmup_runs: Number of warmup runs (not timed)\n",
    "        \n",
    "        Returns:\n",
    "            BenchmarkResult object\n",
    "        \"\"\"\n",
    "        # Warmup runs (for JIT compilation, cache warming, etc.)\n",
    "        for _ in range(warmup_runs):\n",
    "            _ = func(*args)\n",
    "        \n",
    "        # Timed runs\n",
    "        times = []\n",
    "        for _ in range(num_runs):\n",
    "            start = time.perf_counter()\n",
    "            result = func(*args)\n",
    "            end = time.perf_counter()\n",
    "            times.append(end - start)\n",
    "        \n",
    "        # Store result\n",
    "        benchmark = BenchmarkResult(\n",
    "            name=name,\n",
    "            problem_size=problem_size,\n",
    "            num_workers=num_workers,\n",
    "            times=times\n",
    "        )\n",
    "        \n",
    "        self.results.append(benchmark)\n",
    "        return benchmark\n",
    "    \n",
    "    def calculate_speedup(self, baseline_name: str, target_name: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate speedup: T_baseline / T_target\n",
    "        \"\"\"\n",
    "        baseline = next(r for r in self.results if r.name == baseline_name)\n",
    "        target = next(r for r in self.results if r.name == target_name)\n",
    "        return baseline.mean_time / target.mean_time\n",
    "    \n",
    "    def calculate_efficiency(self, baseline_name: str, target_name: str, \n",
    "                           num_workers: int) -> float:\n",
    "        \"\"\"\n",
    "        Calculate parallel efficiency: Speedup / num_workers\n",
    "        \"\"\"\n",
    "        speedup = self.calculate_speedup(baseline_name, target_name)\n",
    "        return speedup / num_workers\n",
    "    \n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert results to pandas DataFrame for analysis.\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        for r in self.results:\n",
    "            data.append({\n",
    "                'Name': r.name,\n",
    "                'Problem Size': r.problem_size,\n",
    "                'Workers': r.num_workers,\n",
    "                'Mean Time (s)': r.mean_time,\n",
    "                'Std Dev (s)': r.std_time,\n",
    "                'Min Time (s)': r.min_time,\n",
    "                'Max Time (s)': r.max_time\n",
    "            })\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(\"Benchmark framework ready!\")\n",
    "print(f\"Available for testing: {num_cores} CPU cores\", end=\"\")\n",
    "if GPU_AVAILABLE:\n",
    "    print(\" + GPU\")\n",
    "else:\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Problem: Monte Carlo π Estimation\n",
    "\n",
    "We'll use Monte Carlo as our test case since it's simple but representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serial implementation\n",
    "def monte_carlo_pi_serial(num_samples):\n",
    "    \"\"\"Serial Monte Carlo π estimation.\"\"\"\n",
    "    inside = 0\n",
    "    for _ in range(num_samples):\n",
    "        x = np.random.random()\n",
    "        y = np.random.random()\n",
    "        if x*x + y*y <= 1.0:\n",
    "            inside += 1\n",
    "    return 4.0 * inside / num_samples\n",
    "\n",
    "\n",
    "# Vectorized implementation\n",
    "def monte_carlo_pi_vectorized(num_samples):\n",
    "    \"\"\"Vectorized Monte Carlo (single thread).\"\"\"\n",
    "    x = np.random.random(num_samples)\n",
    "    y = np.random.random(num_samples)\n",
    "    inside = np.sum(x*x + y*y <= 1.0)\n",
    "    return 4.0 * inside / num_samples\n",
    "\n",
    "\n",
    "# Parallel implementation\n",
    "def estimate_pi_chunk(num_samples):\n",
    "    \"\"\"Worker function for parallel version.\"\"\"\n",
    "    x = np.random.random(num_samples)\n",
    "    y = np.random.random(num_samples)\n",
    "    return np.sum(x*x + y*y <= 1.0)\n",
    "\n",
    "\n",
    "def monte_carlo_pi_parallel(num_samples, num_processes):\n",
    "    \"\"\"Parallel Monte Carlo using multiprocessing.\"\"\"\n",
    "    samples_per_process = num_samples // num_processes\n",
    "    \n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        results = pool.map(estimate_pi_chunk, [samples_per_process] * num_processes)\n",
    "    \n",
    "    total_inside = sum(results)\n",
    "    return 4.0 * total_inside / num_samples\n",
    "\n",
    "\n",
    "print(\"Monte Carlo implementations ready!\")\n",
    "print(\"\\nQuick test (10K samples):\")\n",
    "test_samples = 10000\n",
    "pi_est = monte_carlo_pi_vectorized(test_samples)\n",
    "print(f\"  π estimate: {pi_est:.6f}\")\n",
    "print(f\"  Actual π:   {np.pi:.6f}\")\n",
    "print(f\"  Error:      {abs(pi_est - np.pi):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Strong Scaling Analysis\n",
    "\n",
    "**Strong scaling**: Fixed problem size, increase number of workers.\n",
    "\n",
    "**Ideal**: Time decreases linearly with workers (speedup = workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STRONG SCALING ANALYSIS: Monte Carlo π Estimation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Fixed problem size\n",
    "problem_size = 10_000_000  # 10 million samples\n",
    "\n",
    "print(f\"\\nProblem size: {problem_size:,} samples (fixed)\")\n",
    "print(f\"Testing with 1 to {num_cores} workers\\n\")\n",
    "\n",
    "# Run benchmarks\n",
    "suite = BenchmarkSuite()\n",
    "\n",
    "# Serial baseline\n",
    "print(\"Serial (baseline)...\")\n",
    "result = suite.run_benchmark(\n",
    "    name=\"Serial\",\n",
    "    func=monte_carlo_pi_vectorized,\n",
    "    args=(problem_size,),\n",
    "    problem_size=problem_size,\n",
    "    num_workers=1,\n",
    "    num_runs=5\n",
    ")\n",
    "print(f\"  Time: {result.mean_time:.4f} ± {result.std_time:.4f} s\")\n",
    "serial_time = result.mean_time\n",
    "\n",
    "# Parallel with varying workers\n",
    "worker_counts = [1, 2, 4] + ([num_cores] if num_cores > 4 else [])\n",
    "\n",
    "for num_workers in worker_counts:\n",
    "    if num_workers > num_cores:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nParallel ({num_workers} workers)...\")\n",
    "    result = suite.run_benchmark(\n",
    "        name=f\"Parallel-{num_workers}\",\n",
    "        func=monte_carlo_pi_parallel,\n",
    "        args=(problem_size, num_workers),\n",
    "        problem_size=problem_size,\n",
    "        num_workers=num_workers,\n",
    "        num_runs=5\n",
    "    )\n",
    "    \n",
    "    speedup = serial_time / result.mean_time\n",
    "    efficiency = speedup / num_workers\n",
    "    \n",
    "    print(f\"  Time: {result.mean_time:.4f} ± {result.std_time:.4f} s\")\n",
    "    print(f\"  Speedup: {speedup:.2f}x\")\n",
    "    print(f\"  Efficiency: {efficiency*100:.1f}%\")\n",
    "\n",
    "# Display summary\n",
    "df_strong = suite.to_dataframe()\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STRONG SCALING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(df_strong.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize strong scaling\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Extract data for parallel runs\n",
    "parallel_results = df_strong[df_strong['Name'].str.startswith('Parallel')].copy()\n",
    "workers = parallel_results['Workers'].values\n",
    "times = parallel_results['Mean Time (s)'].values\n",
    "speedups = serial_time / times\n",
    "efficiencies = speedups / workers * 100\n",
    "\n",
    "# Plot 1: Speedup\n",
    "axes[0].plot(workers, speedups, 'o-', linewidth=2, markersize=10, label='Actual')\n",
    "axes[0].plot(workers, workers, '--', linewidth=2, color='gray', label='Ideal (linear)')\n",
    "axes[0].set_xlabel('Number of Workers', fontsize=12)\n",
    "axes[0].set_ylabel('Speedup', fontsize=12)\n",
    "axes[0].set_title('Strong Scaling: Speedup', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(workers)\n",
    "\n",
    "# Plot 2: Efficiency\n",
    "axes[1].plot(workers, efficiencies, 'o-', linewidth=2, markersize=10, color='green')\n",
    "axes[1].axhline(y=100, linestyle='--', color='gray', linewidth=2, label='100% (ideal)')\n",
    "axes[1].set_xlabel('Number of Workers', fontsize=12)\n",
    "axes[1].set_ylabel('Efficiency (%)', fontsize=12)\n",
    "axes[1].set_title('Parallel Efficiency', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(workers)\n",
    "axes[1].set_ylim([0, 110])\n",
    "\n",
    "# Plot 3: Execution Time\n",
    "axes[2].plot(workers, times, 'o-', linewidth=2, markersize=10, color='red')\n",
    "axes[2].axhline(y=serial_time, linestyle='--', color='gray', linewidth=2, label='Serial time')\n",
    "axes[2].set_xlabel('Number of Workers', fontsize=12)\n",
    "axes[2].set_ylabel('Execution Time (seconds)', fontsize=12)\n",
    "axes[2].set_title('Execution Time vs Workers', fontsize=14, fontweight='bold')\n",
    "axes[2].legend(fontsize=11)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].set_xticks(workers)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('strong_scaling_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Strong scaling plots saved to: strong_scaling_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Weak Scaling Analysis\n",
    "\n",
    "**Weak scaling**: Problem size increases proportionally with workers.\n",
    "\n",
    "**Ideal**: Time remains constant (each worker does same amount of work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"WEAK SCALING ANALYSIS: Monte Carlo π Estimation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Samples per worker (constant work per core)\n",
    "samples_per_worker = 2_000_000  # 2 million per worker\n",
    "\n",
    "print(f\"\\nSamples per worker: {samples_per_worker:,} (constant)\")\n",
    "print(f\"Total problem size increases with workers\\n\")\n",
    "\n",
    "suite_weak = BenchmarkSuite()\n",
    "\n",
    "# Baseline: 1 worker\n",
    "print(\"1 worker (baseline)...\")\n",
    "total_samples = 1 * samples_per_worker\n",
    "result = suite_weak.run_benchmark(\n",
    "    name=\"Weak-1\",\n",
    "    func=monte_carlo_pi_vectorized,\n",
    "    args=(total_samples,),\n",
    "    problem_size=total_samples,\n",
    "    num_workers=1,\n",
    "    num_runs=5\n",
    ")\n",
    "print(f\"  Problem size: {total_samples:,}\")\n",
    "print(f\"  Time: {result.mean_time:.4f} ± {result.std_time:.4f} s\")\n",
    "baseline_time = result.mean_time\n",
    "\n",
    "# Increase workers and problem size proportionally\n",
    "for num_workers in worker_counts:\n",
    "    if num_workers == 1 or num_workers > num_cores:\n",
    "        continue\n",
    "    \n",
    "    total_samples = num_workers * samples_per_worker\n",
    "    \n",
    "    print(f\"\\n{num_workers} workers...\")\n",
    "    result = suite_weak.run_benchmark(\n",
    "        name=f\"Weak-{num_workers}\",\n",
    "        func=monte_carlo_pi_parallel,\n",
    "        args=(total_samples, num_workers),\n",
    "        problem_size=total_samples,\n",
    "        num_workers=num_workers,\n",
    "        num_runs=5\n",
    "    )\n",
    "    \n",
    "    # Weak scaling efficiency: T_1 / T_p\n",
    "    weak_efficiency = baseline_time / result.mean_time\n",
    "    \n",
    "    print(f\"  Problem size: {total_samples:,}\")\n",
    "    print(f\"  Time: {result.mean_time:.4f} ± {result.std_time:.4f} s\")\n",
    "    print(f\"  Weak scaling efficiency: {weak_efficiency*100:.1f}%\")\n",
    "\n",
    "# Summary\n",
    "df_weak = suite_weak.to_dataframe()\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"WEAK SCALING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(df_weak.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize weak scaling\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "workers_weak = df_weak['Workers'].values\n",
    "times_weak = df_weak['Mean Time (s)'].values\n",
    "problem_sizes = df_weak['Problem Size'].values\n",
    "\n",
    "# Plot 1: Execution time (should be constant)\n",
    "axes[0].plot(workers_weak, times_weak, 'o-', linewidth=2, markersize=10, color='purple')\n",
    "axes[0].axhline(y=baseline_time, linestyle='--', color='gray', linewidth=2, label='Ideal (constant)')\n",
    "axes[0].set_xlabel('Number of Workers', fontsize=12)\n",
    "axes[0].set_ylabel('Execution Time (seconds)', fontsize=12)\n",
    "axes[0].set_title('Weak Scaling: Time vs Workers', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(workers_weak)\n",
    "\n",
    "# Plot 2: Problem size scaling\n",
    "ax2 = axes[1]\n",
    "ax2.bar(workers_weak, problem_sizes / 1e6, alpha=0.7, color='orange')\n",
    "ax2.set_xlabel('Number of Workers', fontsize=12)\n",
    "ax2.set_ylabel('Problem Size (millions of samples)', fontsize=12)\n",
    "ax2.set_title('Problem Size Growth', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "ax2.set_xticks(workers_weak)\n",
    "\n",
    "# Add execution time on secondary axis\n",
    "ax2_twin = ax2.twinx()\n",
    "ax2_twin.plot(workers_weak, times_weak, 'ro-', linewidth=2, markersize=8, label='Time')\n",
    "ax2_twin.set_ylabel('Execution Time (seconds)', fontsize=12, color='red')\n",
    "ax2_twin.tick_params(axis='y', labelcolor='red')\n",
    "ax2_twin.legend(loc='upper left', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('weak_scaling_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Weak scaling plots saved to: weak_scaling_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistical Analysis\n",
    "\n",
    "Proper benchmarking requires statistical rigor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def analyze_benchmark_statistics(benchmark_result: BenchmarkResult):\n",
    "    \"\"\"\n",
    "    Comprehensive statistical analysis of benchmark results.\n",
    "    \"\"\"\n",
    "    times = np.array(benchmark_result.times)\n",
    "    \n",
    "    print(f\"Benchmark: {benchmark_result.name}\")\n",
    "    print(f\"Problem size: {benchmark_result.problem_size:,}\")\n",
    "    print(f\"Number of runs: {len(times)}\")\n",
    "    print(f\"\\nDescriptive Statistics:\")\n",
    "    print(f\"  Mean:     {np.mean(times):.6f} s\")\n",
    "    print(f\"  Median:   {np.median(times):.6f} s\")\n",
    "    print(f\"  Std Dev:  {np.std(times):.6f} s\")\n",
    "    print(f\"  Min:      {np.min(times):.6f} s\")\n",
    "    print(f\"  Max:      {np.max(times):.6f} s\")\n",
    "    print(f\"  Range:    {np.max(times) - np.min(times):.6f} s\")\n",
    "    print(f\"  CV:       {np.std(times)/np.mean(times)*100:.2f}%\")  # Coefficient of variation\n",
    "    \n",
    "    # Confidence intervals\n",
    "    ci_95 = stats.t.interval(0.95, len(times)-1, loc=np.mean(times), scale=stats.sem(times))\n",
    "    ci_99 = stats.t.interval(0.99, len(times)-1, loc=np.mean(times), scale=stats.sem(times))\n",
    "    \n",
    "    print(f\"\\nConfidence Intervals:\")\n",
    "    print(f\"  95% CI:   [{ci_95[0]:.6f}, {ci_95[1]:.6f}] s\")\n",
    "    print(f\"  99% CI:   [{ci_99[0]:.6f}, {ci_99[1]:.6f}] s\")\n",
    "    \n",
    "    # Test for normality\n",
    "    if len(times) >= 3:\n",
    "        shapiro_stat, shapiro_p = stats.shapiro(times)\n",
    "        print(f\"\\nNormality Test (Shapiro-Wilk):\")\n",
    "        print(f\"  Statistic: {shapiro_stat:.4f}\")\n",
    "        print(f\"  P-value:   {shapiro_p:.4f}\")\n",
    "        print(f\"  Normal:    {'Yes' if shapiro_p > 0.05 else 'No'} (α=0.05)\")\n",
    "    \n",
    "    return {\n",
    "        'mean': np.mean(times),\n",
    "        'median': np.median(times),\n",
    "        'std': np.std(times),\n",
    "        'ci_95': ci_95,\n",
    "        'ci_99': ci_99\n",
    "    }\n",
    "\n",
    "\n",
    "# Analyze one benchmark in detail\n",
    "print(\"=\"*70)\n",
    "print(\"DETAILED STATISTICAL ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Get a benchmark result\n",
    "sample_result = suite.results[0]  # Serial baseline\n",
    "stats_result = analyze_benchmark_statistics(sample_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of timing results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Get results for different configurations\n",
    "results_to_plot = [\n",
    "    suite.results[0],  # Serial\n",
    "    suite.results[1] if len(suite.results) > 1 else suite.results[0],  # Parallel-1\n",
    "    suite.results[2] if len(suite.results) > 2 else suite.results[0],  # Parallel-2\n",
    "    suite.results[-1]  # Parallel-max\n",
    "]\n",
    "\n",
    "for idx, result in enumerate(results_to_plot):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    times = result.times\n",
    "    \n",
    "    # Histogram with KDE\n",
    "    ax.hist(times, bins=10, alpha=0.7, color='skyblue', edgecolor='black', density=True)\n",
    "    \n",
    "    # Add KDE if we have enough points\n",
    "    if len(times) > 3:\n",
    "        from scipy.stats import gaussian_kde\n",
    "        kde = gaussian_kde(times)\n",
    "        x_range = np.linspace(min(times), max(times), 100)\n",
    "        ax.plot(x_range, kde(x_range), 'r-', linewidth=2, label='KDE')\n",
    "    \n",
    "    # Add mean and median lines\n",
    "    ax.axvline(np.mean(times), color='green', linestyle='--', linewidth=2, label=f'Mean: {np.mean(times):.4f}s')\n",
    "    ax.axvline(np.median(times), color='orange', linestyle='--', linewidth=2, label=f'Median: {np.median(times):.4f}s')\n",
    "    \n",
    "    ax.set_xlabel('Execution Time (seconds)', fontsize=11)\n",
    "    ax.set_ylabel('Density', fontsize=11)\n",
    "    ax.set_title(f'{result.name} - Distribution of Times', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('timing_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Timing distribution plots saved to: timing_distributions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comprehensive Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_table(suite: BenchmarkSuite, baseline_name: str = \"Serial\"):\n",
    "    \"\"\"\n",
    "    Create comprehensive performance comparison table.\n",
    "    \"\"\"\n",
    "    baseline = next(r for r in suite.results if r.name == baseline_name)\n",
    "    baseline_time = baseline.mean_time\n",
    "    \n",
    "    data = []\n",
    "    for result in suite.results:\n",
    "        speedup = baseline_time / result.mean_time\n",
    "        efficiency = speedup / result.num_workers * 100 if result.num_workers > 0 else 0\n",
    "        \n",
    "        data.append({\n",
    "            'Implementation': result.name,\n",
    "            'Workers': result.num_workers,\n",
    "            'Mean Time (s)': f\"{result.mean_time:.4f}\",\n",
    "            '± Std Dev': f\"{result.std_time:.4f}\",\n",
    "            'Speedup': f\"{speedup:.2f}x\",\n",
    "            'Efficiency': f\"{efficiency:.1f}%\",\n",
    "            'Samples/sec': f\"{result.problem_size/result.mean_time/1e6:.2f}M\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMPREHENSIVE PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "perf_table = create_performance_table(suite)\n",
    "print(perf_table.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "perf_table.to_csv('performance_comparison.csv', index=False)\n",
    "print(\"\\nTable saved to: performance_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Amdahl's Law Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amdahls_law(p, n):\n",
    "    \"\"\"\n",
    "    Calculate theoretical speedup using Amdahl's Law.\n",
    "    \n",
    "    Speedup = 1 / ((1 - p) + p/n)\n",
    "    \n",
    "    Args:\n",
    "        p: Fraction of program that is parallelizable (0 to 1)\n",
    "        n: Number of processors\n",
    "    \n",
    "    Returns:\n",
    "        Theoretical speedup\n",
    "    \"\"\"\n",
    "    return 1 / ((1 - p) + p / n)\n",
    "\n",
    "\n",
    "# Plot Amdahl's Law for different parallelizable fractions\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "processors = np.arange(1, 65)\n",
    "parallel_fractions = [0.5, 0.75, 0.9, 0.95, 0.99, 1.0]\n",
    "\n",
    "for p in parallel_fractions:\n",
    "    speedups = [amdahls_law(p, n) for n in processors]\n",
    "    label = f'{p*100:.0f}% parallelizable' if p < 1 else 'Perfect (100%)'\n",
    "    plt.plot(processors, speedups, linewidth=2, label=label)\n",
    "\n",
    "# Add ideal (linear) speedup\n",
    "plt.plot(processors, processors, 'k--', linewidth=1, alpha=0.5, label='Ideal (linear)')\n",
    "\n",
    "# Mark our actual results\n",
    "if len(parallel_results) > 0:\n",
    "    actual_workers = parallel_results['Workers'].values\n",
    "    actual_speedups = serial_time / parallel_results['Mean Time (s)'].values\n",
    "    plt.scatter(actual_workers, actual_speedups, s=150, c='red', marker='*', \n",
    "               zorder=10, edgecolors='black', linewidths=1.5,\n",
    "               label='Our Results')\n",
    "\n",
    "plt.xlabel('Number of Processors', fontsize=12)\n",
    "plt.ylabel('Speedup', fontsize=12)\n",
    "plt.title(\"Amdahl's Law: Maximum Speedup vs Parallelizable Fraction\", \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='upper left', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([1, 64])\n",
    "plt.ylim([1, 64])\n",
    "\n",
    "# Add annotation\n",
    "plt.text(32, 5, \n",
    "         \"Even 10% serial code\\nlimits max speedup to 10x\",\n",
    "         fontsize=11, bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('amdahls_law.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Amdahl's Law plot saved to: amdahls_law.png\")\n",
    "print(\"\\nKey insight: Serial portion limits maximum achievable speedup!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Bottleneck Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"BOTTLENECK ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Common Performance Bottlenecks:\n",
    "\n",
    "1. SERIAL SECTIONS (Amdahl's Law)\n",
    "   - Data initialization\n",
    "   - Result aggregation\n",
    "   - I/O operations\n",
    "   → Minimize or parallelize\n",
    "\n",
    "2. SYNCHRONIZATION OVERHEAD\n",
    "   - Thread/process creation\n",
    "   - Locks and barriers\n",
    "   - Communication between workers\n",
    "   → Use larger work chunks\n",
    "\n",
    "3. LOAD IMBALANCE\n",
    "   - Some workers finish early\n",
    "   - Idle time while waiting\n",
    "   → Dynamic work distribution\n",
    "\n",
    "4. MEMORY BANDWIDTH\n",
    "   - CPU-GPU transfers\n",
    "   - Cache misses\n",
    "   - Memory contention\n",
    "   → Optimize access patterns\n",
    "\n",
    "5. FALSE SHARING\n",
    "   - Threads modifying adjacent memory\n",
    "   - Cache line bouncing\n",
    "   → Pad data structures\n",
    "\"\"\")\n",
    "\n",
    "# Analyze our results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"YOUR RESULTS ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "if len(parallel_results) > 0:\n",
    "    max_workers = parallel_results['Workers'].max()\n",
    "    max_speedup = speedups.max()\n",
    "    max_efficiency = efficiencies.max()\n",
    "    \n",
    "    print(f\"Maximum speedup achieved: {max_speedup:.2f}x with {max_workers} workers\")\n",
    "    print(f\"Peak efficiency: {max_efficiency:.1f}%\")\n",
    "    \n",
    "    # Estimate parallel fraction from best speedup\n",
    "    # Using Amdahl's law: S = 1 / ((1-p) + p/n)\n",
    "    # Solving for p: p = (n*(S-1))/(S*(n-1))\n",
    "    S = max_speedup\n",
    "    n = max_workers\n",
    "    if n > 1 and S > 1:\n",
    "        p_estimated = (n * (S - 1)) / (S * (n - 1))\n",
    "        serial_fraction = 1 - p_estimated\n",
    "        \n",
    "        print(f\"\\nEstimated parallelizable fraction: {p_estimated*100:.1f}%\")\n",
    "        print(f\"Estimated serial fraction: {serial_fraction*100:.1f}%\")\n",
    "        print(f\"\\nTheoretical max speedup (infinite cores): {1/serial_fraction:.2f}x\")\n",
    "    \n",
    "    # Scaling efficiency analysis\n",
    "    if len(efficiencies) > 1:\n",
    "        efficiency_drop = efficiencies[0] - efficiencies[-1]\n",
    "        print(f\"\\nEfficiency drop from 1 to {max_workers} workers: {efficiency_drop:.1f}%\")\n",
    "        \n",
    "        if efficiency_drop > 20:\n",
    "            print(\"⚠ Significant efficiency loss - check for:\")\n",
    "            print(\"  - Synchronization overhead\")\n",
    "            print(\"  - Load imbalance\")\n",
    "            print(\"  - Memory contention\")\n",
    "        elif efficiency_drop > 10:\n",
    "            print(\"⚠ Moderate efficiency loss - room for optimization\")\n",
    "        else:\n",
    "            print(\"✓ Good scaling efficiency!\")\n",
    "else:\n",
    "    print(\"Not enough data for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PERFORMANCE BENCHMARKING BEST PRACTICES\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1. EXPERIMENTAL DESIGN:\n",
    "   ✓ Multiple runs (5-10) for statistical significance\n",
    "   ✓ Warmup runs before timing (JIT compilation, caching)\n",
    "   ✓ Controlled environment (close other programs)\n",
    "   ✓ Test various problem sizes\n",
    "   ✓ Test various worker counts\n",
    "\n",
    "2. METRICS TO COLLECT:\n",
    "   ✓ Execution time (mean, std, min, max)\n",
    "   ✓ Speedup (T_serial / T_parallel)\n",
    "   ✓ Efficiency (Speedup / num_workers)\n",
    "   ✓ Throughput (work/time)\n",
    "   ✓ Memory usage\n",
    "   ✓ CPU/GPU utilization\n",
    "\n",
    "3. STATISTICAL RIGOR:\n",
    "   ✓ Report confidence intervals\n",
    "   ✓ Test for outliers\n",
    "   ✓ Check distribution normality\n",
    "   ✓ Use appropriate statistical tests\n",
    "\n",
    "4. VISUALIZATION:\n",
    "   ✓ Speedup curves (actual vs ideal)\n",
    "   ✓ Efficiency plots\n",
    "   ✓ Strong/weak scaling graphs\n",
    "   ✓ Error bars showing variability\n",
    "   ✓ Comparison tables\n",
    "\n",
    "5. ANALYSIS:\n",
    "   ✓ Compare to theoretical limits (Amdahl's Law)\n",
    "   ✓ Identify bottlenecks\n",
    "   ✓ Calculate parallel fraction\n",
    "   ✓ Determine optimal configuration\n",
    "\n",
    "6. REPORTING:\n",
    "   ✓ Document hardware/software versions\n",
    "   ✓ Describe problem characteristics\n",
    "   ✓ Explain methodology\n",
    "   ✓ Provide reproducible code\n",
    "   ✓ Save data and plots\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FILES GENERATED IN THIS SESSION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "  strong_scaling_analysis.png   - Strong scaling plots\n",
    "  weak_scaling_analysis.png     - Weak scaling plots\n",
    "  timing_distributions.png      - Statistical distributions\n",
    "  amdahls_law.png              - Theoretical vs actual speedup\n",
    "  performance_comparison.csv    - Detailed results table\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this module, you learned:\n",
    "\n",
    "1. **Benchmark Design**\n",
    "   - Framework for systematic testing\n",
    "   - Multiple runs for statistical validity\n",
    "   - Warmup and timing methodology\n",
    "\n",
    "2. **Scaling Analysis**\n",
    "   - Strong scaling (fixed problem size)\n",
    "   - Weak scaling (scaled problem size)\n",
    "   - Speedup and efficiency metrics\n",
    "\n",
    "3. **Statistical Methods**\n",
    "   - Confidence intervals\n",
    "   - Distribution analysis\n",
    "   - Normality testing\n",
    "\n",
    "4. **Visualization**\n",
    "   - Professional performance plots\n",
    "   - Comparison charts\n",
    "   - Amdahl's Law analysis\n",
    "\n",
    "5. **Bottleneck Identification**\n",
    "   - Serial sections\n",
    "   - Synchronization overhead\n",
    "   - Load imbalance\n",
    "\n",
    "**What's Next?**\n",
    "\n",
    "- **Module 09**: Advanced optimization techniques and hybrid approaches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
