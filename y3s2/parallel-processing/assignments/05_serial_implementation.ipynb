{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 05: Serial Implementation - Baseline Performance\n",
    "\n",
    "**Difficulty**: ⭐⭐\n",
    "\n",
    "**Estimated Time**: 60 minutes\n",
    "\n",
    "**Prerequisites**: \n",
    "- Basic Python programming\n",
    "- Understanding of loops and functions\n",
    "- NumPy basics\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Implement serial (non-parallel) versions of computationally intensive problems\n",
    "2. Use profiling tools to measure performance and identify bottlenecks\n",
    "3. Establish baseline performance metrics for comparison with parallel implementations\n",
    "4. Apply code documentation best practices for scientific computing\n",
    "5. Structure code for easy parallelization in future modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "We'll use several profiling and timing tools to measure performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "from typing import Tuple, List\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Timing Utilities\n",
    "\n",
    "Before implementing our problems, let's create utilities for accurate timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_function(func, *args, num_runs=5, **kwargs):\n",
    "    \"\"\"\n",
    "    Time a function execution with multiple runs for accuracy.\n",
    "    \n",
    "    Args:\n",
    "        func: Function to time\n",
    "        *args: Positional arguments for func\n",
    "        num_runs: Number of times to run (default: 5)\n",
    "        **kwargs: Keyword arguments for func\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (mean_time, std_time, result_from_last_run)\n",
    "    \"\"\"\n",
    "    times = []\n",
    "    result = None\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        times.append(end - start)\n",
    "    \n",
    "    mean_time = np.mean(times)\n",
    "    std_time = np.std(times)\n",
    "    \n",
    "    return mean_time, std_time, result\n",
    "\n",
    "\n",
    "def print_timing_result(name, mean_time, std_time):\n",
    "    \"\"\"\n",
    "    Print timing results in a formatted way.\n",
    "    \n",
    "    Args:\n",
    "        name: Name of the operation\n",
    "        mean_time: Mean execution time in seconds\n",
    "        std_time: Standard deviation of execution time\n",
    "    \"\"\"\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Mean time: {mean_time:.4f} seconds\")\n",
    "    print(f\"  Std dev:   {std_time:.4f} seconds\")\n",
    "    print(f\"  Range:     [{mean_time - std_time:.4f}, {mean_time + std_time:.4f}] seconds\")\n",
    "\n",
    "\n",
    "# Test the timing utilities\n",
    "def test_function(n):\n",
    "    \"\"\"Simple test function that sums numbers.\"\"\"\n",
    "    return sum(range(n))\n",
    "\n",
    "mean_t, std_t, result = time_function(test_function, 1000000, num_runs=3)\n",
    "print_timing_result(\"Test function (sum 1M numbers)\", mean_t, std_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Problem 1: Image Processing (Filters)\n",
    "\n",
    "Image filtering is highly parallelizable because each pixel can be processed independently.\n",
    "We'll implement Gaussian blur and edge detection filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_image(size=(512, 512)):\n",
    "    \"\"\"\n",
    "    Create a test image with various patterns for filter testing.\n",
    "    \n",
    "    Args:\n",
    "        size: Tuple of (height, width)\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Test image (grayscale, values 0-255)\n",
    "    \"\"\"\n",
    "    height, width = size\n",
    "    image = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    # Create gradient background\n",
    "    for i in range(height):\n",
    "        image[i, :] = int(255 * i / height)\n",
    "    \n",
    "    # Add some geometric shapes (edges for edge detection)\n",
    "    # Rectangle\n",
    "    image[100:200, 100:300] = 200\n",
    "    \n",
    "    # Circle\n",
    "    center_y, center_x = height // 2, width // 2\n",
    "    radius = 80\n",
    "    y, x = np.ogrid[:height, :width]\n",
    "    mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2\n",
    "    image[mask] = 150\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.randint(-20, 20, size=(height, width))\n",
    "    image = np.clip(image.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "# Create test images of different sizes\n",
    "small_image = create_test_image((256, 256))\n",
    "medium_image = create_test_image((512, 512))\n",
    "large_image = create_test_image((1024, 1024))\n",
    "\n",
    "# Visualize test image\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(small_image, cmap='gray')\n",
    "plt.title(f'Small Image ({small_image.shape[0]}x{small_image.shape[1]})')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(medium_image, cmap='gray')\n",
    "plt.title(f'Medium Image ({medium_image.shape[0]}x{medium_image.shape[1]})')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(large_image, cmap='gray')\n",
    "plt.title(f'Large Image ({large_image.shape[0]}x{large_image.shape[1]})')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Created test images: {small_image.shape}, {medium_image.shape}, {large_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Serial Gaussian Blur Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_kernel(size=5, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Create a Gaussian kernel for image filtering.\n",
    "    \n",
    "    Args:\n",
    "        size: Kernel size (must be odd)\n",
    "        sigma: Standard deviation of Gaussian distribution\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Normalized Gaussian kernel\n",
    "    \"\"\"\n",
    "    # Ensure size is odd\n",
    "    if size % 2 == 0:\n",
    "        size += 1\n",
    "    \n",
    "    # Create coordinate arrays\n",
    "    ax = np.arange(-size // 2 + 1, size // 2 + 1)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    \n",
    "    # Calculate Gaussian values\n",
    "    kernel = np.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "    \n",
    "    # Normalize so sum equals 1\n",
    "    kernel = kernel / np.sum(kernel)\n",
    "    \n",
    "    return kernel\n",
    "\n",
    "\n",
    "def apply_filter_serial(image, kernel):\n",
    "    \"\"\"\n",
    "    Apply a convolution filter to an image using serial processing.\n",
    "    \n",
    "    This is the baseline implementation that processes each pixel sequentially.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (2D numpy array)\n",
    "        kernel: Convolution kernel (2D numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Filtered image\n",
    "    \"\"\"\n",
    "    height, width = image.shape\n",
    "    k_height, k_width = kernel.shape\n",
    "    \n",
    "    # Calculate padding needed\n",
    "    pad_h = k_height // 2\n",
    "    pad_w = k_width // 2\n",
    "    \n",
    "    # Pad image to handle borders\n",
    "    padded = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode='edge')\n",
    "    \n",
    "    # Create output image\n",
    "    output = np.zeros_like(image, dtype=np.float32)\n",
    "    \n",
    "    # Apply convolution - THIS IS THE BOTTLENECK\n",
    "    # Each pixel processed sequentially (nested loops)\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            # Extract region of interest\n",
    "            region = padded[i:i+k_height, j:j+k_width]\n",
    "            \n",
    "            # Apply kernel (element-wise multiply and sum)\n",
    "            output[i, j] = np.sum(region * kernel)\n",
    "    \n",
    "    # Clip values to valid range and convert back to uint8\n",
    "    output = np.clip(output, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "# Create Gaussian kernel\n",
    "gaussian_kernel = create_gaussian_kernel(size=5, sigma=1.5)\n",
    "\n",
    "print(\"Gaussian Kernel (5x5):\")\n",
    "print(gaussian_kernel)\n",
    "print(f\"\\nKernel sum (should be ~1.0): {np.sum(gaussian_kernel):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Test Gaussian Blur and Measure Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on small image first\n",
    "print(\"Testing Gaussian blur on small image...\")\n",
    "mean_t, std_t, blurred_small = time_function(\n",
    "    apply_filter_serial, \n",
    "    small_image, \n",
    "    gaussian_kernel,\n",
    "    num_runs=3\n",
    ")\n",
    "print_timing_result(\"Small image (256x256)\", mean_t, std_t)\n",
    "\n",
    "# Visualize result\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(small_image, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(blurred_small, cmap='gray')\n",
    "plt.title('Gaussian Blur (Serial)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark different image sizes\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GAUSSIAN BLUR PERFORMANCE BENCHMARK (Serial)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "benchmark_results = []\n",
    "\n",
    "test_images = [\n",
    "    (\"Small (256x256)\", small_image),\n",
    "    (\"Medium (512x512)\", medium_image),\n",
    "    (\"Large (1024x1024)\", large_image)\n",
    "]\n",
    "\n",
    "for name, img in test_images:\n",
    "    print(f\"\\nTesting {name}...\")\n",
    "    mean_t, std_t, _ = time_function(\n",
    "        apply_filter_serial, \n",
    "        img, \n",
    "        gaussian_kernel,\n",
    "        num_runs=3\n",
    "    )\n",
    "    print_timing_result(name, mean_t, std_t)\n",
    "    \n",
    "    # Calculate pixels processed per second\n",
    "    pixels = img.shape[0] * img.shape[1]\n",
    "    pixels_per_sec = pixels / mean_t\n",
    "    \n",
    "    benchmark_results.append({\n",
    "        'Image Size': name,\n",
    "        'Pixels': pixels,\n",
    "        'Mean Time (s)': mean_t,\n",
    "        'Std Dev (s)': std_t,\n",
    "        'Pixels/sec': pixels_per_sec\n",
    "    })\n",
    "\n",
    "# Display results as table\n",
    "df_results = pd.DataFrame(benchmark_results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*60)\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Serial Edge Detection Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sobel_kernels():\n",
    "    \"\"\"\n",
    "    Create Sobel edge detection kernels for horizontal and vertical edges.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (horizontal_kernel, vertical_kernel)\n",
    "    \"\"\"\n",
    "    # Sobel horizontal (detects vertical edges)\n",
    "    sobel_x = np.array([\n",
    "        [-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Sobel vertical (detects horizontal edges)\n",
    "    sobel_y = np.array([\n",
    "        [-1, -2, -1],\n",
    "        [ 0,  0,  0],\n",
    "        [ 1,  2,  1]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    return sobel_x, sobel_y\n",
    "\n",
    "\n",
    "def edge_detection_serial(image):\n",
    "    \"\"\"\n",
    "    Perform edge detection using Sobel operator (serial implementation).\n",
    "    \n",
    "    Args:\n",
    "        image: Input grayscale image\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Edge magnitude image\n",
    "    \"\"\"\n",
    "    sobel_x, sobel_y = create_sobel_kernels()\n",
    "    \n",
    "    # Apply both kernels\n",
    "    edges_x = apply_filter_serial(image, sobel_x)\n",
    "    edges_y = apply_filter_serial(image, sobel_y)\n",
    "    \n",
    "    # Calculate edge magnitude\n",
    "    magnitude = np.sqrt(edges_x.astype(np.float32)**2 + edges_y.astype(np.float32)**2)\n",
    "    \n",
    "    # Normalize to 0-255 range\n",
    "    magnitude = np.clip(magnitude, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return magnitude\n",
    "\n",
    "\n",
    "# Test edge detection\n",
    "print(\"Testing edge detection on small image...\")\n",
    "mean_t, std_t, edges_small = time_function(\n",
    "    edge_detection_serial, \n",
    "    small_image,\n",
    "    num_runs=3\n",
    ")\n",
    "print_timing_result(\"Edge detection (256x256)\", mean_t, std_t)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(small_image, cmap='gray')\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(blurred_small, cmap='gray')\n",
    "plt.title('Gaussian Blur')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(edges_small, cmap='gray')\n",
    "plt.title('Edge Detection')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Problem 2: Matrix Multiplication\n",
    "\n",
    "Matrix multiplication is a fundamental operation in scientific computing and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_multiply_serial(A, B):\n",
    "    \"\"\"\n",
    "    Multiply two matrices using serial triple-nested loop.\n",
    "    \n",
    "    This is the naive implementation that serves as our baseline.\n",
    "    Time complexity: O(n³) for n×n matrices\n",
    "    \n",
    "    Args:\n",
    "        A: First matrix (m × n)\n",
    "        B: Second matrix (n × p)\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Result matrix (m × p)\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    n2, p = B.shape\n",
    "    \n",
    "    # Verify dimensions are compatible\n",
    "    assert n == n2, f\"Incompatible dimensions: {A.shape} × {B.shape}\"\n",
    "    \n",
    "    # Initialize result matrix\n",
    "    C = np.zeros((m, p), dtype=np.float64)\n",
    "    \n",
    "    # Triple nested loop - THIS IS THE BOTTLENECK\n",
    "    for i in range(m):\n",
    "        for j in range(p):\n",
    "            for k in range(n):\n",
    "                C[i, j] += A[i, k] * B[k, j]\n",
    "    \n",
    "    return C\n",
    "\n",
    "\n",
    "def matrix_multiply_numpy(A, B):\n",
    "    \"\"\"\n",
    "    Multiply matrices using NumPy's optimized implementation.\n",
    "    \n",
    "    This uses BLAS/LAPACK libraries and serves as comparison.\n",
    "    NumPy's implementation is already highly optimized.\n",
    "    \n",
    "    Args:\n",
    "        A: First matrix\n",
    "        B: Second matrix\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Result matrix\n",
    "    \"\"\"\n",
    "    return np.dot(A, B)\n",
    "\n",
    "\n",
    "# Create test matrices\n",
    "small_matrix_a = np.random.rand(100, 100)\n",
    "small_matrix_b = np.random.rand(100, 100)\n",
    "\n",
    "medium_matrix_a = np.random.rand(300, 300)\n",
    "medium_matrix_b = np.random.rand(300, 300)\n",
    "\n",
    "large_matrix_a = np.random.rand(500, 500)\n",
    "large_matrix_b = np.random.rand(500, 500)\n",
    "\n",
    "print(\"Test matrices created:\")\n",
    "print(f\"  Small: {small_matrix_a.shape} × {small_matrix_b.shape}\")\n",
    "print(f\"  Medium: {medium_matrix_a.shape} × {medium_matrix_b.shape}\")\n",
    "print(f\"  Large: {large_matrix_a.shape} × {large_matrix_b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify correctness first (compare with NumPy)\n",
    "print(\"Verifying correctness on small matrix...\")\n",
    "result_serial = matrix_multiply_serial(small_matrix_a, small_matrix_b)\n",
    "result_numpy = matrix_multiply_numpy(small_matrix_a, small_matrix_b)\n",
    "\n",
    "# Check if results are close (within floating point precision)\n",
    "are_close = np.allclose(result_serial, result_numpy, rtol=1e-10)\n",
    "max_diff = np.max(np.abs(result_serial - result_numpy))\n",
    "\n",
    "print(f\"Results match NumPy: {are_close}\")\n",
    "print(f\"Maximum difference: {max_diff:.2e}\")\n",
    "\n",
    "if are_close:\n",
    "    print(\"✓ Serial implementation is correct!\")\n",
    "else:\n",
    "    print(\"✗ Implementation error detected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark matrix multiplication\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MATRIX MULTIPLICATION PERFORMANCE BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "matrix_results = []\n",
    "\n",
    "test_matrices = [\n",
    "    (\"Small (100×100)\", small_matrix_a, small_matrix_b),\n",
    "    (\"Medium (300×300)\", medium_matrix_a, medium_matrix_b),\n",
    "    # Large matrix takes too long with serial implementation\n",
    "    # (\"Large (500×500)\", large_matrix_a, large_matrix_b)\n",
    "]\n",
    "\n",
    "for name, A, B in test_matrices:\n",
    "    print(f\"\\nTesting {name}...\")\n",
    "    \n",
    "    # Serial implementation\n",
    "    print(\"  Serial implementation:\")\n",
    "    mean_serial, std_serial, _ = time_function(\n",
    "        matrix_multiply_serial, A, B, num_runs=3\n",
    "    )\n",
    "    print(f\"    Mean: {mean_serial:.4f} s, Std: {std_serial:.4f} s\")\n",
    "    \n",
    "    # NumPy implementation (for comparison)\n",
    "    print(\"  NumPy implementation (optimized):\")\n",
    "    mean_numpy, std_numpy, _ = time_function(\n",
    "        matrix_multiply_numpy, A, B, num_runs=3\n",
    "    )\n",
    "    print(f\"    Mean: {mean_numpy:.4f} s, Std: {std_numpy:.4f} s\")\n",
    "    \n",
    "    # Calculate speedup (how much faster is NumPy)\n",
    "    speedup = mean_serial / mean_numpy\n",
    "    print(f\"  NumPy speedup: {speedup:.2f}x\")\n",
    "    \n",
    "    # Calculate FLOPS (floating point operations per second)\n",
    "    # Matrix multiplication requires 2n³ operations for n×n matrices\n",
    "    n = A.shape[0]\n",
    "    flops = 2 * n**3\n",
    "    gflops_serial = (flops / mean_serial) / 1e9\n",
    "    gflops_numpy = (flops / mean_numpy) / 1e9\n",
    "    \n",
    "    matrix_results.append({\n",
    "        'Matrix Size': name,\n",
    "        'Serial Time (s)': mean_serial,\n",
    "        'NumPy Time (s)': mean_numpy,\n",
    "        'Speedup': speedup,\n",
    "        'Serial GFLOPS': gflops_serial,\n",
    "        'NumPy GFLOPS': gflops_numpy\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "df_matrix = pd.DataFrame(matrix_results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*60)\n",
    "print(df_matrix.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Problem 3: Monte Carlo Simulation\n",
    "\n",
    "Monte Carlo methods use random sampling to solve problems. We'll estimate π and calculate option prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Monte Carlo π Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pi_serial(num_samples):\n",
    "    \"\"\"\n",
    "    Estimate π using Monte Carlo method (serial implementation).\n",
    "    \n",
    "    Method: Generate random points in unit square [0,1]×[0,1].\n",
    "    Count how many fall inside the quarter circle (x²+y²≤1).\n",
    "    π ≈ 4 × (points inside circle) / (total points)\n",
    "    \n",
    "    Args:\n",
    "        num_samples: Number of random points to generate\n",
    "    \n",
    "    Returns:\n",
    "        float: Estimated value of π\n",
    "    \"\"\"\n",
    "    inside_circle = 0\n",
    "    \n",
    "    # Generate and test points one by one - THIS IS THE BOTTLENECK\n",
    "    for _ in range(num_samples):\n",
    "        # Random point in unit square\n",
    "        x = np.random.random()\n",
    "        y = np.random.random()\n",
    "        \n",
    "        # Check if inside quarter circle\n",
    "        if x*x + y*y <= 1.0:\n",
    "            inside_circle += 1\n",
    "    \n",
    "    # Calculate π estimate\n",
    "    pi_estimate = 4.0 * inside_circle / num_samples\n",
    "    \n",
    "    return pi_estimate\n",
    "\n",
    "\n",
    "def estimate_pi_vectorized(num_samples):\n",
    "    \"\"\"\n",
    "    Estimate π using vectorized NumPy operations.\n",
    "    \n",
    "    This is faster than the serial version but not parallel (single thread).\n",
    "    \n",
    "    Args:\n",
    "        num_samples: Number of random points\n",
    "    \n",
    "    Returns:\n",
    "        float: Estimated value of π\n",
    "    \"\"\"\n",
    "    # Generate all points at once (vectorized)\n",
    "    x = np.random.random(num_samples)\n",
    "    y = np.random.random(num_samples)\n",
    "    \n",
    "    # Check which points are inside circle (vectorized)\n",
    "    inside_circle = np.sum(x*x + y*y <= 1.0)\n",
    "    \n",
    "    # Calculate π estimate\n",
    "    pi_estimate = 4.0 * inside_circle / num_samples\n",
    "    \n",
    "    return pi_estimate\n",
    "\n",
    "\n",
    "# Test with small sample\n",
    "print(\"Testing π estimation...\")\n",
    "pi_est = estimate_pi_serial(10000)\n",
    "error = abs(pi_est - np.pi)\n",
    "print(f\"Estimated π: {pi_est:.6f}\")\n",
    "print(f\"Actual π:    {np.pi:.6f}\")\n",
    "print(f\"Error:       {error:.6f} ({100*error/np.pi:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark π estimation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MONTE CARLO π ESTIMATION BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pi_results = []\n",
    "\n",
    "sample_sizes = [\n",
    "    (\"Small\", 100_000),\n",
    "    (\"Medium\", 1_000_000),\n",
    "    (\"Large\", 10_000_000)\n",
    "]\n",
    "\n",
    "for name, num_samples in sample_sizes:\n",
    "    print(f\"\\nTesting {name} ({num_samples:,} samples)...\")\n",
    "    \n",
    "    # Serial implementation\n",
    "    print(\"  Serial implementation:\")\n",
    "    mean_serial, std_serial, pi_serial = time_function(\n",
    "        estimate_pi_serial, num_samples, num_runs=3\n",
    "    )\n",
    "    print(f\"    Time: {mean_serial:.4f} s, π estimate: {pi_serial:.6f}\")\n",
    "    \n",
    "    # Vectorized implementation\n",
    "    print(\"  Vectorized implementation:\")\n",
    "    mean_vec, std_vec, pi_vec = time_function(\n",
    "        estimate_pi_vectorized, num_samples, num_runs=3\n",
    "    )\n",
    "    print(f\"    Time: {mean_vec:.4f} s, π estimate: {pi_vec:.6f}\")\n",
    "    \n",
    "    speedup = mean_serial / mean_vec\n",
    "    print(f\"  Vectorization speedup: {speedup:.2f}x\")\n",
    "    \n",
    "    pi_results.append({\n",
    "        'Sample Size': f\"{num_samples:,}\",\n",
    "        'Serial Time (s)': mean_serial,\n",
    "        'Vectorized Time (s)': mean_vec,\n",
    "        'Speedup': speedup,\n",
    "        'π Estimate': pi_serial,\n",
    "        'Error': abs(pi_serial - np.pi)\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "df_pi = pd.DataFrame(pi_results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*60)\n",
    "print(df_pi.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Monte Carlo Option Pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_option_pricing_serial(S0, K, T, r, sigma, num_simulations):\n",
    "    \"\"\"\n",
    "    Price a European call option using Monte Carlo simulation (serial).\n",
    "    \n",
    "    Black-Scholes formula for stock price evolution:\n",
    "    S(T) = S(0) * exp((r - σ²/2)T + σ√T*Z)\n",
    "    where Z ~ N(0,1)\n",
    "    \n",
    "    Args:\n",
    "        S0: Initial stock price\n",
    "        K: Strike price\n",
    "        T: Time to maturity (years)\n",
    "        r: Risk-free interest rate\n",
    "        sigma: Volatility\n",
    "        num_simulations: Number of price paths to simulate\n",
    "    \n",
    "    Returns:\n",
    "        float: Estimated option price\n",
    "    \"\"\"\n",
    "    payoffs = []\n",
    "    \n",
    "    # Simulate each price path independently - THIS IS THE BOTTLENECK\n",
    "    for _ in range(num_simulations):\n",
    "        # Generate random normal variable\n",
    "        Z = np.random.standard_normal()\n",
    "        \n",
    "        # Calculate stock price at maturity\n",
    "        ST = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * Z)\n",
    "        \n",
    "        # Calculate payoff (max(S-K, 0) for call option)\n",
    "        payoff = max(ST - K, 0)\n",
    "        payoffs.append(payoff)\n",
    "    \n",
    "    # Discount average payoff to present value\n",
    "    option_price = np.exp(-r * T) * np.mean(payoffs)\n",
    "    \n",
    "    return option_price\n",
    "\n",
    "\n",
    "def monte_carlo_option_pricing_vectorized(S0, K, T, r, sigma, num_simulations):\n",
    "    \"\"\"\n",
    "    Price a European call option using vectorized Monte Carlo.\n",
    "    \n",
    "    Args:\n",
    "        S0: Initial stock price\n",
    "        K: Strike price\n",
    "        T: Time to maturity\n",
    "        r: Risk-free rate\n",
    "        sigma: Volatility\n",
    "        num_simulations: Number of simulations\n",
    "    \n",
    "    Returns:\n",
    "        float: Estimated option price\n",
    "    \"\"\"\n",
    "    # Generate all random variables at once\n",
    "    Z = np.random.standard_normal(num_simulations)\n",
    "    \n",
    "    # Calculate all final stock prices (vectorized)\n",
    "    ST = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * Z)\n",
    "    \n",
    "    # Calculate all payoffs (vectorized)\n",
    "    payoffs = np.maximum(ST - K, 0)\n",
    "    \n",
    "    # Discount average payoff\n",
    "    option_price = np.exp(-r * T) * np.mean(payoffs)\n",
    "    \n",
    "    return option_price\n",
    "\n",
    "\n",
    "# Test option pricing\n",
    "print(\"Testing option pricing...\")\n",
    "print(\"\\nOption parameters:\")\n",
    "S0 = 100      # Initial stock price\n",
    "K = 105       # Strike price\n",
    "T = 1.0       # 1 year to maturity\n",
    "r = 0.05      # 5% risk-free rate\n",
    "sigma = 0.2   # 20% volatility\n",
    "\n",
    "print(f\"  S0 (initial price): ${S0}\")\n",
    "print(f\"  K (strike price):   ${K}\")\n",
    "print(f\"  T (maturity):       {T} years\")\n",
    "print(f\"  r (risk-free rate): {r*100}%\")\n",
    "print(f\"  σ (volatility):     {sigma*100}%\")\n",
    "\n",
    "price_serial = monte_carlo_option_pricing_serial(S0, K, T, r, sigma, 10000)\n",
    "print(f\"\\nEstimated option price: ${price_serial:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark option pricing\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MONTE CARLO OPTION PRICING BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "option_results = []\n",
    "\n",
    "simulation_counts = [\n",
    "    (\"Small\", 10_000),\n",
    "    (\"Medium\", 100_000),\n",
    "    (\"Large\", 1_000_000)\n",
    "]\n",
    "\n",
    "for name, num_sims in simulation_counts:\n",
    "    print(f\"\\nTesting {name} ({num_sims:,} simulations)...\")\n",
    "    \n",
    "    # Serial\n",
    "    print(\"  Serial implementation:\")\n",
    "    mean_serial, std_serial, price_serial = time_function(\n",
    "        monte_carlo_option_pricing_serial,\n",
    "        S0, K, T, r, sigma, num_sims,\n",
    "        num_runs=3\n",
    "    )\n",
    "    print(f\"    Time: {mean_serial:.4f} s, Price: ${price_serial:.4f}\")\n",
    "    \n",
    "    # Vectorized\n",
    "    print(\"  Vectorized implementation:\")\n",
    "    mean_vec, std_vec, price_vec = time_function(\n",
    "        monte_carlo_option_pricing_vectorized,\n",
    "        S0, K, T, r, sigma, num_sims,\n",
    "        num_runs=3\n",
    "    )\n",
    "    print(f\"    Time: {mean_vec:.4f} s, Price: ${price_vec:.4f}\")\n",
    "    \n",
    "    speedup = mean_serial / mean_vec\n",
    "    print(f\"  Vectorization speedup: {speedup:.2f}x\")\n",
    "    \n",
    "    option_results.append({\n",
    "        'Simulations': f\"{num_sims:,}\",\n",
    "        'Serial Time (s)': mean_serial,\n",
    "        'Vectorized Time (s)': mean_vec,\n",
    "        'Speedup': speedup,\n",
    "        'Option Price': price_serial\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "df_option = pd.DataFrame(option_results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*60)\n",
    "print(df_option.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Profiling with cProfile\n",
    "\n",
    "Let's use Python's built-in profiler to identify bottlenecks in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_function(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Profile a function using cProfile and display results.\n",
    "    \n",
    "    Args:\n",
    "        func: Function to profile\n",
    "        *args: Arguments for function\n",
    "        **kwargs: Keyword arguments for function\n",
    "    \"\"\"\n",
    "    profiler = cProfile.Profile()\n",
    "    \n",
    "    # Run function under profiler\n",
    "    profiler.enable()\n",
    "    result = func(*args, **kwargs)\n",
    "    profiler.disable()\n",
    "    \n",
    "    # Get statistics\n",
    "    s = StringIO()\n",
    "    stats = pstats.Stats(profiler, stream=s)\n",
    "    stats.sort_stats('cumulative')\n",
    "    stats.print_stats(20)  # Top 20 functions\n",
    "    \n",
    "    print(s.getvalue())\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Profiling image filter (small image)...\")\n",
    "print(\"=\"*60)\n",
    "profile_function(apply_filter_serial, small_image, gaussian_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nProfiling matrix multiplication (small matrix)...\")\n",
    "print(\"=\"*60)\n",
    "profile_function(matrix_multiply_serial, small_matrix_a, small_matrix_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nProfiling Monte Carlo simulation (100K samples)...\")\n",
    "print(\"=\"*60)\n",
    "profile_function(estimate_pi_serial, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary: Baseline Performance Results\n",
    "\n",
    "Let's consolidate all our baseline performance measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"BASELINE PERFORMANCE SUMMARY (SERIAL IMPLEMENTATIONS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. IMAGE PROCESSING (Gaussian Blur)\")\n",
    "print(\"-\" * 70)\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n2. MATRIX MULTIPLICATION\")\n",
    "print(\"-\" * 70)\n",
    "print(df_matrix.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n3. MONTE CARLO π ESTIMATION\")\n",
    "print(\"-\" * 70)\n",
    "print(df_pi.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\n4. MONTE CARLO OPTION PRICING\")\n",
    "print(\"-\" * 70)\n",
    "print(df_option.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1. IMAGE PROCESSING: O(n²) complexity - scales quadratically with image size\n",
    "   - Each pixel requires convolution with kernel\n",
    "   - Highly parallelizable (pixels are independent)\n",
    "\n",
    "2. MATRIX MULTIPLICATION: O(n³) complexity - scales cubically\n",
    "   - Triple nested loop is the bottleneck\n",
    "   - NumPy is 10-100x faster (using optimized BLAS)\n",
    "   - Excellent candidate for parallelization\n",
    "\n",
    "3. MONTE CARLO: O(n) complexity - linear with sample size\n",
    "   - Each sample is independent (embarrassingly parallel)\n",
    "   - Vectorization gives 10-50x speedup\n",
    "   - Perfect candidate for GPU acceleration\n",
    "\n",
    "NEXT STEPS:\n",
    "- Module 06: Implement multi-core CPU parallelization\n",
    "- Module 07: Implement GPU acceleration (CUDA)\n",
    "- Module 08: Comprehensive performance benchmarking\n",
    "- Module 09: Advanced optimization techniques\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exercises\n",
    "\n",
    "Practice implementing and profiling serial algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Implement Median Filter\n",
    "\n",
    "Implement a median filter for noise removal. Instead of weighted average (like Gaussian), use the median value of the neighborhood.\n",
    "\n",
    "**Task**: Complete the function below and benchmark it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter_serial(image, kernel_size=5):\n",
    "    \"\"\"\n",
    "    Apply median filter to remove noise.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image\n",
    "        kernel_size: Size of filter window (must be odd)\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Filtered image\n",
    "    \"\"\"\n",
    "    # TODO: Implement median filter\n",
    "    # Hint: Use np.median() on the neighborhood\n",
    "    pass\n",
    "\n",
    "# Test your implementation\n",
    "# filtered = median_filter_serial(small_image, kernel_size=5)\n",
    "# plt.imshow(filtered, cmap='gray')\n",
    "# plt.title('Median Filtered')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Matrix Multiplication with Different Loop Orders\n",
    "\n",
    "Matrix multiplication has 6 possible loop orderings (ijk, ikj, jik, jki, kij, kji). Try different orders and measure performance.\n",
    "\n",
    "**Task**: Why does loop order matter? (Hint: cache locality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_multiply_ikj(A, B):\n",
    "    \"\"\"\n",
    "    Matrix multiplication with i-k-j loop order.\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    n2, p = B.shape\n",
    "    C = np.zeros((m, p), dtype=np.float64)\n",
    "    \n",
    "    # TODO: Implement i-k-j loop order\n",
    "    # for i in range(m):\n",
    "    #     for k in range(n):\n",
    "    #         for j in range(p):\n",
    "    #             ...\n",
    "    \n",
    "    return C\n",
    "\n",
    "# Benchmark different loop orders\n",
    "# Compare: ijk, ikj, jik, jki, kij, kji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Monte Carlo Integration\n",
    "\n",
    "Use Monte Carlo to estimate the integral of f(x) = x² from 0 to 1.\n",
    "\n",
    "**Analytical answer**: ∫₀¹ x² dx = 1/3 ≈ 0.333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_integrate(func, a, b, num_samples):\n",
    "    \"\"\"\n",
    "    Estimate integral of func from a to b using Monte Carlo.\n",
    "    \n",
    "    Method: Average value × interval length\n",
    "    ∫ₐᵇ f(x)dx ≈ (b-a) × mean(f(random points))\n",
    "    \n",
    "    Args:\n",
    "        func: Function to integrate\n",
    "        a: Lower bound\n",
    "        b: Upper bound\n",
    "        num_samples: Number of random samples\n",
    "    \n",
    "    Returns:\n",
    "        float: Estimated integral\n",
    "    \"\"\"\n",
    "    # TODO: Implement Monte Carlo integration\n",
    "    pass\n",
    "\n",
    "# Test\n",
    "# def f(x):\n",
    "#     return x**2\n",
    "# \n",
    "# estimate = monte_carlo_integrate(f, 0, 1, 1000000)\n",
    "# print(f\"Estimated: {estimate:.6f}\")\n",
    "# print(f\"Actual:    {1/3:.6f}\")\n",
    "# print(f\"Error:     {abs(estimate - 1/3):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this module, you learned:\n",
    "\n",
    "1. **Serial Implementation Patterns**\n",
    "   - Image processing (2D convolution)\n",
    "   - Matrix operations (dense linear algebra)\n",
    "   - Monte Carlo simulations (random sampling)\n",
    "\n",
    "2. **Performance Profiling**\n",
    "   - Timing with `time.perf_counter()`\n",
    "   - Statistical analysis (mean, std dev)\n",
    "   - Bottleneck identification with cProfile\n",
    "\n",
    "3. **Baseline Metrics**\n",
    "   - Execution time measurements\n",
    "   - Throughput calculations (pixels/sec, GFLOPS)\n",
    "   - Comparison with optimized libraries (NumPy)\n",
    "\n",
    "4. **Code Structure for Parallelization**\n",
    "   - Independent iterations (perfect for parallelization)\n",
    "   - Data dependencies (require careful handling)\n",
    "   - Vectorization opportunities\n",
    "\n",
    "**What's Next?**\n",
    "\n",
    "- **Module 06**: Multi-core CPU parallelization with multiprocessing\n",
    "- **Module 07**: GPU acceleration with Numba CUDA\n",
    "- **Module 08**: Comprehensive benchmarking and analysis\n",
    "\n",
    "**Additional Resources**\n",
    "\n",
    "- Python profiling: https://docs.python.org/3/library/profile.html\n",
    "- NumPy performance tips: https://numpy.org/doc/stable/user/performance.html\n",
    "- Algorithm complexity: https://www.bigocheatsheet.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
