{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 03: Memory Management in Distributed Systems\n",
    "\n",
    "**Difficulty**: â­â­â­  \n",
    "**Estimated Time**: 90 minutes  \n",
    "**Prerequisites**: \n",
    "- [Module 00: Setup and Introduction](00_setup_introduction.ipynb)\n",
    "- [Module 01: Introduction to Distributed Systems](01_introduction_distributed_systems.ipynb)\n",
    "- [Module 02: Transparency and Architectures](02_transparency_architectures.ipynb)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "1. **Understand** centralized memory management concepts (virtual memory, paging, segmentation)\n",
    "2. **Differentiate** between Simple, Shared, and Distributed Shared Memory models\n",
    "3. **Implement** basic shared memory programs using Python's multiprocessing\n",
    "4. **Analyze** memory migration strategies (replication vs migration)\n",
    "5. **Compare** OpenMP and MPI programming models\n",
    "6. **Design** parallel algorithms with appropriate memory management strategies\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Centralized Memory Management Review\n",
    "\n",
    "### 1.1 Virtual Memory Fundamentals\n",
    "\n",
    "Virtual memory extends available memory beyond physical RAM by using disk storage. This is crucial for distributed systems as tasks grow larger.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Virtual Memory**: Extends physical memory using disk storage\n",
    "- **Paging**: Fixed-size memory blocks\n",
    "- **Segmentation**: Variable-size memory blocks based on logical divisions\n",
    "- **Fragmentation**: Wasted memory space\n",
    "  - **Internal**: Waste within allocated blocks\n",
    "  - **External**: Waste between allocated blocks\n",
    "\n",
    "Let's simulate virtual memory with paging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup: Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from multiprocessing import Process, Manager, Lock, Queue, cpu_count\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"âœ“ Python environment ready\")\n",
    "print(f\"âœ“ Available CPU cores: {cpu_count()}\")\n",
    "print(f\"âœ“ Total system memory: {psutil.virtual_memory().total / (1024**3):.2f} GB\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class VirtualMemorySimulator:\n",
    "    \"\"\"\n",
    "    Simulates virtual memory with paging.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    physical_pages : int\n",
    "        Number of physical memory pages (RAM)\n",
    "    page_size : int\n",
    "        Size of each page in bytes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, physical_pages=4, page_size=1024):\n",
    "        self.physical_pages = physical_pages\n",
    "        self.page_size = page_size\n",
    "        # Page table: maps virtual page number to physical page number\n",
    "        self.page_table = {}\n",
    "        # Physical memory (RAM)\n",
    "        self.physical_memory = [None] * physical_pages\n",
    "        # Disk storage (unlimited)\n",
    "        self.disk = {}\n",
    "        # Track page faults\n",
    "        self.page_faults = 0\n",
    "        # LRU tracking\n",
    "        self.access_order = []\n",
    "        \n",
    "    def access_page(self, virtual_page_num):\n",
    "        \"\"\"\n",
    "        Access a virtual page. If not in physical memory, trigger page fault.\n",
    "        \"\"\"\n",
    "        # Check if page is in physical memory\n",
    "        if virtual_page_num in self.page_table:\n",
    "            # Page hit - update LRU\n",
    "            physical_page = self.page_table[virtual_page_num]\n",
    "            if virtual_page_num in self.access_order:\n",
    "                self.access_order.remove(virtual_page_num)\n",
    "            self.access_order.append(virtual_page_num)\n",
    "            return f\"Page {virtual_page_num} HIT (in physical page {physical_page})\"\n",
    "        else:\n",
    "            # Page fault - need to load from disk\n",
    "            self.page_faults += 1\n",
    "            return self._handle_page_fault(virtual_page_num)\n",
    "    \n",
    "    def _handle_page_fault(self, virtual_page_num):\n",
    "        \"\"\"\n",
    "        Handle page fault using LRU (Least Recently Used) replacement.\n",
    "        \"\"\"\n",
    "        # Find free physical page\n",
    "        free_page = None\n",
    "        for i, page in enumerate(self.physical_memory):\n",
    "            if page is None:\n",
    "                free_page = i\n",
    "                break\n",
    "        \n",
    "        if free_page is not None:\n",
    "            # Load page into free slot\n",
    "            self.physical_memory[free_page] = virtual_page_num\n",
    "            self.page_table[virtual_page_num] = free_page\n",
    "            self.access_order.append(virtual_page_num)\n",
    "            return f\"Page {virtual_page_num} FAULT â†’ Loaded into physical page {free_page}\"\n",
    "        else:\n",
    "            # Need to evict LRU page\n",
    "            lru_page = self.access_order.pop(0)\n",
    "            physical_page = self.page_table[lru_page]\n",
    "            \n",
    "            # Evict to disk\n",
    "            self.disk[lru_page] = self.physical_memory[physical_page]\n",
    "            del self.page_table[lru_page]\n",
    "            \n",
    "            # Load new page\n",
    "            self.physical_memory[physical_page] = virtual_page_num\n",
    "            self.page_table[virtual_page_num] = physical_page\n",
    "            self.access_order.append(virtual_page_num)\n",
    "            \n",
    "            return f\"Page {virtual_page_num} FAULT â†’ Evicted page {lru_page}, loaded into physical page {physical_page}\"\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Return current statistics.\"\"\"\n",
    "        return {\n",
    "            'page_faults': self.page_faults,\n",
    "            'pages_in_memory': len(self.page_table),\n",
    "            'pages_on_disk': len(self.disk)\n",
    "        }\n",
    "\n",
    "# Demonstrate virtual memory\n",
    "vm = VirtualMemorySimulator(physical_pages=4, page_size=1024)\n",
    "\n",
    "print(\"Virtual Memory Simulation (4 physical pages)\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Simulate page accesses\n",
    "access_sequence = [0, 1, 2, 3, 0, 4, 1, 5, 0, 1]\n",
    "\n",
    "for page_num in access_sequence:\n",
    "    result = vm.access_page(page_num)\n",
    "    print(f\"Access page {page_num}: {result}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "stats = vm.get_stats()\n",
    "print(f\"\\nFinal Statistics:\")\n",
    "print(f\"  Total Page Faults: {stats['page_faults']}\")\n",
    "print(f\"  Pages in Physical Memory: {stats['pages_in_memory']}\")\n",
    "print(f\"  Pages on Disk: {stats['pages_on_disk']}\")\n",
    "print(f\"  Page Fault Rate: {stats['page_faults']/len(access_sequence)*100:.1f}%\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Fragmentation Demonstration\n",
    "\n",
    "Fragmentation occurs when memory is allocated and deallocated, leaving unusable gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def visualize_fragmentation():\n",
    "    \"\"\"\n",
    "    Visualize internal vs external fragmentation.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
    "    \n",
    "    # Internal Fragmentation (Fixed-size blocks)\n",
    "    block_size = 10\n",
    "    allocations = [7, 9, 5, 8]  # Actual data sizes\n",
    "    colors_internal = ['skyblue', 'lightcoral', 'lightgreen', 'gold']\n",
    "    \n",
    "    x_pos = 0\n",
    "    for i, alloc in enumerate(allocations):\n",
    "        # Used space\n",
    "        ax1.barh(0, alloc, left=x_pos, height=0.8, \n",
    "                color=colors_internal[i], edgecolor='black', label=f'Process {i+1}')\n",
    "        # Wasted space (internal fragmentation)\n",
    "        waste = block_size - alloc\n",
    "        ax1.barh(0, waste, left=x_pos+alloc, height=0.8, \n",
    "                color='gray', alpha=0.3, edgecolor='black', hatch='//')\n",
    "        ax1.text(x_pos + block_size/2, 0, f'{waste}B\\nwaste', \n",
    "                ha='center', va='center', fontsize=9)\n",
    "        x_pos += block_size\n",
    "    \n",
    "    ax1.set_ylim(-0.5, 0.5)\n",
    "    ax1.set_xlim(0, x_pos)\n",
    "    ax1.set_xlabel('Memory Address (bytes)')\n",
    "    ax1.set_title('Internal Fragmentation\\n(Fixed 10B blocks, wasted space within blocks)', \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax1.set_yticks([])\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # External Fragmentation (Variable-size blocks with gaps)\n",
    "    allocations_ext = [(0, 15, 'Process A'), (20, 35, 'Process B'), \n",
    "                       (40, 52, 'Process C'), (60, 70, 'Process D')]\n",
    "    colors_ext = ['skyblue', 'lightcoral', 'lightgreen', 'gold']\n",
    "    \n",
    "    for i, (start, end, label) in enumerate(allocations_ext):\n",
    "        ax2.barh(0, end-start, left=start, height=0.8, \n",
    "                color=colors_ext[i], edgecolor='black', label=label)\n",
    "        ax2.text(start + (end-start)/2, 0, label, \n",
    "                ha='center', va='center', fontsize=9)\n",
    "    \n",
    "    # Mark gaps (external fragmentation)\n",
    "    gaps = [(15, 20), (35, 40), (52, 60)]\n",
    "    for start, end in gaps:\n",
    "        ax2.barh(0, end-start, left=start, height=0.8, \n",
    "                color='red', alpha=0.3, edgecolor='black', hatch='xx')\n",
    "        ax2.text(start + (end-start)/2, 0, f'{end-start}B\\nwaste', \n",
    "                ha='center', va='center', fontsize=8, color='darkred')\n",
    "    \n",
    "    ax2.set_ylim(-0.5, 0.5)\n",
    "    ax2.set_xlim(0, 75)\n",
    "    ax2.set_xlabel('Memory Address (bytes)')\n",
    "    ax2.set_title('External Fragmentation\\n(Gaps between variable-size allocations)', \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax2.set_yticks([])\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_internal_waste = sum(10 - alloc for alloc in allocations)\n",
    "    total_external_waste = sum(end - start for start, end in gaps)\n",
    "    \n",
    "    print(f\"\\nFragmentation Analysis:\")\n",
    "    print(f\"  Internal Fragmentation: {total_internal_waste}B wasted ({total_internal_waste/(len(allocations)*10)*100:.1f}%)\")\n",
    "    print(f\"  External Fragmentation: {total_external_waste}B wasted (gaps between allocations)\")\n",
    "\n",
    "visualize_fragmentation()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Shared Memory Models\n",
    "\n",
    "### 2.1 Simple Memory Model\n",
    "\n",
    "In the **Simple Memory Model**, all processors have equal access times to memory. This is ideal but rarely practical for large systems.\n",
    "\n",
    "**Characteristics:**\n",
    "- Equal memory access times for all processors\n",
    "- Strict control of multiprogramming degree\n",
    "- Often avoids virtual memory/caching due to overhead\n",
    "\n",
    "### 2.2 Shared Memory Model\n",
    "\n",
    "**Shared Memory** allows multiple processes to share memory locations for inter-process communication (IPC).\n",
    "\n",
    "**Key Features:**\n",
    "- Inter-process communication through shared memory\n",
    "- Memory access via common bus â†’ **bus contention** possible\n",
    "- Example: OpenMP (directive-based parallelism)\n",
    "- Threading is the most popular programming technique\n",
    "\n",
    "Let's implement shared memory communication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def worker_process(shared_array, process_id, lock, iterations=1000):\n",
    "    \"\"\"\n",
    "    Worker process that increments shared counter.\n",
    "    Demonstrates need for synchronization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    shared_array : multiprocessing.Array\n",
    "        Shared memory array\n",
    "    process_id : int\n",
    "        Unique ID for this process\n",
    "    lock : multiprocessing.Lock\n",
    "        Lock for synchronization\n",
    "    iterations : int\n",
    "        Number of increments to perform\n",
    "    \"\"\"\n",
    "    for _ in range(iterations):\n",
    "        # Critical section - must be protected\n",
    "        with lock:\n",
    "            shared_array[0] += 1\n",
    "            shared_array[process_id + 1] += 1\n",
    "\n",
    "def demonstrate_shared_memory():\n",
    "    \"\"\"\n",
    "    Demonstrate shared memory communication between processes.\n",
    "    \"\"\"\n",
    "    from multiprocessing import Array, Lock, Process\n",
    "    import ctypes\n",
    "    \n",
    "    num_processes = 4\n",
    "    iterations = 5000\n",
    "    \n",
    "    # Create shared memory array\n",
    "    # Index 0: global counter\n",
    "    # Index 1-4: per-process counters\n",
    "    shared_array = Array(ctypes.c_int, num_processes + 1)\n",
    "    lock = Lock()\n",
    "    \n",
    "    print(f\"Shared Memory Demo: {num_processes} processes, {iterations} iterations each\\n\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Create and start processes\n",
    "    processes = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(num_processes):\n",
    "        p = Process(target=worker_process, \n",
    "                   args=(shared_array, i, lock, iterations))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "    \n",
    "    # Wait for all processes to complete\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nResults after {end_time - start_time:.3f} seconds:\")\n",
    "    print(f\"  Global Counter: {shared_array[0]} (expected: {num_processes * iterations})\")\n",
    "    print(f\"\\nPer-Process Counters:\")\n",
    "    for i in range(num_processes):\n",
    "        print(f\"    Process {i}: {shared_array[i+1]} increments\")\n",
    "    \n",
    "    # Verify correctness\n",
    "    expected = num_processes * iterations\n",
    "    actual = shared_array[0]\n",
    "    if actual == expected:\n",
    "        print(f\"\\nâœ“ SUCCESS: Counter is correct ({actual} == {expected})\")\n",
    "    else:\n",
    "        print(f\"\\nâœ— ERROR: Counter mismatch ({actual} != {expected})\")\n",
    "\n",
    "demonstrate_shared_memory()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Bus Contention Simulation\n",
    "\n",
    "**Bus contention** occurs when multiple processors compete for access to shared memory via a common bus.\n",
    "\n",
    "**Problem**: Systems with >32 CPUs cannot use a single bus efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def simulate_bus_contention(num_processors_list=[2, 4, 8, 16, 32, 64]):\n",
    "    \"\"\"\n",
    "    Simulate bus contention as number of processors increases.\n",
    "    \n",
    "    Assumption: Bus can handle 1 transaction at a time.\n",
    "    With more processors, wait time increases.\n",
    "    \"\"\"\n",
    "    # Simulate bus access patterns\n",
    "    memory_accesses_per_processor = 1000\n",
    "    bus_bandwidth = 100  # arbitrary units\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for num_procs in num_processors_list:\n",
    "        # Total requests to bus\n",
    "        total_requests = num_procs * memory_accesses_per_processor\n",
    "        \n",
    "        # With contention, processors must wait\n",
    "        # Simplified model: each processor gets 1/N of bus bandwidth\n",
    "        effective_bandwidth_per_proc = bus_bandwidth / num_procs\n",
    "        \n",
    "        # Time to complete (inversely proportional to bandwidth)\n",
    "        completion_time = total_requests / bus_bandwidth\n",
    "        \n",
    "        # Contention overhead (waiting time)\n",
    "        contention_overhead = (num_procs - 1) / num_procs * 100  # percentage\n",
    "        \n",
    "        results.append({\n",
    "            'processors': num_procs,\n",
    "            'effective_bandwidth': effective_bandwidth_per_proc,\n",
    "            'contention_overhead': contention_overhead,\n",
    "            'completion_time': completion_time\n",
    "        })\n",
    "    \n",
    "    # Visualize\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    processors = [r['processors'] for r in results]\n",
    "    bandwidths = [r['effective_bandwidth'] for r in results]\n",
    "    overheads = [r['contention_overhead'] for r in results]\n",
    "    \n",
    "    # Plot 1: Effective Bandwidth per Processor\n",
    "    ax1.plot(processors, bandwidths, marker='o', linewidth=2, markersize=8, color='steelblue')\n",
    "    ax1.set_xlabel('Number of Processors', fontsize=11)\n",
    "    ax1.set_ylabel('Effective Bandwidth per Processor', fontsize=11)\n",
    "    ax1.set_title('Bus Contention: Bandwidth Degradation', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.axvline(x=32, color='red', linestyle='--', alpha=0.7, label='32 CPU limit')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot 2: Contention Overhead\n",
    "    ax2.bar(range(len(processors)), overheads, color='coral', edgecolor='black', alpha=0.7)\n",
    "    ax2.set_xticks(range(len(processors)))\n",
    "    ax2.set_xticklabels(processors)\n",
    "    ax2.set_xlabel('Number of Processors', fontsize=11)\n",
    "    ax2.set_ylabel('Contention Overhead (%)', fontsize=11)\n",
    "    ax2.set_title('Bus Contention Overhead', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    ax2.axhline(y=90, color='red', linestyle='--', alpha=0.7, label='Critical threshold')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nBus Contention Analysis:\")\n",
    "    print(\"=\" * 70)\n",
    "    for r in results:\n",
    "        print(f\"{r['processors']:3d} processors: \"\n",
    "              f\"Bandwidth/proc = {r['effective_bandwidth']:6.2f}, \"\n",
    "              f\"Contention = {r['contention_overhead']:5.1f}%\")\n",
    "    \n",
    "    print(\"\\nâš ï¸  Systems with >32 CPUs need alternative interconnects (not single bus)\")\n",
    "\n",
    "simulate_bus_contention()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Distributed Shared Memory (DSM)\n",
    "\n",
    "**Distributed Shared Memory (DSM)** was introduced in 1989 to provide a logical shared memory abstraction for multi-computer systems.\n",
    "\n",
    "### 3.1 DSM Characteristics\n",
    "\n",
    "- Presents **logical shared memory** for physically distributed systems\n",
    "- Maintains communication and data consistency\n",
    "- Portions of local memory mapped onto DSM\n",
    "- Directory service tracks all data locations\n",
    "\n",
    "### 3.2 DSM Management Decisions\n",
    "\n",
    "1. **How to distribute shared data?**\n",
    "   - **Replication**: Multiple copies at various locations\n",
    "   - **Migration**: Single copy moves to different locations\n",
    "\n",
    "2. **How many readers/writers allowed?**\n",
    "   - Single writer / multiple readers\n",
    "   - Multiple writers (requires sophisticated consistency protocols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class DistributedSharedMemory:\n",
    "    \"\"\"\n",
    "    Simplified DSM implementation with replication.\n",
    "    \n",
    "    Demonstrates basic DSM concepts:\n",
    "    - Data replication across nodes\n",
    "    - Consistency maintenance\n",
    "    - Directory service\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_nodes=4):\n",
    "        self.num_nodes = num_nodes\n",
    "        # Each node has local memory\n",
    "        self.local_memories = [{} for _ in range(num_nodes)]\n",
    "        # Directory: tracks which nodes have copies of each data item\n",
    "        self.directory = {}\n",
    "        # Statistics\n",
    "        self.reads = 0\n",
    "        self.writes = 0\n",
    "        self.invalidations = 0\n",
    "        \n",
    "    def write(self, node_id, key, value):\n",
    "        \"\"\"\n",
    "        Write to DSM. Invalidates all other copies (write-invalidate protocol).\n",
    "        \"\"\"\n",
    "        self.writes += 1\n",
    "        \n",
    "        # Write to local memory\n",
    "        self.local_memories[node_id][key] = value\n",
    "        \n",
    "        # Invalidate copies on other nodes\n",
    "        if key in self.directory:\n",
    "            for other_node in self.directory[key]:\n",
    "                if other_node != node_id:\n",
    "                    if key in self.local_memories[other_node]:\n",
    "                        del self.local_memories[other_node][key]\n",
    "                        self.invalidations += 1\n",
    "        \n",
    "        # Update directory\n",
    "        self.directory[key] = {node_id}\n",
    "        \n",
    "        return f\"Node {node_id} wrote '{key}' = {value} (invalidated {len(self.directory.get(key, set())) - 1} copies)\"\n",
    "    \n",
    "    def read(self, node_id, key):\n",
    "        \"\"\"\n",
    "        Read from DSM. If not in local memory, fetch from another node.\n",
    "        \"\"\"\n",
    "        self.reads += 1\n",
    "        \n",
    "        # Check local memory first\n",
    "        if key in self.local_memories[node_id]:\n",
    "            return f\"Node {node_id} read '{key}' = {self.local_memories[node_id][key]} (local)\"\n",
    "        \n",
    "        # Not local - fetch from another node\n",
    "        if key in self.directory and self.directory[key]:\n",
    "            source_node = list(self.directory[key])[0]\n",
    "            value = self.local_memories[source_node][key]\n",
    "            \n",
    "            # Replicate to local memory\n",
    "            self.local_memories[node_id][key] = value\n",
    "            self.directory[key].add(node_id)\n",
    "            \n",
    "            return f\"Node {node_id} read '{key}' = {value} (fetched from Node {source_node})\"\n",
    "        \n",
    "        return f\"Node {node_id} read '{key}' = NOT FOUND\"\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Return DSM statistics.\"\"\"\n",
    "        return {\n",
    "            'total_reads': self.reads,\n",
    "            'total_writes': self.writes,\n",
    "            'total_invalidations': self.invalidations,\n",
    "            'unique_keys': len(self.directory)\n",
    "        }\n",
    "    \n",
    "    def visualize_state(self):\n",
    "        \"\"\"Visualize current DSM state.\"\"\"\n",
    "        print(\"\\nDSM State:\")\n",
    "        print(\"=\" * 70)\n",
    "        for i, memory in enumerate(self.local_memories):\n",
    "            print(f\"Node {i}: {memory if memory else '(empty)'}\")\n",
    "        print(\"\\nDirectory:\")\n",
    "        for key, nodes in self.directory.items():\n",
    "            print(f\"  '{key}': replicated on nodes {sorted(nodes)}\")\n",
    "\n",
    "# Demonstrate DSM\n",
    "dsm = DistributedSharedMemory(num_nodes=4)\n",
    "\n",
    "print(\"Distributed Shared Memory Simulation\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Sequence of operations\n",
    "print(dsm.write(0, 'x', 100))\n",
    "print(dsm.read(1, 'x'))  # Node 1 reads x (will replicate)\n",
    "print(dsm.read(2, 'x'))  # Node 2 reads x (will replicate)\n",
    "print(dsm.write(1, 'x', 200))  # Node 1 writes x (invalidates Node 0, 2)\n",
    "print(dsm.read(0, 'x'))  # Node 0 reads x (must fetch new value)\n",
    "print(dsm.write(3, 'y', 500))  # Node 3 writes new variable y\n",
    "print(dsm.read(2, 'y'))  # Node 2 reads y\n",
    "\n",
    "dsm.visualize_state()\n",
    "\n",
    "stats = dsm.get_stats()\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nStatistics:\")\n",
    "print(f\"  Total Reads: {stats['total_reads']}\")\n",
    "print(f\"  Total Writes: {stats['total_writes']}\")\n",
    "print(f\"  Invalidations: {stats['total_invalidations']}\")\n",
    "print(f\"  Unique Variables: {stats['unique_keys']}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 DSM Performance Issues\n",
    "\n",
    "**Key Performance Considerations:**\n",
    "\n",
    "1. **Data Location**: Where to place original data copy?\n",
    "2. **Implementation**: Hardware vs software vs hybrid?\n",
    "3. **Thrashing**: Avoid constant data movement between locations\n",
    "4. **Block Size**: Optimal size for sharable data blocks (page size, packet size, segment size)?\n",
    "\n",
    "**Non-local memory references are expensive** (up to 10:1 ratio compared to local access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def simulate_memory_access_latency():\n",
    "    \"\"\"\n",
    "    Demonstrate local vs remote memory access latency.\n",
    "    \"\"\"\n",
    "    # Latency values (nanoseconds)\n",
    "    access_types = [\n",
    "        ('L1 Cache', 1),\n",
    "        ('L2 Cache', 4),\n",
    "        ('L3 Cache', 10),\n",
    "        ('Local RAM', 100),\n",
    "        ('Remote RAM\\n(same node)', 200),\n",
    "        ('Remote RAM\\n(different node)', 1000)\n",
    "    ]\n",
    "    \n",
    "    labels = [name for name, _ in access_types]\n",
    "    latencies = [latency for _, latency in access_types]\n",
    "    colors = ['green', 'lightgreen', 'yellow', 'orange', 'coral', 'red']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars = ax.barh(labels, latencies, color=colors, edgecolor='black', alpha=0.7)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, latency) in enumerate(zip(bars, latencies)):\n",
    "        ax.text(latency + 20, i, f'{latency} ns', \n",
    "               va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Latency (nanoseconds)', fontsize=12)\n",
    "    ax.set_title('Memory Access Latency Hierarchy\\n(Remote access can be 10x slower)', \n",
    "                fontsize=13, fontweight='bold')\n",
    "    ax.set_xscale('log')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nMemory Access Latency Comparison:\")\n",
    "    print(\"=\" * 70)\n",
    "    base_latency = latencies[3]  # Local RAM as baseline\n",
    "    for name, latency in access_types:\n",
    "        ratio = latency / base_latency\n",
    "        print(f\"{name:25s}: {latency:5d} ns ({ratio:4.1f}x local RAM)\")\n",
    "\n",
    "simulate_memory_access_latency()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Memory Migration\n",
    "\n",
    "### 4.1 Replication vs Migration\n",
    "\n",
    "Two fundamental strategies for distributing data in DSM:\n",
    "\n",
    "| **Replication** | **Migration** |\n",
    "|-----------------|---------------|\n",
    "| Multiple copies at various locations | Single copy moves between locations |\n",
    "| Faster reads (local copy) | Simpler consistency (only one copy) |\n",
    "| Complex write consistency | Slower if frequently accessed from multiple nodes |\n",
    "| More storage overhead | Less storage overhead |\n",
    "\n",
    "### 4.2 Migration Decisions\n",
    "\n",
    "**Two fundamental questions:**\n",
    "1. **When** in the migration process to migrate memory?\n",
    "2. **How much** memory needs to be migrated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class MemoryMigrationSimulator:\n",
    "    \"\"\"\n",
    "    Simulates memory migration vs replication strategies.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_nodes=4):\n",
    "        self.num_nodes = num_nodes\n",
    "        self.migration_data = {}  # key -> node_id\n",
    "        self.replication_data = {}  # key -> set of node_ids\n",
    "        \n",
    "        # Costs\n",
    "        self.migration_moves = 0\n",
    "        self.replication_copies = 0\n",
    "        self.replication_invalidations = 0\n",
    "        \n",
    "    def migration_access(self, node_id, key, is_write=False):\n",
    "        \"\"\"\n",
    "        Access data using migration strategy.\n",
    "        Data moves to the accessing node.\n",
    "        \"\"\"\n",
    "        if key not in self.migration_data:\n",
    "            # First write\n",
    "            self.migration_data[key] = node_id\n",
    "            return f\"Migration: Node {node_id} created '{key}'\"\n",
    "        \n",
    "        current_node = self.migration_data[key]\n",
    "        \n",
    "        if current_node != node_id:\n",
    "            # Need to migrate\n",
    "            self.migration_data[key] = node_id\n",
    "            self.migration_moves += 1\n",
    "            return f\"Migration: Moved '{key}' from Node {current_node} to Node {node_id}\"\n",
    "        else:\n",
    "            return f\"Migration: Node {node_id} accessed '{key}' (local)\"\n",
    "    \n",
    "    def replication_access(self, node_id, key, is_write=False):\n",
    "        \"\"\"\n",
    "        Access data using replication strategy.\n",
    "        Reads create copies; writes invalidate other copies.\n",
    "        \"\"\"\n",
    "        if key not in self.replication_data:\n",
    "            # First write\n",
    "            self.replication_data[key] = {node_id}\n",
    "            return f\"Replication: Node {node_id} created '{key}'\"\n",
    "        \n",
    "        if is_write:\n",
    "            # Write: invalidate all other copies\n",
    "            num_invalidated = len(self.replication_data[key]) - (1 if node_id in self.replication_data[key] else 0)\n",
    "            self.replication_invalidations += num_invalidated\n",
    "            self.replication_data[key] = {node_id}\n",
    "            return f\"Replication: Node {node_id} wrote '{key}' (invalidated {num_invalidated} copies)\"\n",
    "        else:\n",
    "            # Read: create copy if not present\n",
    "            if node_id not in self.replication_data[key]:\n",
    "                self.replication_data[key].add(node_id)\n",
    "                self.replication_copies += 1\n",
    "                return f\"Replication: Node {node_id} read '{key}' (created local copy)\"\n",
    "            else:\n",
    "                return f\"Replication: Node {node_id} read '{key}' (local copy)\"\n",
    "    \n",
    "    def compare_strategies(self, access_sequence):\n",
    "        \"\"\"\n",
    "        Compare migration vs replication for a given access sequence.\n",
    "        \n",
    "        access_sequence: list of tuples (node_id, key, is_write)\n",
    "        \"\"\"\n",
    "        print(\"\\nComparing Migration vs Replication Strategies\\n\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Access Sequence: {len(access_sequence)} operations\\n\")\n",
    "        \n",
    "        # Reset statistics\n",
    "        self.migration_moves = 0\n",
    "        self.replication_copies = 0\n",
    "        self.replication_invalidations = 0\n",
    "        \n",
    "        # Process accesses\n",
    "        for node_id, key, is_write in access_sequence:\n",
    "            self.migration_access(node_id, key, is_write)\n",
    "            self.replication_access(node_id, key, is_write)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"Migration Strategy:\")\n",
    "        print(f\"  Data movements: {self.migration_moves}\")\n",
    "        print(f\"  Storage overhead: 1x (single copy)\")\n",
    "        print(f\"  Total cost: {self.migration_moves} moves\\n\")\n",
    "        \n",
    "        print(\"Replication Strategy:\")\n",
    "        print(f\"  Copies created: {self.replication_copies}\")\n",
    "        print(f\"  Invalidations: {self.replication_invalidations}\")\n",
    "        total_copies = sum(len(nodes) for nodes in self.replication_data.values())\n",
    "        print(f\"  Storage overhead: {total_copies}x (multiple copies)\")\n",
    "        print(f\"  Total cost: {self.replication_copies + self.replication_invalidations} operations\\n\")\n",
    "        \n",
    "        # Visualize\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        \n",
    "        strategies = ['Migration', 'Replication']\n",
    "        costs = [\n",
    "            self.migration_moves,\n",
    "            self.replication_copies + self.replication_invalidations\n",
    "        ]\n",
    "        colors_bar = ['skyblue', 'coral']\n",
    "        \n",
    "        bars = ax.bar(strategies, costs, color=colors_bar, edgecolor='black', alpha=0.7)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, cost in zip(bars, costs):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{int(cost)} ops',\n",
    "                   ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        ax.set_ylabel('Total Operations (cost)', fontsize=12)\n",
    "        ax.set_title('Migration vs Replication: Performance Comparison', \n",
    "                    fontsize=13, fontweight='bold')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Recommendation\n",
    "        if self.migration_moves < (self.replication_copies + self.replication_invalidations):\n",
    "            print(\"\\nâœ“ Recommendation: MIGRATION is more efficient for this access pattern\")\n",
    "        else:\n",
    "            print(\"\\nâœ“ Recommendation: REPLICATION is more efficient for this access pattern\")\n",
    "\n",
    "# Test with different access patterns\n",
    "sim = MemoryMigrationSimulator(num_nodes=4)\n",
    "\n",
    "# Access pattern: Mostly reads from different nodes (favors replication)\n",
    "access_pattern_1 = [\n",
    "    (0, 'data', True),   # Node 0 writes\n",
    "    (1, 'data', False),  # Node 1 reads\n",
    "    (2, 'data', False),  # Node 2 reads\n",
    "    (3, 'data', False),  # Node 3 reads\n",
    "    (0, 'data', False),  # Node 0 reads\n",
    "    (1, 'data', False),  # Node 1 reads\n",
    "]\n",
    "\n",
    "print(\"\\nðŸ“Š Test Case 1: Read-heavy workload (multiple nodes reading)\")\n",
    "sim.compare_strategies(access_pattern_1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Access pattern: Alternating writes from different nodes (favors migration)\n",
    "access_pattern_2 = [\n",
    "    (0, 'data', True),   # Node 0 writes\n",
    "    (0, 'data', False),  # Node 0 reads\n",
    "    (0, 'data', False),  # Node 0 reads\n",
    "    (1, 'data', True),   # Node 1 writes (invalidates)\n",
    "    (1, 'data', False),  # Node 1 reads\n",
    "    (2, 'data', True),   # Node 2 writes (invalidates)\n",
    "    (2, 'data', False),  # Node 2 reads\n",
    "]\n",
    "\n",
    "print(\"\\nðŸ“Š Test Case 2: Write-heavy workload (alternating writers)\")\n",
    "sim2 = MemoryMigrationSimulator(num_nodes=4)\n",
    "sim2.compare_strategies(access_pattern_2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Programming Models Comparison\n",
    "\n",
    "### 5.1 OpenMP vs MPI\n",
    "\n",
    "| **OpenMP** | **MPI** |\n",
    "|------------|----------|\n",
    "| **Shared Memory** model | **Distributed Memory** model |\n",
    "| Add pragmas to existing code | Must rewrite for message passing |\n",
    "| Compiler handles parallelization | Explicit data movement |\n",
    "| Easy to use | More control, more complex |\n",
    "| Limited to single node | Works across nodes |\n",
    "| Threading-based | Process-based |\n",
    "\n",
    "### 5.2 Synchronous vs Asynchronous Communication\n",
    "\n",
    "**Synchronous**:\n",
    "- `send()` returns when receiver acknowledges\n",
    "- `recv()` returns when data copied to receiver\n",
    "- Potential for deadlock\n",
    "\n",
    "**Asynchronous**:\n",
    "- `send()` returns immediately\n",
    "- `recv()` posts intent, returns immediately  \n",
    "- Use `checksend()`, `checkrecv()` to verify status\n",
    "- More flexible, better performance\n",
    "\n",
    "Let's simulate message passing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def simulate_message_passing():\n",
    "    \"\"\"\n",
    "    Simulate MPI-style message passing between processes.\n",
    "    \"\"\"\n",
    "    from multiprocessing import Process, Queue\n",
    "    import time\n",
    "    \n",
    "    def sender_process(send_queue, process_id, num_messages=5):\n",
    "        \"\"\"Send messages to queue.\"\"\"\n",
    "        for i in range(num_messages):\n",
    "            message = f\"Message {i} from Process {process_id}\"\n",
    "            send_queue.put(message)\n",
    "            print(f\"  [Sender {process_id}] Sent: {message}\")\n",
    "            time.sleep(0.1)  # Simulate work\n",
    "        send_queue.put(None)  # Sentinel to indicate done\n",
    "    \n",
    "    def receiver_process(recv_queue, process_id, num_senders=2):\n",
    "        \"\"\"Receive messages from queue.\"\"\"\n",
    "        received = 0\n",
    "        done_senders = 0\n",
    "        \n",
    "        while done_senders < num_senders:\n",
    "            message = recv_queue.get()\n",
    "            if message is None:\n",
    "                done_senders += 1\n",
    "            else:\n",
    "                received += 1\n",
    "                print(f\"  [Receiver {process_id}] Received: {message}\")\n",
    "        \n",
    "        print(f\"\\n  [Receiver {process_id}] Total messages received: {received}\")\n",
    "    \n",
    "    print(\"\\nMessage Passing Simulation (MPI-style)\\n\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Create communication queue\n",
    "    message_queue = Queue()\n",
    "    \n",
    "    # Create sender processes\n",
    "    num_senders = 2\n",
    "    senders = []\n",
    "    for i in range(num_senders):\n",
    "        p = Process(target=sender_process, args=(message_queue, i, 3))\n",
    "        senders.append(p)\n",
    "        p.start()\n",
    "    \n",
    "    # Create receiver process\n",
    "    receiver = Process(target=receiver_process, args=(message_queue, 0, num_senders))\n",
    "    receiver.start()\n",
    "    \n",
    "    # Wait for all to complete\n",
    "    for p in senders:\n",
    "        p.join()\n",
    "    receiver.join()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"âœ“ Message passing complete\")\n",
    "\n",
    "simulate_message_passing()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Practical Exercises\n",
    "\n",
    "### Exercise 1: Page Replacement Algorithm\n",
    "\n",
    "Implement and compare different page replacement algorithms:\n",
    "- FIFO (First-In-First-Out)\n",
    "- LRU (Least Recently Used)\n",
    "- Optimal (theoretical best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def fifo_page_replacement(page_sequence, num_frames):\n",
    "    \"\"\"\n",
    "    EXERCISE: Implement FIFO page replacement algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    page_sequence : list\n",
    "        Sequence of page accesses\n",
    "    num_frames : int\n",
    "        Number of available page frames\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    int : Number of page faults\n",
    "    \n",
    "    TODO: Complete this implementation\n",
    "    Hint: Use a queue to track insertion order\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    page_faults = 0\n",
    "    \n",
    "    for page in page_sequence:\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    return page_faults\n",
    "\n",
    "# Test your implementation\n",
    "test_sequence = [7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2]\n",
    "faults = fifo_page_replacement(test_sequence, num_frames=3)\n",
    "print(f\"FIFO Page Faults: {faults}\")\n",
    "print(f\"Expected: ~12 page faults\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Shared Memory Producer-Consumer\n",
    "\n",
    "Implement a producer-consumer pattern using shared memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def producer_consumer_exercise():\n",
    "    \"\"\"\n",
    "    EXERCISE: Implement producer-consumer with shared memory.\n",
    "    \n",
    "    Requirements:\n",
    "    1. Create a shared buffer (queue) of size 5\n",
    "    2. Producer adds items to buffer\n",
    "    3. Consumer removes items from buffer\n",
    "    4. Use locks to prevent race conditions\n",
    "    5. Handle buffer full/empty conditions\n",
    "    \n",
    "    TODO: Complete the producer and consumer functions below\n",
    "    \"\"\"\n",
    "    from multiprocessing import Process, Queue, Lock\n",
    "    import time\n",
    "    \n",
    "    def producer(shared_queue, lock, items_to_produce):\n",
    "        \"\"\"\n",
    "        Produce items and add to shared queue.\n",
    "        YOUR CODE HERE\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def consumer(shared_queue, lock, items_to_consume):\n",
    "        \"\"\"\n",
    "        Consume items from shared queue.\n",
    "        YOUR CODE HERE\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    # Test your implementation\n",
    "    buffer = Queue(maxsize=5)\n",
    "    lock = Lock()\n",
    "    \n",
    "    # Create processes\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    print(\"Producer-Consumer exercise complete!\")\n",
    "\n",
    "# Uncomment to test\n",
    "# producer_consumer_exercise()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: DSM Consistency Protocol\n",
    "\n",
    "Implement a simple DSM consistency protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def dsm_consistency_exercise():\n",
    "    \"\"\"\n",
    "    EXERCISE: Extend the DSM implementation with:\n",
    "    \n",
    "    1. Write-update protocol (instead of write-invalidate)\n",
    "    2. Track number of messages sent\n",
    "    3. Compare message overhead of update vs invalidate\n",
    "    \n",
    "    Write-Update: On write, send new value to all nodes with copies\n",
    "    Write-Invalidate: On write, invalidate all other copies\n",
    "    \n",
    "    TODO: Implement write-update DSM class\n",
    "    \"\"\"\n",
    "    \n",
    "    class DSM_WriteUpdate:\n",
    "        \"\"\"YOUR CODE HERE\"\"\"\n",
    "        pass\n",
    "    \n",
    "    # Test both protocols and compare\n",
    "    print(\"Compare Write-Update vs Write-Invalidate protocols\")\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "# Uncomment to test\n",
    "# dsm_consistency_exercise()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Concepts Covered\n",
    "\n",
    "1. **Centralized Memory Management**\n",
    "   - Virtual memory extends physical memory using disk\n",
    "   - Paging (fixed-size) vs Segmentation (variable-size)\n",
    "   - Internal vs External fragmentation\n",
    "   - Page replacement algorithms (LRU, FIFO)\n",
    "\n",
    "2. **Memory Models**\n",
    "   - **Simple Memory**: Equal access times, simple but limited\n",
    "   - **Shared Memory**: IPC via shared locations, bus contention issues\n",
    "   - **Distributed Shared Memory**: Logical shared memory across physical nodes\n",
    "\n",
    "3. **DSM Management**\n",
    "   - **Replication**: Multiple copies, fast reads, complex consistency\n",
    "   - **Migration**: Single copy moves, simpler consistency, slower multi-node access\n",
    "   - Directory service tracks data locations\n",
    "\n",
    "4. **Programming Models**\n",
    "   - **OpenMP**: Shared memory, pragma-based, easy\n",
    "   - **MPI**: Distributed memory, explicit messages, scalable\n",
    "   - Synchronous vs Asynchronous communication\n",
    "\n",
    "5. **Performance Considerations**\n",
    "   - Bus contention limits scalability (>32 CPUs)\n",
    "   - Non-local memory access is 10x slower\n",
    "   - Trade-offs between consistency overhead and performance\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In the next module, we'll explore:\n",
    "- Real-time systems and their requirements\n",
    "- Clock synchronization in distributed systems\n",
    "- Distributed operating systems\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "### Documentation\n",
    "- [OpenMP Official Documentation](https://www.openmp.org/)\n",
    "- [MPI Tutorial](https://mpitutorial.com/)\n",
    "- [Python Multiprocessing](https://docs.python.org/3/library/multiprocessing.html)\n",
    "\n",
    "### Further Reading\n",
    "- Tanenbaum & Van Steen: *Distributed Systems: Principles and Paradigms*\n",
    "- Hennessy & Patterson: *Computer Architecture: A Quantitative Approach*\n",
    "\n",
    "### Practice\n",
    "- [Lawrence Livermore OpenMP Tutorial](https://hpc-tutorials.llnl.gov/openmp/)\n",
    "- [MPI Examples](https://www.mcs.anl.gov/research/projects/mpi/tutorial/)\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You've completed Module 03: Memory Management in Distributed Systems. ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
