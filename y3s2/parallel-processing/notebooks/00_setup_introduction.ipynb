{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 00: Course Setup and Introduction\n",
    "\n",
    "**Course**: BMCS3003 - Distributed Systems and Parallel Computing  \n",
    "**Difficulty**: â­â­â­  \n",
    "**Estimated Time**: 45 minutes  \n",
    "**Prerequisites**: Basic knowledge of operating systems, computer architecture, and Python programming\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Understand** the scope and structure of the Distributed Systems and Parallel Computing course\n",
    "2. **Set up** your development environment for parallel and distributed computing\n",
    "3. **Identify** the key learning outcomes and assessment components\n",
    "4. **Verify** that your system meets the technical requirements for the course\n",
    "5. **Execute** basic parallel programming examples to confirm environment setup\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Course Overview\n",
    "\n",
    "### Course Learning Outcomes (CLOs)\n",
    "\n",
    "This course has three main learning outcomes:\n",
    "\n",
    "| CLO | Description | Bloom's Level |\n",
    "|-----|-------------|---------------|\n",
    "| **CLO 1** | Discuss the variety of parallel and distributed computing techniques | C2 (Understand) |\n",
    "| **CLO 2** | Analyse a given scenario with parallel and distributed computing techniques | C4 (Analyze) |\n",
    "| **CLO 3** | Demonstrate appropriate programming skills with regards to parallel and distributed computing | P4 (Apply) |\n",
    "\n",
    "### Assessment Structure\n",
    "\n",
    "- **Midterm Test**: 40% (Week 7/8)\n",
    "- **Assignment**: 60% (Completed Week 12, Presented Week 13-14)\n",
    "- **Final Examination**: Based on past years' papers\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "1. Introduction to Distributed Systems\n",
    "2. Real-time Systems  \n",
    "3. System Architectures (Tightly vs Loosely Coupled)\n",
    "4. Transparency in Distributed Systems\n",
    "5. Clock Synchronization\n",
    "6. Operating Systems for Distributed Computing\n",
    "7. Parallel Programming with OpenMP\n",
    "8. GPU Programming with CUDA\n",
    "9. Message Passing Interface (MPI)\n",
    "10. Advanced Topics in Distributed Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Setup\n",
    "\n",
    "### 2.1 Check Python Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "import platform\n",
    "\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Machine: {platform.machine()}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Check for Multi-core Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "# Get the number of CPU cores\n",
    "cpu_count_logical = os.cpu_count()  # Logical cores (including hyperthreading)\n",
    "cpu_count_physical = multiprocessing.cpu_count()  # Physical cores\n",
    "\n",
    "print(f\"Number of Logical CPU Cores: {cpu_count_logical}\")\n",
    "print(f\"Number of Physical CPU Cores: {cpu_count_physical}\")\n",
    "\n",
    "# Verify parallel processing is possible\n",
    "if cpu_count_logical >= 2:\n",
    "    print(\"\\nâœ“ Your system supports parallel processing!\")\n",
    "else:\n",
    "    print(\"\\nâš  Warning: Your system has limited cores for parallel processing.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Install Required Libraries\n",
    "\n",
    "For this course, we'll primarily use Python for demonstrations. Install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Uncomment and run this cell if packages are not installed\n",
    "# !pip install numpy matplotlib multiprocess mpi4py psutil"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Verify Package Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if required packages are available\n",
    "packages_to_check = {\n",
    "    'numpy': 'Numerical computing',\n",
    "    'matplotlib': 'Visualization',\n",
    "    'multiprocessing': 'Parallel processing (built-in)',\n",
    "    'psutil': 'System monitoring'\n",
    "}\n",
    "\n",
    "print(\"Checking required packages:\\n\")\n",
    "for package, description in packages_to_check.items():\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"âœ“ {package:20s} - {description}\")\n",
    "    except ImportError:\n",
    "        print(f\"âœ— {package:20s} - {description} (NOT INSTALLED)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. First Parallel Program\n",
    "\n",
    "Let's write a simple parallel program to verify everything is working. We'll compare sequential vs parallel execution.\n",
    "\n",
    "### 3.1 Sequential Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import time\n",
    "\n",
    "def calculate_square(number):\n",
    "    \"\"\"\n",
    "    Calculate the square of a number with artificial delay.\n",
    "    The delay simulates a computationally expensive operation.\n",
    "    \"\"\"\n",
    "    time.sleep(0.1)  # Simulate computation time\n",
    "    return number * number\n",
    "\n",
    "# Sequential execution\n",
    "numbers = list(range(10))\n",
    "\n",
    "start_time = time.time()\n",
    "sequential_results = [calculate_square(n) for n in numbers]\n",
    "end_time = time.time()\n",
    "\n",
    "sequential_time = end_time - start_time\n",
    "print(f\"Sequential Results: {sequential_results}\")\n",
    "print(f\"Sequential Execution Time: {sequential_time:.2f} seconds\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# Parallel execution using multiprocessing\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a pool of worker processes\n",
    "# Using 4 processes for demonstration\n",
    "with Pool(processes=4) as pool:\n",
    "    parallel_results = pool.map(calculate_square, numbers)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "parallel_time = end_time - start_time\n",
    "print(f\"Parallel Results: {parallel_results}\")\n",
    "print(f\"Parallel Execution Time: {parallel_time:.2f} seconds\")\n",
    "print(f\"\\nSpeedup: {sequential_time / parallel_time:.2f}x\")\n",
    "print(f\"Efficiency: {(sequential_time / parallel_time) / 4 * 100:.1f}%\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualize Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create visualization of execution times\n",
    "execution_methods = ['Sequential', 'Parallel\\n(4 cores)']\n",
    "execution_times = [sequential_time, parallel_time]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(execution_methods, execution_times, color=['#FF6B6B', '#4ECDC4'])\n",
    "plt.ylabel('Execution Time (seconds)', fontsize=12)\n",
    "plt.title('Sequential vs Parallel Execution Time', fontsize=14, fontweight='bold')\n",
    "plt.ylim(0, max(execution_times) * 1.2)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.2f}s',\n",
    "             ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Analysis:\")\n",
    "print(f\"   Parallel execution is {sequential_time / parallel_time:.2f}x faster!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Understanding Your Hardware\n",
    "\n",
    "### 4.1 CPU Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import psutil\n",
    "\n",
    "# Get detailed CPU information\n",
    "cpu_freq = psutil.cpu_freq()\n",
    "cpu_percent_per_core = psutil.cpu_percent(interval=1, percpu=True)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"CPU INFORMATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Physical Cores: {psutil.cpu_count(logical=False)}\")\n",
    "print(f\"Logical Cores: {psutil.cpu_count(logical=True)}\")\n",
    "print(f\"\\nCurrent Frequency: {cpu_freq.current:.2f} MHz\")\n",
    "print(f\"Min Frequency: {cpu_freq.min:.2f} MHz\")\n",
    "print(f\"Max Frequency: {cpu_freq.max:.2f} MHz\")\n",
    "print(f\"\\nCPU Usage Per Core:\")\n",
    "for i, percent in enumerate(cpu_percent_per_core):\n",
    "    print(f\"  Core {i}: {percent}%\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Memory Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get memory information\n",
    "memory = psutil.virtual_memory()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MEMORY INFORMATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Memory: {memory.total / (1024**3):.2f} GB\")\n",
    "print(f\"Available Memory: {memory.available / (1024**3):.2f} GB\")\n",
    "print(f\"Used Memory: {memory.used / (1024**3):.2f} GB\")\n",
    "print(f\"Memory Usage: {memory.percent}%\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exercises\n",
    "\n",
    "### Exercise 1: Speedup Analysis\n",
    "\n",
    "**Task**: Modify the parallel execution example to use different numbers of processes (1, 2, 4, 8) and measure the speedup for each. Create a plot showing speedup vs number of processes.\n",
    "\n",
    "**Expected Learning**: Understand that speedup doesn't scale linearly with the number of cores due to overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Your code here\n",
    "# Hint: Use a loop to test different process counts\n",
    "# Store results in lists and plot them\n",
    "\n",
    "process_counts = [1, 2, 4, 8]\n",
    "speedups = []\n",
    "\n",
    "# TODO: Implement speedup measurement for each process count\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Amdahl's Law\n",
    "\n",
    "**Task**: Implement Amdahl's Law to calculate theoretical speedup:\n",
    "\n",
    "$$Speedup = \\frac{1}{(1-P) + \\frac{P}{N}}$$\n",
    "\n",
    "Where:\n",
    "- P = Proportion of program that can be parallelized (0 to 1)\n",
    "- N = Number of processors\n",
    "\n",
    "Calculate and plot the theoretical maximum speedup for P = 0.5, 0.75, 0.9, 0.95 with N ranging from 1 to 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def amdahls_law(P, N):\n",
    "    \"\"\"\n",
    "    Calculate speedup using Amdahl's Law.\n",
    "    \n",
    "    Parameters:\n",
    "    P (float): Proportion of parallelizable code (0 to 1)\n",
    "    N (int): Number of processors\n",
    "    \n",
    "    Returns:\n",
    "    float: Theoretical speedup\n",
    "    \"\"\"\n",
    "    # TODO: Implement Amdahl's Law formula\n",
    "    pass\n",
    "\n",
    "# TODO: Test with different values and create visualization\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Resource Monitoring\n",
    "\n",
    "**Task**: Create a function that monitors CPU and memory usage while running a parallel workload. Plot the resource usage over time.\n",
    "\n",
    "**Hints**:\n",
    "- Use `psutil` to monitor resources\n",
    "- Run monitoring in a separate thread\n",
    "- Collect data at regular intervals (e.g., every 0.1 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import threading\n",
    "\n",
    "def monitor_resources(duration=5, interval=0.1):\n",
    "    \"\"\"\n",
    "    Monitor CPU and memory usage over time.\n",
    "    \n",
    "    Parameters:\n",
    "    duration (float): How long to monitor (seconds)\n",
    "    interval (float): Sampling interval (seconds)\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (timestamps, cpu_usage, memory_usage)\n",
    "    \"\"\"\n",
    "    # TODO: Implement resource monitoring\n",
    "    pass\n",
    "\n",
    "# TODO: Test the function and visualize results\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "In this introductory module, you have:\n",
    "\n",
    "âœ… **Understood** the course structure, learning outcomes, and assessment  \n",
    "âœ… **Set up** your Python environment for parallel and distributed computing  \n",
    "âœ… **Verified** your system's capabilities for parallel processing  \n",
    "âœ… **Executed** your first parallel program and observed speedup  \n",
    "âœ… **Analyzed** the performance differences between sequential and parallel execution  \n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Parallel processing** can significantly reduce execution time for suitable workloads\n",
    "2. **Speedup** doesn't scale linearly due to overhead and communication costs\n",
    "3. **Understanding hardware** (cores, memory) is crucial for efficient parallel programming\n",
    "4. **Not all problems** benefit equally from parallelization (Amdahl's Law)\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 01**, we'll dive deep into:\n",
    "- What is a Distributed System?\n",
    "- Traditional vs Distributed architectures\n",
    "- Benefits and challenges of distributed systems\n",
    "- Tightly vs Loosely coupled systems\n",
    "\n",
    "---\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [CUDA Toolkit Documentation](https://docs.nvidia.com/cuda/)\n",
    "- [OpenMP Documentation](https://www.openmp.org/wp-content/uploads/OpenMPRefCard-5-2-web.pdf)\n",
    "- [OpenACC Programming Guide](https://www.openacc.org/sites/default/files/inline-files/openacc-guide.pdf)\n",
    "- Python `multiprocessing` module documentation\n",
    "\n",
    "---\n",
    "\n",
    "**Course**: BMCS3003 - Distributed Systems and Parallel Computing  \n",
    "**Instructor**: Assoc Prof Ts Dr Tew Yiqi  \n",
    "**Contact**: yiqi@tarc.edu.my"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
