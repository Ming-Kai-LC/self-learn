{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 01: Introduction to Distributed Systems\n",
    "\n",
    "**Difficulty**: ‚≠ê‚≠ê‚≠ê  \n",
    "**Estimated Time**: 90 minutes  \n",
    "**Prerequisites**: Module 00 - Course Setup and Introduction\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Define** what constitutes a distributed system and identify its key characteristics\n",
    "2. **Compare** traditional (centralized) vs distributed system architectures\n",
    "3. **Analyze** the benefits of distributed systems (scalability, reliability, performance, geographical distribution)\n",
    "4. **Identify** the challenges when building distributed systems\n",
    "5. **Distinguish** between tightly-coupled and loosely-coupled hardware architectures\n",
    "6. **Implement** basic distributed system concepts using Python\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a Distributed System?\n",
    "\n",
    "### Definition\n",
    "\n",
    "> **A distributed system is a computing environment in which various components are spread across multiple computers (or nodes) connected by a network, working together to appear as a single coherent system to end users.**\n",
    "\n",
    "### Key Characteristics\n",
    "\n",
    "1. **Multiple autonomous computers** working together\n",
    "2. **Connected via a network** (LAN, WAN, or Internet)\n",
    "3. **Appears as a single system** to users (transparency)\n",
    "4. **No shared physical memory** between nodes\n",
    "5. **Coordinated through message passing**\n",
    "\n",
    "### What Can Be Distributed?\n",
    "\n",
    "- üíæ **Database / Data**: Distributed databases, file systems\n",
    "- ‚öôÔ∏è **Operating System**: Processes running on different machines\n",
    "- üìÅ **File System**: Files stored across multiple servers\n",
    "- üîê **Authentication**: Centralized vs distributed auth systems\n",
    "- üíº **Business Logic**: Microservices architecture\n",
    "- üñ•Ô∏è **Workload**: Load balancing across servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Traditional vs Distributed Systems\n",
    "\n",
    "### 2.1 Visualization Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Traditional (Centralized) Database Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Traditional Database Architecture\n",
    "ax1.set_xlim(0, 10)\n",
    "ax1.set_ylim(0, 10)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Traditional Database (1990s-2000s)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Main database\n",
    "db_rect = patches.FancyBboxPatch((3.5, 5), 3, 2, boxstyle=\"round,pad=0.1\",\n",
    "                                  edgecolor='#2E86AB', facecolor='#A23B72', linewidth=2)\n",
    "ax1.add_patch(db_rect)\n",
    "ax1.text(5, 6, 'Main\\nDatabase', ha='center', va='center',\n",
    "         fontsize=11, fontweight='bold', color='white')\n",
    "\n",
    "# Backup servers\n",
    "backup1 = patches.FancyBboxPatch((7.5, 5), 1.5, 1.5, boxstyle=\"round,pad=0.05\",\n",
    "                                  edgecolor='#F18F01', facecolor='#FFF3B0', linewidth=2)\n",
    "ax1.add_patch(backup1)\n",
    "ax1.text(8.25, 5.75, 'Backup\\nServer', ha='center', va='center', fontsize=9)\n",
    "\n",
    "backup2 = patches.FancyBboxPatch((8, 2.5), 1.5, 1.5, boxstyle=\"round,pad=0.05\",\n",
    "                                  edgecolor='#F18F01', facecolor='#FFF3B0', linewidth=2)\n",
    "ax1.add_patch(backup2)\n",
    "ax1.text(8.75, 3.25, 'Tape/Disk\\nBackup', ha='center', va='center', fontsize=9)\n",
    "\n",
    "# Arrows\n",
    "ax1.arrow(6.5, 6, 0.8, 0, head_width=0.2, head_length=0.2, fc='#2E86AB', ec='#2E86AB')\n",
    "ax1.arrow(6.5, 5.5, 1.2, -1.8, head_width=0.2, head_length=0.2, fc='#2E86AB', ec='#2E86AB')\n",
    "\n",
    "# Characteristics\n",
    "ax1.text(5, 1.5, '‚úì Single Point of Failure\\n‚úì Limited Scalability\\n‚úì Simple Architecture\\n‚úì Easier Maintenance',\n",
    "         ha='center', fontsize=10, bbox=dict(boxstyle='round', facecolor='#E0E0E0', alpha=0.8))\n",
    "\n",
    "# Distributed Database Architecture\n",
    "ax2.set_xlim(0, 10)\n",
    "ax2.set_ylim(0, 10)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Distributed Database (2010s and Beyond)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Multiple distributed nodes\n",
    "node_positions = [(2, 7), (5, 8), (8, 7), (2, 4), (5, 5), (8, 4), (5, 2)]\n",
    "for i, (x, y) in enumerate(node_positions):\n",
    "    node = patches.Circle((x, y), 0.6, edgecolor='#06A77D', facecolor='#A8DADC', linewidth=2)\n",
    "    ax2.add_patch(node)\n",
    "    ax2.text(x, y, f'Node\\n{i+1}', ha='center', va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "# Network connections\n",
    "connections = [(0, 1), (1, 2), (0, 3), (1, 4), (2, 5), (3, 4), (4, 5), (4, 6)]\n",
    "for i, j in connections:\n",
    "    x1, y1 = node_positions[i]\n",
    "    x2, y2 = node_positions[j]\n",
    "    ax2.plot([x1, x2], [y1, y2], 'b--', alpha=0.3, linewidth=1.5)\n",
    "\n",
    "# Benefits\n",
    "benefits = [\n",
    "    '1. Scale-Out vs Scale-Up',\n",
    "    '2. Local vs Shared Storage',\n",
    "    '3. Elastic vs Static Infrastructure'\n",
    "]\n",
    "ax2.text(5, 0.5, '\\n'.join(benefits), ha='center', fontsize=9,\n",
    "         bbox=dict(boxstyle='round', facecolor='#90EE90', alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Benefits of Distributed Systems\n",
    "\n",
    "### 3.1 Scalability\n",
    "\n",
    "**Definition**: The ability to continuously evolve and support growing amounts of work.\n",
    "\n",
    "#### Types of Scalability:\n",
    "\n",
    "1. **Horizontal Scaling (Scale-Out)**: Add more machines\n",
    "   - More cost-effective over time\n",
    "   - Better for distributed systems\n",
    "   \n",
    "2. **Vertical Scaling (Scale-Up)**: Add more resources to existing machines\n",
    "   - Limited by hardware constraints\n",
    "   - Costs rise sharply after a certain point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Simulate scalability scenarios\n",
    "def simulate_scalability(workload_size, scaling_type='horizontal', num_nodes=1):\n",
    "    \"\"\"\n",
    "    Simulate processing time for different scaling approaches.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    workload_size : int\n",
    "        Size of the workload to process\n",
    "    scaling_type : str\n",
    "        'horizontal' or 'vertical'\n",
    "    num_nodes : int\n",
    "        Number of nodes (for horizontal scaling)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Processing time in seconds\n",
    "    \"\"\"\n",
    "    base_processing_time = workload_size * 0.01  # Base time per unit\n",
    "    \n",
    "    if scaling_type == 'horizontal':\n",
    "        # Horizontal scaling: distribute workload across nodes\n",
    "        # Communication overhead increases with nodes\n",
    "        communication_overhead = (num_nodes - 1) * 0.1\n",
    "        processing_time = (base_processing_time / num_nodes) + communication_overhead\n",
    "    else:\n",
    "        # Vertical scaling: diminishing returns\n",
    "        processing_time = base_processing_time / (1 + np.log(num_nodes))\n",
    "    \n",
    "    return max(processing_time, 0.1)  # Minimum time\n",
    "\n",
    "# Compare scaling approaches\n",
    "workloads = [100, 500, 1000, 2000, 5000]\n",
    "node_counts = [1, 2, 4, 8, 16]\n",
    "\n",
    "horizontal_times = []\n",
    "vertical_times = []\n",
    "\n",
    "for workload in workloads:\n",
    "    h_times = [simulate_scalability(workload, 'horizontal', n) for n in node_counts]\n",
    "    v_times = [simulate_scalability(workload, 'vertical', n) for n in node_counts]\n",
    "    horizontal_times.append(h_times)\n",
    "    vertical_times.append(v_times)\n",
    "\n",
    "# Visualize scaling comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot for workload = 1000\n",
    "workload_idx = 2\n",
    "ax1.plot(node_counts, horizontal_times[workload_idx], 'o-', label='Horizontal Scaling',\n",
    "         linewidth=2, markersize=8, color='#06A77D')\n",
    "ax1.plot(node_counts, vertical_times[workload_idx], 's-', label='Vertical Scaling',\n",
    "         linewidth=2, markersize=8, color='#E63946')\n",
    "ax1.set_xlabel('Number of Nodes', fontsize=12)\n",
    "ax1.set_ylabel('Processing Time (seconds)', fontsize=12)\n",
    "ax1.set_title(f'Scalability Comparison (Workload = {workloads[workload_idx]})',\n",
    "              fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xscale('log', base=2)\n",
    "\n",
    "# Cost analysis\n",
    "# Assume: Horizontal node cost = $100/node, Vertical upgrade cost increases exponentially\n",
    "horizontal_costs = [100 * n for n in node_counts]\n",
    "vertical_costs = [100 * (2 ** (n-1)) for n in range(1, len(node_counts)+1)]\n",
    "\n",
    "ax2.plot(node_counts, horizontal_costs, 'o-', label='Horizontal Scaling Cost',\n",
    "         linewidth=2, markersize=8, color='#06A77D')\n",
    "ax2.plot(node_counts, vertical_costs, 's-', label='Vertical Scaling Cost',\n",
    "         linewidth=2, markersize=8, color='#E63946')\n",
    "ax2.set_xlabel('Scaling Level', fontsize=12)\n",
    "ax2.set_ylabel('Cost ($)', fontsize=12)\n",
    "ax2.set_title('Cost Comparison: Horizontal vs Vertical Scaling',\n",
    "              fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Key Insight:\")\n",
    "print(\"   Horizontal scaling becomes more cost-effective as demand grows.\")\n",
    "print(f\"   At 16x scaling: Horizontal = ${horizontal_costs[-1]}, Vertical = ${vertical_costs[-1]}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Reliability and Fault Tolerance\n",
    "\n",
    "Distributed systems can maintain service even when individual components fail.\n",
    "\n",
    "**Example**: Facebook's Maelstrom system replicates data across multiple data centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import random\n",
    "\n",
    "class DistributedSystem:\n",
    "    \"\"\"\n",
    "    Simulate a distributed system with fault tolerance.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_nodes, replication_factor=3):\n",
    "        \"\"\"\n",
    "        Initialize distributed system.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        num_nodes : int\n",
    "            Total number of nodes in the system\n",
    "        replication_factor : int\n",
    "            How many copies of data to maintain\n",
    "        \"\"\"\n",
    "        self.num_nodes = num_nodes\n",
    "        self.replication_factor = replication_factor\n",
    "        self.nodes = {f\"Node_{i}\": True for i in range(num_nodes)}  # True = healthy\n",
    "        \n",
    "    def simulate_failure(self, failure_rate=0.1):\n",
    "        \"\"\"\n",
    "        Randomly fail some nodes based on failure rate.\n",
    "        \"\"\"\n",
    "        for node in self.nodes:\n",
    "            if random.random() < failure_rate:\n",
    "                self.nodes[node] = False\n",
    "    \n",
    "    def check_data_availability(self):\n",
    "        \"\"\"\n",
    "        Check if data is still available despite failures.\n",
    "        Data is available if at least one replica survives.\n",
    "        \"\"\"\n",
    "        healthy_nodes = sum(1 for status in self.nodes.values() if status)\n",
    "        return healthy_nodes >= 1  # At least one node must be healthy\n",
    "    \n",
    "    def get_system_status(self):\n",
    "        \"\"\"\n",
    "        Return current system status.\n",
    "        \"\"\"\n",
    "        healthy = sum(1 for status in self.nodes.values() if status)\n",
    "        failed = self.num_nodes - healthy\n",
    "        availability = (healthy / self.num_nodes) * 100\n",
    "        \n",
    "        return {\n",
    "            'healthy_nodes': healthy,\n",
    "            'failed_nodes': failed,\n",
    "            'availability': availability,\n",
    "            'data_available': self.check_data_availability()\n",
    "        }\n",
    "\n",
    "# Simulate fault tolerance\n",
    "print(\"=\" * 60)\n",
    "print(\"FAULT TOLERANCE SIMULATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create systems with different replication factors\n",
    "systems = {\n",
    "    'No Replication': DistributedSystem(10, replication_factor=1),\n",
    "    '3x Replication': DistributedSystem(10, replication_factor=3),\n",
    "    '5x Replication': DistributedSystem(10, replication_factor=5)\n",
    "}\n",
    "\n",
    "# Run simulation 1000 times\n",
    "num_simulations = 1000\n",
    "failure_rate = 0.2  # 20% node failure rate\n",
    "\n",
    "results = {name: [] for name in systems.keys()}\n",
    "\n",
    "for _ in range(num_simulations):\n",
    "    for name, system in systems.items():\n",
    "        # Reset system\n",
    "        system.nodes = {f\"Node_{i}\": True for i in range(system.num_nodes)}\n",
    "        \n",
    "        # Simulate failures\n",
    "        system.simulate_failure(failure_rate)\n",
    "        \n",
    "        # Check if data is still available\n",
    "        status = system.get_system_status()\n",
    "        results[name].append(status['data_available'])\n",
    "\n",
    "# Calculate reliability\n",
    "print(f\"\\nSimulation Results ({num_simulations} runs, {failure_rate*100}% failure rate):\\n\")\n",
    "for name, availability_list in results.items():\n",
    "    reliability = (sum(availability_list) / num_simulations) * 100\n",
    "    print(f\"{name:20s}: {reliability:6.2f}% data availability\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "reliabilities = [(sum(results[name]) / num_simulations) * 100 for name in systems.keys()]\n",
    "colors = ['#E63946', '#F1FAEE', '#06A77D']\n",
    "bars = ax.bar(systems.keys(), reliabilities, color=colors, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "ax.set_ylabel('Data Availability (%)', fontsize=12)\n",
    "ax.set_title('Impact of Replication on System Reliability', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, 105)\n",
    "ax.axhline(y=99.9, color='r', linestyle='--', label='99.9% SLA Target')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Performance Through Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "import math\n",
    "\n",
    "def compute_intensive_task(n):\n",
    "    \"\"\"\n",
    "    Simulate a compute-intensive task.\n",
    "    Calculate sum of square roots from 1 to n.\n",
    "    \"\"\"\n",
    "    result = sum(math.sqrt(i) for i in range(1, n + 1))\n",
    "    return result\n",
    "\n",
    "# Test with different workload sizes\n",
    "workload_sizes = [1000000, 2000000, 3000000, 4000000]\n",
    "process_counts = [1, 2, 4, 8]\n",
    "\n",
    "print(\"Performance Comparison: Sequential vs Distributed Processing\\n\")\n",
    "print(f\"{'Workload':>12s} | {'Processes':>10s} | {'Time (s)':>10s} | {'Speedup':>8s}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for workload in workload_sizes:\n",
    "    # Divide workload into chunks\n",
    "    base_time = None\n",
    "    \n",
    "    for num_processes in process_counts:\n",
    "        chunk_size = workload // num_processes\n",
    "        chunks = [chunk_size] * num_processes\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        if num_processes == 1:\n",
    "            # Sequential\n",
    "            results = [compute_intensive_task(c) for c in chunks]\n",
    "        else:\n",
    "            # Parallel\n",
    "            with Pool(processes=num_processes) as pool:\n",
    "                results = pool.map(compute_intensive_task, chunks)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        if base_time is None:\n",
    "            base_time = elapsed_time\n",
    "            speedup_str = \"-\"\n",
    "        else:\n",
    "            speedup = base_time / elapsed_time\n",
    "            speedup_str = f\"{speedup:.2f}x\"\n",
    "        \n",
    "        print(f\"{workload:12,d} | {num_processes:10d} | {elapsed_time:10.4f} | {speedup_str:>8s}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nüí° Insight: Performance improves with more processes, but speedup is not linear\")\n",
    "print(\"   due to communication overhead and Amdahl's Law.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Geographical Distribution\n",
    "\n",
    "Distributed systems can place resources closer to users, reducing latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Simulate latency for different geographical distributions\n",
    "def simulate_latency(user_location, server_locations, distributed=False):\n",
    "    \"\"\"\n",
    "    Simulate network latency based on geographical distance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    user_location : tuple\n",
    "        (latitude, longitude) of user\n",
    "    server_locations : dict\n",
    "        Dictionary of server locations with their coordinates\n",
    "    distributed : bool\n",
    "        If True, use nearest server; if False, use specific server\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Latency in milliseconds\n",
    "    \"\"\"\n",
    "    def calculate_distance(loc1, loc2):\n",
    "        # Simplified distance calculation (Euclidean)\n",
    "        return np.sqrt((loc1[0] - loc2[0])**2 + (loc1[1] - loc2[1])**2)\n",
    "    \n",
    "    if distributed:\n",
    "        # Find nearest server\n",
    "        distances = {name: calculate_distance(user_location, loc) \n",
    "                    for name, loc in server_locations.items()}\n",
    "        nearest_distance = min(distances.values())\n",
    "    else:\n",
    "        # Use specific server (e.g., US East)\n",
    "        nearest_distance = calculate_distance(user_location, server_locations['US East'])\n",
    "    \n",
    "    # Latency increases with distance (roughly 1ms per 100km)\n",
    "    latency = nearest_distance * 10  # Simplified: 10ms per degree\n",
    "    return latency\n",
    "\n",
    "# Define server locations (simplified coordinates)\n",
    "servers = {\n",
    "    'US East': (40, -75),      # New York area\n",
    "    'US West': (37, -122),     # California\n",
    "    'Europe': (51, 0),         # London\n",
    "    'Asia Pacific': (1, 103),  # Singapore\n",
    "    'Australia': (-33, 151)    # Sydney\n",
    "}\n",
    "\n",
    "# Simulate users from different locations\n",
    "user_locations = {\n",
    "    'New York User': (40, -74),\n",
    "    'London User': (51, -0.1),\n",
    "    'Singapore User': (1.3, 103.8),\n",
    "    'Sydney User': (-33.9, 151.2),\n",
    "    'Mumbai User': (19, 72.8)\n",
    "}\n",
    "\n",
    "# Calculate latencies\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"GEOGRAPHICAL DISTRIBUTION IMPACT ON LATENCY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{'User Location':20s} | {'Centralized (ms)':>18s} | {'Distributed (ms)':>18s} | {'Improvement':>12s}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "centralized_latencies = []\n",
    "distributed_latencies = []\n",
    "user_names = []\n",
    "\n",
    "for user_name, user_loc in user_locations.items():\n",
    "    centralized = simulate_latency(user_loc, servers, distributed=False)\n",
    "    distributed = simulate_latency(user_loc, servers, distributed=True)\n",
    "    improvement = ((centralized - distributed) / centralized) * 100\n",
    "    \n",
    "    centralized_latencies.append(centralized)\n",
    "    distributed_latencies.append(distributed)\n",
    "    user_names.append(user_name)\n",
    "    \n",
    "    print(f\"{user_name:20s} | {centralized:18.1f} | {distributed:18.1f} | {improvement:11.1f}%\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Visualize latency comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(user_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, centralized_latencies, width, label='Centralized (US East only)',\n",
    "               color='#E63946', edgecolor='black', linewidth=1.5)\n",
    "bars2 = ax.bar(x + width/2, distributed_latencies, width, label='Distributed (Nearest Server)',\n",
    "               color='#06A77D', edgecolor='black', linewidth=1.5)\n",
    "\n",
    "ax.set_ylabel('Latency (milliseconds)', fontsize=12)\n",
    "ax.set_title('Impact of Geographical Distribution on Network Latency', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([name.replace(' User', '') for name in user_names], rotation=45, ha='right')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "avg_improvement = np.mean([(c - d) / c * 100 for c, d in zip(centralized_latencies, distributed_latencies)])\n",
    "print(f\"\\nüìà Average latency improvement with distributed servers: {avg_improvement:.1f}%\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Challenges in Distributed Systems\n",
    "\n",
    "### Key Challenges:\n",
    "\n",
    "1. **Avoid Single Point of Failure (SPOF)**\n",
    "2. **Replication**: Maintaining consistent copies of data\n",
    "3. **Availability and Performance**: Trade-offs (CAP theorem)\n",
    "4. **Resource Naming and Addressing**: Finding and accessing resources\n",
    "5. **Binding**: Mapping between system components\n",
    "\n",
    "### 4.1 Single Point of Failure (SPOF) Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class ServiceWithSPOF:\n",
    "    \"\"\"\n",
    "    Simulates a service with a single point of failure.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.critical_component_healthy = True\n",
    "        self.requests_served = 0\n",
    "        self.requests_failed = 0\n",
    "    \n",
    "    def handle_request(self):\n",
    "        if self.critical_component_healthy:\n",
    "            self.requests_served += 1\n",
    "            return True\n",
    "        else:\n",
    "            self.requests_failed += 1\n",
    "            return False\n",
    "    \n",
    "    def simulate_failure(self):\n",
    "        self.critical_component_healthy = False\n",
    "\n",
    "class ResilientService:\n",
    "    \"\"\"\n",
    "    Simulates a resilient service with redundancy.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_replicas=3):\n",
    "        self.replicas = [True] * num_replicas\n",
    "        self.requests_served = 0\n",
    "        self.requests_failed = 0\n",
    "    \n",
    "    def handle_request(self):\n",
    "        # Service is available if at least one replica is healthy\n",
    "        if any(self.replicas):\n",
    "            self.requests_served += 1\n",
    "            return True\n",
    "        else:\n",
    "            self.requests_failed += 1\n",
    "            return False\n",
    "    \n",
    "    def simulate_random_failures(self, failure_probability=0.1):\n",
    "        for i in range(len(self.replicas)):\n",
    "            if random.random() < failure_probability:\n",
    "                self.replicas[i] = False\n",
    "\n",
    "# Run simulation\n",
    "num_requests = 10000\n",
    "failure_happens_at = num_requests // 2\n",
    "\n",
    "service_spof = ServiceWithSPOF()\n",
    "service_resilient = ResilientService(num_replicas=3)\n",
    "\n",
    "print(\"\\nSimulating 10,000 requests with failure at request 5,000...\\n\")\n",
    "\n",
    "for i in range(num_requests):\n",
    "    # Simulate failure halfway through\n",
    "    if i == failure_happens_at:\n",
    "        service_spof.simulate_failure()\n",
    "        service_resilient.simulate_random_failures(failure_probability=0.3)\n",
    "    \n",
    "    service_spof.handle_request()\n",
    "    service_resilient.handle_request()\n",
    "\n",
    "# Results\n",
    "print(f\"{'Service Type':30s} | {'Served':>10s} | {'Failed':>10s} | {'Success Rate':>15s}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "spof_success = (service_spof.requests_served / num_requests) * 100\n",
    "resilient_success = (service_resilient.requests_served / num_requests) * 100\n",
    "\n",
    "print(f\"{'Service with SPOF':30s} | {service_spof.requests_served:10,d} | {service_spof.requests_failed:10,d} | {spof_success:14.2f}%\")\n",
    "print(f\"{'Resilient Service (3 replicas)':30s} | {service_resilient.requests_served:10,d} | {service_resilient.requests_failed:10,d} | {resilient_success:14.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Resilient service maintained {resilient_success:.1f}% availability despite failures!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tightly-Coupled vs Loosely-Coupled Systems\n",
    "\n",
    "### 5.1 Tightly-Coupled Systems (Parallel Processing)\n",
    "\n",
    "**Characteristics**:\n",
    "- Processors physically part of same computer\n",
    "- Connected by high-speed backplane bus or on same motherboard/chip\n",
    "- Shared clock (synchronization possible)\n",
    "- Shared memory (fast inter-processor communication)\n",
    "- Examples: Multi-core CPUs (2-64 cores)\n",
    "\n",
    "**Advantages**:\n",
    "- Fast communication\n",
    "- Easier synchronization\n",
    "- Simple programming model\n",
    "\n",
    "**Disadvantages**:\n",
    "- Fixed architecture\n",
    "- Expensive\n",
    "- Limited scalability\n",
    "\n",
    "### 5.2 Loosely-Coupled Systems (Distributed Computing)\n",
    "\n",
    "**Characteristics**:\n",
    "- Processors in separate computers\n",
    "- Connected by network technology\n",
    "- Each computer has its own clock (loose synchronization needed)\n",
    "- Separate memory (message passing for communication)\n",
    "- Heterogeneous (different OS, hardware)\n",
    "- Autonomous nodes\n",
    "\n",
    "**Advantages**:\n",
    "- Scalable\n",
    "- Cost-effective (commodity hardware)\n",
    "- Flexible growth\n",
    "- Geographical distribution\n",
    "\n",
    "**Disadvantages**:\n",
    "- Complex synchronization\n",
    "- Network overhead\n",
    "- Harder to program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Tightly-coupled architecture\n",
    "ax1 = axes[0, 0]\n",
    "ax1.set_xlim(0, 10)\n",
    "ax1.set_ylim(0, 10)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Tightly-Coupled System\\n(Shared Memory Multiprocessor)', \n",
    "              fontsize=12, fontweight='bold')\n",
    "\n",
    "# Shared memory\n",
    "memory = patches.Rectangle((2, 7), 6, 1.5, edgecolor='#2E86AB', \n",
    "                           facecolor='#A8DADC', linewidth=2)\n",
    "ax1.add_patch(memory)\n",
    "ax1.text(5, 7.75, 'Shared Memory', ha='center', va='center', \n",
    "         fontsize=10, fontweight='bold')\n",
    "\n",
    "# CPUs\n",
    "cpu_positions = [2.5, 4, 5.5, 7]\n",
    "for i, x in enumerate(cpu_positions):\n",
    "    cpu = patches.Rectangle((x, 4), 1, 1.5, edgecolor='#E63946',\n",
    "                           facecolor='#FFB4A2', linewidth=2)\n",
    "    ax1.add_patch(cpu)\n",
    "    ax1.text(x + 0.5, 4.75, f'CPU\\n{i}', ha='center', va='center', fontsize=9)\n",
    "    # Connection to memory\n",
    "    ax1.arrow(x + 0.5, 5.6, 0, 1.2, head_width=0.15, head_length=0.1, \n",
    "             fc='black', ec='black', linewidth=1.5)\n",
    "\n",
    "# Bus\n",
    "ax1.plot([1.5, 8.5], [3.5, 3.5], 'k-', linewidth=3)\n",
    "ax1.text(5, 3, 'High-Speed Bus', ha='center', fontsize=9, style='italic')\n",
    "\n",
    "# Clock\n",
    "clock = patches.Circle((5, 1.5), 0.5, edgecolor='black', facecolor='#F1FAEE', linewidth=2)\n",
    "ax1.add_patch(clock)\n",
    "ax1.text(5, 1.5, 'CLK', ha='center', va='center', fontsize=8, fontweight='bold')\n",
    "ax1.text(5, 0.5, 'Shared Clock', ha='center', fontsize=9)\n",
    "\n",
    "# Loosely-coupled architecture\n",
    "ax2 = axes[0, 1]\n",
    "ax2.set_xlim(0, 10)\n",
    "ax2.set_ylim(0, 10)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Loosely-Coupled System\\n(Distributed Network)', \n",
    "              fontsize=12, fontweight='bold')\n",
    "\n",
    "# Network cloud\n",
    "network = patches.Ellipse((5, 5), 4, 2.5, edgecolor='#06A77D', \n",
    "                         facecolor='#D4F1F4', linewidth=2)\n",
    "ax2.add_patch(network)\n",
    "ax2.text(5, 5, 'Network', ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Nodes with separate memory and clock\n",
    "node_positions = [(2, 8.5), (8, 8.5), (2, 1.5), (8, 1.5)]\n",
    "for i, (x, y) in enumerate(node_positions):\n",
    "    # Node box\n",
    "    node = patches.FancyBboxPatch((x-0.7, y-0.6), 1.4, 1.2, \n",
    "                                  boxstyle=\"round,pad=0.05\",\n",
    "                                  edgecolor='#E63946', facecolor='#FFE5E5', linewidth=2)\n",
    "    ax2.add_patch(node)\n",
    "    ax2.text(x, y + 0.2, f'Node {i}', ha='center', fontsize=9, fontweight='bold')\n",
    "    ax2.text(x, y - 0.2, 'Mem+CLK', ha='center', fontsize=7)\n",
    "    \n",
    "    # Connection to network\n",
    "    if y > 5:\n",
    "        ax2.plot([x, x], [y - 0.6, 6.5], 'k--', linewidth=1.5, alpha=0.5)\n",
    "    else:\n",
    "        ax2.plot([x, x], [y + 0.6, 3.5], 'k--', linewidth=1.5, alpha=0.5)\n",
    "\n",
    "# Performance comparison\n",
    "ax3 = axes[1, 0]\n",
    "categories = ['Communication\\nSpeed', 'Scalability', 'Cost\\nEfficiency', 'Fault\\nTolerance']\n",
    "tight_scores = [9, 3, 2, 4]\n",
    "loose_scores = [4, 9, 9, 8]\n",
    "\n",
    "x_pos = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax3.bar(x_pos - width/2, tight_scores, width, label='Tightly-Coupled',\n",
    "               color='#FFB4A2', edgecolor='black')\n",
    "bars2 = ax3.bar(x_pos + width/2, loose_scores, width, label='Loosely-Coupled',\n",
    "               color='#06A77D', edgecolor='black')\n",
    "\n",
    "ax3.set_ylabel('Score (0-10)', fontsize=10)\n",
    "ax3.set_title('Performance Comparison', fontsize=12, fontweight='bold')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(categories, fontsize=9)\n",
    "ax3.set_ylim(0, 10)\n",
    "ax3.legend(fontsize=9)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Use cases\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "ax4.set_title('Typical Use Cases', fontsize=12, fontweight='bold')\n",
    "\n",
    "tight_uses = [\n",
    "    \"‚Ä¢ Scientific simulations\",\n",
    "    \"‚Ä¢ Real-time data processing\",\n",
    "    \"‚Ä¢ High-performance computing\",\n",
    "    \"‚Ä¢ Shared-memory algorithms\"\n",
    "]\n",
    "\n",
    "loose_uses = [\n",
    "    \"‚Ä¢ Web services\",\n",
    "    \"‚Ä¢ Cloud computing\",\n",
    "    \"‚Ä¢ Big data processing\",\n",
    "    \"‚Ä¢ Microservices architecture\"\n",
    "]\n",
    "\n",
    "ax4.text(0.1, 0.8, 'Tightly-Coupled:', fontsize=11, fontweight='bold', color='#E63946')\n",
    "ax4.text(0.1, 0.6, '\\n'.join(tight_uses), fontsize=9, verticalalignment='top')\n",
    "\n",
    "ax4.text(0.1, 0.4, 'Loosely-Coupled:', fontsize=11, fontweight='bold', color='#06A77D')\n",
    "ax4.text(0.1, 0.2, '\\n'.join(loose_uses), fontsize=9, verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exercises\n",
    "\n",
    "### Exercise 1: Analyze a Distributed System\n",
    "\n",
    "**Task**: Research a real-world distributed system (e.g., Netflix, Amazon AWS, Google Search) and analyze:\n",
    "\n",
    "1. What components are distributed?\n",
    "2. What benefits does distribution provide?\n",
    "3. What challenges does the system face?\n",
    "4. Is it tightly-coupled or loosely-coupled?\n",
    "\n",
    "Write your analysis below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Analysis Here**:\n",
    "\n",
    "System chosen: ________________\n",
    "\n",
    "1. Distributed components:\n",
    "   -\n",
    "   -\n",
    "\n",
    "2. Benefits:\n",
    "   -\n",
    "   -\n",
    "\n",
    "3. Challenges:\n",
    "   -\n",
    "   -\n",
    "\n",
    "4. Architecture type: ________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Implement CAP Theorem Simulation\n",
    "\n",
    "**Task**: The CAP theorem states that a distributed system can only guarantee 2 out of 3 properties:\n",
    "- **C**onsistency\n",
    "- **A**vailability  \n",
    "- **P**artition tolerance\n",
    "\n",
    "Implement a simulation that demonstrates this trade-off.\n",
    "\n",
    "**Hints**:\n",
    "- Create a distributed key-value store with 3 replicas\n",
    "- Simulate network partitions\n",
    "- Show the trade-off between consistency and availability during partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class DistributedKeyValueStore:\n",
    "    \"\"\"\n",
    "    Simulates a distributed key-value store.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_replicas=3):\n",
    "        # TODO: Initialize replicas\n",
    "        pass\n",
    "    \n",
    "    def write(self, key, value, consistency_level='strong'):\n",
    "        \"\"\"\n",
    "        Write operation with configurable consistency.\n",
    "        \n",
    "        consistency_level:\n",
    "        - 'strong': Wait for all replicas (CP)\n",
    "        - 'eventual': Write to one replica, propagate later (AP)\n",
    "        \"\"\"\n",
    "        # TODO: Implement write with consistency guarantees\n",
    "        pass\n",
    "    \n",
    "    def read(self, key, consistency_level='strong'):\n",
    "        \"\"\"\n",
    "        Read operation with configurable consistency.\n",
    "        \"\"\"\n",
    "        # TODO: Implement read with consistency guarantees\n",
    "        pass\n",
    "    \n",
    "    def simulate_partition(self, partition_nodes):\n",
    "        \"\"\"\n",
    "        Simulate network partition.\n",
    "        \"\"\"\n",
    "        # TODO: Implement partition simulation\n",
    "        pass\n",
    "\n",
    "# TODO: Test CAP theorem scenarios\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Latency vs Throughput Trade-off\n",
    "\n",
    "**Task**: Implement a simulation that demonstrates the trade-off between latency and throughput in distributed systems.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create a message queue system\n",
    "2. Implement batch processing vs real-time processing\n",
    "3. Measure latency and throughput for different batch sizes\n",
    "4. Visualize the trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class MessageQueueSystem:\n",
    "    def __init__(self, batch_size=1):\n",
    "        \"\"\"\n",
    "        Initialize message queue.\n",
    "        \n",
    "        batch_size: Number of messages to process together\n",
    "                   1 = real-time, >1 = batched\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.queue = []\n",
    "        self.latencies = []\n",
    "        self.throughput = 0\n",
    "    \n",
    "    def send_message(self, message):\n",
    "        # TODO: Implement message sending\n",
    "        pass\n",
    "    \n",
    "    def process_batch(self):\n",
    "        # TODO: Implement batch processing\n",
    "        pass\n",
    "\n",
    "# TODO: Test with different batch sizes and visualize results\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "In this module, you have learned:\n",
    "\n",
    "‚úÖ **Definition** of distributed systems and their key characteristics  \n",
    "‚úÖ **Differences** between traditional and distributed architectures  \n",
    "‚úÖ **Benefits** of distributed systems:\n",
    "   - Scalability (horizontal vs vertical)\n",
    "   - Reliability and fault tolerance\n",
    "   - Performance through parallelism\n",
    "   - Geographical distribution\n",
    "\n",
    "‚úÖ **Challenges** in building distributed systems:\n",
    "   - Single points of failure\n",
    "   - Replication and consistency\n",
    "   - Resource naming and addressing\n",
    "\n",
    "‚úÖ **Architecture types**:\n",
    "   - Tightly-coupled (shared memory, multiprocessor)\n",
    "   - Loosely-coupled (message passing, distributed)\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Distribution is about trade-offs**: No single solution is best for all scenarios\n",
    "2. **Scalability types matter**: Horizontal scaling is more cost-effective long-term\n",
    "3. **Replication improves reliability**: But adds complexity\n",
    "4. **Location matters**: Geographical distribution reduces latency\n",
    "5. **CAP theorem**: You can't have all three (Consistency, Availability, Partition tolerance)\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Module 02**, we will explore:\n",
    "- Distribution system architectures (Client-Server, Peer-to-Peer, Workstation-Server, Processor Pool)\n",
    "- Transparency in distributed systems (8 types)\n",
    "- Design principles for distributed systems\n",
    "\n",
    "---\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- Tanenbaum & Van Steen: \"Distributed Systems: Principles and Paradigms\"\n",
    "- [CAP Theorem Explained](https://www.ibm.com/cloud/learn/cap-theorem)\n",
    "- [Facebook's Maelstrom System](https://engineering.fb.com/2018/06/20/core-data/maelstrom/)\n",
    "- [Scale-Out vs Scale-Up](https://www.mongodb.com/basics/scaling)\n",
    "\n",
    "**Course**: BMCS3003 - Distributed Systems and Parallel Computing  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
